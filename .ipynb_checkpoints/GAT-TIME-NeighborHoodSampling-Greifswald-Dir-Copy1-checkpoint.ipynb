{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11a4ca8",
   "metadata": {},
   "source": [
    "## GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c344596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Assessable data are 528101 cases and 1015074 CBCs\n",
      "Control data are 527038 cases and 1013548 CBCs\n",
      "Sepsis data are 1488 cases and 1526 CBCs\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "Testing: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 365794, Sepsis: 490\n",
      "Assessable data are 180494 cases and 366284 CBCs\n",
      "Control data are 180157 cases and 365794 CBCs\n",
      "Sepsis data are 472 cases and 490 CBCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 437629, Sepsis: 448\n",
      "Assessable data are 157922 cases and 438077 CBCs\n",
      "Control data are 180157 cases and 437629 CBCs\n",
      "Sepsis data are 438 cases and 448 CBCs\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import torch\n",
    "\n",
    "data = pd.read_csv(r\"extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1591ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((data_analysis.get_training_data(), data_analysis.get_testing_data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3297def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_Id = data[\"Id\"].unique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42e4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_data = data_analysis.get_gw_testing_data().copy(deep=True)\n",
    "gw_data = gw_data.assign(Id=lambda x: x.Id + max_Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c81fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((data, gw_data))\n",
    "data = cudf.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fedac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6d2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = data[\"Id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da8d8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6556e31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          665587\n",
       "1          665588\n",
       "2          665589\n",
       "3          665590\n",
       "4          665591\n",
       "            ...  \n",
       "1819430    665580\n",
       "1819431    665581\n",
       "1819432    665582\n",
       "1819433    665585\n",
       "1819434    665586\n",
       "Name: index, Length: 1819435, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pop(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4d5473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values([\"Id\", \"Time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06361768",
   "metadata": {},
   "source": [
    "## Creating edge index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cbb0678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cupy as cp\n",
    "# import time\n",
    "\n",
    "# source_edge_index = np.array([], dtype= cp.int32)\n",
    "# target_edge_index = np.array([], dtype= cp.int32)\n",
    "\n",
    "# start = time.time()\n",
    "# j = 0\n",
    "# for Id, group in data.groupby(\"Id\"):\n",
    "#     indices = group.index\n",
    "#     offset = indices[0]\n",
    "#     num_nodes = len(indices)\n",
    "#     edge_index = torch.zeros((2, sum(range(num_nodes + 1))), dtype=torch.long)+offset\n",
    "\n",
    "#     ## Self edges\n",
    "#     edge_index[:, 0:num_nodes] = (torch.arange(num_nodes) + offset).view(1, -1)\n",
    "#     idx = num_nodes\n",
    "#     for i in range(1, num_nodes):\n",
    "#         edge_index[1, idx:idx + i] = i+offset\n",
    "#         edge_index[0, idx:idx + i] = torch.arange(i)+offset\n",
    "#         idx += i\n",
    "    \n",
    "#     source_edge_index = np.concatenate((source_edge_index, edge_index[0, :].numpy()))\n",
    "#     target_edge_index = np.concatenate((target_edge_index, edge_index[1, :].numpy()))\n",
    "#     j+=1\n",
    "#     if j % 1000 == 0:\n",
    "#         print(f\"{str(j / unique_ids.shape[0] * 100)} %\")\n",
    "\n",
    "# print(time.time() - start )\n",
    "# print(source_edge_index.shape)\n",
    "# print(target_edge_index.shape)\n",
    "\n",
    "# edge_index = np.asarray([np.asarray(source_edge_index), np.asarray(target_edge_index)])\n",
    "# edge_index = torch.tensor(edge_index)\n",
    "# pd.DataFrame(edge_index.numpy().transpose()).to_csv(\"dir_edge_index_sorted_ids_w_gw_corr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a95826d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "756329ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "edge_index = torch.tensor(pd.read_csv(\"dir_edge_index_sorted_ids_w_gw_corr.csv\", header=None, skiprows=1).values.transpose(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "420009b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "508f7a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Center</th>\n",
       "      <th>Set</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Time</th>\n",
       "      <th>TargetIcu</th>\n",
       "      <th>SecToIcu</th>\n",
       "      <th>CRP</th>\n",
       "      <th>HGB</th>\n",
       "      <th>MCV</th>\n",
       "      <th>PCT</th>\n",
       "      <th>PLT</th>\n",
       "      <th>RBC</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>AMB</td>\n",
       "      <td>1</td>\n",
       "      <td>3884100.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5.2</td>\n",
       "      <td>102.3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>208.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>AMB</td>\n",
       "      <td>1</td>\n",
       "      <td>3277380.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.87</td>\n",
       "      <td>5.3</td>\n",
       "      <td>103.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>194.0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>AMB</td>\n",
       "      <td>1</td>\n",
       "      <td>2766900.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14.15</td>\n",
       "      <td>5.6</td>\n",
       "      <td>99.6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>230.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>10.4</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>AMB</td>\n",
       "      <td>1</td>\n",
       "      <td>2073600.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.94</td>\n",
       "      <td>5.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>346.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>AMB</td>\n",
       "      <td>1</td>\n",
       "      <td>1474140.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>27.37</td>\n",
       "      <td>5.5</td>\n",
       "      <td>102.5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>413.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>AMB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.43</td>\n",
       "      <td>4.2</td>\n",
       "      <td>103.3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>329.0</td>\n",
       "      <td>2.11</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Age Sex Diagnosis   Center       Set Sender  Episode       Time  \\\n",
       "7    8   64   W   Control  Leipzig  Training    AMB        1  3884100.0   \n",
       "8    8   64   W   Control  Leipzig  Training    AMB        1  3277380.0   \n",
       "9    8   64   W   Control  Leipzig  Training    AMB        1  2766900.0   \n",
       "10   8   64   W   Control  Leipzig  Training    AMB        1  2073600.0   \n",
       "11   8   64   W   Control  Leipzig  Training    AMB        1  1474140.0   \n",
       "12   8   64   W   Control  Leipzig  Training    AMB        1        0.0   \n",
       "\n",
       "   TargetIcu SecToIcu    CRP  HGB    MCV   PCT    PLT   RBC   WBC    Label  \n",
       "7       <NA>     <NA>   1.30  5.2  102.3  <NA>  208.0  2.56   5.5  Control  \n",
       "8       <NA>     <NA>   5.87  5.3  103.0  <NA>  194.0  2.71   7.2  Control  \n",
       "9       <NA>     <NA>  14.15  5.6   99.6  <NA>  230.0  2.82  10.4  Control  \n",
       "10      <NA>     <NA>   2.94  5.1  100.0  <NA>  346.0  2.62   5.6  Control  \n",
       "11      <NA>     <NA>  27.37  5.5  102.5  <NA>  413.0  2.77   6.4  Control  \n",
       "12      <NA>     <NA>  37.43  4.2  103.3  <NA>  329.0  2.11   4.3  Control  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Id\"] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaf6f634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, 10, 11, 12,  7,  7,  8,  7,  8,  9],\n",
       "        [ 9, 10, 11, 12,  8,  9,  9, 10, 10, 10]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index[:, 10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b446b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Constants import SEX_CATEGORY_COLUMN_NAME, SEX_COLUMN_NAME, FEATURES\n",
    "data[SEX_CATEGORY_COLUMN_NAME] = data.loc[:, SEX_COLUMN_NAME] ==\"W\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da53cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[SEX_CATEGORY_COLUMN_NAME] = data[SEX_CATEGORY_COLUMN_NAME].astype(\"int8\")\n",
    "data[\"Label\"] = data[\"Label\"] == \"Sepsis\"\n",
    "data[\"Label\"] = data[\"Label\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3aa4124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getPositionEncoding(seq_len, d = len(FEATURES), n=10000):\n",
    "    P = np.zeros((seq_len, d))\n",
    "    for k in range(seq_len):\n",
    "        for i in np.arange(int(d/2)):\n",
    "            denominator = np.power(n, 2*i/d)\n",
    "            P[k, 2*i] = np.sin(k/denominator)\n",
    "            P[k, 2*i+1] = np.cos(k/denominator)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5b293ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = torch.tensor(data[FEATURES].values.get()).type(torch.float32)\n",
    "y = torch.tensor(data[\"Label\"].values.get()).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7923af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.FeatureImportance import normalize\n",
    "\n",
    "X_features = normalize(X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84390e9",
   "metadata": {},
   "source": [
    "## Creating positional encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5670b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# pos_encodings = None\n",
    "\n",
    "# start = time.time()\n",
    "# i = 0\n",
    "# final_shape = 0\n",
    "# for Id, group in data.groupby(\"Id\"):\n",
    "#     encoding = getPositionEncoding(group.shape[0])\n",
    "# #     sorted_group = group.reset_index().sort_values(\"Time\")\n",
    "# #     encoding = encoding[sorted_group.index.to_numpy()]\n",
    "#     final_shape += group.shape[0]\n",
    "#     pos_encodings = encoding if pos_encodings is None else np.concatenate((pos_encodings, encoding), axis=0)\n",
    "#     i+=1\n",
    "#     if i % 1000 == 0:\n",
    "#         print(f\"{str(i / unique_ids.shape[0] * 100)} %\")\n",
    "\n",
    "# print(pos_encodings.shape[0] == final_shape)\n",
    "# pd.DataFrame(pos_encodings).to_csv(\"pos_encodings_new_w_gw_corr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc415746",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encodings = pd.read_csv(\"pos_encodings_new_w_gw_corr.csv\", header=None, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61943440",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encodings = pos_encodings.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e1f5f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1067, -0.9899,  0.4046,  ...,  0.3607, -0.4256, -0.6549],\n",
       "        [-1.2956, -0.9899,  2.0656,  ...,  2.3851, -1.3951, -0.3717],\n",
       "        [-0.6404,  1.0102,  0.8033,  ...,  0.3729,  0.1943,  0.5042],\n",
       "        ...,\n",
       "        [-0.1490, -0.9899,  1.7334,  ...,  1.6290,  0.0513, -0.0444],\n",
       "        [ 0.0693,  1.0102,  1.4676,  ...,  1.3851,  0.4804,  1.1501],\n",
       "        [ 0.0693,  1.0102,  1.0690,  ...,  0.8973,  0.2102,  0.8493]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ba9f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_features = X_features + pos_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecfc5879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1819435, 7])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37effc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_bool_switch(tensor, ratio = 0.8):\n",
    "    random = np.random.uniform(0, 1 ,tensor.shape[0])\n",
    "    val_ratio_mask = (random >= ratio)\n",
    "    train_ratio_mask = (random < ratio)\n",
    "    val_mask = np.logical_and(tensor.tolist(), val_ratio_mask.tolist())\n",
    "    train_mask = np.logical_and(tensor.tolist(), train_ratio_mask.tolist())\n",
    "    return torch.from_numpy(train_mask).type(torch.bool), torch.from_numpy(val_mask).type(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2ae8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "train_mask_ser = data[\"Set\"] != \"Validation\"\n",
    "train_mask, val_mask = ratio_bool_switch(train_mask_ser.values)\n",
    "test_mask = torch.from_numpy(np.logical_and((data[\"Set\"] == \"Validation\").values.get(), (data[\"Center\"] == \"Leipzig\").values.get())).type(torch.bool)\n",
    "test_gw_mask = torch.from_numpy(np.logical_and((data[\"Set\"] == \"Validation\").values.get(), (data[\"Center\"] == \"Greifswald\").values.get())).type(torch.bool)\n",
    "graph = Data(x=X_new_features, train_mask = train_mask, test_mask=test_mask, val_mask=val_mask, y= y, edge_index=edge_index,\n",
    "             test_gw_mask = test_gw_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "582df19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1819435)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gw_mask.sum() + test_mask.sum()+val_mask.sum()+train_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eee4dd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0,       1,       2,  ..., 1819433, 1819434, 1819433],\n",
       "        [      0,       1,       2,  ..., 1819433, 1819434, 1819434]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03ea4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66aca9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "kwargs = {\n",
    "    \"num_neighbors\":[-1] * 2,\n",
    "    \"batch_size\":50_000\n",
    "}\n",
    "loader = NeighborLoader(\n",
    "    graph,\n",
    "    input_nodes=graph.train_mask,\n",
    "    **kwargs\n",
    ")\n",
    "val_loader = NeighborLoader(\n",
    "    graph,\n",
    "    input_nodes=graph.val_mask,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb2089f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shifted to the device cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# graph = graph.to(device)\n",
    "WEIGHT = torch.tensor([664*4/5])#\n",
    "WEIGHT = WEIGHT.to(device)\n",
    "\n",
    "print(\"Data shifted to the device \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fd1bb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(203118)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.val_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54eb5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, GCNConv,GATv2Conv, GINConv, global_add_pool\n",
    "from torch.nn import Linear\n",
    "import torch\n",
    "from dataAnalysis.Constants import FEATURES\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "from torch.nn import BatchNorm1d as BatchNorm\n",
    "\n",
    "class GraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim = 128, out_channels = 1):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        input_dim = len(FEATURES)      \n",
    "        \n",
    "        HEADS = 5\n",
    "        \n",
    "        conv_1= GATConv(input_dim, hidden_dim,heads=HEADS, add_self_loops = False)\n",
    "        conv_end = GATConv((-1,-1), out_channels,add_self_loops = False)\n",
    "        \n",
    "        self.conv_1 = conv_1\n",
    "        self.conv_end = conv_end\n",
    "        \n",
    "\n",
    "    def forward(self, graph):\n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = x.type(torch.float)\n",
    "        x = self.conv_1(x, edge_index) \n",
    "        x = F.normalize(x, p=2., dim=-1)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv_end(x, edge_index)\n",
    "        return x\n",
    "            \n",
    "    def predict_proba(self, graph, mask):\n",
    "        with torch.inference_mode():\n",
    "            self.eval()\n",
    "            logits = self.forward(graph)\n",
    "            scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "            scores = torch.unsqueeze(scores, 0)\n",
    "            proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "            return torch.transpose(proba_predict, 0, 1)\n",
    "            \n",
    "    def predict(self, graph, mask):\n",
    "        return torch.round(self.predict_proba(graph, mask)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "526044da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm.notebook import tqdm\n",
    "from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, graph):\n",
    "        self.LEARNING_RATE = 3e-4\n",
    "        self.MAX_EPOCHS = 10000 #40000\n",
    "\n",
    "        self.model = GraphNeuralNetwork(hidden_dim = 128, out_channels=1) \n",
    "        self.model = self.model.to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.LEARNING_RATE,betas=(0.9, 0.999), eps=1e-08)\n",
    "        self.graph = graph\n",
    "        \n",
    "        self.last_loss = 0\n",
    "        self.increased_loss = 0\n",
    "        self.BREAKING_THRESHOLD = 5  \n",
    "        self.val_loss = []\n",
    "        self.train_loss = []\n",
    "        self.epochs = self.MAX_EPOCHS\n",
    "        \n",
    "    def change_lr(self, lr):\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g['lr'] = lr\n",
    "    \n",
    "    def validate(self):\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            acc_loss = 0\n",
    "            batch_size = 0\n",
    "            for batch, graph in enumerate(val_loader):\n",
    "                graph = graph.to(device)\n",
    "                out = self.model(graph)\n",
    "                loss = F.binary_cross_entropy_with_logits(torch.squeeze(out), graph.y.type(torch.float32),\n",
    "                                                          pos_weight=WEIGHT)\n",
    "                acc_loss += loss.item()\n",
    "                batch_size += 1\n",
    "            avg_loss = acc_loss / batch_size\n",
    "            self.val_loss.append(avg_loss)\n",
    "            if avg_loss > self.last_loss:\n",
    "                self.increased_loss += 1\n",
    "            else:\n",
    "                self.increased_loss = 0\n",
    "            self.last_loss = avg_loss\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in tqdm(range(self.MAX_EPOCHS)):\n",
    "            acc_loss = 0\n",
    "            batch_size = 0\n",
    "                \n",
    "#             if epoch == 10:\n",
    "#                 self.change_lr(1e-5)\n",
    "#                 self.plot_loss()\n",
    "#                 self.evaluate()\n",
    "#             if epoch == 20:\n",
    "#                 self.change_lr(5e-4)\n",
    "#                 self.plot_loss()\n",
    "#                 self.evaluate()\n",
    "#             if epoch == 30:\n",
    "#                 self.change_lr(1e-4)\n",
    "#                 self.plot_loss()\n",
    "#                 self.evaluate()\n",
    "            for batch, graph in enumerate(loader):\n",
    "                graph = graph.to(device)\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(graph)\n",
    "                loss = F.binary_cross_entropy_with_logits(torch.squeeze(out), graph.y.type(torch.float32),\n",
    "                                                          pos_weight=WEIGHT)\n",
    "                acc_loss += loss.item()\n",
    "                batch_size += 1\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            self.train_loss.append(acc_loss/batch_size)\n",
    "            self.validate() \n",
    "\n",
    "            if self.increased_loss >= self.BREAKING_THRESHOLD:\n",
    "                self.epochs = epoch + 1\n",
    "                print(f\"Breaked at {str(epoch)}\")\n",
    "                break\n",
    "            \n",
    "    def get_model(self):\n",
    "        return self.model    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(range(len(self.train_loss)), self.train_loss, 'g', label='Training loss')\n",
    "        plt.plot(range(len(self.val_loss)), self.val_loss, 'y', label='Validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.model = self.model.cpu()\n",
    "        self.graph = self.graph.cpu()\n",
    "        y_dict = Evaluation.create_y_dict(self.model.predict(self.graph, self.graph.test_mask), self.model.predict_proba(self.graph, self.graph.test_mask) , self.graph.y[self.graph.test_mask])\n",
    "        y_dict_gw = Evaluation.create_y_dict(self.model.predict(self.graph, self.graph.test_gw_mask), self.model.predict_proba(self.graph, self.graph.test_gw_mask) , self.graph.y[self.graph.test_gw_mask])\n",
    "        eval_df = Evaluation.get_df_metrics_from_pred(y_dict, y_dict_gw)\n",
    "        print(eval_df)\n",
    "        self.model = self.model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d129a047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acaf594a61824929aac21b12969a0aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_wrapper \u001b[38;5;241m=\u001b[39m ModelWrapper(graph)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 63\u001b[0m, in \u001b[0;36mModelWrapper.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m             batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#             if epoch == 10:\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#                 self.change_lr(1e-5)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#                 self.plot_loss()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#                 self.plot_loss()\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#                 self.evaluate()\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m batch, graph \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m     64\u001b[0m                 graph \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/base.py:36\u001b[0m, in \u001b[0;36mDataLoaderIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_fn(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_wrapper = ModelWrapper(graph)\n",
    "model_wrapper.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a38932",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from dataAnalysis.Metrics import Evaluation\n",
    "train_times = []\n",
    "eval_int_times = []\n",
    "eval_ext_times = []\n",
    "models= []\n",
    "dfs = []\n",
    "for i in range(100-32):\n",
    "    graph = graph.to(device)\n",
    "    model_wrapper = ModelWrapper(graph)\n",
    "    \n",
    "    start = time.time()\n",
    "    model_wrapper.train()\n",
    "    print(start -time.time())\n",
    "    train_times.append(start -time.time())\n",
    "    \n",
    "    model = model_wrapper.get_model()\n",
    "    graph = graph.cpu()\n",
    "    model = model.cpu()\n",
    "    models.append(model)\n",
    "      \n",
    "    start = time.time()\n",
    "    y_dict = Evaluation.create_y_dict(model.predict(graph, test_mask), model.predict_proba(graph, test_mask) , graph.y[test_mask])\n",
    "    eval_int_times.append(time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    y_dict_gw = Evaluation.create_y_dict(model.predict(graph, test_gw_mask), model.predict_proba(graph, test_gw_mask) , graph.y[test_gw_mask])\n",
    "    eval_ext_times.append(time.time() - start)\n",
    "    df = Evaluation.get_df_metrics_from_pred(y_dict, y_dict_gw)\n",
    "    print(df)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_wrapper.get_model()\n",
    "graph = graph.cpu()\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892ce7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"directed_gat_corr.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "y_dict = Evaluation.create_y_dict(model.predict(graph, test_mask), model.predict_proba(graph, test_mask) , graph.y[test_mask])\n",
    "y_dict_gw = Evaluation.create_y_dict(model.predict(graph, test_gw_mask), model.predict_proba(graph, test_gw_mask) , graph.y[test_gw_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "Evaluation.plot_confusion_matrix_from_pred(model.predict(graph, test_mask), graph.y[test_mask])\n",
    "Evaluation.plot_confusion_matrix_from_pred(model.predict(graph, test_gw_mask), graph.y[test_gw_mask])\n",
    "Evaluation.get_df_metrics_from_pred(y_dict, y_dict_gw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e35162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "sound_file = './finish_sound.mp3'\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69310bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO:\n",
    "# - change weight\n",
    "# - gradients as features\n",
    "# - different learning rate and number of layers\n",
    "# - general architecture- less neurons but linear layer before and after convs? \n",
    "#       -adding hidden layers with each others for more stable training (guaranteed only when hidden dim is euqal betwene layers)\n",
    "# - GATv2\n",
    "# - MIMIC und Greifswald\n",
    "# - more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d262420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for i in range(10000):\n",
    "    time.sleep(60)\n",
    "    print(\"Sleeping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3a608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
