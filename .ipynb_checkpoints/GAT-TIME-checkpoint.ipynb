{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77186db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "sbc = pd.read_csv(\"extdata/sbcdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba680ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811e3de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def apply(group):\n",
    "#     print(np.any(group[\"Diagnosis\"].str.contains(\"Sepsis\").values))\n",
    "#     if group.shape[0] < 2 or not np.any(group[\"Diagnosis\"].str.contains(\"Sepsis\").values):\n",
    "#         return\n",
    "#     group = group.sort_values(\"Time\")\n",
    "#     plt.plot(group[\"Time\"], group[\"WBC\"])\n",
    "#     plt.show()\n",
    "    return group.shape[0]\n",
    "\n",
    "sbc_grouped = sbc.groupby(\"Id\").apply(apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de071de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbc_grouped = sbc.groupby(\"Id\").filter(lambda x: x.shape[0] >= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f785be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbc_grouped[sbc_grouped[\"Diagnosis\"] == \"Sepsis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbc_ones = sbc.groupby(\"Id\").filter(lambda x: x.shape[0] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d70bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbc_ones_sepsis = sbc_ones.loc[sbc_ones[\"Diagnosis\"] == \"Sepsis\", :]\n",
    "sbc_ones_sepsis_val = sbc_ones_sepsis.loc[sbc_ones[\"Set\"] == \"Validation\", :]\n",
    "sbc_ones_sepsis_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbc.groupby(\"Id\").apply(lambda x: x.loc[x[\"Diagnosis\"] == \"Sepsis\", :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388d3e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Assessable data are 528101 cases and 1015074 CBCs\n",
      "Control data are 527038 cases and 1013548 CBCs\n",
      "Sepsis data are 1488 cases and 1526 CBCs\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "Testing: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 365794, Sepsis: 490\n",
      "Assessable data are 180494 cases and 366284 CBCs\n",
      "Control data are 180157 cases and 365794 CBCs\n",
      "Sepsis data are 472 cases and 490 CBCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 437629, Sepsis: 448\n",
      "Assessable data are 157922 cases and 438077 CBCs\n",
      "Control data are 180157 cases and 437629 CBCs\n",
      "Sepsis data are 438 cases and 448 CBCs\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73b6feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataAnalysis.Constants import FEATURES_IN_TABLE\n",
    "import numpy as np\n",
    "\n",
    "train_data = data_analysis.get_training_data()\n",
    "test_data = data_analysis.get_testing_data()\n",
    "test_gw_data = data_analysis.get_gw_testing_data()\n",
    "WINDOW_SIZE = 5\n",
    "\n",
    "def get_seq(data):\n",
    "    data[\"Label\"] = data.loc[:, \"Label\"] == \"Sepsis\"\n",
    "    data[\"Sex\"] = data.loc[:, \"Sex\"] == \"W\"\n",
    "    data = data.astype({'Sex': 'int8', \"Label\": \"int8\"})\n",
    "    features = []\n",
    "    labels = []\n",
    "    for identifier, group in data.groupby([\"Id\",\"Center\"]):\n",
    "        sorted_group = group.sort_values(\"Time\", ascending=False)\n",
    "        if sorted_group.shape[0] < WINDOW_SIZE:\n",
    "            first_element = sorted_group.iloc[0, :]\n",
    "            first_features = np.expand_dims(first_element.loc[FEATURES_IN_TABLE].values, 0)\n",
    "            first_seq = np.repeat(first_features, WINDOW_SIZE - sorted_group.shape[0], axis= 0)\n",
    "            second_seq = sorted_group.loc[:, FEATURES_IN_TABLE].values\n",
    "            features.append(np.concatenate((first_seq, second_seq), axis = 0))\n",
    "            labels.append(sorted_group.iloc[-1][\"Label\"])\n",
    "        if sorted_group.shape[0] >= WINDOW_SIZE:\n",
    "            last_five_elements = sorted_group.iloc[-5:, :]\n",
    "            last_five_features = last_five_elements.loc[:, FEATURES_IN_TABLE].values\n",
    "            features.append(last_five_features)\n",
    "            labels.append(sorted_group.iloc[-1][\"Label\"])\n",
    "    return features, labels\n",
    "            \n",
    "    \n",
    "train_features, train_labels = get_seq(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "356f4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int, dropout: float = 0.0, max_len: int = 5):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, input_dim, 2) * (-math.log(10000.0) / input_dim))\n",
    "        pe = torch.zeros(max_len, 1, input_dim)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        print(x)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        print(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Transformer_Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(input_dim)\n",
    "        encoder_layers = TransformerEncoderLayer(input_dim, num_heads, hidden_dim, 0)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, 2)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18b3df30",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (7) must match the existing size (4) at non-singleton dimension 2.  Target sizes: [5, 1, 7].  Tensor sizes: [5, 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      6\u001b[0m LEARNINLEARNING_RATERATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3e-2\u001b[39m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFEATURES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparams, lr \u001b[38;5;241m=\u001b[39m LEARNING_RATE)\n\u001b[1;32m     10\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss(pos_weight\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m10\u001b[39m))\n",
      "Cell \u001b[0;32mIn[35], line 38\u001b[0m, in \u001b[0;36mTransformer_Model.__init__\u001b[0;34m(self, input_dim, hidden_dim, output_dim, num_heads)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim \u001b[38;5;241m=\u001b[39m output_dim\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads \u001b[38;5;241m=\u001b[39m num_heads\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mPositionalEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m encoder_layers \u001b[38;5;241m=\u001b[39m TransformerEncoderLayer(input_dim, num_heads, hidden_dim, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder \u001b[38;5;241m=\u001b[39m TransformerEncoder(encoder_layers, \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[35], line 16\u001b[0m, in \u001b[0;36mPositionalEncoding.__init__\u001b[0;34m(self, input_dim, dropout, max_len)\u001b[0m\n\u001b[1;32m     14\u001b[0m div_term \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, input_dim, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m10000.0\u001b[39m) \u001b[38;5;241m/\u001b[39m input_dim))\n\u001b[1;32m     15\u001b[0m pe \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(max_len, \u001b[38;5;241m1\u001b[39m, input_dim)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mpe\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msin(position \u001b[38;5;241m*\u001b[39m div_term)\n\u001b[1;32m     17\u001b[0m pe[:, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcos(position \u001b[38;5;241m*\u001b[39m div_term)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpe\u001b[39m\u001b[38;5;124m'\u001b[39m, pe)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (7) must match the existing size (4) at non-singleton dimension 2.  Target sizes: [5, 1, 7].  Tensor sizes: [5, 4]"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from dataAnalysis.Constants import FEATURES\n",
    "\n",
    "EPOCHS = 100\n",
    "LEARNINLEARNING_RATERATE = 3e-2\n",
    "\n",
    "model = Transformer_Model(input_dim = len(FEATURES),hidden_dim = 128, output_dim = 1, num_heads = 1)\n",
    "optimizer = Adam(model.params, lr = LEARNING_RATE)\n",
    "loss_fn = BCEWithLogitsLoss(pos_weight=torch.tensor(10))\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    out = model(X_train)\n",
    "    loss = loss_fn(out.unsqueeze(1), y_train)\n",
    "    print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d4e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_646930/4032326726.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(0).to(device)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Generate sample time series data\n",
    "data = torch.tensor(train_features, dtype=torch.float32) #np.random.randn(10000, 5, 7)  # Shape: [10000, 5, 7]\n",
    "labels = torch.tensor(train_labels) #np.random.randint(2, size=10000)  # Binary labels\n",
    "\n",
    "# Convert data and labels to PyTorch tensors\n",
    "data_tensor = data #torch.tensor(data, dtype=torch.float32)\n",
    "labels_tensor = labels #torch.tensor(labels)\n",
    "\n",
    "# Create a custom dataset\n",
    "dataset = TensorDataset(data_tensor, labels_tensor)\n",
    "\n",
    "# Define the TransformerEncoder class\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, dropout, max_len=5000):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.positional_encoding = PositionalEncoding(hidden_dim, max_len=max_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_heads, dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.classifier = nn.Linear(hidden_dim, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = x.permute(1, 0, 2)  # Adjust the dimensions for the Transformer\n",
    "        output = self.transformer_encoder(x)\n",
    "        output = output.mean(dim=0)  # Average the encoder outputs over the sequence length\n",
    "        output = self.classifier(output).squeeze(1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model\n",
    "input_dim = 7\n",
    "hidden_dim = 64\n",
    "num_layers = 1\n",
    "num_heads = 1\n",
    "dropout = 0.1\n",
    "max_len = data.shape[1]\n",
    "model = TransformerEncoder(input_dim, hidden_dim, num_layers, num_heads, dropout, max_len=max_len).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        inputs, labels = dataset[i]\n",
    "        inputs = inputs.unsqueeze(0).to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    average_loss = total_loss / len(dataset)\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")\n",
    "\n",
    "# Evaluation (optional)\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    total_correct = 0\n",
    "    for i in range(len(dataset)):\n",
    "        inputs, labels = dataset[i]\n",
    "        inputs = inputs.unsqueeze(0).to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        predicted_labels = (outputs >= 0.5).float()\n",
    "\n",
    "        total_correct += (predicted_labels.squeeze() == labels.squeeze()).sum().item()\n",
    "\n",
    "    accuracy = total_correct / len(dataset)\n",
    "    print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d32ab41f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m60\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(60):\n",
    "    print(\"Sleeping\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a4ca8",
   "metadata": {},
   "source": [
    "## GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8fe769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Assessable data are 528101 cases and 1015074 CBCs\n",
      "Control data are 527038 cases and 1013548 CBCs\n",
      "Sepsis data are 1488 cases and 1526 CBCs\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "Testing: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 365794, Sepsis: 490\n",
      "Assessable data are 180494 cases and 366284 CBCs\n",
      "Control data are 180157 cases and 365794 CBCs\n",
      "Sepsis data are 472 cases and 490 CBCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 437629, Sepsis: 448\n",
      "Assessable data are 157922 cases and 438077 CBCs\n",
      "Control data are 180157 cases and 437629 CBCs\n",
      "Sepsis data are 438 cases and 448 CBCs\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c344596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Assessable data are 528101 cases and 1015074 CBCs\n",
      "Control data are 527038 cases and 1013548 CBCs\n",
      "Sepsis data are 1488 cases and 1526 CBCs\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "Testing: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 365794, Sepsis: 490\n",
      "Assessable data are 180494 cases and 366284 CBCs\n",
      "Control data are 180157 cases and 365794 CBCs\n",
      "Sepsis data are 472 cases and 490 CBCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 437629, Sepsis: 448\n",
      "Assessable data are 157922 cases and 438077 CBCs\n",
      "Control data are 180157 cases and 437629 CBCs\n",
      "Sepsis data are 438 cases and 448 CBCs\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "import cudf\n",
    "\n",
    "data = pd.read_csv(r\"extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1591ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((data_analysis.get_training_data(), data_analysis.get_testing_data()))\n",
    "data = cudf.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dfc0fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/cudf/core/groupby/groupby.py:1191: RuntimeWarning: GroupBy.apply() performance scales poorly with number of groups. Got 708595 groups. Some functions may perform better by passing engine='jit'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([601702,   5962, 756765, 165039,  68017, 832715, 889231, 264347,\n",
       "            321489, 446789,\n",
       "            ...\n",
       "             25563,  62523, 187771,  48581, 151065, 206792, 214540, 222910,\n",
       "            319258, 364398],\n",
       "           dtype='int64', length=1381358)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby([\"Id\", \"Center\"]).apply(lambda x: x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49456a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = data[\"Id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b831b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "0.3863487243652344\n",
      "0.1411243375976404 %\n",
      "8.447920322418213\n",
      "0.2822486751952808 %\n",
      "15.594621896743774\n",
      "0.4233730127929212 %\n",
      "22.813016653060913\n",
      "0.5644973503905616 %\n",
      "30.06106734275818\n",
      "0.705621687988202 %\n",
      "37.329527854919434\n",
      "0.8467460255858424 %\n",
      "44.63788938522339\n",
      "0.9878703631834829 %\n",
      "52.003878116607666\n",
      "1.1289947007811232 %\n",
      "59.41252279281616\n",
      "1.2701190383787637 %\n",
      "66.85702896118164\n",
      "1.411243375976404 %\n",
      "74.34396123886108\n",
      "1.5523677135740444 %\n",
      "81.85710644721985\n",
      "1.6934920511716849 %\n",
      "89.3711051940918\n",
      "1.8346163887693252 %\n",
      "96.92373657226562\n",
      "1.9757407263669657 %\n",
      "104.50927758216858\n",
      "2.116865063964606 %\n",
      "112.10162711143494\n",
      "2.2579894015622464 %\n",
      "119.73893761634827\n",
      "2.399113739159887 %\n",
      "127.37569284439087\n",
      "2.5402380767575274 %\n",
      "135.02311968803406\n",
      "2.6813624143551675 %\n",
      "142.7527310848236\n",
      "2.822486751952808 %\n",
      "150.48534655570984\n",
      "2.963611089550448 %\n",
      "158.2176558971405\n",
      "3.1047354271480887 %\n",
      "166.01249814033508\n",
      "3.2458597647457297 %\n",
      "173.86647725105286\n",
      "3.3869841023433698 %\n",
      "181.71287417411804\n",
      "3.52810843994101 %\n",
      "189.56167030334473\n",
      "3.6692327775386504 %\n",
      "197.43778347969055\n",
      "3.810357115136291 %\n",
      "205.39635515213013\n",
      "3.9514814527339315 %\n",
      "213.36681938171387\n",
      "4.092605790331572 %\n",
      "221.35076713562012\n",
      "4.233730127929212 %\n",
      "229.32601237297058\n",
      "4.374854465526853 %\n",
      "237.4033465385437\n",
      "4.515978803124493 %\n",
      "245.4870855808258\n",
      "4.657103140722133 %\n",
      "253.57087874412537\n",
      "4.798227478319774 %\n",
      "261.6510097980499\n",
      "4.939351815917414 %\n",
      "269.73764204978943\n",
      "5.080476153515055 %\n",
      "277.8482801914215\n",
      "5.221600491112695 %\n",
      "286.04629349708557\n",
      "5.362724828710335 %\n",
      "294.2559337615967\n",
      "5.503849166307976 %\n",
      "302.4599349498749\n",
      "5.644973503905616 %\n",
      "310.6753571033478\n",
      "5.786097841503256 %\n",
      "318.88789224624634\n",
      "5.927222179100896 %\n",
      "327.10498237609863\n",
      "6.068346516698537 %\n",
      "335.3650915622711\n",
      "6.209470854296177 %\n",
      "343.68907618522644\n",
      "6.350595191893818 %\n",
      "352.0087881088257\n",
      "6.491719529491459 %\n",
      "360.33147835731506\n",
      "6.632843867089099 %\n",
      "368.6687536239624\n",
      "6.7739682046867395 %\n",
      "377.0036680698395\n",
      "6.915092542284379 %\n",
      "385.34353017807007\n",
      "7.05621687988202 %\n",
      "393.677903175354\n",
      "7.197341217479661 %\n",
      "402.07594299316406\n",
      "7.338465555077301 %\n",
      "410.51454186439514\n",
      "7.479589892674941 %\n",
      "418.95396518707275\n",
      "7.620714230272582 %\n",
      "427.398628950119\n",
      "7.761838567870222 %\n",
      "435.84326815605164\n",
      "7.902962905467863 %\n",
      "444.28825879096985\n",
      "8.044087243065503 %\n",
      "452.7273917198181\n",
      "8.185211580663143 %\n",
      "461.1585166454315\n",
      "8.326335918260783 %\n",
      "469.61274695396423\n",
      "8.467460255858423 %\n",
      "478.1530792713165\n",
      "8.608584593456065 %\n",
      "486.70966267585754\n",
      "8.749708931053705 %\n",
      "495.24473333358765\n",
      "8.890833268651345 %\n",
      "503.7825906276703\n",
      "9.031957606248985 %\n",
      "512.3310205936432\n",
      "9.173081943846626 %\n",
      "520.8833420276642\n",
      "9.314206281444266 %\n",
      "529.4357163906097\n",
      "9.455330619041908 %\n",
      "537.9865665435791\n",
      "9.596454956639548 %\n",
      "546.5227875709534\n",
      "9.737579294237188 %\n",
      "555.0786755084991\n",
      "9.878703631834828 %\n",
      "563.640572309494\n",
      "10.019827969432468 %\n",
      "572.2844498157501\n",
      "10.16095230703011 %\n",
      "580.9426651000977\n",
      "10.302076644627748 %\n",
      "589.6154127120972\n",
      "10.44320098222539 %\n",
      "598.2795424461365\n",
      "10.58432531982303 %\n",
      "606.9374208450317\n",
      "10.72544965742067 %\n",
      "615.5946843624115\n",
      "10.86657399501831 %\n",
      "624.2672545909882\n",
      "11.007698332615952 %\n",
      "632.9374556541443\n",
      "11.148822670213592 %\n",
      "641.5965480804443\n",
      "11.289947007811232 %\n",
      "650.2558903694153\n",
      "11.431071345408872 %\n",
      "658.9133336544037\n",
      "11.572195683006512 %\n",
      "667.5735721588135\n",
      "11.713320020604154 %\n",
      "676.2984373569489\n",
      "11.854444358201793 %\n",
      "685.0593459606171\n",
      "11.995568695799435 %\n",
      "693.825083732605\n",
      "12.136693033397075 %\n",
      "702.5970690250397\n",
      "12.277817370994715 %\n",
      "711.3618986606598\n",
      "12.418941708592355 %\n",
      "720.1241960525513\n",
      "12.560066046189997 %\n",
      "728.8905806541443\n",
      "12.701190383787637 %\n",
      "737.6621301174164\n",
      "12.842314721385275 %\n",
      "746.4387850761414\n",
      "12.983439058982919 %\n",
      "755.2137830257416\n",
      "13.124563396580557 %\n",
      "763.9742231369019\n",
      "13.265687734178197 %\n",
      "772.7453622817993\n",
      "13.406812071775839 %\n",
      "781.5203113555908\n",
      "13.547936409373479 %\n",
      "790.2944250106812\n",
      "13.68906074697112 %\n",
      "799.0676424503326\n",
      "13.830185084568758 %\n",
      "807.8529789447784\n",
      "13.9713094221664 %\n",
      "816.7315080165863\n",
      "14.11243375976404 %\n",
      "825.617433309555\n",
      "14.25355809736168 %\n",
      "834.5090553760529\n",
      "14.394682434959321 %\n",
      "843.3910331726074\n",
      "14.535806772556962 %\n",
      "852.2785584926605\n",
      "14.676931110154602 %\n",
      "861.159245967865\n",
      "14.818055447752243 %\n",
      "870.040679693222\n",
      "14.959179785349882 %\n",
      "878.9264152050018\n",
      "15.100304122947522 %\n",
      "887.8227062225342\n",
      "15.241428460545164 %\n",
      "896.6980020999908\n",
      "15.382552798142804 %\n",
      "905.5807063579559\n",
      "15.523677135740444 %\n",
      "914.46821641922\n",
      "15.664801473338086 %\n",
      "923.3539822101593\n",
      "15.805925810935726 %\n",
      "932.2418885231018\n",
      "15.947050148533364 %\n",
      "941.1379444599152\n",
      "16.088174486131006 %\n",
      "950.0385973453522\n",
      "16.229298823728648 %\n",
      "958.9516727924347\n",
      "16.370423161326286 %\n",
      "967.844465970993\n",
      "16.511547498923925 %\n",
      "976.7375872135162\n",
      "16.652671836521566 %\n",
      "985.6776475906372\n",
      "16.79379617411921 %\n",
      "994.6239159107208\n",
      "16.934920511716847 %\n",
      "1003.5820603370667\n",
      "17.07604484931449 %\n",
      "1012.5520446300507\n",
      "17.21716918691213 %\n",
      "1021.5108802318573\n",
      "17.35829352450977 %\n",
      "1030.4662458896637\n",
      "17.49941786210741 %\n",
      "1039.4231462478638\n",
      "17.64054219970505 %\n",
      "1048.3981733322144\n",
      "17.78166653730269 %\n",
      "1057.360612154007\n",
      "17.922790874900333 %\n",
      "1066.3161935806274\n",
      "18.06391521249797 %\n",
      "1075.2808229923248\n",
      "18.205039550095613 %\n",
      "1084.25546169281\n",
      "18.34616388769325 %\n",
      "1093.2221465110779\n",
      "18.487288225290893 %\n",
      "1102.183219909668\n",
      "18.62841256288853 %\n",
      "1111.160823583603\n",
      "18.769536900486173 %\n",
      "1120.1212406158447\n",
      "18.910661238083815 %\n",
      "1129.0697391033173\n",
      "19.051785575681453 %\n",
      "1138.0325326919556\n",
      "19.192909913279095 %\n",
      "1147.0066411495209\n",
      "19.334034250876737 %\n",
      "1155.9834656715393\n",
      "19.475158588474375 %\n",
      "1164.9608838558197\n",
      "19.616282926072014 %\n",
      "1173.9423587322235\n",
      "19.757407263669656 %\n",
      "1182.9078080654144\n",
      "19.898531601267297 %\n",
      "1191.8870928287506\n",
      "20.039655938864936 %\n",
      "1200.861577987671\n",
      "20.180780276462578 %\n",
      "1209.8392100334167\n",
      "20.32190461406022 %\n",
      "1218.8117463588715\n",
      "20.463028951657858 %\n",
      "1227.7805700302124\n",
      "20.604153289255496 %\n",
      "1236.7479083538055\n",
      "20.745277626853138 %\n",
      "1245.7200644016266\n",
      "20.88640196445078 %\n",
      "1254.6970689296722\n",
      "21.027526302048418 %\n",
      "1263.6867725849152\n",
      "21.16865063964606 %\n",
      "1272.671028137207\n",
      "21.309774977243702 %\n",
      "1281.643630027771\n",
      "21.45089931484134 %\n",
      "1290.6224348545074\n",
      "21.592023652438982 %\n",
      "1299.5958065986633\n",
      "21.73314799003662 %\n",
      "1308.5833487510681\n",
      "21.874272327634262 %\n",
      "1317.566172361374\n",
      "22.015396665231904 %\n",
      "1326.539090871811\n",
      "22.156521002829543 %\n",
      "1335.5112736225128\n",
      "22.297645340427184 %\n",
      "1344.486071586609\n",
      "22.438769678024823 %\n",
      "1353.4574494361877\n",
      "22.579894015622465 %\n",
      "1362.425057888031\n",
      "22.721018353220103 %\n",
      "1371.405079126358\n",
      "22.862142690817745 %\n",
      "1380.368601322174\n",
      "23.003267028415387 %\n",
      "1389.351793050766\n",
      "23.144391366013025 %\n",
      "1398.3254942893982\n",
      "23.285515703610667 %\n",
      "1407.2947294712067\n",
      "23.42664004120831 %\n",
      "1416.2738218307495\n",
      "23.567764378805947 %\n",
      "1425.2482821941376\n",
      "23.708888716403585 %\n",
      "1434.2197616100311\n",
      "23.85001305400123 %\n",
      "1443.183954000473\n",
      "23.99113739159887 %\n",
      "1452.1521275043488\n",
      "24.132261729196507 %\n",
      "1461.1256639957428\n",
      "24.27338606679415 %\n",
      "1470.122777223587\n",
      "24.41451040439179 %\n",
      "1479.1072051525116\n",
      "24.55563474198943 %\n",
      "1488.0870435237885\n",
      "24.696759079587068 %\n",
      "1497.0720520019531\n",
      "24.83788341718471 %\n",
      "1506.064445734024\n",
      "24.97900775478235 %\n",
      "1515.060415506363\n",
      "25.120132092379993 %\n",
      "1524.0517053604126\n",
      "25.261256429977628 %\n",
      "1533.0417425632477\n",
      "25.402380767575274 %\n",
      "1542.0291936397552\n",
      "25.543505105172915 %\n",
      "1551.0103154182434\n",
      "25.68462944277055 %\n",
      "1559.99573802948\n",
      "25.825753780368192 %\n",
      "1568.9911153316498\n",
      "25.966878117965837 %\n",
      "1577.9848668575287\n",
      "26.108002455563472 %\n",
      "1586.9823513031006\n",
      "26.249126793161114 %\n",
      "1595.9821002483368\n",
      "26.390251130758756 %\n",
      "1604.9811787605286\n",
      "26.531375468356394 %\n",
      "1613.9609217643738\n",
      "26.672499805954036 %\n",
      "1622.9366447925568\n",
      "26.813624143551678 %\n",
      "1631.9342782497406\n",
      "26.954748481149316 %\n",
      "1640.921728849411\n",
      "27.095872818746958 %\n",
      "1649.9113056659698\n",
      "27.2369971563446 %\n",
      "1658.9127414226532\n",
      "27.37812149394224 %\n",
      "1667.9056487083435\n",
      "27.51924583153988 %\n",
      "1676.9018559455872\n",
      "27.660370169137515 %\n",
      "1685.893098115921\n",
      "27.801494506735157 %\n",
      "1694.8990199565887\n",
      "27.9426188443328 %\n",
      "1703.9065380096436\n",
      "28.083743181930437 %\n",
      "1712.9035136699677\n",
      "28.22486751952808 %\n",
      "1721.8913769721985\n",
      "28.36599185712572 %\n",
      "1730.8819966316223\n",
      "28.50711619472336 %\n",
      "1739.8725080490112\n",
      "28.648240532321 %\n",
      "1748.8469648361206\n",
      "28.789364869918643 %\n",
      "1757.836493730545\n",
      "28.93048920751628 %\n",
      "1766.8274445533752\n",
      "29.071613545113923 %\n",
      "1775.8335373401642\n",
      "29.212737882711565 %\n",
      "1784.8197770118713\n",
      "29.353862220309203 %\n",
      "1793.7932510375977\n",
      "29.494986557906845 %\n",
      "1802.7781472206116\n",
      "29.636110895504487 %\n",
      "1811.7659282684326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.77723523310212 %\n",
      "1820.773567199707\n",
      "29.918359570699764 %\n",
      "1829.7692749500275\n",
      "30.05948390829741 %\n",
      "1838.758261680603\n",
      "30.200608245895044 %\n",
      "1847.7519180774689\n",
      "30.341732583492686 %\n",
      "1856.7575011253357\n",
      "30.482856921090328 %\n",
      "1865.7543542385101\n",
      "30.623981258687966 %\n",
      "1874.7644464969635\n",
      "30.765105596285608 %\n",
      "1883.7565517425537\n",
      "30.90622993388325 %\n",
      "1892.7518498897552\n",
      "31.047354271480888 %\n",
      "1901.7475593090057\n",
      "31.18847860907853 %\n",
      "1910.7353291511536\n",
      "31.32960294667617 %\n",
      "1919.737226486206\n",
      "31.47072728427381 %\n",
      "1928.751981973648\n",
      "31.611851621871452 %\n",
      "1937.7622175216675\n",
      "31.752975959469094 %\n",
      "1946.7787611484528\n",
      "31.89410029706673 %\n",
      "1955.7873392105103\n",
      "32.035224634664374 %\n",
      "1964.8011636734009\n",
      "32.17634897226201 %\n",
      "1973.8125562667847\n",
      "32.31747330985965 %\n",
      "1982.8322396278381\n",
      "32.458597647457296 %\n",
      "1991.8533148765564\n",
      "32.59972198505493 %\n",
      "2000.8740351200104\n",
      "32.74084632265257 %\n",
      "2009.8771817684174\n",
      "32.88197066025022 %\n",
      "2018.8705615997314\n",
      "33.02309499784785 %\n",
      "2027.8794844150543\n",
      "33.164219335445495 %\n",
      "2036.900752544403\n",
      "33.30534367304313 %\n",
      "2045.916654586792\n",
      "33.44646801064077 %\n",
      "2054.9226503372192\n",
      "33.58759234823842 %\n",
      "2063.912784576416\n",
      "33.728716685836055 %\n",
      "2072.9211196899414\n",
      "33.86984102343369 %\n",
      "2081.933339357376\n",
      "34.01096536103134 %\n",
      "2090.962081193924\n",
      "34.15208969862898 %\n",
      "2099.9818835258484\n",
      "34.293214036226615 %\n",
      "2108.9994716644287\n",
      "34.43433837382426 %\n",
      "2118.0059723854065\n",
      "34.5754627114219 %\n",
      "2127.004629611969\n",
      "34.71658704901954 %\n",
      "2136.009111881256\n",
      "34.85771138661718 %\n",
      "2145.0255103111267\n",
      "34.99883572421482 %\n",
      "2154.033194065094\n",
      "35.13996006181246 %\n",
      "2163.0393056869507\n",
      "35.2810843994101 %\n",
      "2172.0610218048096\n",
      "35.42220873700774 %\n",
      "2181.0864095687866\n",
      "35.56333307460538 %\n",
      "2190.1040008068085\n",
      "35.70445741220302 %\n",
      "2199.1133279800415\n",
      "35.845581749800665 %\n",
      "2208.1324050426483\n",
      "35.986706087398304 %\n",
      "2217.142696619034\n",
      "36.12783042499594 %\n",
      "2226.145178079605\n",
      "36.26895476259358 %\n",
      "2235.1619629859924\n",
      "36.410079100191226 %\n",
      "2244.191528081894\n",
      "36.551203437788864 %\n",
      "2253.218104839325\n",
      "36.6923277753865 %\n",
      "2262.2187621593475\n",
      "36.83345211298415 %\n",
      "2271.2292697429657\n",
      "36.974576450581786 %\n",
      "2280.247264146805\n",
      "37.115700788179424 %\n",
      "2289.2611558437347\n",
      "37.25682512577706 %\n",
      "2298.276345729828\n",
      "37.39794946337471 %\n",
      "2307.2958011627197\n",
      "37.539073800972346 %\n",
      "2316.3017077445984\n",
      "37.680198138569985 %\n",
      "2325.30344414711\n",
      "37.82132247616763 %\n",
      "2334.3005378246307\n",
      "37.96244681376527 %\n",
      "2343.3012273311615\n",
      "38.10357115136291 %\n",
      "2352.318321466446\n",
      "38.24469548896055 %\n",
      "2361.3430960178375\n",
      "38.38581982655819 %\n",
      "2370.3585188388824\n",
      "38.52694416415583 %\n",
      "2379.3708951473236\n",
      "38.668068501753474 %\n",
      "2388.3851318359375\n",
      "38.809192839351105 %\n",
      "2397.4119431972504\n",
      "38.95031717694875 %\n",
      "2406.4354808330536\n",
      "39.091441514546396 %\n",
      "2415.460236787796\n",
      "39.23256585214403 %\n",
      "2424.4783494472504\n",
      "39.37369018974167 %\n",
      "2433.4992632865906\n",
      "39.51481452733931 %\n",
      "2442.5233104228973\n",
      "39.65593886493695 %\n",
      "2451.5470893383026\n",
      "39.797063202534595 %\n",
      "2460.5710458755493\n",
      "39.93818754013223 %\n",
      "2469.5906155109406\n",
      "40.07931187772987 %\n",
      "2478.618411064148\n",
      "40.22043621532752 %\n",
      "2487.638247728348\n",
      "40.361560552925155 %\n",
      "2496.645661354065\n",
      "40.502684890522794 %\n",
      "2505.6587183475494\n",
      "40.64380922812044 %\n",
      "2514.680583715439\n",
      "40.78493356571807 %\n",
      "2523.699091911316\n",
      "40.926057903315716 %\n",
      "2532.731092453003\n",
      "41.06718224091336 %\n",
      "2541.7568595409393\n",
      "41.20830657851099 %\n",
      "2550.760956764221\n",
      "41.34943091610864 %\n",
      "2559.7784628868103\n",
      "41.490555253706276 %\n",
      "2568.802447795868\n",
      "41.631679591303914 %\n",
      "2577.8109896183014\n",
      "41.77280392890156 %\n",
      "2586.8120262622833\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "source_edge_index = cp.array([], dtype= cp.int32)\n",
    "target_edge_index = cp.array([], dtype= cp.int32)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(unique_ids.shape[0]):\n",
    "    Id = unique_ids[i]\n",
    "    group = data[data[\"Id\"] == Id]\n",
    "    indices = group.index\n",
    "    indices = cp.expand_dims(indices.values, axis = 1)\n",
    "    target = cp.repeat(indices, indices.shape[0], axis = 1)\n",
    "    source = target.transpose().flatten()\n",
    "    target = target.flatten()\n",
    "    \n",
    "    source_edge_index = cp.concatenate((source_edge_index, source))\n",
    "    target_edge_index = cp.concatenate((target_edge_index, target))\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{str(i / unique_ids.shape[0] * 100)} %\")\n",
    "        print(time.time() - start )\n",
    "print(source_edge_index.shape)\n",
    "print(target_edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb1e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbb0678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "df_c = data # data_analysis.get_training_data() ## TODO in future merge with test and then split again (train test split via masks or train test split based on timeseries subgraphs)\n",
    "# source_edge_index_c = cp.array([], dtype= cp.int32)\n",
    "# target_edge_index_c = cp.array([], dtype= cp.int32)\n",
    "\n",
    "start = time.time()\n",
    "i = 0\n",
    "for Id, group in df.groupby(\"Id\"):\n",
    "    indices = group.index\n",
    "    indices = cp.expand_dims(indices.values, axis = 1)\n",
    "    target = cp.repeat(indices, indices.shape[0], axis = 1)\n",
    "    source = target.transpose().flatten()\n",
    "    target = target.flatten()\n",
    "    if Id == 520861:\n",
    "        print(Id)\n",
    "        print(indices)\n",
    "        break\n",
    "#     source_edge_index_c = cp.concatenate((source_edge_index_c, source))\n",
    "#     target_edge_index_c = cp.concatenate((target_edge_index_c, target))\n",
    "    i+=1\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{str(i / unique_ids.shape[0] * 100)} %\")\n",
    "#     if indices.shape[0] >= 100:\n",
    "#         print(time.time() - start )\n",
    "#         break\n",
    "print(time.time() - start )\n",
    "print(source_edge_index_c.shape)\n",
    "print(target_edge_index_c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a95826d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([601702,   5962, 756765, ..., 222910, 319258, 364398]),\n",
       " array([601702,   5962, 756765, ..., 364398, 364398, 364398]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_edge_index, target_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b446b9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Center</th>\n",
       "      <th>Set</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Time</th>\n",
       "      <th>TargetIcu</th>\n",
       "      <th>SecToIcu</th>\n",
       "      <th>CRP</th>\n",
       "      <th>HGB</th>\n",
       "      <th>MCV</th>\n",
       "      <th>PCT</th>\n",
       "      <th>PLT</th>\n",
       "      <th>RBC</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Label</th>\n",
       "      <th>SexCategory</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1211783</th>\n",
       "      <td>210439</td>\n",
       "      <td>39</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>AMB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.9</td>\n",
       "      <td>88.1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>266.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042196</th>\n",
       "      <td>145178</td>\n",
       "      <td>59</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>3021360.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>687780.0</td>\n",
       "      <td>105.05</td>\n",
       "      <td>6.5</td>\n",
       "      <td>82.3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.72</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  Age Sex Diagnosis   Center       Set Sender  Episode  \\\n",
       "index                                                                   \n",
       "1211783  210439   39   W   Control  Leipzig  Training    AMB        1   \n",
       "1042196  145178   59   M    Sepsis  Leipzig  Training    GEN        1   \n",
       "\n",
       "              Time TargetIcu  SecToIcu     CRP  HGB   MCV   PCT    PLT   RBC  \\\n",
       "index                                                                          \n",
       "1211783        0.0      <NA>      <NA>    <NA>  6.9  88.1  <NA>  266.0  3.70   \n",
       "1042196  3021360.0      MICU  687780.0  105.05  6.5  82.3  <NA>   60.0  3.72   \n",
       "\n",
       "          WBC    Label  SexCategory  \n",
       "index                                \n",
       "1211783  12.0  Control         True  \n",
       "1042196   8.0  Control        False  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataAnalysis.Constants import SEX_CATEGORY_COLUMN_NAME, SEX_COLUMN_NAME, FEATURES\n",
    "df[SEX_CATEGORY_COLUMN_NAME] = df.loc[:, SEX_COLUMN_NAME] ==\"W\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f8ce3f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([785479, 365813,  94876, 319392,  94876, 319392, 158886, 131094,\n",
       "        102747,  50835, 264336, 270433, 276166, 340454,  50835]),\n",
       " array([785479, 365813,  94876,  94876, 319392, 319392, 158886, 131094,\n",
       "        102747,  50835,  50835,  50835,  50835,  50835, 264336]))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 15\n",
    "m = 6941950\n",
    "source_edge_index[m:m+n], target_edge_index[m:m+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[[319258,364398], :]\n",
    "#df.loc[:, [df.index == 364398]]\n",
    "df.reset_index()[df.reset_index().index == 264336]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9619c7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Center</th>\n",
       "      <th>Set</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Time</th>\n",
       "      <th>...</th>\n",
       "      <th>SecToIcu</th>\n",
       "      <th>CRP</th>\n",
       "      <th>HGB</th>\n",
       "      <th>MCV</th>\n",
       "      <th>PCT</th>\n",
       "      <th>PLT</th>\n",
       "      <th>RBC</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Label</th>\n",
       "      <th>SexCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115190</th>\n",
       "      <td>2017884</td>\n",
       "      <td>520861</td>\n",
       "      <td>63</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>531300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.13</td>\n",
       "      <td>7.1</td>\n",
       "      <td>84.6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>217.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Control</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264336</th>\n",
       "      <td>2017885</td>\n",
       "      <td>520861</td>\n",
       "      <td>63</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>709800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>17.03</td>\n",
       "      <td>6.0</td>\n",
       "      <td>85.1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>283.0</td>\n",
       "      <td>3.42</td>\n",
       "      <td>12.3</td>\n",
       "      <td>Control</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635145</th>\n",
       "      <td>2017883</td>\n",
       "      <td>520861</td>\n",
       "      <td>63</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>23.42</td>\n",
       "      <td>7.0</td>\n",
       "      <td>86.8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>261.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>10.7</td>\n",
       "      <td>Control</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index      Id  Age Sex Diagnosis   Center       Set Sender  Episode  \\\n",
       "115190  2017884  520861   63   W   Control  Leipzig  Training    GEN        1   \n",
       "264336  2017885  520861   63   W   Control  Leipzig  Training    GEN        1   \n",
       "635145  2017883  520861   63   W   Control  Leipzig  Training    GEN        1   \n",
       "\n",
       "            Time  ... SecToIcu    CRP  HGB   MCV   PCT    PLT   RBC   WBC  \\\n",
       "115190  531300.0  ...     <NA>   6.13  7.1  84.6  <NA>  217.0  4.08   7.7   \n",
       "264336  709800.0  ...     <NA>  17.03  6.0  85.1  <NA>  283.0  3.42  12.3   \n",
       "635145       0.0  ...     <NA>  23.42  7.0  86.8  <NA>  261.0  4.01  10.7   \n",
       "\n",
       "          Label SexCategory  \n",
       "115190  Control        True  \n",
       "264336  Control        True  \n",
       "635145  Control        True  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Id\"] == 520861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa4124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getPositionEncoding(seq_len, d, n=10000):\n",
    "    P = np.zeros((seq_len, d))\n",
    "    for k in range(seq_len):\n",
    "        for i in np.arange(int(d/2)):\n",
    "            denominator = np.power(n, 2*i/d)\n",
    "            P[k, 2*i] = np.sin(k/denominator)\n",
    "            P[k, 2*i+1] = np.cos(k/denominator)\n",
    "    return P\n",
    "\n",
    "P = getPositionEncoding(seq_len=4, d=len(FEATURES))\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37effc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_bool_switch(tensor, ratio = 0.8):\n",
    "    random = np.random.uniform(0, 1 ,tensor.shape[0])\n",
    "    val_mask = np.logical(tensor, random >= 0.8)\n",
    "    train_mask = np.logical(tensor, random < 0.8)\n",
    "    return val_mask, train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "train_mask = ratio_bool_switch(data[\"Set\"] != \"Validation\")\n",
    "val_mask = ratio_bool_switch(data[\"Set\"] != \"Validation\")\n",
    "test_mask = data[\"Set\"] == \"Validation\"\n",
    "graph = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask.sum(), val_mask.sum(), test_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eb5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, GCNConv,GATv2Conv, GINConv, global_add_pool\n",
    "from torch.nn import Linear\n",
    "import torch\n",
    "from dataAnalysis.Constants import FEATURES\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "from torch.nn import BatchNorm1d as BatchNorm\n",
    "\n",
    "class GraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim = 128, out_channels = 1):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        input_dim = len(FEATURES)      \n",
    "        \n",
    "        conv_1= GATConv(input_dim, hidden_dim,heads=1, add_self_loops = False)\n",
    "        conv_end = GATConv((-1,-1), out_channels,add_self_loops = False)\n",
    "        \n",
    "        self.conv_1 = conv_1\n",
    "        self.conv_end = conv_end\n",
    "\n",
    "    def forward(self, graph):\n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv_1(x, edge_index).relu()\n",
    "        x = self.conv_end(x, edge_index)\n",
    "        return x\n",
    "            \n",
    "    def predict_proba(self, graph, mask):\n",
    "        with torch.inference_mode():\n",
    "            self.eval()\n",
    "            logits = self.forward(graph)\n",
    "            scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "            scores = torch.unsqueeze(scores, 0)\n",
    "            proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "            return torch.transpose(proba_predict, 0, 1)\n",
    "            \n",
    "    def predict(self, graph, mask):\n",
    "        return torch.round(self.predict_proba(graph, mask)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2089f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "graph = graph.to(device)\n",
    "WEIGHT = torch.tensor([664])\n",
    "WEIGHT = WEIGHT.to(device)\n",
    "\n",
    "print(\"Data shifted to the device \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526044da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, graph):\n",
    "        self.LEARNING_RATE = 3e-4\n",
    "        self.MAX_EPOCHS = 40000\n",
    "\n",
    "        self.model = GraphNeuralNetwork(hidden_dim = 128, out_channels=1) \n",
    "        self.model = self.model.to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.LEARNING_RATE,betas=(0.9, 0.999), eps=1e-08)\n",
    "        self.graph = graph\n",
    "        \n",
    "        self.last_loss = 0\n",
    "        self.increased_loss = 0\n",
    "        self.BREAKING_THRESHOLD = 10    \n",
    "        self.val_loss = []\n",
    "        self.train_loss = []\n",
    "    \n",
    "    def validate(self):\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            out = self.model(self.graph)\n",
    "            loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[val_mask]), self.graph.y[val_mask].type(torch.float32),\n",
    "                                                      pos_weight=WEIGHT)\n",
    "            self.val_loss.append(loss.item())\n",
    "            if loss.item() > self.last_loss:\n",
    "                self.increased_loss += 1\n",
    "            else:\n",
    "                self.increased_loss = 0\n",
    "            self.last_loss = loss.item()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.MAX_EPOCHS):\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            out = self.model(self.graph)\n",
    "            loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[train_mask]), self.graph.y[train_mask].type(torch.float32),\n",
    "                                                      pos_weight=WEIGHT)\n",
    "            self.train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.validate() \n",
    "\n",
    "            if self.increased_loss >= self.BREAKING_THRESHOLD:\n",
    "#                 print(f\"Breaked at {str(epoch)}\")\n",
    "                break\n",
    "            \n",
    "    def get_model(self):\n",
    "        return self.model    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.epochs, self.train_loss, 'g', label='Training loss')\n",
    "        plt.plot(self.epochs, self.val_loss, 'y', label='Validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
