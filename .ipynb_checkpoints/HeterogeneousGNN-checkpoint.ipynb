{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "68e59c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "def count_cbc_cases(data):\n",
    "    comp_data = data.query(\"~(WBC.isnull() & HGB.isnull() & MCV.isnull() & PLT.isnull() & RBC.isnull())\",\n",
    "                           engine='python')\n",
    "    unique_data = comp_data.drop_duplicates(subset=[\"Id\", \"Center\"])\n",
    "    return len(unique_data)\n",
    "\n",
    "\n",
    "def count_cbc(data):\n",
    "    comp_data = data.query(\"~(WBC.isnull() & HGB.isnull() & MCV.isnull() & PLT.isnull() & RBC.isnull())\",\n",
    "                           engine='python')\n",
    "    return len(comp_data)\n",
    "\n",
    "\n",
    "class Features:\n",
    "    def __init__(self, data):\n",
    "        unique_data = data.drop_duplicates(subset=[\"Id\", \"Center\", \"Time\"], keep=False)\n",
    "        non_icu_unique_data = unique_data.query(\"~(Sender.str.contains('ICU')) & ~(~SecToIcu.isnull() & SecToIcu < 0)\",\n",
    "                                                engine='python')\n",
    "        first_non_icu_unique_data = non_icu_unique_data.query(\"Episode == 1 \", engine='python')\n",
    "        complete_first_non_icu_unique_data = first_non_icu_unique_data.query(\"~(WBC.isnull() | HGB.isnull() | \"\n",
    "                                                                             \"MCV.isnull() | PLT.isnull() | \"\n",
    "                                                                             \"RBC.isnull())\", engine='python')\n",
    "        sirs_complete_first_non_icu_unique_data = complete_first_non_icu_unique_data.query(\"Diagnosis != 'SIRS'\",\n",
    "                                                                                           engine='python')\n",
    "        sirs_complete_first_non_icu_unique_data = \\\n",
    "            sirs_complete_first_non_icu_unique_data.query(\"(Diagnosis == 'Control') | ((Diagnosis == 'Sepsis') & (\"\n",
    "                                                          \"~TargetIcu.isnull() & \"\n",
    "                                                          \"TargetIcu.str.contains('MICU')))\",\n",
    "                                                                                           engine='python')\n",
    "        self.data = sirs_complete_first_non_icu_unique_data\n",
    "        self.data['Label'] = self.data['Diagnosis']\n",
    "        self.data['W'] = self.data['Sex'] == \"W\"\n",
    "        self.data['M'] = self.data['Sex'] == \"M\"\n",
    "\n",
    "        control_filter = (self.data[\"Diagnosis\"] == 'Control') | \\\n",
    "                         ((self.data[\"SecToIcu\"] > 3600 * 6) & (\n",
    "                                     ~self.data[\"TargetIcu\"].isnull() & self.data[\"TargetIcu\"]\n",
    "                                     .str.contains('MICU', na=False)))\n",
    "        sepsis_filter = (self.data[\"Diagnosis\"] == 'Sepsis') & \\\n",
    "                        (self.data[\"SecToIcu\"] <= 3600 * 6) & \\\n",
    "                        (self.data[\"TargetIcu\"].str.contains('MICU', na=False))\n",
    "        self.data.loc[control_filter, \"Label\"] = \"Control\"\n",
    "        self.data.loc[sepsis_filter, \"Label\"] = \"Sepsis\"\n",
    "        self.data[\"Label\"] = self.data[\"Label\"] == \"Sepsis\"\n",
    "\n",
    "        self.control_data = self.data.loc[control_filter]\n",
    "        self.sepsis_data = self.data.loc[sepsis_filter]\n",
    "\n",
    "    def get_x(self):\n",
    "        feature_columns = [\"Age\",\"Sex\", \"HGB\", \"PLT\", \"RBC\", \"WBC\", \"MCV\"]\n",
    "        return self.data.loc[:, feature_columns].replace(to_replace='W', value=1).replace(to_replace='M', value=0)#QuantileTransformer(n_quantiles=100).fit_transform(\n",
    "\n",
    "    def get_y(self):\n",
    "        return (self.data[\"Label\"] == \"Sepsis\").astype(int) #self.data.loc[:, \"Label\"]\n",
    "\n",
    "    def get_control_data(self):\n",
    "        return self.control_data\n",
    "\n",
    "    def get_sepsis_data(self):\n",
    "        return self.sepsis_data\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data.sample(frac=1).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8dde8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training(Features):\n",
    "    def __init__(self, data):\n",
    "        leipzig_training_data = data.query(\"Center == 'Leipzig' & Set == 'Training'\")\n",
    "        Features.__init__(self, leipzig_training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "346fa6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation(Features):\n",
    "    def __init__(self, data):\n",
    "        leipzig_validation_data = data.query(\"Center == 'Leipzig' & Set == 'Validation'\")\n",
    "        Features.__init__(self, leipzig_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "29413394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreifswaldValidation(Features):\n",
    "    def __init__(self, data):\n",
    "        greifswald_validation_data = data.query(\"Center == 'Greifswald' & Set == 'Validation'\")\n",
    "        Features.__init__(self, greifswald_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9fb08a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement greifswald validation\n",
    "class DataAnalysis:\n",
    "    def __init__(self, data):\n",
    "        self.training = Training(data)\n",
    "        print(\"Training: \")\n",
    "        print(f\"Assessable data are {count_cbc_cases(self.training.get_data())} cases \"\n",
    "              f\"and {count_cbc(self.training.get_data())} CBCs\")\n",
    "        print(f\"Control data are {count_cbc_cases(self.training.get_control_data())} cases \"\n",
    "              f\"and {count_cbc(self.training.get_control_data())} CBCs\")\n",
    "        print(f\"Sepsis data are {count_cbc_cases(self.training.get_sepsis_data())} cases \"\n",
    "              f\"and {count_cbc(self.training.get_sepsis_data())} CBCs\")\n",
    "        print(20 * \"$\")\n",
    "        print(\"Testing: \")\n",
    "        self.validation = Validation(data)\n",
    "        print(f\"Controls: {self.validation.get_control_data().shape[0]},\"\n",
    "              f\" Sepsis: {self.validation.get_sepsis_data().shape[0]}\")\n",
    "        print(f\"Assessable data are {count_cbc_cases(self.validation.get_data())} cases \"\n",
    "              f\"and {count_cbc(self.validation.get_data())} CBCs\")\n",
    "        print(f\"Control data are {count_cbc_cases(self.validation.get_control_data())} cases \"\n",
    "              f\"and {count_cbc(self.validation.get_control_data())} CBCs\")\n",
    "        print(f\"Sepsis data are {count_cbc_cases(self.validation.get_sepsis_data())} cases \"\n",
    "              f\"and {count_cbc(self.validation.get_sepsis_data())} CBCs\")\n",
    "\n",
    "        self.greifswald_vaidation = GreifswaldValidation(data)\n",
    "        print(f\"Controls: {self.greifswald_vaidation.get_control_data().shape[0]},\"\n",
    "              f\" Sepsis: {self.greifswald_vaidation.get_sepsis_data().shape[0]}\")\n",
    "        print(f\"Assessable data are {count_cbc_cases(self.greifswald_vaidation.get_data())} cases \"\n",
    "              f\"and {count_cbc(self.greifswald_vaidation.get_data())} CBCs\")\n",
    "        print(f\"Control data are {count_cbc_cases(self.validation.get_control_data())} cases \"\n",
    "              f\"and {count_cbc(self.greifswald_vaidation.get_control_data())} CBCs\")\n",
    "        print(f\"Sepsis data are {count_cbc_cases(self.greifswald_vaidation.get_sepsis_data())} cases \"\n",
    "              f\"and {count_cbc(self.greifswald_vaidation.get_sepsis_data())} CBCs\")\n",
    "\n",
    "    def get_training_data(self):\n",
    "        return self.training.get_data()\n",
    "\n",
    "    def get_testing_data(self):\n",
    "        return self.validation.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6c929aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1105139/1941090038.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n",
      "/tmp/ipykernel_1105139/1941090038.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['W'] = self.data['Sex'] == \"W\"\n",
      "/tmp/ipykernel_1105139/1941090038.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['M'] = self.data['Sex'] == \"M\"\n",
      "/tmp/ipykernel_1105139/1941090038.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[\"Label\"] = self.data[\"Label\"] == \"Sepsis\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Assessable data are 528101 cases and 1015074 CBCs\n",
      "Control data are 527038 cases and 1013548 CBCs\n",
      "Sepsis data are 1488 cases and 1526 CBCs\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "Testing: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1105139/1941090038.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n",
      "/tmp/ipykernel_1105139/1941090038.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['W'] = self.data['Sex'] == \"W\"\n",
      "/tmp/ipykernel_1105139/1941090038.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['M'] = self.data['Sex'] == \"M\"\n",
      "/tmp/ipykernel_1105139/1941090038.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[\"Label\"] = self.data[\"Label\"] == \"Sepsis\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 365794, Sepsis: 490\n",
      "Assessable data are 180494 cases and 366284 CBCs\n",
      "Control data are 180157 cases and 365794 CBCs\n",
      "Sepsis data are 472 cases and 490 CBCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1105139/1941090038.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n",
      "/tmp/ipykernel_1105139/1941090038.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['W'] = self.data['Sex'] == \"W\"\n",
      "/tmp/ipykernel_1105139/1941090038.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['M'] = self.data['Sex'] == \"M\"\n",
      "/tmp/ipykernel_1105139/1941090038.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[\"Label\"] = self.data[\"Label\"] == \"Sepsis\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 437629, Sepsis: 448\n",
      "Assessable data are 157922 cases and 438077 CBCs\n",
      "Control data are 180157 cases and 437629 CBCs\n",
      "Sepsis data are 438 cases and 448 CBCs\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"extdata/sbcdata.csv\", header=0)\n",
    "# data = pd.read_csv(r\"extdata/sbc_small.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)\n",
    "\n",
    "training = data_analysis.get_training_data()\n",
    "testing = data_analysis.get_testing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151563a",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9e88f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGB_COLUMN_NAME = \"HGB\"\n",
    "WBC_COLUMN_NAME = \"WBC\"\n",
    "RBC_COLUMN_NAME = \"RBC\"\n",
    "MCV_COLUMN_NAME = \"MCV\"\n",
    "PLT_COLUMN_NAME = \"PLT\"\n",
    "\n",
    "SEX_COLUMN_NAME = \"Sex\"\n",
    "W_COLUMN_NAME = \"W\"\n",
    "M_COLUMN_NAME = \"M\"\n",
    "AGE_COLUMN_NAME = \"Age\"\n",
    "PATIENT_NAME = \"PATIENT\"\n",
    "EDGE_TYPE = \"HAS\"\n",
    "LABEL_COLUMN_NAME = \"Label\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a6f4c",
   "metadata": {},
   "source": [
    "## Functions for discretization of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "09c59b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def to_tensor(df):\n",
    "    return torch.Tensor(list(df.values))\n",
    "\n",
    "def get_quantil_tensor():\n",
    "#     number_of_quantiles = 20\n",
    "#     q = torch.arange(0, 1, 1/number_of_quantiles)\n",
    "    q = torch.Tensor([0.025,0.05, 0.1, 0.2, 0.35, 0.5, 0.65, 0.8, 0.9, 0.95, 0.975, 1])\n",
    "    return q\n",
    "\n",
    "def get_quantiles(tensor):\n",
    "    q = get_quantil_tensor() \n",
    "    return torch.quantile(tensor, q)\n",
    "\n",
    "def normalize(tensor):\n",
    "    mean = torch.mean(tensor, dim = 0)\n",
    "    std = torch.std(tensor, dim = 0)\n",
    "    mean_diff = tensor - mean\n",
    "    return mean_diff / std\n",
    "\n",
    "def get_quantile_indices(tensor, quantiles):\n",
    "    quantile_indices = []\n",
    "    all_indices = torch.Tensor([])\n",
    "    prev_quantile = 0\n",
    "    indices_control = torch.arange(0, tensor.shape[0])\n",
    "    for i in range(quantiles.nelement()):\n",
    "        indices_u = (tensor >= prev_quantile).nonzero(as_tuple=True)[0] # (tensor > prev_quantile and tensor <= quantiles[i]).nonzero(as_tuple=True)[0]\n",
    "        indices_o = (tensor < quantiles[i]).nonzero(as_tuple=True)[0]\n",
    "        indices = torch.from_numpy(np.intersect1d(indices_u, indices_o))\n",
    "        quantile_indices.append(indices)\n",
    "        prev_quantile = quantiles[i]\n",
    "    final_indices = (tensor >= prev_quantile).nonzero(as_tuple=True)[0] \n",
    "    quantile_indices.append(final_indices)\n",
    "    return quantile_indices\n",
    "\n",
    "\n",
    "def create_node_features(node_type, quantiles):\n",
    "    nodes_features = []\n",
    "    prev_quantile = torch.Tensor([0])\n",
    "    for i in range(quantiles.nelement()):\n",
    "        node_features = [prev_quantile.item(), quantiles[i].item(), get_quantil_tensor()[i].item()]\n",
    "        prev_quantile = quantiles[i]\n",
    "        nodes_features.append(node_features)\n",
    "    nodes_features.append([prev_quantile.item(), prev_quantile.item(), 1])\n",
    "    return torch.tensor(nodes_features)\n",
    "\n",
    "def create_edge_features_to_patient(node_type, quantile_indices):\n",
    "    source_edge_list = None\n",
    "    target_edge_list = None\n",
    "    for i in range(len(quantile_indices)):\n",
    "        target_edges = torch.ones((quantile_indices[i].nelement())) * i\n",
    "        source_edges = quantile_indices[i]\n",
    "        source_edge_list = source_edges if source_edge_list is None else torch.concat((source_edge_list, source_edges))\n",
    "        target_edge_list = target_edges if target_edge_list is None else torch.concat((target_edge_list, target_edges))\n",
    "    return torch.stack([source_edge_list, target_edge_list]).type(torch.long)\n",
    "\n",
    "def add_features_and_edges(graph, node_type, dataframe, rus_indices):\n",
    "    node_values = torch.Tensor(dataframe[node_type])[rus_indices] if rus_indices is not None else torch.Tensor(dataframe[node_type])\n",
    "    node_quantiles = get_quantiles(node_values)\n",
    "    quantile_indices = get_quantile_indices(node_values, node_quantiles)\n",
    "    graph[node_type].x = create_node_features(node_type, node_quantiles)\n",
    "    graph[PATIENT_NAME, EDGE_TYPE, node_type].edge_index = create_edge_features_to_patient(node_type, quantile_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac9ea86",
   "metadata": {},
   "source": [
    "## Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9b8b2f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1526)\n",
      "torch.Size([1015074])\n",
      "(1526,)\n",
      "(3052,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1105139/1707544717.py:5: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.Tensor(list(df.values))\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "graph = HeteroData()\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "training_x = training.loc[:, (AGE_COLUMN_NAME, W_COLUMN_NAME, M_COLUMN_NAME, HGB_COLUMN_NAME, RBC_COLUMN_NAME, WBC_COLUMN_NAME, PLT_COLUMN_NAME, MCV_COLUMN_NAME)]\n",
    "training_y = training.loc[:, LABEL_COLUMN_NAME]\n",
    "x_t, y_t = rus.fit_resample(training_x, training_y)\n",
    "rus_indices = rus.sample_indices_\n",
    "\n",
    "graph[PATIENT_NAME].x = to_tensor(training_x)[rus_indices]\n",
    "add_features_and_edges(graph, WBC_COLUMN_NAME, training, rus_indices)\n",
    "add_features_and_edges(graph, RBC_COLUMN_NAME, training, rus_indices)\n",
    "add_features_and_edges(graph, PLT_COLUMN_NAME, training, rus_indices)\n",
    "add_features_and_edges(graph, MCV_COLUMN_NAME, training, rus_indices)\n",
    "add_features_and_edges(graph, HGB_COLUMN_NAME, training, rus_indices)\n",
    "graph[PATIENT_NAME].y = to_tensor(training_y)[rus_indices]\n",
    "labels = to_tensor(training_y)\n",
    "print(labels.count_nonzero())\n",
    "print(labels.shape)\n",
    "print(training_y.to_numpy()[training_y.to_numpy().nonzero()].shape)\n",
    "\n",
    "print(rus.sample_indices_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "01a28ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1105139/1707544717.py:5: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.Tensor(list(df.values))\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "test_graph = HeteroData()\n",
    "\n",
    "test_graph[PATIENT_NAME].x = to_tensor(testing.loc[:, (AGE_COLUMN_NAME, W_COLUMN_NAME, M_COLUMN_NAME, HGB_COLUMN_NAME, RBC_COLUMN_NAME, WBC_COLUMN_NAME, PLT_COLUMN_NAME, MCV_COLUMN_NAME)])\n",
    "add_features_and_edges(test_graph, WBC_COLUMN_NAME, testing, None)\n",
    "add_features_and_edges(test_graph, RBC_COLUMN_NAME, testing, None)\n",
    "add_features_and_edges(test_graph, PLT_COLUMN_NAME, testing, None)\n",
    "add_features_and_edges(test_graph, MCV_COLUMN_NAME, testing, None)\n",
    "add_features_and_edges(test_graph, HGB_COLUMN_NAME, testing, None)\n",
    "test_graph[PATIENT_NAME].y = to_tensor(testing.loc[:, LABEL_COLUMN_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "065bbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.RandomNodeSplit(num_test=0, num_val=.2)\n",
    "graph = transform(graph)\n",
    "graph = T.ToUndirected()(graph)\n",
    "test_graph = T.ToUndirected()(test_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c1a8f9f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mPATIENT\u001b[0m={\n",
      "    x=[3052, 8],\n",
      "    y=[3052],\n",
      "    train_mask=[3052],\n",
      "    val_mask=[3052],\n",
      "    test_mask=[3052]\n",
      "  },\n",
      "  \u001b[1mWBC\u001b[0m={ x=[13, 3] },\n",
      "  \u001b[1mRBC\u001b[0m={ x=[13, 3] },\n",
      "  \u001b[1mPLT\u001b[0m={ x=[13, 3] },\n",
      "  \u001b[1mMCV\u001b[0m={ x=[13, 3] },\n",
      "  \u001b[1mHGB\u001b[0m={ x=[13, 3] },\n",
      "  \u001b[1m(PATIENT, HAS, WBC)\u001b[0m={ edge_index=[2, 3052] },\n",
      "  \u001b[1m(PATIENT, HAS, RBC)\u001b[0m={ edge_index=[2, 3052] },\n",
      "  \u001b[1m(PATIENT, HAS, PLT)\u001b[0m={ edge_index=[2, 3052] },\n",
      "  \u001b[1m(PATIENT, HAS, MCV)\u001b[0m={ edge_index=[2, 3052] },\n",
      "  \u001b[1m(PATIENT, HAS, HGB)\u001b[0m={ edge_index=[2, 3052] },\n",
      "  \u001b[1m(WBC, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 3052] },\n",
      "  \u001b[1m(RBC, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 3052] },\n",
      "  \u001b[1m(PLT, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 3052] },\n",
      "  \u001b[1m(MCV, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 3052] },\n",
      "  \u001b[1m(HGB, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 3052] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mPATIENT\u001b[0m={\n",
      "    x=[366284, 8],\n",
      "    y=[366284]\n",
      "  },\n",
      "  \u001b[1mWBC\u001b[0m={ x=[13, 3] },\n",
      "  \u001b[1mRBC\u001b[0m={ x=[13, 3] },\n",
      "  \u001b[1mPLT\u001b[0m={ x=[13, 3] },\n",
      "  \u001b[1mMCV\u001b[0m={ x=[13, 3] },\n",
      "  \u001b[1mHGB\u001b[0m={ x=[13, 3] },\n",
      "  \u001b[1m(PATIENT, HAS, WBC)\u001b[0m={ edge_index=[2, 366284] },\n",
      "  \u001b[1m(PATIENT, HAS, RBC)\u001b[0m={ edge_index=[2, 366284] },\n",
      "  \u001b[1m(PATIENT, HAS, PLT)\u001b[0m={ edge_index=[2, 366284] },\n",
      "  \u001b[1m(PATIENT, HAS, MCV)\u001b[0m={ edge_index=[2, 366284] },\n",
      "  \u001b[1m(PATIENT, HAS, HGB)\u001b[0m={ edge_index=[2, 366284] },\n",
      "  \u001b[1m(WBC, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 366284] },\n",
      "  \u001b[1m(RBC, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 366284] },\n",
      "  \u001b[1m(PLT, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 366284] },\n",
      "  \u001b[1m(MCV, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 366284] },\n",
      "  \u001b[1m(HGB, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 366284] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(graph)\n",
    "print(test_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e41cf",
   "metadata": {},
   "source": [
    "### Model and optimizer defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "57e45295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, to_hetero,Linear\n",
    "from torch_geometric.nn.conv import HANConv\n",
    "\n",
    "from torchmetrics import AUROC\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.conv1 = GATConv((-1,-1), 16, add_self_loops=False)\n",
    "#         self.conv2 = GATConv((-1,-1), 8,  add_self_loops=False)\n",
    "#         self.conv3 = GATConv((-1,-1), 2,  add_self_loops=False)\n",
    "        self.conv1 = HANConv(-1, 32, graph.metadata())\n",
    "        self.conv2 = HANConv(-1, 16, graph.metadata())\n",
    "        self.conv3 = HANConv(-1, 8, graph.metadata())\n",
    "        self.lin_end = Linear(8, 1)\n",
    "#         self.batchnorm_1 = torch.nn.BatchNorm1d(16)\n",
    "#         self.batchnorm_2 = torch.nn.BatchNorm1d(8)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        x, edge_index = graph.x_dict, graph.edge_index_dict\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.lin_end(x[PATIENT_NAME])\n",
    "        return x # torch.log_softmax(x[PATIENT_NAME], dim=-1)#torch.log_softmax(x[PATIENT_NAME], dim=-1) ##TODO change this \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83687371",
   "metadata": {},
   "source": [
    "### Sample weight calulcation for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d6e0c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepsis_cases = torch.count_nonzero(graph[PATIENT_NAME].y)\n",
    "# control_cases = graph[PATIENT_NAME].y.size(dim=0) - sepsis_cases\n",
    "# control_weight = sepsis_cases / (1*(control_cases + sepsis_cases))\n",
    "# sepsis_weight = control_cases*1 / (control_cases + sepsis_cases)\n",
    "# class_weights = torch.tensor([control_weight, sepsis_weight ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "33b243ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/dwalke/.local/lib/python3.10/site-packages/torch/fx/graph_module.py\", line 267, in __call__\n",
      "    return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/home/dwalke/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"<eval_with_key>.3\", line 12, in forward\n",
      "    getattr_1__PATIENT = graph__PATIENT.x_dict\n",
      "AttributeError: 'NoneType' object has no attribute 'x_dict'\n",
      "\n",
      "Call using an FX-traced Module, line 12 of the traced Module's generated forward function:\n",
      "    graph__HGB = graph_dict.get('HGB', None);  graph_dict = None\n",
      "    getattr_1__PATIENT = graph__PATIENT.x_dict\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    getattr_1__WBC = graph__WBC.x_dict\n",
      "\n",
      "    getattr_1__RBC = graph__RBC.x_dict\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'x_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epochs:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(epoch)\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     validate_unseen()\n\u001b[1;32m     46\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, loss_values, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[146], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 21\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     class_weight = torch.clone(graph[PATIENT_NAME].y) * class_weights[1] + class_weights[0]\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(torch\u001b[38;5;241m.\u001b[39msqueeze(out), graph[PATIENT_NAME]\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:658\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:275\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_with_key\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m topmost_framesummary\u001b[38;5;241m.\u001b[39mfilename:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28mprint\u001b[39m(_WrappedCall\u001b[38;5;241m.\u001b[39m_generate_error_message(topmost_framesummary),\n\u001b[1;32m    274\u001b[0m           file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'x_dict'"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import NeighborLoader, ImbalancedSampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_mask = graph[PATIENT_NAME].train_mask\n",
    "val_mask = graph[PATIENT_NAME].val_mask\n",
    "auroc_metric = AUROC(task=\"binary\")\n",
    "model = GNN()\n",
    "model = to_hetero(model, graph.metadata(), aggr='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "epochs = range(10)\n",
    "\n",
    "# all_weights = torch.clone(graph[PATIENT_NAME].y) * sepsis_weight + control_weight\n",
    "loss_values = []\n",
    "\n",
    "def train():\n",
    "#     weight = torch.clone(graph[PATIENT_NAME].y) * torch.max(all_weights) + torch.min(all_weights)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(graph)\n",
    "#     class_weight = torch.clone(graph[PATIENT_NAME].y) * class_weights[1] + class_weights[0]\n",
    "    loss = F.binary_cross_entropy_with_logits(torch.squeeze(out), graph[PATIENT_NAME].y.type(torch.float))\n",
    "    print(loss.item())\n",
    "    loss_values.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "@torch.no_grad()\n",
    "def validate_unseen():\n",
    "    model.eval()\n",
    "    pred = model(test_graph)\n",
    "    pred_patient = torch.round(torch.sigmoid(torch.squeeze(pred)))\n",
    "    print(pred_patient)\n",
    "    auroc = auroc_metric(pred_patient, test_graph[PATIENT_NAME].y)\n",
    "    print(f\"AUROC: {auroc.item():.4f}\")\n",
    "    correct = (pred_patient == test_graph[PATIENT_NAME].y).sum()\n",
    "    acc = int(correct) / int(test_graph[PATIENT_NAME].x.size(dim=0))\n",
    "    print(f'Accuracy: {acc:.4f}')\n",
    "    \n",
    "for epoch in epochs:\n",
    "    print(epoch)\n",
    "    train()\n",
    "    validate_unseen()\n",
    "plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#     if epoch % 1 == 0:\n",
    "#         test()\n",
    "#     print(\"validate\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db0fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaaec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.model_selection.StratifiedKFold as skfold\n",
    "\n",
    "# skf = skfold(n_splits=10)\n",
    "# for i, (train_index, test_index) in enumerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee6dea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still sleeping and waiting for you so you dont have to reconnect everything\n",
      "Still sleeping and waiting for you so you dont have to reconnect everything\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStill sleeping and waiting for you so you dont have to reconnect everything\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43msleeper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m, in \u001b[0;36msleeper\u001b[0;34m(minutes)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msleeper\u001b[39m(minutes):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(minutes):\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStill sleeping and waiting for you so you dont have to reconnect everything\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "def sleeper(minutes):\n",
    "    for i in range(minutes):\n",
    "        time.sleep(60)\n",
    "        print(\"Still sleeping and waiting for you so you dont have to reconnect everything\")\n",
    "sleeper(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ee451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
