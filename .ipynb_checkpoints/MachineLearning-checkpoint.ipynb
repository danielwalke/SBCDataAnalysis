{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342af1fd",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c929aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Assessable data are 528101 cases and 1015074 CBCs\n",
      "Control data are 527038 cases and 1013548 CBCs\n",
      "Sepsis data are 1488 cases and 1526 CBCs\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "Testing: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 365794, Sepsis: 490\n",
      "Assessable data are 180494 cases and 366284 CBCs\n",
      "Control data are 180157 cases and 365794 CBCs\n",
      "Sepsis data are 472 cases and 490 CBCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 437629, Sepsis: 448\n",
      "Assessable data are 157922 cases and 438077 CBCs\n",
      "Control data are 180157 cases and 437629 CBCs\n",
      "Sepsis data are 438 cases and 448 CBCs\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee56dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_analysis.get_y_train()\n",
    "X_train = data_analysis.get_X_train()\n",
    "\n",
    "y_test = data_analysis.get_y_test()\n",
    "X_test = data_analysis.get_X_test()\n",
    "\n",
    "y_gw_test = data_analysis.get_y_gw()\n",
    "X_gw_test = data_analysis.get_X_gw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125b9de",
   "metadata": {},
   "source": [
    "## Metrics definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c918088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "evaluation = Evaluation(y_test, y_gw_test, X_test, X_gw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867b247",
   "metadata": {},
   "source": [
    "## Feature variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec5ee742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.FeatureImportance import FeatureImportance\n",
    "feature_importance = FeatureImportance(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc4f264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance.plot_feature_importance(logistic_regression, title = \"Logistic regression\")\n",
    "feature_importance.plot_feature_importance(decision_tree, title=\"Decision tree\")\n",
    "feature_importance.plot_feature_importance(random_forest, title=\"Random forest\")\n",
    "feature_importance.plot_feature_importance(xgb_classifier, title=\"XGBoost\")\n",
    "feature_importance.plot_feature_importance(rus_boost, title=\"RUSBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a3a59",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a3e7da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1-Micro</th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Binary</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leipzig</td>\n",
       "      <td>0.044219</td>\n",
       "      <td>0.776133</td>\n",
       "      <td>0.441226</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>0.836916</td>\n",
       "      <td>0.009453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greifswald</td>\n",
       "      <td>0.022229</td>\n",
       "      <td>0.592021</td>\n",
       "      <td>0.373617</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.755808</td>\n",
       "      <td>0.004283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name       MCC  F1-Micro  F1-Macro  F1-Binary     AUROC     AUPRC\n",
       "0     Leipzig  0.044219  0.776133  0.441226   0.008632  0.836916  0.009453\n",
       "1  Greifswald  0.022229  0.592021  0.373617   0.003746  0.755808  0.004283"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression(random_state=0, solver=\"liblinear\", class_weight=\"balanced\")\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "evaluation.get_df_metrics(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e925c7",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c11a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42, max_features=6, min_samples_leaf=0.005,\n",
    "                       min_samples_split=0.03, class_weight=\"balanced\")\n",
    "decision_tree.fit(X_train, y_train)\n",
    "evaluation.get_df_metrics(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e002cb9",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(class_weight={0: 0.0025, 1: 1}, max_leaf_nodes=79,\n",
    "                           min_samples_leaf=0.0001,\n",
    "                           min_samples_split=0.0055,\n",
    "                           n_estimators=500, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "evaluation.get_df_metrics(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3c81d",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c938520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_classifier = XGBClassifier(tree_method='gpu_hist', \n",
    "                           scale_pos_weight = 660,\n",
    "                           n_estimators=478,\n",
    "                           max_depth=2,\n",
    "                           eta=0.1,\n",
    "                           min_child_weight = 7,\n",
    "                           max_delta_step= 7,\n",
    "                           sampling_method= \"uniform\")\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "evaluation.get_df_metrics(xgb_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d73428",
   "metadata": {},
   "source": [
    "## RUS Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02646a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "rus_boost = RUSBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=79, min_samples_leaf= 5, min_samples_split = 10),\n",
    "                   learning_rate=0.90369, n_estimators=495,\n",
    "                   random_state=1714400672, sampling_strategy=35/65)\n",
    "rus_boost.fit(X_train, y_train)\n",
    "evaluation.get_df_metrics(rus_boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d384aeb",
   "metadata": {},
   "source": [
    "## Error evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207da953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def error_evaluation(model):\n",
    "    global X_train, y_train, evaluation\n",
    "    dfs = []\n",
    "    times = []\n",
    "    for i in range(100):\n",
    "        start = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        times.append(time.time() - start)\n",
    "        dfs.append(evaluation.get_df_metrics(model))\n",
    "    return dfs, times    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32b213f8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         NAME       MCC  F1-Micro  F1-Macro  F1-Binary     AUROC     AUPRC\n",
      "0     Leipzig  0.044219  0.776133  0.441226   0.008632  0.836916  0.009453\n",
      "1  Greifswald  0.022229  0.592021  0.373617   0.003746  0.755808  0.004283\n",
      "         NAME       MCC  F1-Micro  F1-Macro  F1-Binary     AUROC     AUPRC\n",
      "0     Leipzig  0.044219  0.776133  0.441226   0.008632  0.836916  0.009453\n",
      "1  Greifswald  0.022229  0.592021  0.373617   0.003746  0.755808  0.004283\n",
      "         NAME       MCC  F1-Micro  F1-Macro  F1-Binary     AUROC     AUPRC\n",
      "0     Leipzig  0.044219  0.776133  0.441226   0.008632  0.836916  0.009453\n",
      "1  Greifswald  0.022229  0.592021  0.373617   0.003746  0.755808  0.004283\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m logistic_regression \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mlogistic_regression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m times\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(evaluation\u001b[38;5;241m.\u001b[39mget_df_metrics(logistic_regression))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1216\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1211\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1212\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m > 1 does not have any effect when\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs))\n\u001b[1;32m   1215\u001b[0m         )\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1188\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(classes_) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1182\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1183\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1185\u001b[0m             \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1186\u001b[0m         )\n\u001b[0;32m-> 1188\u001b[0m     class_weight_ \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1190\u001b[0m     class_weight_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/class_weight.py:42\u001b[0m, in \u001b[0;36mcompute_class_weight\u001b[0;34m(class_weight, classes, y)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Import error caused by circular imports.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(classes):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses should include all valid labels that can be in y\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_weight) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# uniform class weights\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\")\n",
    "dfs, times = error_evaluation(logistic_regression)\n",
    "for t in times:\n",
    "    print(t)\n",
    "for df in dfs:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a96b26",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.790726661682129\n",
      "1.895261287689209\n",
      "1.9152584075927734\n",
      "2.2044918537139893\n",
      "2.091141700744629\n",
      "1.9341957569122314\n",
      "1.8977007865905762\n",
      "1.9537184238433838\n",
      "2.0247366428375244\n",
      "1.8892550468444824\n",
      "1.939300775527954\n",
      "1.989821434020996\n",
      "1.9349770545959473\n",
      "1.954049825668335\n",
      "1.9736316204071045\n",
      "1.9414918422698975\n",
      "1.9420883655548096\n",
      "1.9330363273620605\n",
      "1.913193702697754\n",
      "1.9454751014709473\n",
      "1.9649560451507568\n",
      "1.9658725261688232\n",
      "2.0409762859344482\n",
      "1.9395778179168701\n",
      "2.0995023250579834\n",
      "1.9508686065673828\n",
      "1.8999097347259521\n",
      "1.9458014965057373\n",
      "2.144897222518921\n",
      "1.957744836807251\n",
      "1.9391870498657227\n",
      "2.0065319538116455\n",
      "1.9260077476501465\n",
      "1.91782808303833\n",
      "1.958606243133545\n",
      "2.0700862407684326\n",
      "2.0420680046081543\n",
      "2.119338274002075\n",
      "2.066373825073242\n",
      "1.9027915000915527\n",
      "2.0001494884490967\n",
      "1.985048532485962\n",
      "1.9693899154663086\n",
      "2.055448532104492\n",
      "1.9297590255737305\n",
      "2.009004831314087\n",
      "1.902858018875122\n",
      "1.9902453422546387\n",
      "1.9500370025634766\n",
      "2.1391332149505615\n",
      "1.9570109844207764\n",
      "2.083777666091919\n",
      "2.0748980045318604\n",
      "2.2145817279815674\n",
      "1.9805049896240234\n",
      "1.968590497970581\n",
      "1.9143121242523193\n",
      "1.9229958057403564\n",
      "2.006770610809326\n",
      "1.930290699005127\n",
      "2.1482105255126953\n",
      "1.9766638278961182\n",
      "1.976189374923706\n",
      "2.1826083660125732\n",
      "2.011185884475708\n",
      "2.1447415351867676\n",
      "1.966559648513794\n",
      "1.985342264175415\n",
      "2.068824052810669\n",
      "2.1197028160095215\n",
      "1.9071929454803467\n",
      "1.9535717964172363\n",
      "1.9280378818511963\n",
      "1.889822244644165\n",
      "2.2491722106933594\n",
      "1.971867322921753\n",
      "1.982175350189209\n",
      "1.9388635158538818\n",
      "1.961362361907959\n",
      "2.011773109436035\n",
      "2.029130458831787\n",
      "1.950432300567627\n",
      "1.9054808616638184\n",
      "1.9993507862091064\n",
      "1.9536538124084473\n",
      "2.0798444747924805\n",
      "1.9755539894104004\n",
      "2.122422218322754\n",
      "2.1207685470581055\n",
      "2.1841838359832764\n",
      "2.260789632797241\n",
      "1.9390182495117188\n",
      "1.94114351272583\n",
      "1.993870496749878\n",
      "1.9483280181884766\n",
      "1.9919226169586182\n",
      "1.971360445022583\n",
      "1.9649379253387451\n",
      "1.9440107345581055\n",
      "1.9169878959655762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(class_weight=\"balanced\", max_features=6, min_samples_leaf=0.005,\n",
    "                           min_samples_split=0.03)\n",
    "dfs, times = error_evaluation(decision_tree)\n",
    "for t in times:\n",
    "    print(t)\n",
    "for df in dfs:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(class_weight={0: 0.0025, 1: 1}, max_leaf_nodes=79,\n",
    "                           min_samples_leaf=0.0001,\n",
    "                           min_samples_split=0.0055,\n",
    "                           n_estimators=500)\n",
    "dfs, times = error_evaluation(random_forest)\n",
    "for t in times:\n",
    "    print(t)\n",
    "for df in dfs:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c091164d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4686625003814697\n",
      "1.357051134109497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 18\u001b[0m\n\u001b[1;32m      7\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      8\u001b[0m xgb_classifier \u001b[38;5;241m=\u001b[39m XGBClassifier(tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      9\u001b[0m                                scale_pos_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m660\u001b[39m,\n\u001b[1;32m     10\u001b[0m                                n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m478\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m                                n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     17\u001b[0m                                sampling_method\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m xgb_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m times\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1516\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m (\n\u001b[1;32m   1489\u001b[0m     model,\n\u001b[1;32m   1490\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1495\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1496\u001b[0m )\n\u001b[1;32m   1497\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1498\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1499\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1513\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1514\u001b[0m )\n\u001b[0;32m-> 1516\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1531\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_classifier = XGBClassifier(tree_method='gpu_hist', \n",
    "                           scale_pos_weight = 660,\n",
    "                           n_estimators=478,\n",
    "                           max_depth=2,\n",
    "                           eta=0.1,\n",
    "                           min_child_weight = 7,\n",
    "                           max_delta_step= 7,\n",
    "                           sampling_method= \"uniform\")\n",
    "dfs, times = error_evaluation(xgb_classifier)\n",
    "for t in times:\n",
    "    print(t)\n",
    "for df in dfs:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b9ccb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/imblearn/ensemble/_weight_boosting.py:267: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212.80669856071472\n",
      "213.4507348537445\n",
      "212.23464679718018\n",
      "212.12417268753052\n",
      "213.36931443214417\n",
      "212.02927899360657\n",
      "212.96053218841553\n",
      "212.31859731674194\n",
      "212.1862998008728\n",
      "212.12298488616943\n",
      "212.3644540309906\n",
      "212.12335085868835\n",
      "212.1904594898224\n",
      "213.21189737319946\n",
      "212.82231521606445\n",
      "213.55142450332642\n",
      "213.32531428337097\n",
      "213.05789136886597\n",
      "212.23580527305603\n",
      "213.68876838684082\n",
      "213.27694010734558\n",
      "212.97632837295532\n",
      "212.68570375442505\n",
      "212.81492066383362\n",
      "212.35430431365967\n",
      "213.45025944709778\n",
      "213.0778956413269\n",
      "212.54280638694763\n",
      "212.404123544693\n",
      "212.53400325775146\n",
      "213.44843578338623\n",
      "212.71002984046936\n",
      "212.42657136917114\n",
      "213.43835377693176\n",
      "212.78365683555603\n",
      "212.79709005355835\n",
      "213.2215883731842\n",
      "213.04196643829346\n",
      "212.86992645263672\n",
      "212.91684246063232\n",
      "213.02313423156738\n",
      "213.6568727493286\n",
      "212.66013503074646\n",
      "213.29742813110352\n",
      "212.93948006629944\n",
      "213.4748980998993\n",
      "213.34142541885376\n",
      "212.77809381484985\n",
      "213.2726650238037\n",
      "212.5645694732666\n",
      "212.9171178340912\n",
      "212.41726398468018\n",
      "212.41516089439392\n",
      "213.36177730560303\n",
      "213.70021176338196\n",
      "213.59462475776672\n",
      "213.50838947296143\n",
      "212.97838401794434\n",
      "213.03400993347168\n",
      "212.41145181655884\n",
      "213.10184931755066\n",
      "212.74899792671204\n",
      "213.0098900794983\n",
      "212.12645387649536\n",
      "213.6804120540619\n",
      "212.35733771324158\n",
      "212.6037745475769\n",
      "212.67837381362915\n",
      "212.9067771434784\n",
      "212.65598034858704\n",
      "212.37844896316528\n",
      "212.96525025367737\n",
      "212.72751569747925\n",
      "213.03811836242676\n",
      "212.6974697113037\n",
      "213.21225261688232\n",
      "213.26558208465576\n",
      "212.64328122138977\n",
      "213.9002833366394\n",
      "213.36703753471375\n",
      "212.2157199382782\n",
      "213.4893617630005\n",
      "212.11910319328308\n",
      "213.1270341873169\n",
      "212.3634533882141\n",
      "213.73165798187256\n",
      "213.04742527008057\n",
      "213.36995458602905\n",
      "213.9703779220581\n",
      "213.3320233821869\n",
      "212.38014435768127\n",
      "212.27845740318298\n",
      "213.05445313453674\n",
      "213.0626995563507\n",
      "212.84045457839966\n",
      "212.88682579994202\n",
      "212.17969512939453\n",
      "212.52244067192078\n",
      "212.47792601585388\n",
      "211.7775797843933\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rus_boost = RUSBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=79, min_samples_leaf= 5, min_samples_split = 10),\n",
    "                   learning_rate=0.90369, n_estimators=495, sampling_strategy=35/65)\n",
    "dfs, times = error_evaluation(rus_boost)\n",
    "for t in times:\n",
    "    print(t)\n",
    "for df in dfs:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e1809e",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a580573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def get_best_estimator(model, param_grid):\n",
    "    grid = GridSearchCV(\n",
    "    n_jobs=-1,\n",
    "    cv=10,\n",
    "    estimator=model,\n",
    "    scoring='roc_auc',\n",
    "    refit='auroc',\n",
    "    return_train_score=True,\n",
    "    param_grid=param_grid,\n",
    "    verbose= 10\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_estimator_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630b003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 3/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 4/10; 3/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 8/144] START class_weight=balanced, max_iter=100, penalty=None, solver=saga\n",
      "[CV 1/10; 8/144] END class_weight=balanced, max_iter=100, penalty=None, solver=saga;, score=(train=0.833, test=0.838) total time= 1.7min\n",
      "[CV 6/10; 17/144] START class_weight=balanced, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 6/10; 17/144] END class_weight=balanced, max_iter=1000, penalty=l2, solver=saga;, score=(train=0.835, test=0.832) total time=19.1min\n",
      "[CV 7/10; 33/144] START class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 7/10; 33/144] END class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=0.834, test=0.861) total time=   2.0s\n",
      "[CV 1/10; 34/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 34/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 34/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 34/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 34/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 34/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 34/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 34/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 34/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 34/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 34/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 34/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 34/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 34/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 34/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 34/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 34/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 34/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 34/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 34/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 35/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 35/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.5s\n",
      "[CV 4/10; 35/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 35/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.6s\n",
      "[CV 8/10; 35/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 35/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.5s\n",
      "[CV 4/10; 36/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 36/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 36/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 36/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 36/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 36/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 37/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 3/10; 37/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 37/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 7/10; 37/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 37/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 37/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 38/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 3/10; 38/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 38/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 6/10; 38/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 39/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 1/10; 39/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 39/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 6/10; 39/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 40/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 2/10; 40/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 40/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 4/10; 40/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 40/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 8/10; 40/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 41/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 2/10; 41/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 41/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 6/10; 41/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 41/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 10/10; 41/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 42/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 3/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 3/10; 3/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 8/144] START class_weight=balanced, max_iter=100, penalty=None, solver=saga\n",
      "[CV 2/10; 8/144] END class_weight=balanced, max_iter=100, penalty=None, solver=saga;, score=(train=0.831, test=0.855) total time= 1.8min\n",
      "[CV 1/10; 19/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 1/10; 19/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 4/10; 19/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 4/10; 19/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 8/10; 19/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 8/10; 19/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.3s\n",
      "[CV 6/10; 20/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 6/10; 20/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=saga;, score=(train=0.835, test=0.832) total time=19.0min\n",
      "[CV 2/10; 33/144] START class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 33/144] END class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=0.834, test=0.855) total time=   2.0s\n",
      "[CV 6/10; 33/144] START class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 33/144] END class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=0.837, test=0.836) total time=   2.0s\n",
      "[CV 10/10; 33/144] START class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 10/10; 33/144] END class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=0.833, test=0.866) total time=   2.3s\n",
      "[CV 1/10; 36/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 36/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 36/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 36/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 36/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 36/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 36/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 36/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 36/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 36/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 37/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 2/10; 37/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 37/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 37/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 37/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 37/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 38/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 2/10; 38/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 38/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 7/10; 38/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 39/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 4/10; 39/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 39/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 8/10; 39/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 39/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 10/10; 39/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 40/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 5/10; 40/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 40/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 10/10; 40/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 41/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 4/10; 41/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 41/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 9/10; 41/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 42/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 1/10; 42/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 42/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 6/10; 42/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 42/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 10/10; 42/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 43/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 2/10; 43/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 43/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 6/10; 43/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 44/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga\n",
      "[CV 1/10; 44/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 44/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga\n",
      "[CV 5/10; 44/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10; 4/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 9/10; 4/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=liblinear;, score=(train=0.838, test=0.816) total time=  17.0s\n",
      "[CV 10/10; 14/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 10/10; 14/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=saga;, score=(train=0.832, test=0.861) total time=20.5min\n",
      "[CV 1/10; 33/144] START class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 33/144] END class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=0.836, test=0.838) total time=   1.7s\n",
      "[CV 3/10; 33/144] START class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 33/144] END class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=0.839, test=0.816) total time=   1.7s\n",
      "[CV 4/10; 33/144] START class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 33/144] END class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=0.839, test=0.814) total time=   2.0s\n",
      "[CV 9/10; 33/144] START class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 9/10; 33/144] END class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=0.838, test=0.816) total time=   1.8s\n",
      "[CV 3/10; 35/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 35/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 6/10; 35/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 35/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.5s\n",
      "[CV 9/10; 35/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 35/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 10/10; 36/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 36/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 37/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 6/10; 37/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 37/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 37/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 38/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 4/10; 38/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 38/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 8/10; 38/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 38/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 10/10; 38/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 39/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 3/10; 39/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 39/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 7/10; 39/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 40/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 3/10; 40/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 40/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 7/10; 40/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 40/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 9/10; 40/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 41/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 1/10; 41/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 41/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 5/10; 41/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 41/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 8/10; 41/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 42/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 42/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 42/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 42/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 43/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 3/10; 43/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 43/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 8/10; 43/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 43/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 10/10; 43/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 44/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga\n",
      "[CV 3/10; 44/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 44/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga\n",
      "[CV 9/10; 44/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 45/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 45/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 45/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 7/10; 45/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 45/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 10/10; 45/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 5/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 9/10; 5/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=saga;, score=(train=0.835, test=0.820) total time= 1.8min\n",
      "[CV 2/10; 20/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 2/10; 20/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=saga;, score=(train=0.832, test=0.854) total time=19.0min\n",
      "[CV 5/10; 33/144] START class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 33/144] END class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=0.838, test=0.830) total time=   1.8s\n",
      "[CV 8/10; 33/144] START class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 33/144] END class_weight=balanced, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=0.838, test=0.820) total time=   1.9s\n",
      "[CV 2/10; 35/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 35/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 5/10; 35/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 35/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 7/10; 35/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 35/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 10/10; 35/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 35/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 8/10; 36/144] START class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 36/144] END class_weight=balanced, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 37/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 37/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 37/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 37/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 38/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 1/10; 38/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 38/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 5/10; 38/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 38/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 9/10; 38/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 39/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 2/10; 39/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 39/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 5/10; 39/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 39/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 9/10; 39/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 40/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 1/10; 40/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 40/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 6/10; 40/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 41/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 3/10; 41/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 41/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 7/10; 41/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 42/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 42/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 42/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 5/10; 42/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 42/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 9/10; 42/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 43/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 4/10; 43/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 43/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 7/10; 43/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 44/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga\n",
      "[CV 2/10; 44/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 44/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga\n",
      "[CV 6/10; 44/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 45/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 45/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 45/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 45/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 46/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 46/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 46/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 46/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 46/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 46/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 42/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 42/144] START class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 7/10; 42/144] END class_weight=0.5384615384615384, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 43/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 1/10; 43/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 43/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 5/10; 43/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 43/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 9/10; 43/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 44/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga\n",
      "[CV 4/10; 44/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 44/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga\n",
      "[CV 7/10; 44/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 44/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga\n",
      "[CV 10/10; 44/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 45/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 45/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 45/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 45/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 46/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 46/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 46/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 46/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 46/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 46/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 46/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 46/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 47/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 47/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 47/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 47/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 47/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 47/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 48/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 48/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 48/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 48/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 49/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 2/10; 49/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 49/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 6/10; 49/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 49/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 49/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 50/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 3/10; 50/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 50/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 7/10; 50/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 50/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 8/10; 50/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 51/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 2/10; 51/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 51/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 5/10; 51/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 51/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 9/10; 51/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 52/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 6/10; 52/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 53/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 1/10; 53/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 1/10; 54/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 1/10; 54/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 54/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 5/10; 54/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 54/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 44/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga\n",
      "[CV 8/10; 44/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 45/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 45/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 45/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 45/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 45/144] START class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 9/10; 45/144] END class_weight=0.5384615384615384, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 46/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 46/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 46/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 46/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 47/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 47/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 47/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 47/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 48/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 48/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 48/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 48/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 49/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 3/10; 49/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 49/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 49/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 50/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 2/10; 50/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 50/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 5/10; 50/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 50/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 10/10; 50/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 51/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 6/10; 51/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 52/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 2/10; 52/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 52/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 5/10; 52/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 4/10; 53/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 4/10; 53/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 53/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 6/10; 53/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 53/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 10/10; 53/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 54/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 54/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 54/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 54/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 54/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 10/10; 54/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 55/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 4/10; 55/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 55/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 8/10; 55/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 56/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 7/10; 56/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 57/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 57/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 57/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 57/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 58/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 58/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 58/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 58/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 59/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 59/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10; 46/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 46/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 47/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 47/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 47/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 47/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 47/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 47/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 48/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 48/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 48/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 48/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 48/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 48/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 49/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 49/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 49/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 49/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 49/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 49/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 50/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 4/10; 50/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 51/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 1/10; 51/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 51/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 7/10; 51/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 52/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 1/10; 52/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 52/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 7/10; 52/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 53/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 2/10; 53/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 53/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 5/10; 53/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 53/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 9/10; 53/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 54/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 4/10; 54/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 55/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 2/10; 55/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 55/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 7/10; 55/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 56/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 2/10; 56/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 56/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 6/10; 56/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 56/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 9/10; 56/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 57/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 57/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 57/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 9/10; 57/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 58/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 58/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 59/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 59/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 60/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 60/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 60/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 60/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 61/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 61/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 61/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 6/10; 61/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 47/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 47/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 47/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 47/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 48/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 48/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 48/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 48/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 48/144] START class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 48/144] END class_weight=0.5384615384615384, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 49/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 49/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 49/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 7/10; 49/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 50/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 1/10; 50/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 50/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 6/10; 50/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 50/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 9/10; 50/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 51/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 3/10; 51/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 51/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 10/10; 51/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 52/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 3/10; 52/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 52/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 8/10; 52/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 52/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 10/10; 52/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 53/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 7/10; 53/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 54/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 6/10; 54/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 55/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 3/10; 55/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 55/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 9/10; 55/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 56/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 3/10; 56/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 56/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 10/10; 56/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 57/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 57/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 57/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 10/10; 57/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 58/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 58/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 59/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 59/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 59/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 59/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 60/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 60/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 60/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 60/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 61/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 7/10; 61/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 62/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 2/10; 62/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 62/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 8/10; 62/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 63/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 4/10; 63/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 2/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 4/10; 2/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=saga;, score=(train=0.836, test=0.820) total time= 1.8min\n",
      "[CV 2/10; 19/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 2/10; 19/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 5/10; 19/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 5/10; 19/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.5s\n",
      "[CV 3/10; 20/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 3/10; 20/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=saga;, score=(train=0.838, test=0.807) total time=19.2min\n",
      "[CV 4/10; 51/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 4/10; 51/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 51/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 8/10; 51/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 52/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 4/10; 52/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 52/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 9/10; 52/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 53/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 3/10; 53/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 53/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 8/10; 53/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 54/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 54/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 54/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 7/10; 54/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 55/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 1/10; 55/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 55/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 6/10; 55/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 56/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 1/10; 56/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 56/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 4/10; 56/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 56/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 8/10; 56/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 57/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 57/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 57/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 57/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 58/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 58/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 58/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 58/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 59/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 59/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 60/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 60/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 61/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 2/10; 61/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 61/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 61/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 62/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 7/10; 62/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 63/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 3/10; 63/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 63/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 8/10; 63/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 64/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 3/10; 64/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 65/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 1/10; 65/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 65/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 7/10; 65/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 66/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 66/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 66/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10; 54/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 55/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 5/10; 55/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 55/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 10/10; 55/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 56/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 5/10; 56/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 57/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 57/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 58/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 58/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 58/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 58/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 59/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 59/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 59/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 59/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 60/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 60/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 60/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 60/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 61/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 3/10; 61/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 61/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 61/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 62/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 3/10; 62/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 62/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 9/10; 62/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 63/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 5/10; 63/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 63/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 10/10; 63/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 64/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 6/10; 64/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 65/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 4/10; 65/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 65/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 10/10; 65/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 66/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 6/10; 66/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 66/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 10/10; 66/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 67/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 6/10; 67/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 68/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 2/10; 68/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 68/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 6/10; 68/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 69/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 69/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 69/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 69/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 70/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 70/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 71/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 71/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 71/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 71/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 72/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 72/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 72/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 72/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10; 5/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 5/10; 5/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=saga;, score=(train=0.836, test=0.822) total time= 1.7min\n",
      "[CV 8/10; 17/144] START class_weight=balanced, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 8/10; 17/144] END class_weight=balanced, max_iter=1000, penalty=l2, solver=saga;, score=(train=0.836, test=0.821) total time=19.3min\n",
      "[CV 7/10; 57/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 7/10; 57/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 58/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 58/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 58/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 58/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 59/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 59/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 59/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 59/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 60/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 60/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 60/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 60/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 61/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 61/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 62/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 4/10; 62/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 62/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 10/10; 62/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 63/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 6/10; 63/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 64/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 1/10; 64/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 64/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 9/10; 64/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 65/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 6/10; 65/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 66/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 66/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 66/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 66/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 67/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 3/10; 67/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 67/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 8/10; 67/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 68/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 4/10; 68/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 69/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 69/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 69/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 10/10; 69/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 70/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 70/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 71/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 71/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 72/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 72/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 72/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 72/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 73/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 3/10; 73/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 73/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 73/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 74/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 3/10; 74/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 74/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 10/10; 74/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 75/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 7/10; 75/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 9/10; 59/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 59/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 60/144] START class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 60/144] END class_weight=0.5384615384615384, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 61/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 61/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 61/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 61/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 62/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 5/10; 62/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 63/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 2/10; 63/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 63/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 9/10; 63/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 64/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 4/10; 64/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 64/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 8/10; 64/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 65/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 3/10; 65/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 65/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 8/10; 65/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 66/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 4/10; 66/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 67/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 1/10; 67/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 67/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 7/10; 67/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 68/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 3/10; 68/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 68/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 8/10; 68/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 69/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 69/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 69/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 9/10; 69/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 70/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 70/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 71/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 71/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 71/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 71/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 72/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 72/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 73/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 73/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 74/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 4/10; 74/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 75/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 1/10; 75/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 75/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 8/10; 75/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 76/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 8/10; 76/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 77/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 8/10; 77/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 78/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 5/10; 78/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 79/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 3/10; 79/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 79/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 8/10; 79/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 80/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga\n",
      "[CV 5/10; 80/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10; 62/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 1/10; 62/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 62/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 6/10; 62/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 63/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 1/10; 63/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 63/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 7/10; 63/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 64/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 5/10; 64/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 64/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 10/10; 64/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 65/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 5/10; 65/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 66/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 1/10; 66/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 66/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 9/10; 66/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 67/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 5/10; 67/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 68/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 1/10; 68/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 68/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 7/10; 68/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 68/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 10/10; 68/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 69/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 69/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 70/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 70/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 70/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 70/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 71/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 71/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 71/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 71/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 72/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 72/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 73/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 6/10; 73/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 74/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 1/10; 74/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 74/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 7/10; 74/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 75/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 5/10; 75/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 75/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 10/10; 75/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 76/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 5/10; 76/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 77/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 1/10; 77/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 77/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 9/10; 77/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 79/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 1/10; 79/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 80/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga\n",
      "[CV 2/10; 80/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 80/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga\n",
      "[CV 9/10; 80/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 81/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 10/10; 81/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 82/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 82/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 64/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 2/10; 64/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 64/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 7/10; 64/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 65/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 2/10; 65/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 65/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 9/10; 65/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 66/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 5/10; 66/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 67/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 2/10; 67/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 67/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 10/10; 67/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 68/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 5/10; 68/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 69/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 69/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 69/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 7/10; 69/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 70/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 70/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 70/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 70/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 70/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 70/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 71/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 71/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 71/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 71/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 72/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 72/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 73/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 73/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 74/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 5/10; 74/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 75/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 3/10; 75/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 76/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 3/10; 76/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 76/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 10/10; 76/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 77/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 6/10; 77/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 78/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 4/10; 78/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 78/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 78/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 79/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 6/10; 79/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 80/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga\n",
      "[CV 6/10; 80/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 81/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 81/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 81/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 9/10; 81/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 82/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 82/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 83/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 83/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 84/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 84/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 85/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 85/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 66/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 67/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 4/10; 67/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 67/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 9/10; 67/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 68/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 9/10; 68/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 69/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 69/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 70/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 70/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 70/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 70/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 71/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 71/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 2/10; 72/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 72/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 72/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 72/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 73/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 73/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 74/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 2/10; 74/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 74/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 9/10; 74/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 75/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 6/10; 75/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 76/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 2/10; 76/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 77/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 3/10; 77/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 9/10; 78/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 9/10; 78/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 80/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga\n",
      "[CV 3/10; 80/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 80/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga\n",
      "[CV 8/10; 80/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 81/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 81/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 82/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 82/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 83/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 83/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 84/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 84/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 84/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 84/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 85/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 6/10; 85/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 86/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 5/10; 86/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 7/10; 87/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 7/10; 87/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 88/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 10/10; 88/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 89/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 9/10; 89/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 90/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 5/10; 90/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 91/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 7/10; 91/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 92/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 6/10; 92/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 93/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 5/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 1/10; 5/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=saga;, score=(train=0.833, test=0.838) total time= 1.7min\n",
      "[CV 7/10; 17/144] START class_weight=balanced, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 7/10; 17/144] END class_weight=balanced, max_iter=1000, penalty=l2, solver=saga;, score=(train=0.832, test=0.864) total time=19.3min\n",
      "[CV 4/10; 72/144] START class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 72/144] END class_weight=0.5384615384615384, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 73/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 2/10; 73/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 73/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 73/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 73/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 73/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 74/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 6/10; 74/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 75/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 2/10; 75/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 76/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 1/10; 76/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 76/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 7/10; 76/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 77/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 5/10; 77/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 78/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 1/10; 78/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 78/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 6/10; 78/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 79/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 4/10; 79/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 80/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga\n",
      "[CV 1/10; 80/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 81/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 81/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 82/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 82/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 82/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 82/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 83/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 83/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 84/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 84/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 85/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 85/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 86/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 10/10; 86/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 87/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 8/10; 87/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 88/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 3/10; 88/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 89/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 1/10; 89/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 89/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 6/10; 89/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 90/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 6/10; 90/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 91/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 5/10; 91/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 92/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 4/10; 92/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 93/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 93/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 94/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 94/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 95/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 95/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 95/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 73/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 7/10; 73/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 74/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 8/10; 74/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 75/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 4/10; 75/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 75/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 9/10; 75/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 76/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 6/10; 76/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 77/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 4/10; 77/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 78/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 78/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 78/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 7/10; 78/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 79/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 5/10; 79/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 79/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 9/10; 79/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 80/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga\n",
      "[CV 7/10; 80/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 81/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 81/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 82/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 82/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 83/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 83/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 83/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 83/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 84/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 84/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 85/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 7/10; 85/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 86/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 6/10; 86/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 87/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 4/10; 87/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 88/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 2/10; 88/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 89/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 4/10; 89/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 90/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 1/10; 90/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 91/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 2/10; 91/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 92/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 8/10; 92/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 93/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 93/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 94/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 94/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 95/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 95/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 96/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 96/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 97/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 97/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 98/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 4/10; 98/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 99/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 2/10; 99/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 100/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 1/10; 100/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 77/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 2/10; 77/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 77/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 10/10; 77/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 78/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 10/10; 78/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 79/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 7/10; 79/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 79/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 10/10; 79/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 80/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga\n",
      "[CV 10/10; 80/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 81/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 7/10; 81/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 82/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 82/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 83/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 83/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 84/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 84/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 85/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 85/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 85/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 85/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 87/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 1/10; 87/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 87/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 9/10; 87/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 88/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 7/10; 88/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 89/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 7/10; 89/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 89/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 10/10; 89/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 90/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 7/10; 90/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 91/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 6/10; 91/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 92/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 7/10; 92/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 93/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 93/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 94/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 94/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 95/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 95/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 95/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 95/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 96/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 96/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 97/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 7/10; 97/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 98/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 5/10; 98/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 99/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 5/10; 99/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 100/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 3/10; 100/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 100/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 10/10; 100/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 102/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 1/10; 102/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 102/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 9/10; 102/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 3/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 2/10; 3/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 7/144] START class_weight=balanced, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 7/10; 7/144] END class_weight=balanced, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 5/10; 8/144] START class_weight=balanced, max_iter=100, penalty=None, solver=saga\n",
      "[CV 5/10; 8/144] END class_weight=balanced, max_iter=100, penalty=None, solver=saga;, score=(train=0.835, test=0.822) total time= 1.8min\n",
      "[CV 3/10; 18/144] START class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 18/144] END class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=0.839, test=0.816) total time=   2.1s\n",
      "[CV 7/10; 20/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 7/10; 20/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=saga;, score=(train=0.832, test=0.864) total time=19.3min\n",
      "[CV 8/10; 81/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 81/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 82/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 82/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 83/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 83/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 84/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 84/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 85/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 2/10; 85/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 86/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 1/10; 86/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 86/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 8/10; 86/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 87/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 5/10; 87/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 88/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 5/10; 88/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 88/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 9/10; 88/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 89/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 8/10; 89/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 90/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 90/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 91/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 8/10; 91/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 92/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 5/10; 92/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 93/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 93/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 94/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 94/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 95/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 95/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 95/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 95/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 96/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 96/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 97/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 97/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 98/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 7/10; 98/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 99/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 4/10; 99/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 100/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 4/10; 100/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 101/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 5/10; 101/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 102/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 102/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 103/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 2/10; 103/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 103/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 9/10; 103/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 104/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 5/10; 2/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 5/10; 2/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=saga;, score=(train=0.830, test=0.817) total time= 1.8min\n",
      "[CV 4/10; 18/144] START class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 4/10; 18/144] END class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=0.839, test=0.814) total time=   2.3s\n",
      "[CV 10/10; 20/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 10/10; 20/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=saga;, score=(train=0.832, test=0.861) total time=19.2min\n",
      "[CV 4/10; 76/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 4/10; 76/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 76/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 9/10; 76/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 77/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 7/10; 77/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 78/144] START class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 78/144] END class_weight=0.6666666666666666, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 79/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 2/10; 79/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 80/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga\n",
      "[CV 4/10; 80/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 81/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 81/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 82/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 82/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 83/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 83/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 84/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 84/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 85/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 3/10; 85/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 86/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 2/10; 86/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 87/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 3/10; 87/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 88/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 6/10; 88/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 90/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 9/10; 90/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 91/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 3/10; 91/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 92/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 1/10; 92/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 92/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 9/10; 92/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 93/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 9/10; 93/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 94/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 94/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 95/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 95/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 96/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 96/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 97/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 6/10; 97/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 98/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 6/10; 98/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 99/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 6/10; 99/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 100/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 6/10; 100/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 101/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 3/10; 101/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 101/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 8/10; 101/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 102/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 5/10; 102/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 103/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10; 81/144] START class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 81/144] END class_weight=0.6666666666666666, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 82/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 82/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 83/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 83/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 84/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 84/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 85/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 85/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 86/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 4/10; 86/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 86/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 9/10; 86/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 87/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 6/10; 87/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 88/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 1/10; 88/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 89/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 3/10; 89/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 90/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 4/10; 90/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 91/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 4/10; 91/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 92/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 2/10; 92/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 7/10; 93/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 7/10; 93/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 94/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 94/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 95/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 95/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 96/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 96/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 97/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 97/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 98/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 2/10; 98/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 99/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 3/10; 99/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 100/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 2/10; 100/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 100/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 9/10; 100/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 101/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 9/10; 101/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 102/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 102/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 103/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 3/10; 103/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 104/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 5/10; 104/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 105/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 105/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 106/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 106/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 107/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 107/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 107/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 107/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 108/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 108/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 109/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 83/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 83/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 84/144] START class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 84/144] END class_weight=0.6666666666666666, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 85/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 85/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 86/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 7/10; 86/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 87/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 10/10; 87/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 89/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 2/10; 89/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 90/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 90/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 90/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 10/10; 90/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 91/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 9/10; 91/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 92/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 10/10; 92/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 93/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 93/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 94/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 94/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 95/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 95/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 96/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 96/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 97/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 2/10; 97/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 98/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 3/10; 98/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 99/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 1/10; 99/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 99/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 10/10; 99/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 101/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 1/10; 101/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 101/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 10/10; 101/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 102/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 10/10; 102/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 103/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 6/10; 103/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 7/10; 104/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 7/10; 104/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 106/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 106/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 107/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 107/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 108/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 108/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 108/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 108/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 109/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 7/10; 109/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 110/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 6/10; 110/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 111/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 5/10; 111/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 112/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 2/10; 112/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 113/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10; 86/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 3/10; 86/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 87/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 2/10; 87/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 88/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 4/10; 88/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 88/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 8/10; 88/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 89/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 5/10; 89/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 90/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 90/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 91/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 1/10; 91/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 91/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 10/10; 91/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 92/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 3/10; 92/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 93/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 93/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 93/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 10/10; 93/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 94/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 94/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 96/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 96/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 97/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 97/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 97/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 97/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 98/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 8/10; 98/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 99/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 9/10; 99/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 100/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 7/10; 100/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 101/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 7/10; 101/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 102/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 7/10; 102/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 103/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 4/10; 103/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 104/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 9/10; 104/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 105/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 10/10; 105/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 106/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 106/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 107/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 107/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 109/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 109/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 109/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 109/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 110/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 7/10; 110/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 111/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 7/10; 111/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 112/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 7/10; 112/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 113/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 4/10; 113/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 114/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 4/10; 114/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 93/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 94/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 94/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 94/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 94/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 96/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 96/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 96/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 96/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 97/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 3/10; 97/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 98/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 1/10; 98/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 98/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 10/10; 98/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 99/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 8/10; 99/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 100/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 5/10; 100/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 101/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 4/10; 101/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 4/10; 102/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 4/10; 102/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 103/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 5/10; 103/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 10/10; 104/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 10/10; 104/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 105/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 7/10; 105/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 106/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 106/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 107/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 107/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 108/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 108/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 109/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 3/10; 109/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 110/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 4/10; 110/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 111/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 4/10; 111/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 112/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 4/10; 112/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 113/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 7/10; 113/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 114/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 10/10; 114/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 115/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 9/10; 115/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 116/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga\n",
      "[CV 10/10; 116/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 118/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 118/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 119/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 119/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 120/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 120/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 121/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 6/10; 121/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 122/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 9/10; 122/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 124/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 1/10; 124/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10; 95/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 96/144] START class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 96/144] END class_weight=0.6666666666666666, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 97/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 97/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 98/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 9/10; 98/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 99/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 7/10; 99/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 100/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 8/10; 100/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 101/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 6/10; 101/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 102/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 102/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 103/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 7/10; 103/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 104/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 2/10; 104/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 105/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 105/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 106/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 106/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 107/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 107/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 108/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 108/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 110/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 1/10; 110/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 111/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 3/10; 111/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 112/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 5/10; 112/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 113/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 6/10; 113/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 114/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 5/10; 114/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 115/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 6/10; 115/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 116/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga\n",
      "[CV 4/10; 116/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 117/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 9/10; 117/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 119/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 119/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 120/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 120/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 121/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 121/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 122/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 1/10; 122/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 123/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 1/10; 123/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 123/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 8/10; 123/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 124/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 10/10; 124/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 126/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 1/10; 126/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 126/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 126/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 127/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 5/10; 127/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 5/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 2/10; 5/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=saga;, score=(train=0.831, test=0.855) total time= 1.8min\n",
      "[CV 2/10; 18/144] START class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 18/144] END class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=0.834, test=0.855) total time=   2.4s\n",
      "[CV 6/10; 19/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 6/10; 19/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 9/10; 19/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 9/10; 19/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 5/10; 20/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 5/10; 20/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=saga;, score=(train=0.836, test=0.824) total time=19.3min\n",
      "[CV 4/10; 104/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 4/10; 104/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 105/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 105/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 106/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 106/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 107/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 107/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 108/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 108/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 109/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 109/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 110/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 5/10; 110/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 111/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 6/10; 111/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 112/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 3/10; 112/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 113/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 2/10; 113/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 114/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 1/10; 114/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 115/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 1/10; 115/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 115/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 10/10; 115/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 116/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga\n",
      "[CV 9/10; 116/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 117/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 117/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 118/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 118/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 119/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 119/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 120/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 120/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 121/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 7/10; 121/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 122/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 8/10; 122/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 124/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 2/10; 124/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 125/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 2/10; 125/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 125/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 8/10; 125/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 126/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 10/10; 126/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 128/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 1/10; 128/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 129/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 129/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 130/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 130/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 131/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10; 103/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 10/10; 103/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 104/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 6/10; 104/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 105/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 105/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 106/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 106/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 107/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 107/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 108/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 108/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 109/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 109/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 110/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 10/10; 110/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 112/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 1/10; 112/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 113/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 3/10; 113/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 114/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 114/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 115/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 2/10; 115/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 116/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga\n",
      "[CV 2/10; 116/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 117/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 117/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 117/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 10/10; 117/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 118/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 118/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 119/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 119/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 120/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 120/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 121/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 121/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 122/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 6/10; 122/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 123/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 4/10; 123/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 124/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 4/10; 124/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 125/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 5/10; 125/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 126/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 126/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 126/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 9/10; 126/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 127/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 6/10; 127/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 128/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 6/10; 128/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 129/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 129/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 130/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 130/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 131/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 131/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 133/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 133/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 134/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 2/10; 101/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 2/10; 101/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 102/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 6/10; 102/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 103/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 1/10; 103/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 104/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 1/10; 104/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 105/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 105/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 106/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 106/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 108/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 108/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 108/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 108/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 109/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 109/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 110/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 8/10; 110/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 111/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 8/10; 111/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 112/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 9/10; 112/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 113/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 9/10; 113/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 114/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 9/10; 114/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 116/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga\n",
      "[CV 1/10; 116/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 117/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 117/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 118/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 118/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 118/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 118/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 119/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 119/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 121/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 121/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 122/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 4/10; 122/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 123/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 5/10; 123/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 125/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 1/10; 125/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 126/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 4/10; 126/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 127/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 4/10; 127/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 127/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 10/10; 127/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 128/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 8/10; 128/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 130/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 130/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 131/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 131/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 132/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 132/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 133/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 133/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 134/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 3/10; 104/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 104/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 8/10; 104/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 105/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 9/10; 105/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 106/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 106/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 107/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 107/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 109/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 2/10; 109/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 110/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 2/10; 110/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 111/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 1/10; 111/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 111/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 10/10; 111/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 112/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 10/10; 112/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 113/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 10/10; 113/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 114/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 7/10; 114/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 115/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 5/10; 115/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 116/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga\n",
      "[CV 7/10; 116/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 117/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 7/10; 117/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 118/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 118/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 119/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 119/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 120/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 120/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 121/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 121/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 122/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 10/10; 122/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 123/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 9/10; 123/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 124/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 8/10; 124/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 125/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 9/10; 125/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 127/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 2/10; 127/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 128/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 4/10; 128/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 129/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 129/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 130/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 130/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 130/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 130/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 131/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 131/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 132/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 132/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 133/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 133/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 134/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 6/10; 134/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10; 103/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 105/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 105/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 105/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 105/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 106/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 106/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 107/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 107/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 108/144] START class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 108/144] END class_weight=0.6666666666666666, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 109/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 109/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 110/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 3/10; 110/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 111/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 2/10; 111/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 112/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 6/10; 112/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 113/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 5/10; 113/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 114/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 6/10; 114/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 115/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 7/10; 115/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 116/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga\n",
      "[CV 5/10; 116/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 117/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 117/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 118/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 118/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 119/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 119/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 120/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 120/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 121/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 3/10; 121/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 122/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 2/10; 122/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 123/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 2/10; 123/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 124/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 3/10; 124/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 125/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 3/10; 125/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 126/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 5/10; 126/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 127/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 8/10; 127/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 128/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 9/10; 128/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 129/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 9/10; 129/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 130/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 130/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 132/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 132/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 133/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 3/10; 133/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 134/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 3/10; 134/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 135/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 3/10; 135/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 109/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 9/10; 110/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 9/10; 110/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 111/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 9/10; 111/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 112/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 8/10; 112/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 113/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 8/10; 113/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 114/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 114/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 115/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 8/10; 115/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 116/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga\n",
      "[CV 8/10; 116/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 117/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 117/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 118/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 118/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 119/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 119/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 120/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 120/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 121/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 2/10; 121/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 122/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 3/10; 122/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 123/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 3/10; 123/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 123/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 6/10; 123/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 124/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 5/10; 124/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 125/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 4/10; 125/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 126/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 126/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 127/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 1/10; 127/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 128/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 7/10; 128/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 129/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 7/10; 129/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 131/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 131/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 132/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 132/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 133/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 2/10; 133/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 134/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 2/10; 134/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 135/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 1/10; 135/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 136/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 1/10; 136/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 137/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 1/10; 137/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 138/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 4/10; 138/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 138/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 10/10; 138/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 139/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 8/10; 139/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 6/10; 140/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10; 140/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 141/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 141/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 143/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 143/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 144/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 144/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 113/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 114/144] START class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 114/144] END class_weight=0.8181818181818182, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 115/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 3/10; 115/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 116/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga\n",
      "[CV 3/10; 116/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 117/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 117/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 118/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 118/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 119/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 119/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 120/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 120/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 121/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 121/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 122/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 5/10; 122/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 123/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 7/10; 123/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 124/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 7/10; 124/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 125/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 7/10; 125/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 126/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 7/10; 126/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 127/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 7/10; 127/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 128/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 5/10; 128/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 129/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 129/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 130/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 130/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 131/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 131/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 132/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 132/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 133/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 7/10; 133/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 134/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 8/10; 134/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 135/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 8/10; 135/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 136/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 8/10; 136/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 137/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 8/10; 137/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 139/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 5/10; 139/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 140/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 9/10; 140/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 141/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 7/10; 141/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 142/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 142/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 143/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 143/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 144/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 144/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 136/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 2/10; 136/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 137/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 2/10; 137/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 137/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 9/10; 137/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 138/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 138/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 139/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 6/10; 139/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 140/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 7/10; 140/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 141/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 9/10; 141/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 142/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 142/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 143/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 143/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 144/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 144/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10; 131/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 132/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 132/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 133/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 133/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 134/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 4/10; 134/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 135/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 2/10; 135/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 136/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 3/10; 136/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 137/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 5/10; 137/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 138/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 3/10; 138/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 139/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 3/10; 139/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 139/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 9/10; 139/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 141/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 141/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 142/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 142/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 142/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 142/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 143/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 143/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 144/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 144/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 134/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 135/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 9/10; 135/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 136/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 9/10; 136/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 137/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 10/10; 137/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 138/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 9/10; 138/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 140/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 1/10; 140/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 141/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 141/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 142/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 142/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 143/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 143/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 144/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 144/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 115/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 4/10; 115/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 116/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga\n",
      "[CV 6/10; 116/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 117/144] START class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 117/144] END class_weight=0.8181818181818182, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 118/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 118/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 119/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 119/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 120/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 120/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 120/144] START class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 120/144] END class_weight=0.8181818181818182, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 121/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 121/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 122/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga\n",
      "[CV 7/10; 122/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 123/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky\n",
      "[CV 10/10; 123/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 124/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 6/10; 124/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/10; 125/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 6/10; 125/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 126/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 6/10; 126/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 127/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 9/10; 127/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 128/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 10/10; 128/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 129/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 10/10; 129/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 130/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 130/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 131/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 131/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 131/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 131/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 133/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 6/10; 133/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 134/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 9/10; 134/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 135/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 10/10; 135/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 136/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 10/10; 136/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 138/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 1/10; 138/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 139/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 2/10; 139/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 140/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 3/10; 140/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 141/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 141/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/10; 142/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 142/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 143/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 143/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 144/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 144/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 128/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 3/10; 128/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 129/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 129/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 129/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 129/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 130/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 130/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 131/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 131/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 132/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 132/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 132/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 132/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 133/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 133/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 134/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 7/10; 134/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 135/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 5/10; 135/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 136/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 4/10; 136/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/10; 137/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 3/10; 137/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 138/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 5/10; 138/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 139/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 4/10; 139/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 140/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 2/10; 140/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 141/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 141/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 142/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 142/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 143/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 143/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 144/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 144/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10; 134/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 135/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 4/10; 135/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 136/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 5/10; 136/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 137/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 4/10; 137/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 138/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 138/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 139/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 1/10; 139/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 140/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 4/10; 140/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 141/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 141/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 142/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 142/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 143/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 143/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 144/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 144/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 135/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 6/10; 135/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 136/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 6/10; 136/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 137/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 6/10; 137/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 138/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 6/10; 138/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 139/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 10/10; 139/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 140/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 8/10; 140/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 141/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 141/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 142/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 142/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 143/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 143/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 144/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 144/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 124/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear\n",
      "[CV 9/10; 124/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 125/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 10/10; 125/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 127/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 3/10; 127/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 128/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 2/10; 128/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 129/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 129/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 130/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 130/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 131/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 131/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 132/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 132/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 132/144] START class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 132/144] END class_weight=0.8181818181818182, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 133/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 133/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 134/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga\n",
      "[CV 5/10; 134/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 135/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky\n",
      "[CV 7/10; 135/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 136/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear\n",
      "[CV 7/10; 136/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 137/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga\n",
      "[CV 7/10; 137/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 138/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky\n",
      "[CV 7/10; 138/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=l2, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 139/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear\n",
      "[CV 7/10; 139/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 140/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 5/10; 140/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 140/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga\n",
      "[CV 10/10; 140/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=saga;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 141/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky\n",
      "[CV 10/10; 141/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=None, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 142/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 142/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 143/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 143/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 144/144] START class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 144/144] END class_weight=0.8181818181818182, max_iter=10000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 5/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 7/10; 5/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=saga;, score=(train=0.831, test=0.862) total time= 1.8min\n",
      "[CV 9/10; 20/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 9/10; 20/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=saga;, score=(train=0.836, test=0.820) total time=19.7min\n",
      "[CV 8/10; 5/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 8/10; 5/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=saga;, score=(train=0.836, test=0.818) total time= 1.8min\n",
      "[CV 10/10; 19/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear\n",
      "[CV 10/10; 19/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.3s\n",
      "[CV 8/10; 20/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 8/10; 20/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=saga;, score=(train=0.836, test=0.821) total time=19.7min\n",
      "[CV 1/10; 3/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 1/10; 3/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 8/144] START class_weight=balanced, max_iter=100, penalty=None, solver=saga\n",
      "[CV 4/10; 8/144] END class_weight=balanced, max_iter=100, penalty=None, solver=saga;, score=(train=0.836, test=0.820) total time= 1.8min\n",
      "[CV 9/10; 17/144] START class_weight=balanced, max_iter=1000, penalty=l2, solver=saga\n",
      "[CV 9/10; 17/144] END class_weight=balanced, max_iter=1000, penalty=l2, solver=saga;, score=(train=0.836, test=0.820) total time=19.9min\n",
      "[CV 5/10; 3/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 5/10; 3/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 8/144] START class_weight=balanced, max_iter=100, penalty=None, solver=saga\n",
      "[CV 3/10; 8/144] END class_weight=balanced, max_iter=100, penalty=None, solver=saga;, score=(train=0.838, test=0.803) total time= 1.8min\n",
      "[CV 1/10; 18/144] START class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 1/10; 18/144] END class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=0.836, test=0.838) total time=   2.9s\n",
      "[CV 1/10; 20/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=saga\n",
      "[CV 1/10; 20/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=saga;, score=(train=0.834, test=0.838) total time=20.0min\n",
      "[CV 3/10; 7/144] START class_weight=balanced, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 3/10; 7/144] END class_weight=balanced, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.6s\n",
      "[CV 4/10; 9/144] START class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 9/144] END class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=0.839, test=0.814) total time=   3.1s\n",
      "[CV 8/10; 11/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 11/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.6s\n",
      "[CV 8/10; 13/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 13/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=0.838, test=0.820) total time=21.8min\n",
      "[CV 2/10; 7/144] START class_weight=balanced, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 2/10; 7/144] END class_weight=balanced, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.5s\n",
      "[CV 3/10; 9/144] START class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 9/144] END class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=0.839, test=0.816) total time=   3.4s\n",
      "[CV 2/10; 12/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 12/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 9/10; 12/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 9/10; 12/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 6/10; 13/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 6/10; 13/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=0.837, test=0.836) total time=22.2min\n",
      "[CV 2/10; 6/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 2/10; 6/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=0.834, test=0.855) total time=   3.7s\n",
      "[CV 4/10; 11/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 4/10; 11/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.5s\n",
      "[CV 10/10; 11/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 11/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.5s\n",
      "[CV 9/10; 13/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 9/10; 13/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=0.838, test=0.816) total time=22.4min\n",
      "[CV 5/10; 6/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 5/10; 6/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=0.838, test=0.830) total time=   3.5s\n",
      "[CV 1/10; 11/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 11/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.6s\n",
      "[CV 9/10; 11/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 9/10; 11/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.6s\n",
      "[CV 10/10; 13/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 13/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=0.834, test=0.866) total time=22.4min\n",
      "[CV 1/10; 7/144] START class_weight=balanced, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 1/10; 7/144] END class_weight=balanced, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.5s\n",
      "[CV 2/10; 9/144] START class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 2/10; 9/144] END class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=0.834, test=0.855) total time=   2.7s\n",
      "[CV 6/10; 10/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 6/10; 10/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 10/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 10/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/10; 10/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 9/10; 10/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 11/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 11/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.5s\n",
      "[CV 7/10; 11/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 7/10; 11/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 6/10; 12/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 6/10; 12/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 12/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 12/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 13/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 3/10; 13/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=0.839, test=0.816) total time=22.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10; 6/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 6/10; 6/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=0.837, test=0.836) total time=   2.3s\n",
      "[CV 5/10; 9/144] START class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 5/10; 9/144] END class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=0.838, test=0.830) total time=   2.0s\n",
      "[CV 4/10; 13/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 13/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=0.839, test=0.814) total time=22.7min\n",
      "[CV 7/10; 6/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 7/10; 6/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=0.834, test=0.861) total time=   3.1s\n",
      "[CV 1/10; 10/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/10; 10/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 10/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/10; 10/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 10/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/10; 10/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 10/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 10/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 10/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/10; 10/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 10/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 10/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 10/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear\n",
      "[CV 10/10; 10/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 3/10; 11/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 3/10; 11/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.6s\n",
      "[CV 1/10; 12/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 1/10; 12/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 12/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 12/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 8/10; 12/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 8/10; 12/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/10; 13/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 13/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=0.838, test=0.830) total time=22.7min\n",
      "[CV 8/10; 6/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 8/10; 6/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=0.838, test=0.820) total time=   3.4s\n",
      "[CV 5/10; 11/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 11/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.7s\n",
      "[CV 5/10; 12/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 5/10; 12/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/10; 13/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 2/10; 13/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=0.834, test=0.855) total time=22.7min\n",
      "[CV 4/10; 7/144] START class_weight=balanced, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 4/10; 7/144] END class_weight=balanced, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.5s\n",
      "[CV 1/10; 9/144] START class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 1/10; 9/144] END class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=0.836, test=0.838) total time=   3.0s\n",
      "[CV 6/10; 11/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 11/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.6s\n",
      "[CV 3/10; 12/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 3/10; 12/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 7/10; 12/144] START class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 12/144] END class_weight=balanced, max_iter=100, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 1/10; 13/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 13/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=0.836, test=0.838) total time=22.7min\n",
      "[CV 4/10; 6/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky\n",
      "[CV 4/10; 6/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=newton-cholesky;, score=(train=0.839, test=0.814) total time=   2.4s\n",
      "[CV 6/10; 9/144] START class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 9/144] END class_weight=balanced, max_iter=100, penalty=None, solver=newton-cholesky;, score=(train=0.837, test=0.836) total time=   2.1s\n",
      "[CV 7/10; 13/144] START class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear\n",
      "[CV 7/10; 13/144] END class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear;, score=(train=0.834, test=0.861) total time=22.7min\n",
      "[CV 3/10; 5/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 3/10; 5/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=saga;, score=(train=0.838, test=0.803) total time= 1.9min\n",
      "[CV 6/10; 21/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 6/10; 21/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=0.837, test=0.836) total time=   1.8s\n",
      "[CV 4/10; 22/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/10; 22/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/10; 22/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 8/10; 22/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/10; 23/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 2/10; 23/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 8/10; 23/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 8/10; 23/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 2/10; 24/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 2/10; 24/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/10; 24/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 4/10; 24/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/10; 24/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 7/10; 24/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/10; 24/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=newton-cholesky\n",
      "[CV 10/10; 24/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 4/10; 25/144] START class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 4/10; 25/144] END class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=0.839, test=0.814) total time=21.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10; 2/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 2/10; 2/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=saga;, score=(train=0.831, test=0.855) total time= 1.9min\n",
      "[CV 5/10; 25/144] START class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 5/10; 25/144] END class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=0.838, test=0.830) total time=21.5min\n",
      "[CV 6/10; 3/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky\n",
      "[CV 6/10; 3/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 10/10; 7/144] START class_weight=balanced, max_iter=100, penalty=None, solver=liblinear\n",
      "[CV 10/10; 7/144] END class_weight=balanced, max_iter=100, penalty=None, solver=liblinear;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 6/10; 8/144] START class_weight=balanced, max_iter=100, penalty=None, solver=saga\n",
      "[CV 6/10; 8/144] END class_weight=balanced, max_iter=100, penalty=None, solver=saga;, score=(train=0.834, test=0.829) total time= 1.8min\n",
      "[CV 10/10; 18/144] START class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 10/10; 18/144] END class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=0.833, test=0.866) total time=   2.8s\n",
      "[CV 8/10; 21/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 8/10; 21/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=0.838, test=0.820) total time=   2.8s\n",
      "[CV 8/10; 25/144] START class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 8/10; 25/144] END class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=0.838, test=0.820) total time=21.6min\n",
      "[CV 10/10; 2/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 10/10; 2/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=saga;, score=(train=0.831, test=0.861) total time= 1.8min\n",
      "[CV 3/10; 21/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 3/10; 21/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=0.839, test=0.816) total time=   2.8s\n",
      "[CV 5/10; 23/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 5/10; 23/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.6s\n",
      "[CV 1/10; 25/144] START class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 1/10; 25/144] END class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=0.836, test=0.838) total time=21.7min\n",
      "[CV 1/10; 2/144] START class_weight=balanced, max_iter=100, penalty=l1, solver=saga\n",
      "[CV 1/10; 2/144] END class_weight=balanced, max_iter=100, penalty=l1, solver=saga;, score=(train=0.833, test=0.838) total time= 1.9min\n",
      "[CV 10/10; 25/144] START class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 10/10; 25/144] END class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=0.834, test=0.866) total time=21.7min\n",
      "[CV 4/10; 5/144] START class_weight=balanced, max_iter=100, penalty=l2, solver=saga\n",
      "[CV 4/10; 5/144] END class_weight=balanced, max_iter=100, penalty=l2, solver=saga;, score=(train=0.836, test=0.820) total time= 1.8min\n",
      "[CV 7/10; 18/144] START class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky\n",
      "[CV 7/10; 18/144] END class_weight=balanced, max_iter=1000, penalty=l2, solver=newton-cholesky;, score=(train=0.834, test=0.861) total time=   2.4s\n",
      "[CV 4/10; 21/144] START class_weight=balanced, max_iter=1000, penalty=None, solver=newton-cholesky\n",
      "[CV 4/10; 21/144] END class_weight=balanced, max_iter=1000, penalty=None, solver=newton-cholesky;, score=(train=0.839, test=0.814) total time=   2.3s\n",
      "[CV 7/10; 22/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=liblinear\n",
      "[CV 7/10; 22/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/10; 23/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 1/10; 23/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 6/10; 23/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 6/10; 23/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 10/10; 23/144] START class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga\n",
      "[CV 10/10; 23/144] END class_weight=balanced, max_iter=1000, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.4s\n",
      "[CV 6/10; 25/144] START class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear\n",
      "[CV 6/10; 25/144] END class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear;, score=(train=0.837, test=0.836) total time=21.7min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter': [100, 1000, 10000],\n",
    "    'class_weight': [\"balanced\", 35/65, 40/60, 45/55],\n",
    "    \"penalty\":[\"l1\", \"l2\", None, \"elasticnet\"],\n",
    "    \"solver\":[\"liblinear\", \"saga\", \"newton-cholesky\"]\n",
    "}\n",
    "logistic_regression = get_best_estimator(LogisticRegression(random_state=0), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "397a6eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "DecisionTreeClassifier(class_weight={0: 0.01595959595959596, 1: 1},\n",
      "                       max_features=6, min_samples_leaf=0.005,\n",
      "                       min_samples_split=0.03, random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1-Micro</th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Binary</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leipzig</td>\n",
       "      <td>0.059718</td>\n",
       "      <td>0.980149</td>\n",
       "      <td>0.510834</td>\n",
       "      <td>0.031695</td>\n",
       "      <td>0.843098</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greifswald</td>\n",
       "      <td>0.034584</td>\n",
       "      <td>0.966606</td>\n",
       "      <td>0.498318</td>\n",
       "      <td>0.013620</td>\n",
       "      <td>0.779145</td>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NAME       MCC  F1-Micro  F1-Macro  F1-Binary     AUROC     AUPRC\n",
       "0     Leipzig  0.059718  0.980149  0.510834   0.031695  0.843098  0.009821\n",
       "1  Greifswald  0.034584  0.966606  0.498318   0.013620  0.779145  0.004028"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10; 2/10] START class_weight={0: 0.0014444444444444444, 1: 1}.............\n",
      "[CV 9/10; 2/10] END class_weight={0: 0.0014444444444444444, 1: 1};, score=(train=0.877, test=0.835) total time=   7.6s\n",
      "[CV 7/10; 9/10] START class_weight={0: 0.004555555555555556, 1: 1}..............\n",
      "[CV 7/10; 9/10] END class_weight={0: 0.004555555555555556, 1: 1};, score=(train=0.878, test=0.866) total time=   5.9s\n",
      "[CV 1/10; 5/100] START class_weight={0: 0.0013636363636363637, 1: 1}............\n",
      "[CV 1/10; 5/100] END class_weight={0: 0.0013636363636363637, 1: 1};, score=(train=0.878, test=0.836) total time=   8.8s\n",
      "[CV 10/10; 11/100] START class_weight={0: 0.0019090909090909093, 1: 1}..........\n",
      "[CV 10/10; 11/100] END class_weight={0: 0.0019090909090909093, 1: 1};, score=(train=0.877, test=0.848) total time=   7.1s\n",
      "[CV 4/10; 16/100] START class_weight={0: 0.0023636363636363638, 1: 1}...........\n",
      "[CV 4/10; 16/100] END class_weight={0: 0.0023636363636363638, 1: 1};, score=(train=0.877, test=0.844) total time=   7.3s\n",
      "[CV 8/10; 21/100] START class_weight={0: 0.0028181818181818186, 1: 1}...........\n",
      "[CV 8/10; 21/100] END class_weight={0: 0.0028181818181818186, 1: 1};, score=(train=0.878, test=0.865) total time=   8.1s\n",
      "[CV 3/10; 28/100] START class_weight={0: 0.003454545454545455, 1: 1}............\n",
      "[CV 3/10; 28/100] END class_weight={0: 0.003454545454545455, 1: 1};, score=(train=0.879, test=0.842) total time=  10.2s\n",
      "[CV 10/10; 35/100] START class_weight={0: 0.004090909090909091, 1: 1}...........\n",
      "[CV 10/10; 35/100] END class_weight={0: 0.004090909090909091, 1: 1};, score=(train=0.879, test=0.851) total time=   9.5s\n",
      "[CV 1/10; 43/100] START class_weight={0: 0.004818181818181819, 1: 1}............\n",
      "[CV 1/10; 43/100] END class_weight={0: 0.004818181818181819, 1: 1};, score=(train=0.879, test=0.848) total time=   9.7s\n",
      "[CV 1/10; 50/100] START class_weight={0: 0.005454545454545455, 1: 1}............\n",
      "[CV 1/10; 50/100] END class_weight={0: 0.005454545454545455, 1: 1};, score=(train=0.879, test=0.842) total time=   7.4s\n",
      "[CV 10/10; 55/100] START class_weight={0: 0.00590909090909091, 1: 1}............\n",
      "[CV 10/10; 55/100] END class_weight={0: 0.00590909090909091, 1: 1};, score=(train=0.879, test=0.858) total time=   7.7s\n",
      "[CV 6/10; 61/100] START class_weight={0: 0.006454545454545455, 1: 1}............\n",
      "[CV 6/10; 61/100] END class_weight={0: 0.006454545454545455, 1: 1};, score=(train=0.879, test=0.836) total time=   7.6s\n",
      "[CV 3/10; 66/100] START class_weight={0: 0.00690909090909091, 1: 1}.............\n",
      "[CV 3/10; 66/100] END class_weight={0: 0.00690909090909091, 1: 1};, score=(train=0.881, test=0.843) total time=   7.6s\n",
      "[CV 1/10; 72/100] START class_weight={0: 0.007454545454545455, 1: 1}............\n",
      "[CV 1/10; 72/100] END class_weight={0: 0.007454545454545455, 1: 1};, score=(train=0.877, test=0.846) total time=   9.7s\n",
      "[CV 9/10; 78/100] START class_weight={0: 0.008, 1: 1}...........................\n",
      "[CV 9/10; 78/100] END class_weight={0: 0.008, 1: 1};, score=(train=0.880, test=0.846) total time=   8.2s\n",
      "[CV 7/10; 84/100] START class_weight={0: 0.008545454545454547, 1: 1}............\n",
      "[CV 7/10; 84/100] END class_weight={0: 0.008545454545454547, 1: 1};, score=(train=0.877, test=0.862) total time=   6.7s\n",
      "[CV 3/10; 89/100] START class_weight={0: 0.009000000000000001, 1: 1}............\n",
      "[CV 3/10; 89/100] END class_weight={0: 0.009000000000000001, 1: 1};, score=(train=0.880, test=0.845) total time=   7.2s\n",
      "[CV 7/10; 94/100] START class_weight={0: 0.009454545454545455, 1: 1}............\n",
      "[CV 7/10; 94/100] END class_weight={0: 0.009454545454545455, 1: 1};, score=(train=0.880, test=0.872) total time=   9.7s\n",
      "[CV 1/10; 1/100] START class_weight={0: 0.01, 1: 1}.............................\n",
      "[CV 1/10; 1/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.879, test=0.844) total time=  10.1s\n",
      "[CV 8/10; 11/100] START class_weight={0: 0.01101010101010101, 1: 1}.............\n",
      "[CV 8/10; 11/100] END class_weight={0: 0.01101010101010101, 1: 1};, score=(train=0.878, test=0.868) total time=   9.0s\n",
      "[CV 7/10; 16/100] START class_weight={0: 0.011515151515151515, 1: 1}............\n",
      "[CV 7/10; 16/100] END class_weight={0: 0.011515151515151515, 1: 1};, score=(train=0.879, test=0.866) total time=   9.9s\n",
      "[CV 9/10; 22/100] START class_weight={0: 0.012121212121212121, 1: 1}............\n",
      "[CV 9/10; 22/100] END class_weight={0: 0.012121212121212121, 1: 1};, score=(train=0.880, test=0.838) total time=  10.5s\n",
      "[CV 2/10; 30/100] START class_weight={0: 0.01292929292929293, 1: 1}.............\n",
      "[CV 2/10; 30/100] END class_weight={0: 0.01292929292929293, 1: 1};, score=(train=0.877, test=0.849) total time=   9.4s\n",
      "[CV 6/10; 36/100] START class_weight={0: 0.013535353535353536, 1: 1}............\n",
      "[CV 6/10; 36/100] END class_weight={0: 0.013535353535353536, 1: 1};, score=(train=0.881, test=0.830) total time=   9.0s\n",
      "[CV 3/10; 42/100] START class_weight={0: 0.014141414141414142, 1: 1}............\n",
      "[CV 3/10; 42/100] END class_weight={0: 0.014141414141414142, 1: 1};, score=(train=0.879, test=0.830) total time=  10.9s\n",
      "[CV 8/10; 49/100] START class_weight={0: 0.014848484848484849, 1: 1}............\n",
      "[CV 8/10; 49/100] END class_weight={0: 0.014848484848484849, 1: 1};, score=(train=0.880, test=0.883) total time=   9.2s\n",
      "[CV 10/10; 55/100] START class_weight={0: 0.015454545454545455, 1: 1}...........\n",
      "[CV 10/10; 55/100] END class_weight={0: 0.015454545454545455, 1: 1};, score=(train=0.882, test=0.870) total time=  10.6s\n",
      "[CV 6/10; 62/100] START class_weight={0: 0.01616161616161616, 1: 1}.............\n",
      "[CV 6/10; 62/100] END class_weight={0: 0.01616161616161616, 1: 1};, score=(train=0.881, test=0.832) total time=  10.9s\n",
      "[CV 3/10; 70/100] START class_weight={0: 0.016969696969696968, 1: 1}............\n",
      "[CV 3/10; 70/100] END class_weight={0: 0.016969696969696968, 1: 1};, score=(train=0.876, test=0.838) total time=   9.7s\n",
      "[CV 1/10; 76/100] START class_weight={0: 0.017575757575757578, 1: 1}............\n",
      "[CV 1/10; 76/100] END class_weight={0: 0.017575757575757578, 1: 1};, score=(train=0.878, test=0.851) total time=   8.1s\n",
      "[CV 9/10; 81/100] START class_weight={0: 0.01808080808080808, 1: 1}.............\n",
      "[CV 9/10; 81/100] END class_weight={0: 0.01808080808080808, 1: 1};, score=(train=0.880, test=0.853) total time=  10.5s\n",
      "[CV 9/10; 88/100] START class_weight={0: 0.018787878787878787, 1: 1}............\n",
      "[CV 9/10; 88/100] END class_weight={0: 0.018787878787878787, 1: 1};, score=(train=0.880, test=0.853) total time=   8.3s\n",
      "[CV 1/10; 94/100] START class_weight={0: 0.019393939393939394, 1: 1}............\n",
      "[CV 1/10; 94/100] END class_weight={0: 0.019393939393939394, 1: 1};, score=(train=0.881, test=0.858) total time=  10.6s\n",
      "[CV 3/10; 2/10] START class_weight={0: 0.0014444444444444444, 1: 1}.............\n",
      "[CV 3/10; 2/10] END class_weight={0: 0.0014444444444444444, 1: 1};, score=(train=0.879, test=0.838) total time=   7.8s\n",
      "[CV 5/10; 10/10] START class_weight={0: 0.005, 1: 1}............................\n",
      "[CV 5/10; 10/10] END class_weight={0: 0.005, 1: 1};, score=(train=0.880, test=0.835) total time=   5.5s\n",
      "[CV 7/10; 5/100] START class_weight={0: 0.0013636363636363637, 1: 1}............\n",
      "[CV 7/10; 5/100] END class_weight={0: 0.0013636363636363637, 1: 1};, score=(train=0.874, test=0.853) total time=   6.9s\n",
      "[CV 6/10; 8/100] START class_weight={0: 0.0016363636363636363, 1: 1}............\n",
      "[CV 6/10; 8/100] END class_weight={0: 0.0016363636363636363, 1: 1};, score=(train=0.881, test=0.827) total time=   9.5s\n",
      "[CV 7/10; 17/100] START class_weight={0: 0.002454545454545455, 1: 1}............\n",
      "[CV 7/10; 17/100] END class_weight={0: 0.002454545454545455, 1: 1};, score=(train=0.876, test=0.863) total time=   8.4s\n",
      "[CV 8/10; 23/100] START class_weight={0: 0.003, 1: 1}...........................\n",
      "[CV 8/10; 23/100] END class_weight={0: 0.003, 1: 1};, score=(train=0.878, test=0.865) total time=   8.6s\n",
      "[CV 4/10; 30/100] START class_weight={0: 0.003636363636363637, 1: 1}............\n",
      "[CV 4/10; 30/100] END class_weight={0: 0.003636363636363637, 1: 1};, score=(train=0.880, test=0.849) total time=  10.3s\n",
      "[CV 1/10; 38/100] START class_weight={0: 0.004363636363636364, 1: 1}............\n",
      "[CV 1/10; 38/100] END class_weight={0: 0.004363636363636364, 1: 1};, score=(train=0.878, test=0.832) total time=  10.2s\n",
      "[CV 5/10; 45/100] START class_weight={0: 0.005, 1: 1}...........................\n",
      "[CV 5/10; 45/100] END class_weight={0: 0.005, 1: 1};, score=(train=0.880, test=0.835) total time=   7.7s\n",
      "[CV 2/10; 51/100] START class_weight={0: 0.005545454545454546, 1: 1}............\n",
      "[CV 2/10; 51/100] END class_weight={0: 0.005545454545454546, 1: 1};, score=(train=0.879, test=0.830) total time=   7.3s\n",
      "[CV 10/10; 56/100] START class_weight={0: 0.006, 1: 1}..........................\n",
      "[CV 10/10; 56/100] END class_weight={0: 0.006, 1: 1};, score=(train=0.879, test=0.858) total time=   9.2s\n",
      "[CV 7/10; 63/100] START class_weight={0: 0.006636363636363637, 1: 1}............\n",
      "[CV 7/10; 63/100] END class_weight={0: 0.006636363636363637, 1: 1};, score=(train=0.877, test=0.864) total time=   7.2s\n",
      "[CV 2/10; 69/100] START class_weight={0: 0.0071818181818181824, 1: 1}...........\n",
      "[CV 2/10; 69/100] END class_weight={0: 0.0071818181818181824, 1: 1};, score=(train=0.878, test=0.851) total time=   8.7s\n",
      "[CV 4/10; 75/100] START class_weight={0: 0.007727272727272728, 1: 1}............\n",
      "[CV 4/10; 75/100] END class_weight={0: 0.007727272727272728, 1: 1};, score=(train=0.877, test=0.841) total time=   8.1s\n",
      "[CV 9/10; 80/100] START class_weight={0: 0.008181818181818182, 1: 1}............\n",
      "[CV 9/10; 80/100] END class_weight={0: 0.008181818181818182, 1: 1};, score=(train=0.881, test=0.845) total time=  11.1s\n",
      "[CV 3/10; 88/100] START class_weight={0: 0.008909090909090908, 1: 1}............\n",
      "[CV 3/10; 88/100] END class_weight={0: 0.008909090909090908, 1: 1};, score=(train=0.880, test=0.844) total time=  10.9s\n",
      "[CV 7/10; 95/100] START class_weight={0: 0.009545454545454548, 1: 1}............\n",
      "[CV 7/10; 95/100] END class_weight={0: 0.009545454545454548, 1: 1};, score=(train=0.879, test=0.874) total time=   8.2s\n",
      "[CV 2/10; 1/100] START class_weight={0: 0.01, 1: 1}.............................\n",
      "[CV 2/10; 1/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.880, test=0.846) total time=   9.0s\n",
      "[CV 1/10; 9/100] START class_weight={0: 0.010808080808080808, 1: 1}.............\n",
      "[CV 1/10; 9/100] END class_weight={0: 0.010808080808080808, 1: 1};, score=(train=0.878, test=0.847) total time=   7.5s\n",
      "[CV 10/10; 13/100] START class_weight={0: 0.011212121212121211, 1: 1}...........\n",
      "[CV 10/10; 13/100] END class_weight={0: 0.011212121212121211, 1: 1};, score=(train=0.876, test=0.867) total time=  10.9s\n",
      "[CV 8/10; 21/100] START class_weight={0: 0.012020202020202021, 1: 1}............\n",
      "[CV 8/10; 21/100] END class_weight={0: 0.012020202020202021, 1: 1};, score=(train=0.880, test=0.883) total time=  10.1s\n",
      "[CV 7/10; 28/100] START class_weight={0: 0.012727272727272728, 1: 1}............\n",
      "[CV 7/10; 28/100] END class_weight={0: 0.012727272727272728, 1: 1};, score=(train=0.879, test=0.866) total time=  11.2s\n",
      "[CV 2/10; 36/100] START class_weight={0: 0.013535353535353536, 1: 1}............\n",
      "[CV 2/10; 36/100] END class_weight={0: 0.013535353535353536, 1: 1};, score=(train=0.878, test=0.845) total time=   9.6s\n",
      "[CV 10/10; 41/100] START class_weight={0: 0.01404040404040404, 1: 1}............\n",
      "[CV 10/10; 41/100] END class_weight={0: 0.01404040404040404, 1: 1};, score=(train=0.878, test=0.865) total time=   7.8s\n",
      "[CV 1/10; 47/100] START class_weight={0: 0.014646464646464647, 1: 1}............\n",
      "[CV 1/10; 47/100] END class_weight={0: 0.014646464646464647, 1: 1};, score=(train=0.880, test=0.870) total time=   8.7s\n",
      "[CV 9/10; 52/100] START class_weight={0: 0.015151515151515152, 1: 1}............\n",
      "[CV 9/10; 52/100] END class_weight={0: 0.015151515151515152, 1: 1};, score=(train=0.880, test=0.837) total time=   9.1s\n",
      "[CV 10/10; 58/100] START class_weight={0: 0.01575757575757576, 1: 1}............\n",
      "[CV 10/10; 58/100] END class_weight={0: 0.01575757575757576, 1: 1};, score=(train=0.879, test=0.869) total time=  10.2s\n",
      "[CV 7/10; 65/100] START class_weight={0: 0.016464646464646467, 1: 1}............\n",
      "[CV 7/10; 65/100] END class_weight={0: 0.016464646464646467, 1: 1};, score=(train=0.881, test=0.853) total time=   8.0s\n",
      "[CV 5/10; 71/100] START class_weight={0: 0.01707070707070707, 1: 1}.............\n",
      "[CV 5/10; 71/100] END class_weight={0: 0.01707070707070707, 1: 1};, score=(train=0.883, test=0.832) total time=  10.9s\n",
      "[CV 2/10; 78/100] START class_weight={0: 0.017777777777777778, 1: 1}............\n",
      "[CV 2/10; 78/100] END class_weight={0: 0.017777777777777778, 1: 1};, score=(train=0.885, test=0.846) total time=  10.8s\n",
      "[CV 6/10; 85/100] START class_weight={0: 0.018484848484848486, 1: 1}............\n",
      "[CV 6/10; 85/100] END class_weight={0: 0.018484848484848486, 1: 1};, score=(train=0.881, test=0.830) total time=   7.7s\n",
      "[CV 7/10; 90/100] START class_weight={0: 0.01898989898989899, 1: 1}.............\n",
      "[CV 7/10; 90/100] END class_weight={0: 0.01898989898989899, 1: 1};, score=(train=0.879, test=0.851) total time=   7.8s\n",
      "[CV 8/10; 95/100] START class_weight={0: 0.019494949494949496, 1: 1}............\n",
      "[CV 8/10; 95/100] END class_weight={0: 0.019494949494949496, 1: 1};, score=(train=0.878, test=0.880) total time=   8.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10; 4/10] START class_weight={0: 0.0023333333333333335, 1: 1}.............\n",
      "[CV 2/10; 4/10] END class_weight={0: 0.0023333333333333335, 1: 1};, score=(train=0.883, test=0.847) total time=  10.8s\n",
      "[CV 7/10; 3/100] START class_weight={0: 0.0011818181818181819, 1: 1}............\n",
      "[CV 7/10; 3/100] END class_weight={0: 0.0011818181818181819, 1: 1};, score=(train=0.872, test=0.846) total time=   6.8s\n",
      "[CV 1/10; 8/100] START class_weight={0: 0.0016363636363636363, 1: 1}............\n",
      "[CV 1/10; 8/100] END class_weight={0: 0.0016363636363636363, 1: 1};, score=(train=0.878, test=0.836) total time=   6.2s\n",
      "[CV 1/10; 14/100] START class_weight={0: 0.002181818181818182, 1: 1}............\n",
      "[CV 1/10; 14/100] END class_weight={0: 0.002181818181818182, 1: 1};, score=(train=0.881, test=0.841) total time=   6.2s\n",
      "[CV 9/10; 19/100] START class_weight={0: 0.0026363636363636363, 1: 1}...........\n",
      "[CV 9/10; 19/100] END class_weight={0: 0.0026363636363636363, 1: 1};, score=(train=0.879, test=0.840) total time=   6.3s\n",
      "[CV 6/10; 24/100] START class_weight={0: 0.003090909090909091, 1: 1}............\n",
      "[CV 6/10; 24/100] END class_weight={0: 0.003090909090909091, 1: 1};, score=(train=0.880, test=0.830) total time=   8.4s\n",
      "[CV 10/10; 30/100] START class_weight={0: 0.003636363636363637, 1: 1}...........\n",
      "[CV 10/10; 30/100] END class_weight={0: 0.003636363636363637, 1: 1};, score=(train=0.879, test=0.851) total time=   8.1s\n",
      "[CV 10/10; 36/100] START class_weight={0: 0.004181818181818182, 1: 1}...........\n",
      "[CV 10/10; 36/100] END class_weight={0: 0.004181818181818182, 1: 1};, score=(train=0.879, test=0.851) total time=   9.9s\n",
      "[CV 4/10; 44/100] START class_weight={0: 0.00490909090909091, 1: 1}.............\n",
      "[CV 4/10; 44/100] END class_weight={0: 0.00490909090909091, 1: 1};, score=(train=0.878, test=0.853) total time=   8.7s\n",
      "[CV 6/10; 50/100] START class_weight={0: 0.005454545454545455, 1: 1}............\n",
      "[CV 6/10; 50/100] END class_weight={0: 0.005454545454545455, 1: 1};, score=(train=0.879, test=0.836) total time=   7.3s\n",
      "[CV 1/10; 56/100] START class_weight={0: 0.006, 1: 1}...........................\n",
      "[CV 1/10; 56/100] END class_weight={0: 0.006, 1: 1};, score=(train=0.877, test=0.846) total time=  11.8s\n",
      "[CV 5/10; 64/100] START class_weight={0: 0.006727272727272728, 1: 1}............\n",
      "[CV 5/10; 64/100] END class_weight={0: 0.006727272727272728, 1: 1};, score=(train=0.880, test=0.836) total time=  11.6s\n",
      "[CV 10/10; 72/100] START class_weight={0: 0.007454545454545455, 1: 1}...........\n",
      "[CV 10/10; 72/100] END class_weight={0: 0.007454545454545455, 1: 1};, score=(train=0.874, test=0.848) total time=  11.8s\n",
      "[CV 4/10; 81/100] START class_weight={0: 0.008272727272727274, 1: 1}............\n",
      "[CV 4/10; 81/100] END class_weight={0: 0.008272727272727274, 1: 1};, score=(train=0.877, test=0.841) total time=  12.7s\n",
      "[CV 6/10; 89/100] START class_weight={0: 0.009000000000000001, 1: 1}............\n",
      "[CV 6/10; 89/100] END class_weight={0: 0.009000000000000001, 1: 1};, score=(train=0.879, test=0.839) total time=   8.1s\n",
      "[CV 5/10; 95/100] START class_weight={0: 0.009545454545454548, 1: 1}............\n",
      "[CV 5/10; 95/100] END class_weight={0: 0.009545454545454548, 1: 1};, score=(train=0.878, test=0.833) total time=  11.4s\n",
      "[CV 10/10; 2/100] START class_weight={0: 0.010101010101010102, 1: 1}............\n",
      "[CV 10/10; 2/100] END class_weight={0: 0.010101010101010102, 1: 1};, score=(train=0.876, test=0.867) total time=   9.3s\n",
      "[CV 7/10; 9/100] START class_weight={0: 0.010808080808080808, 1: 1}.............\n",
      "[CV 7/10; 9/100] END class_weight={0: 0.010808080808080808, 1: 1};, score=(train=0.880, test=0.869) total time=  12.6s\n",
      "[CV 1/10; 19/100] START class_weight={0: 0.011818181818181818, 1: 1}............\n",
      "[CV 1/10; 19/100] END class_weight={0: 0.011818181818181818, 1: 1};, score=(train=0.877, test=0.864) total time=   9.1s\n",
      "[CV 9/10; 24/100] START class_weight={0: 0.012323232323232323, 1: 1}............\n",
      "[CV 9/10; 24/100] END class_weight={0: 0.012323232323232323, 1: 1};, score=(train=0.880, test=0.838) total time=  11.4s\n",
      "[CV 2/10; 32/100] START class_weight={0: 0.013131313131313133, 1: 1}............\n",
      "[CV 2/10; 32/100] END class_weight={0: 0.013131313131313133, 1: 1};, score=(train=0.878, test=0.850) total time=   9.4s\n",
      "[CV 2/10; 38/100] START class_weight={0: 0.013737373737373737, 1: 1}............\n",
      "[CV 2/10; 38/100] END class_weight={0: 0.013737373737373737, 1: 1};, score=(train=0.884, test=0.844) total time=  10.0s\n",
      "[CV 6/10; 44/100] START class_weight={0: 0.014343434343434344, 1: 1}............\n",
      "[CV 6/10; 44/100] END class_weight={0: 0.014343434343434344, 1: 1};, score=(train=0.881, test=0.832) total time=   8.9s\n",
      "[CV 8/10; 50/100] START class_weight={0: 0.014949494949494949, 1: 1}............\n",
      "[CV 8/10; 50/100] END class_weight={0: 0.014949494949494949, 1: 1};, score=(train=0.880, test=0.878) total time=  11.2s\n",
      "[CV 3/10; 58/100] START class_weight={0: 0.01575757575757576, 1: 1}.............\n",
      "[CV 3/10; 58/100] END class_weight={0: 0.01575757575757576, 1: 1};, score=(train=0.876, test=0.838) total time=   9.7s\n",
      "[CV 6/10; 64/100] START class_weight={0: 0.016363636363636365, 1: 1}............\n",
      "[CV 6/10; 64/100] END class_weight={0: 0.016363636363636365, 1: 1};, score=(train=0.881, test=0.826) total time=   9.7s\n",
      "[CV 7/10; 70/100] START class_weight={0: 0.016969696969696968, 1: 1}............\n",
      "[CV 7/10; 70/100] END class_weight={0: 0.016969696969696968, 1: 1};, score=(train=0.881, test=0.853) total time=   8.7s\n",
      "[CV 4/10; 76/100] START class_weight={0: 0.017575757575757578, 1: 1}............\n",
      "[CV 4/10; 76/100] END class_weight={0: 0.017575757575757578, 1: 1};, score=(train=0.882, test=0.838) total time=   8.9s\n",
      "[CV 3/10; 82/100] START class_weight={0: 0.01818181818181818, 1: 1}.............\n",
      "[CV 3/10; 82/100] END class_weight={0: 0.01818181818181818, 1: 1};, score=(train=0.876, test=0.838) total time=   8.4s\n",
      "[CV 4/10; 87/100] START class_weight={0: 0.01868686868686869, 1: 1}.............\n",
      "[CV 4/10; 87/100] END class_weight={0: 0.01868686868686869, 1: 1};, score=(train=0.884, test=0.844) total time=  11.3s\n",
      "[CV 10/10; 94/100] START class_weight={0: 0.019393939393939394, 1: 1}...........\n",
      "[CV 10/10; 94/100] END class_weight={0: 0.019393939393939394, 1: 1};, score=(train=0.879, test=0.869) total time=   9.8s\n",
      "[CV 5/10; 4/10] START class_weight={0: 0.0023333333333333335, 1: 1}.............\n",
      "[CV 5/10; 4/10] END class_weight={0: 0.0023333333333333335, 1: 1};, score=(train=0.878, test=0.838) total time=   6.7s\n",
      "[CV 5/10; 8/10] START class_weight={0: 0.004111111111111111, 1: 1}..............\n",
      "[CV 5/10; 8/10] END class_weight={0: 0.004111111111111111, 1: 1};, score=(train=0.880, test=0.836) total time=   6.4s\n",
      "[CV 4/10; 5/100] START class_weight={0: 0.0013636363636363637, 1: 1}............\n",
      "[CV 4/10; 5/100] END class_weight={0: 0.0013636363636363637, 1: 1};, score=(train=0.879, test=0.823) total time=   6.6s\n",
      "[CV 10/10; 7/100] START class_weight={0: 0.0015454545454545456, 1: 1}...........\n",
      "[CV 10/10; 7/100] END class_weight={0: 0.0015454545454545456, 1: 1};, score=(train=0.879, test=0.851) total time=   6.8s\n",
      "[CV 7/10; 14/100] START class_weight={0: 0.002181818181818182, 1: 1}............\n",
      "[CV 7/10; 14/100] END class_weight={0: 0.002181818181818182, 1: 1};, score=(train=0.876, test=0.851) total time=   7.5s\n",
      "[CV 10/10; 20/100] START class_weight={0: 0.0027272727272727275, 1: 1}..........\n",
      "[CV 10/10; 20/100] END class_weight={0: 0.0027272727272727275, 1: 1};, score=(train=0.875, test=0.847) total time=   7.3s\n",
      "[CV 9/10; 26/100] START class_weight={0: 0.003272727272727273, 1: 1}............\n",
      "[CV 9/10; 26/100] END class_weight={0: 0.003272727272727273, 1: 1};, score=(train=0.880, test=0.851) total time=   7.8s\n",
      "[CV 10/10; 32/100] START class_weight={0: 0.0038181818181818187, 1: 1}..........\n",
      "[CV 10/10; 32/100] END class_weight={0: 0.0038181818181818187, 1: 1};, score=(train=0.878, test=0.855) total time=   8.2s\n",
      "[CV 2/10; 39/100] START class_weight={0: 0.004454545454545455, 1: 1}............\n",
      "[CV 2/10; 39/100] END class_weight={0: 0.004454545454545455, 1: 1};, score=(train=0.880, test=0.826) total time=   9.1s\n",
      "[CV 3/10; 45/100] START class_weight={0: 0.005, 1: 1}...........................\n",
      "[CV 3/10; 45/100] END class_weight={0: 0.005, 1: 1};, score=(train=0.881, test=0.836) total time=   7.3s\n",
      "[CV 7/10; 50/100] START class_weight={0: 0.005454545454545455, 1: 1}............\n",
      "[CV 7/10; 50/100] END class_weight={0: 0.005454545454545455, 1: 1};, score=(train=0.876, test=0.861) total time=   7.9s\n",
      "[CV 6/10; 56/100] START class_weight={0: 0.006, 1: 1}...........................\n",
      "[CV 6/10; 56/100] END class_weight={0: 0.006, 1: 1};, score=(train=0.879, test=0.841) total time=   6.2s\n",
      "[CV 2/10; 61/100] START class_weight={0: 0.006454545454545455, 1: 1}............\n",
      "[CV 2/10; 61/100] END class_weight={0: 0.006454545454545455, 1: 1};, score=(train=0.880, test=0.831) total time=   8.7s\n",
      "[CV 4/10; 67/100] START class_weight={0: 0.007, 1: 1}...........................\n",
      "[CV 4/10; 67/100] END class_weight={0: 0.007, 1: 1};, score=(train=0.879, test=0.836) total time=   6.3s\n",
      "[CV 7/10; 71/100] START class_weight={0: 0.007363636363636364, 1: 1}............\n",
      "[CV 7/10; 71/100] END class_weight={0: 0.007363636363636364, 1: 1};, score=(train=0.877, test=0.862) total time=   8.1s\n",
      "[CV 2/10; 77/100] START class_weight={0: 0.00790909090909091, 1: 1}.............\n",
      "[CV 2/10; 77/100] END class_weight={0: 0.00790909090909091, 1: 1};, score=(train=0.879, test=0.858) total time=   7.6s\n",
      "[CV 8/10; 82/100] START class_weight={0: 0.008363636363636365, 1: 1}............\n",
      "[CV 8/10; 82/100] END class_weight={0: 0.008363636363636365, 1: 1};, score=(train=0.874, test=0.866) total time=   9.9s\n",
      "[CV 8/10; 89/100] START class_weight={0: 0.009000000000000001, 1: 1}............\n",
      "[CV 8/10; 89/100] END class_weight={0: 0.009000000000000001, 1: 1};, score=(train=0.878, test=0.867) total time=  10.0s\n",
      "[CV 7/10; 96/100] START class_weight={0: 0.009636363636363637, 1: 1}............\n",
      "[CV 7/10; 96/100] END class_weight={0: 0.009636363636363637, 1: 1};, score=(train=0.878, test=0.860) total time=   9.1s\n",
      "[CV 9/10; 2/100] START class_weight={0: 0.010101010101010102, 1: 1}.............\n",
      "[CV 9/10; 2/100] END class_weight={0: 0.010101010101010102, 1: 1};, score=(train=0.880, test=0.848) total time=   8.4s\n",
      "[CV 10/10; 7/100] START class_weight={0: 0.010606060606060607, 1: 1}............\n",
      "[CV 10/10; 7/100] END class_weight={0: 0.010606060606060607, 1: 1};, score=(train=0.876, test=0.867) total time=   8.8s\n",
      "[CV 6/10; 14/100] START class_weight={0: 0.011313131313131313, 1: 1}............\n",
      "[CV 6/10; 14/100] END class_weight={0: 0.011313131313131313, 1: 1};, score=(train=0.877, test=0.836) total time=   7.8s\n",
      "[CV 3/10; 20/100] START class_weight={0: 0.01191919191919192, 1: 1}.............\n",
      "[CV 3/10; 20/100] END class_weight={0: 0.01191919191919192, 1: 1};, score=(train=0.879, test=0.828) total time=  10.2s\n",
      "[CV 10/10; 26/100] START class_weight={0: 0.012525252525252526, 1: 1}...........\n",
      "[CV 10/10; 26/100] END class_weight={0: 0.012525252525252526, 1: 1};, score=(train=0.880, test=0.866) total time=   9.6s\n",
      "[CV 2/10; 33/100] START class_weight={0: 0.013232323232323233, 1: 1}............\n",
      "[CV 2/10; 33/100] END class_weight={0: 0.013232323232323233, 1: 1};, score=(train=0.884, test=0.844) total time=   9.4s\n",
      "[CV 5/10; 39/100] START class_weight={0: 0.013838383838383839, 1: 1}............\n",
      "[CV 5/10; 39/100] END class_weight={0: 0.013838383838383839, 1: 1};, score=(train=0.882, test=0.839) total time=   7.9s\n",
      "[CV 9/10; 44/100] START class_weight={0: 0.014343434343434344, 1: 1}............\n",
      "[CV 9/10; 44/100] END class_weight={0: 0.014343434343434344, 1: 1};, score=(train=0.880, test=0.837) total time=   9.7s\n",
      "[CV 4/10; 51/100] START class_weight={0: 0.01505050505050505, 1: 1}.............\n",
      "[CV 4/10; 51/100] END class_weight={0: 0.01505050505050505, 1: 1};, score=(train=0.884, test=0.844) total time=   9.7s\n",
      "[CV 6/10; 57/100] START class_weight={0: 0.015656565656565657, 1: 1}............\n",
      "[CV 6/10; 57/100] END class_weight={0: 0.015656565656565657, 1: 1};, score=(train=0.881, test=0.826) total time=   8.1s\n",
      "[CV 8/10; 62/100] START class_weight={0: 0.01616161616161616, 1: 1}.............\n",
      "[CV 8/10; 62/100] END class_weight={0: 0.01616161616161616, 1: 1};, score=(train=0.880, test=0.872) total time=   7.8s\n",
      "[CV 8/10; 67/100] START class_weight={0: 0.016666666666666666, 1: 1}............\n",
      "[CV 8/10; 67/100] END class_weight={0: 0.016666666666666666, 1: 1};, score=(train=0.880, test=0.872) total time=  10.3s\n",
      "[CV 1/10; 75/100] START class_weight={0: 0.017474747474747476, 1: 1}............\n",
      "[CV 1/10; 75/100] END class_weight={0: 0.017474747474747476, 1: 1};, score=(train=0.880, test=0.861) total time=  10.1s\n",
      "[CV 2/10; 81/100] START class_weight={0: 0.01808080808080808, 1: 1}.............\n",
      "[CV 2/10; 81/100] END class_weight={0: 0.01808080808080808, 1: 1};, score=(train=0.885, test=0.846) total time=  10.2s\n",
      "[CV 3/10; 88/100] START class_weight={0: 0.018787878787878787, 1: 1}............\n",
      "[CV 3/10; 88/100] END class_weight={0: 0.018787878787878787, 1: 1};, score=(train=0.880, test=0.828) total time=  10.0s\n",
      "[CV 8/10; 94/100] START class_weight={0: 0.019393939393939394, 1: 1}............\n",
      "[CV 8/10; 94/100] END class_weight={0: 0.019393939393939394, 1: 1};, score=(train=0.879, test=0.885) total time=  10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10; 6/10] START class_weight={0: 0.0032222222222222222, 1: 1}.............\n",
      "[CV 9/10; 6/10] END class_weight={0: 0.0032222222222222222, 1: 1};, score=(train=0.881, test=0.839) total time=   7.5s\n",
      "[CV 6/10; 10/10] START class_weight={0: 0.005, 1: 1}............................\n",
      "[CV 6/10; 10/10] END class_weight={0: 0.005, 1: 1};, score=(train=0.880, test=0.835) total time=   5.9s\n",
      "[CV 8/10; 6/100] START class_weight={0: 0.0014545454545454547, 1: 1}............\n",
      "[CV 8/10; 6/100] END class_weight={0: 0.0014545454545454547, 1: 1};, score=(train=0.876, test=0.874) total time=   9.2s\n",
      "[CV 2/10; 13/100] START class_weight={0: 0.002090909090909091, 1: 1}............\n",
      "[CV 2/10; 13/100] END class_weight={0: 0.002090909090909091, 1: 1};, score=(train=0.881, test=0.838) total time=   9.1s\n",
      "[CV 3/10; 19/100] START class_weight={0: 0.0026363636363636363, 1: 1}...........\n",
      "[CV 3/10; 19/100] END class_weight={0: 0.0026363636363636363, 1: 1};, score=(train=0.879, test=0.840) total time=   7.4s\n",
      "[CV 7/10; 24/100] START class_weight={0: 0.003090909090909091, 1: 1}............\n",
      "[CV 7/10; 24/100] END class_weight={0: 0.003090909090909091, 1: 1};, score=(train=0.876, test=0.859) total time=   7.1s\n",
      "[CV 3/10; 29/100] START class_weight={0: 0.0035454545454545456, 1: 1}...........\n",
      "[CV 3/10; 29/100] END class_weight={0: 0.0035454545454545456, 1: 1};, score=(train=0.878, test=0.843) total time=   6.8s\n",
      "[CV 5/10; 34/100] START class_weight={0: 0.004, 1: 1}...........................\n",
      "[CV 5/10; 34/100] END class_weight={0: 0.004, 1: 1};, score=(train=0.880, test=0.838) total time=   7.6s\n",
      "[CV 5/10; 40/100] START class_weight={0: 0.004545454545454545, 1: 1}............\n",
      "[CV 5/10; 40/100] END class_weight={0: 0.004545454545454545, 1: 1};, score=(train=0.881, test=0.839) total time=   6.6s\n",
      "[CV 6/10; 45/100] START class_weight={0: 0.005, 1: 1}...........................\n",
      "[CV 6/10; 45/100] END class_weight={0: 0.005, 1: 1};, score=(train=0.880, test=0.835) total time=   9.2s\n",
      "[CV 6/10; 52/100] START class_weight={0: 0.005636363636363636, 1: 1}............\n",
      "[CV 6/10; 52/100] END class_weight={0: 0.005636363636363636, 1: 1};, score=(train=0.879, test=0.840) total time=   7.7s\n",
      "[CV 10/10; 57/100] START class_weight={0: 0.006090909090909091, 1: 1}...........\n",
      "[CV 10/10; 57/100] END class_weight={0: 0.006090909090909091, 1: 1};, score=(train=0.879, test=0.858) total time=   6.9s\n",
      "[CV 3/10; 63/100] START class_weight={0: 0.006636363636363637, 1: 1}............\n",
      "[CV 3/10; 63/100] END class_weight={0: 0.006636363636363637, 1: 1};, score=(train=0.880, test=0.844) total time=   7.1s\n",
      "[CV 4/10; 68/100] START class_weight={0: 0.007090909090909091, 1: 1}............\n",
      "[CV 4/10; 68/100] END class_weight={0: 0.007090909090909091, 1: 1};, score=(train=0.879, test=0.836) total time=   8.8s\n",
      "[CV 7/10; 74/100] START class_weight={0: 0.007636363636363637, 1: 1}............\n",
      "[CV 7/10; 74/100] END class_weight={0: 0.007636363636363637, 1: 1};, score=(train=0.877, test=0.862) total time=   7.2s\n",
      "[CV 1/10; 79/100] START class_weight={0: 0.008090909090909091, 1: 1}............\n",
      "[CV 1/10; 79/100] END class_weight={0: 0.008090909090909091, 1: 1};, score=(train=0.877, test=0.844) total time=  10.1s\n",
      "[CV 10/10; 86/100] START class_weight={0: 0.008727272727272728, 1: 1}...........\n",
      "[CV 10/10; 86/100] END class_weight={0: 0.008727272727272728, 1: 1};, score=(train=0.876, test=0.853) total time=  11.8s\n",
      "[CV 4/10; 94/100] START class_weight={0: 0.009454545454545455, 1: 1}............\n",
      "[CV 4/10; 94/100] END class_weight={0: 0.009454545454545455, 1: 1};, score=(train=0.879, test=0.833) total time=   9.8s\n",
      "[CV 10/10; 100/100] START class_weight={0: 0.01, 1: 1}..........................\n",
      "[CV 10/10; 100/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.876, test=0.867) total time=   6.2s\n",
      "[CV 3/10; 7/100] START class_weight={0: 0.010606060606060607, 1: 1}.............\n",
      "[CV 3/10; 7/100] END class_weight={0: 0.010606060606060607, 1: 1};, score=(train=0.879, test=0.835) total time=   9.0s\n",
      "[CV 9/10; 10/100] START class_weight={0: 0.01090909090909091, 1: 1}.............\n",
      "[CV 9/10; 10/100] END class_weight={0: 0.01090909090909091, 1: 1};, score=(train=0.880, test=0.848) total time=  11.3s\n",
      "[CV 10/10; 18/100] START class_weight={0: 0.011717171717171718, 1: 1}...........\n",
      "[CV 10/10; 18/100] END class_weight={0: 0.011717171717171718, 1: 1};, score=(train=0.878, test=0.865) total time=   9.0s\n",
      "[CV 4/10; 24/100] START class_weight={0: 0.012323232323232323, 1: 1}............\n",
      "[CV 4/10; 24/100] END class_weight={0: 0.012323232323232323, 1: 1};, score=(train=0.876, test=0.838) total time=   9.3s\n",
      "[CV 10/10; 29/100] START class_weight={0: 0.012828282828282828, 1: 1}...........\n",
      "[CV 10/10; 29/100] END class_weight={0: 0.012828282828282828, 1: 1};, score=(train=0.880, test=0.866) total time=   8.9s\n",
      "[CV 7/10; 35/100] START class_weight={0: 0.013434343434343434, 1: 1}............\n",
      "[CV 7/10; 35/100] END class_weight={0: 0.013434343434343434, 1: 1};, score=(train=0.878, test=0.862) total time=   8.9s\n",
      "[CV 4/10; 41/100] START class_weight={0: 0.01404040404040404, 1: 1}.............\n",
      "[CV 4/10; 41/100] END class_weight={0: 0.01404040404040404, 1: 1};, score=(train=0.882, test=0.843) total time=  10.4s\n",
      "[CV 4/10; 48/100] START class_weight={0: 0.014747474747474749, 1: 1}............\n",
      "[CV 4/10; 48/100] END class_weight={0: 0.014747474747474749, 1: 1};, score=(train=0.884, test=0.844) total time=   9.6s\n",
      "[CV 4/10; 54/100] START class_weight={0: 0.015353535353535354, 1: 1}............\n",
      "[CV 4/10; 54/100] END class_weight={0: 0.015353535353535354, 1: 1};, score=(train=0.884, test=0.844) total time=   9.7s\n",
      "[CV 10/10; 60/100] START class_weight={0: 0.01595959595959596, 1: 1}............\n",
      "[CV 10/10; 60/100] END class_weight={0: 0.01595959595959596, 1: 1};, score=(train=0.879, test=0.869) total time=   9.6s\n",
      "[CV 2/10; 67/100] START class_weight={0: 0.016666666666666666, 1: 1}............\n",
      "[CV 2/10; 67/100] END class_weight={0: 0.016666666666666666, 1: 1};, score=(train=0.884, test=0.843) total time=   9.5s\n",
      "[CV 5/10; 73/100] START class_weight={0: 0.017272727272727273, 1: 1}............\n",
      "[CV 5/10; 73/100] END class_weight={0: 0.017272727272727273, 1: 1};, score=(train=0.881, test=0.830) total time=  10.9s\n",
      "[CV 4/10; 80/100] START class_weight={0: 0.017979797979797978, 1: 1}............\n",
      "[CV 4/10; 80/100] END class_weight={0: 0.017979797979797978, 1: 1};, score=(train=0.884, test=0.844) total time=  11.6s\n",
      "[CV 10/10; 87/100] START class_weight={0: 0.01868686868686869, 1: 1}............\n",
      "[CV 10/10; 87/100] END class_weight={0: 0.01868686868686869, 1: 1};, score=(train=0.879, test=0.869) total time=   9.4s\n",
      "[CV 5/10; 94/100] START class_weight={0: 0.019393939393939394, 1: 1}............\n",
      "[CV 5/10; 94/100] END class_weight={0: 0.019393939393939394, 1: 1};, score=(train=0.881, test=0.828) total time=  10.9s\n",
      "[CV 5/10; 5/10] START class_weight={0: 0.002777777777777778, 1: 1}..............\n",
      "[CV 5/10; 5/10] END class_weight={0: 0.002777777777777778, 1: 1};, score=(train=0.877, test=0.833) total time=   8.2s\n",
      "[CV 4/10; 1/100] START class_weight={0: 0.001, 1: 1}............................\n",
      "[CV 4/10; 1/100] END class_weight={0: 0.001, 1: 1};, score=(train=0.876, test=0.845) total time=   7.1s\n",
      "[CV 4/10; 8/100] START class_weight={0: 0.0016363636363636363, 1: 1}............\n",
      "[CV 4/10; 8/100] END class_weight={0: 0.0016363636363636363, 1: 1};, score=(train=0.877, test=0.829) total time=   7.0s\n",
      "[CV 6/10; 14/100] START class_weight={0: 0.002181818181818182, 1: 1}............\n",
      "[CV 6/10; 14/100] END class_weight={0: 0.002181818181818182, 1: 1};, score=(train=0.878, test=0.838) total time=   8.5s\n",
      "[CV 1/10; 21/100] START class_weight={0: 0.0028181818181818186, 1: 1}...........\n",
      "[CV 1/10; 21/100] END class_weight={0: 0.0028181818181818186, 1: 1};, score=(train=0.881, test=0.840) total time=   7.1s\n",
      "[CV 2/10; 27/100] START class_weight={0: 0.003363636363636364, 1: 1}............\n",
      "[CV 2/10; 27/100] END class_weight={0: 0.003363636363636364, 1: 1};, score=(train=0.880, test=0.846) total time=   8.5s\n",
      "[CV 7/10; 33/100] START class_weight={0: 0.003909090909090909, 1: 1}............\n",
      "[CV 7/10; 33/100] END class_weight={0: 0.003909090909090909, 1: 1};, score=(train=0.877, test=0.860) total time=   6.3s\n",
      "[CV 10/10; 37/100] START class_weight={0: 0.0042727272727272735, 1: 1}..........\n",
      "[CV 10/10; 37/100] END class_weight={0: 0.0042727272727272735, 1: 1};, score=(train=0.878, test=0.855) total time=   7.0s\n",
      "[CV 5/10; 43/100] START class_weight={0: 0.004818181818181819, 1: 1}............\n",
      "[CV 5/10; 43/100] END class_weight={0: 0.004818181818181819, 1: 1};, score=(train=0.880, test=0.846) total time=   7.4s\n",
      "[CV 8/10; 48/100] START class_weight={0: 0.0052727272727272735, 1: 1}...........\n",
      "[CV 8/10; 48/100] END class_weight={0: 0.0052727272727272735, 1: 1};, score=(train=0.877, test=0.865) total time=   7.2s\n",
      "[CV 7/10; 54/100] START class_weight={0: 0.005818181818181819, 1: 1}............\n",
      "[CV 7/10; 54/100] END class_weight={0: 0.005818181818181819, 1: 1};, score=(train=0.876, test=0.867) total time=   7.5s\n",
      "[CV 1/10; 60/100] START class_weight={0: 0.006363636363636364, 1: 1}............\n",
      "[CV 1/10; 60/100] END class_weight={0: 0.006363636363636364, 1: 1};, score=(train=0.877, test=0.846) total time=  10.4s\n",
      "[CV 5/10; 67/100] START class_weight={0: 0.007, 1: 1}...........................\n",
      "[CV 5/10; 67/100] END class_weight={0: 0.007, 1: 1};, score=(train=0.880, test=0.831) total time=   8.5s\n",
      "[CV 10/10; 73/100] START class_weight={0: 0.007545454545454546, 1: 1}...........\n",
      "[CV 10/10; 73/100] END class_weight={0: 0.007545454545454546, 1: 1};, score=(train=0.877, test=0.850) total time=   8.3s\n",
      "[CV 6/10; 79/100] START class_weight={0: 0.008090909090909091, 1: 1}............\n",
      "[CV 6/10; 79/100] END class_weight={0: 0.008090909090909091, 1: 1};, score=(train=0.879, test=0.836) total time=   9.3s\n",
      "[CV 3/10; 86/100] START class_weight={0: 0.008727272727272728, 1: 1}............\n",
      "[CV 3/10; 86/100] END class_weight={0: 0.008727272727272728, 1: 1};, score=(train=0.877, test=0.848) total time=   7.7s\n",
      "[CV 2/10; 91/100] START class_weight={0: 0.009181818181818183, 1: 1}............\n",
      "[CV 2/10; 91/100] END class_weight={0: 0.009181818181818183, 1: 1};, score=(train=0.879, test=0.852) total time=   7.9s\n",
      "[CV 8/10; 96/100] START class_weight={0: 0.009636363636363637, 1: 1}............\n",
      "[CV 8/10; 96/100] END class_weight={0: 0.009636363636363637, 1: 1};, score=(train=0.877, test=0.866) total time=  10.0s\n",
      "[CV 6/10; 3/100] START class_weight={0: 0.010202020202020202, 1: 1}.............\n",
      "[CV 6/10; 3/100] END class_weight={0: 0.010202020202020202, 1: 1};, score=(train=0.878, test=0.839) total time=   8.5s\n",
      "[CV 9/10; 7/100] START class_weight={0: 0.010606060606060607, 1: 1}.............\n",
      "[CV 9/10; 7/100] END class_weight={0: 0.010606060606060607, 1: 1};, score=(train=0.880, test=0.848) total time=   9.4s\n",
      "[CV 10/10; 14/100] START class_weight={0: 0.011313131313131313, 1: 1}...........\n",
      "[CV 10/10; 14/100] END class_weight={0: 0.011313131313131313, 1: 1};, score=(train=0.880, test=0.866) total time=   9.5s\n",
      "[CV 5/10; 21/100] START class_weight={0: 0.012020202020202021, 1: 1}............\n",
      "[CV 5/10; 21/100] END class_weight={0: 0.012020202020202021, 1: 1};, score=(train=0.878, test=0.841) total time=   9.9s\n",
      "[CV 3/10; 28/100] START class_weight={0: 0.012727272727272728, 1: 1}............\n",
      "[CV 3/10; 28/100] END class_weight={0: 0.012727272727272728, 1: 1};, score=(train=0.876, test=0.838) total time=   7.3s\n",
      "[CV 10/10; 32/100] START class_weight={0: 0.013131313131313133, 1: 1}...........\n",
      "[CV 10/10; 32/100] END class_weight={0: 0.013131313131313133, 1: 1};, score=(train=0.877, test=0.860) total time=   8.5s\n",
      "[CV 9/10; 38/100] START class_weight={0: 0.013737373737373737, 1: 1}............\n",
      "[CV 9/10; 38/100] END class_weight={0: 0.013737373737373737, 1: 1};, score=(train=0.880, test=0.837) total time=  11.3s\n",
      "[CV 9/10; 45/100] START class_weight={0: 0.014444444444444444, 1: 1}............\n",
      "[CV 9/10; 45/100] END class_weight={0: 0.014444444444444444, 1: 1};, score=(train=0.880, test=0.837) total time=   9.7s\n",
      "[CV 1/10; 52/100] START class_weight={0: 0.015151515151515152, 1: 1}............\n",
      "[CV 1/10; 52/100] END class_weight={0: 0.015151515151515152, 1: 1};, score=(train=0.878, test=0.851) total time=  11.6s\n",
      "[CV 4/10; 59/100] START class_weight={0: 0.015858585858585857, 1: 1}............\n",
      "[CV 4/10; 59/100] END class_weight={0: 0.015858585858585857, 1: 1};, score=(train=0.881, test=0.841) total time=  10.5s\n",
      "[CV 5/10; 66/100] START class_weight={0: 0.016565656565656565, 1: 1}............\n",
      "[CV 5/10; 66/100] END class_weight={0: 0.016565656565656565, 1: 1};, score=(train=0.883, test=0.836) total time=  11.4s\n",
      "[CV 9/10; 73/100] START class_weight={0: 0.017272727272727273, 1: 1}............\n",
      "[CV 9/10; 73/100] END class_weight={0: 0.017272727272727273, 1: 1};, score=(train=0.882, test=0.840) total time=   9.4s\n",
      "[CV 1/10; 80/100] START class_weight={0: 0.017979797979797978, 1: 1}............\n",
      "[CV 1/10; 80/100] END class_weight={0: 0.017979797979797978, 1: 1};, score=(train=0.880, test=0.861) total time=  11.6s\n",
      "[CV 6/10; 87/100] START class_weight={0: 0.01868686868686869, 1: 1}.............\n",
      "[CV 6/10; 87/100] END class_weight={0: 0.01868686868686869, 1: 1};, score=(train=0.881, test=0.826) total time=  10.0s\n",
      "[CV 3/10; 94/100] START class_weight={0: 0.019393939393939394, 1: 1}............\n",
      "[CV 3/10; 94/100] END class_weight={0: 0.019393939393939394, 1: 1};, score=(train=0.882, test=0.833) total time=  11.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10; 3/10] START class_weight={0: 0.001888888888888889, 1: 1}..............\n",
      "[CV 9/10; 3/10] END class_weight={0: 0.001888888888888889, 1: 1};, score=(train=0.881, test=0.848) total time=   7.7s\n",
      "[CV 4/10; 10/10] START class_weight={0: 0.005, 1: 1}............................\n",
      "[CV 4/10; 10/10] END class_weight={0: 0.005, 1: 1};, score=(train=0.879, test=0.849) total time=   6.0s\n",
      "[CV 4/10; 6/100] START class_weight={0: 0.0014545454545454547, 1: 1}............\n",
      "[CV 4/10; 6/100] END class_weight={0: 0.0014545454545454547, 1: 1};, score=(train=0.878, test=0.828) total time=   7.4s\n",
      "[CV 1/10; 10/100] START class_weight={0: 0.0018181818181818182, 1: 1}...........\n",
      "[CV 1/10; 10/100] END class_weight={0: 0.0018181818181818182, 1: 1};, score=(train=0.883, test=0.845) total time=   7.1s\n",
      "[CV 4/10; 15/100] START class_weight={0: 0.0022727272727272726, 1: 1}...........\n",
      "[CV 4/10; 15/100] END class_weight={0: 0.0022727272727272726, 1: 1};, score=(train=0.876, test=0.845) total time=   7.6s\n",
      "[CV 3/10; 21/100] START class_weight={0: 0.0028181818181818186, 1: 1}...........\n",
      "[CV 3/10; 21/100] END class_weight={0: 0.0028181818181818186, 1: 1};, score=(train=0.878, test=0.839) total time=   6.5s\n",
      "[CV 1/10; 27/100] START class_weight={0: 0.003363636363636364, 1: 1}............\n",
      "[CV 1/10; 27/100] END class_weight={0: 0.003363636363636364, 1: 1};, score=(train=0.881, test=0.840) total time=   8.2s\n",
      "[CV 6/10; 33/100] START class_weight={0: 0.003909090909090909, 1: 1}............\n",
      "[CV 6/10; 33/100] END class_weight={0: 0.003909090909090909, 1: 1};, score=(train=0.879, test=0.831) total time=   9.8s\n",
      "[CV 7/10; 40/100] START class_weight={0: 0.004545454545454545, 1: 1}............\n",
      "[CV 7/10; 40/100] END class_weight={0: 0.004545454545454545, 1: 1};, score=(train=0.876, test=0.861) total time=   8.0s\n",
      "[CV 8/10; 46/100] START class_weight={0: 0.005090909090909091, 1: 1}............\n",
      "[CV 8/10; 46/100] END class_weight={0: 0.005090909090909091, 1: 1};, score=(train=0.877, test=0.865) total time=   9.0s\n",
      "[CV 2/10; 53/100] START class_weight={0: 0.0057272727272727275, 1: 1}...........\n",
      "[CV 2/10; 53/100] END class_weight={0: 0.0057272727272727275, 1: 1};, score=(train=0.880, test=0.833) total time=   9.4s\n",
      "[CV 10/10; 59/100] START class_weight={0: 0.006272727272727274, 1: 1}...........\n",
      "[CV 10/10; 59/100] END class_weight={0: 0.006272727272727274, 1: 1};, score=(train=0.878, test=0.860) total time=  11.5s\n",
      "[CV 6/10; 68/100] START class_weight={0: 0.007090909090909091, 1: 1}............\n",
      "[CV 6/10; 68/100] END class_weight={0: 0.007090909090909091, 1: 1};, score=(train=0.879, test=0.837) total time=   8.7s\n",
      "[CV 6/10; 74/100] START class_weight={0: 0.007636363636363637, 1: 1}............\n",
      "[CV 6/10; 74/100] END class_weight={0: 0.007636363636363637, 1: 1};, score=(train=0.879, test=0.837) total time=   8.8s\n",
      "[CV 6/10; 80/100] START class_weight={0: 0.008181818181818182, 1: 1}............\n",
      "[CV 6/10; 80/100] END class_weight={0: 0.008181818181818182, 1: 1};, score=(train=0.879, test=0.836) total time=   9.9s\n",
      "[CV 6/10; 87/100] START class_weight={0: 0.008818181818181819, 1: 1}............\n",
      "[CV 6/10; 87/100] END class_weight={0: 0.008818181818181819, 1: 1};, score=(train=0.879, test=0.836) total time=   9.3s\n",
      "[CV 8/10; 93/100] START class_weight={0: 0.009363636363636366, 1: 1}............\n",
      "[CV 8/10; 93/100] END class_weight={0: 0.009363636363636366, 1: 1};, score=(train=0.877, test=0.863) total time=   7.7s\n",
      "[CV 9/10; 98/100] START class_weight={0: 0.00981818181818182, 1: 1}.............\n",
      "[CV 9/10; 98/100] END class_weight={0: 0.00981818181818182, 1: 1};, score=(train=0.880, test=0.848) total time=   7.1s\n",
      "[CV 7/10; 3/100] START class_weight={0: 0.010202020202020202, 1: 1}.............\n",
      "[CV 7/10; 3/100] END class_weight={0: 0.010202020202020202, 1: 1};, score=(train=0.880, test=0.869) total time=  11.4s\n",
      "[CV 2/10; 13/100] START class_weight={0: 0.011212121212121211, 1: 1}............\n",
      "[CV 2/10; 13/100] END class_weight={0: 0.011212121212121211, 1: 1};, score=(train=0.878, test=0.850) total time=   9.6s\n",
      "[CV 5/10; 18/100] START class_weight={0: 0.011717171717171718, 1: 1}............\n",
      "[CV 5/10; 18/100] END class_weight={0: 0.011717171717171718, 1: 1};, score=(train=0.878, test=0.841) total time=   8.5s\n",
      "[CV 3/10; 23/100] START class_weight={0: 0.012222222222222223, 1: 1}............\n",
      "[CV 3/10; 23/100] END class_weight={0: 0.012222222222222223, 1: 1};, score=(train=0.876, test=0.838) total time=   7.1s\n",
      "[CV 9/10; 27/100] START class_weight={0: 0.012626262626262626, 1: 1}............\n",
      "[CV 9/10; 27/100] END class_weight={0: 0.012626262626262626, 1: 1};, score=(train=0.880, test=0.838) total time=  11.2s\n",
      "[CV 4/10; 35/100] START class_weight={0: 0.013434343434343434, 1: 1}............\n",
      "[CV 4/10; 35/100] END class_weight={0: 0.013434343434343434, 1: 1};, score=(train=0.882, test=0.843) total time=  10.3s\n",
      "[CV 9/10; 41/100] START class_weight={0: 0.01404040404040404, 1: 1}.............\n",
      "[CV 9/10; 41/100] END class_weight={0: 0.01404040404040404, 1: 1};, score=(train=0.880, test=0.837) total time=   9.3s\n",
      "[CV 5/10; 48/100] START class_weight={0: 0.014747474747474749, 1: 1}............\n",
      "[CV 5/10; 48/100] END class_weight={0: 0.014747474747474749, 1: 1};, score=(train=0.882, test=0.839) total time=  10.3s\n",
      "[CV 2/10; 55/100] START class_weight={0: 0.015454545454545455, 1: 1}............\n",
      "[CV 2/10; 55/100] END class_weight={0: 0.015454545454545455, 1: 1};, score=(train=0.884, test=0.843) total time=  10.3s\n",
      "[CV 8/10; 61/100] START class_weight={0: 0.01606060606060606, 1: 1}.............\n",
      "[CV 8/10; 61/100] END class_weight={0: 0.01606060606060606, 1: 1};, score=(train=0.880, test=0.879) total time=  11.0s\n",
      "[CV 7/10; 68/100] START class_weight={0: 0.016767676767676768, 1: 1}............\n",
      "[CV 7/10; 68/100] END class_weight={0: 0.016767676767676768, 1: 1};, score=(train=0.880, test=0.867) total time=  10.1s\n",
      "[CV 5/10; 75/100] START class_weight={0: 0.017474747474747476, 1: 1}............\n",
      "[CV 5/10; 75/100] END class_weight={0: 0.017474747474747476, 1: 1};, score=(train=0.883, test=0.836) total time=   7.5s\n",
      "[CV 2/10; 80/100] START class_weight={0: 0.017979797979797978, 1: 1}............\n",
      "[CV 2/10; 80/100] END class_weight={0: 0.017979797979797978, 1: 1};, score=(train=0.885, test=0.846) total time=  12.1s\n",
      "[CV 6/10; 88/100] START class_weight={0: 0.018787878787878787, 1: 1}............\n",
      "[CV 6/10; 88/100] END class_weight={0: 0.018787878787878787, 1: 1};, score=(train=0.881, test=0.832) total time=  10.8s\n",
      "[CV 1/10; 95/100] START class_weight={0: 0.019494949494949496, 1: 1}............\n",
      "[CV 1/10; 95/100] END class_weight={0: 0.019494949494949496, 1: 1};, score=(train=0.879, test=0.854) total time=   9.9s\n",
      "[CV 2/10; 5/10] START class_weight={0: 0.002777777777777778, 1: 1}..............\n",
      "[CV 2/10; 5/10] END class_weight={0: 0.002777777777777778, 1: 1};, score=(train=0.883, test=0.852) total time=   9.4s\n",
      "[CV 3/10; 2/100] START class_weight={0: 0.001090909090909091, 1: 1}.............\n",
      "[CV 3/10; 2/100] END class_weight={0: 0.001090909090909091, 1: 1};, score=(train=0.879, test=0.837) total time=  10.0s\n",
      "[CV 4/10; 13/100] START class_weight={0: 0.002090909090909091, 1: 1}............\n",
      "[CV 4/10; 13/100] END class_weight={0: 0.002090909090909091, 1: 1};, score=(train=0.877, test=0.840) total time=  10.0s\n",
      "[CV 1/10; 20/100] START class_weight={0: 0.0027272727272727275, 1: 1}...........\n",
      "[CV 1/10; 20/100] END class_weight={0: 0.0027272727272727275, 1: 1};, score=(train=0.882, test=0.840) total time=   7.5s\n",
      "[CV 10/10; 25/100] START class_weight={0: 0.003181818181818182, 1: 1}...........\n",
      "[CV 10/10; 25/100] END class_weight={0: 0.003181818181818182, 1: 1};, score=(train=0.880, test=0.851) total time=   8.6s\n",
      "[CV 7/10; 32/100] START class_weight={0: 0.0038181818181818187, 1: 1}...........\n",
      "[CV 7/10; 32/100] END class_weight={0: 0.0038181818181818187, 1: 1};, score=(train=0.877, test=0.861) total time=  11.1s\n",
      "[CV 8/10; 40/100] START class_weight={0: 0.004545454545454545, 1: 1}............\n",
      "[CV 8/10; 40/100] END class_weight={0: 0.004545454545454545, 1: 1};, score=(train=0.877, test=0.864) total time=   9.4s\n",
      "[CV 6/10; 47/100] START class_weight={0: 0.005181818181818182, 1: 1}............\n",
      "[CV 6/10; 47/100] END class_weight={0: 0.005181818181818182, 1: 1};, score=(train=0.879, test=0.840) total time=   8.3s\n",
      "[CV 1/10; 54/100] START class_weight={0: 0.005818181818181819, 1: 1}............\n",
      "[CV 1/10; 54/100] END class_weight={0: 0.005818181818181819, 1: 1};, score=(train=0.878, test=0.839) total time=   9.2s\n",
      "[CV 6/10; 60/100] START class_weight={0: 0.006363636363636364, 1: 1}............\n",
      "[CV 6/10; 60/100] END class_weight={0: 0.006363636363636364, 1: 1};, score=(train=0.879, test=0.836) total time=  11.4s\n",
      "[CV 1/10; 69/100] START class_weight={0: 0.0071818181818181824, 1: 1}...........\n",
      "[CV 1/10; 69/100] END class_weight={0: 0.0071818181818181824, 1: 1};, score=(train=0.877, test=0.842) total time=   8.4s\n",
      "[CV 2/10; 75/100] START class_weight={0: 0.007727272727272728, 1: 1}............\n",
      "[CV 2/10; 75/100] END class_weight={0: 0.007727272727272728, 1: 1};, score=(train=0.879, test=0.858) total time=   8.5s\n",
      "[CV 2/10; 81/100] START class_weight={0: 0.008272727272727274, 1: 1}............\n",
      "[CV 2/10; 81/100] END class_weight={0: 0.008272727272727274, 1: 1};, score=(train=0.879, test=0.858) total time=   8.5s\n",
      "[CV 4/10; 87/100] START class_weight={0: 0.008818181818181819, 1: 1}............\n",
      "[CV 4/10; 87/100] END class_weight={0: 0.008818181818181819, 1: 1};, score=(train=0.879, test=0.833) total time=  11.3s\n",
      "[CV 9/10; 94/100] START class_weight={0: 0.009454545454545455, 1: 1}............\n",
      "[CV 9/10; 94/100] END class_weight={0: 0.009454545454545455, 1: 1};, score=(train=0.881, test=0.843) total time=  11.9s\n",
      "[CV 5/10; 2/100] START class_weight={0: 0.010101010101010102, 1: 1}.............\n",
      "[CV 5/10; 2/100] END class_weight={0: 0.010101010101010102, 1: 1};, score=(train=0.879, test=0.836) total time=   7.4s\n",
      "[CV 5/10; 7/100] START class_weight={0: 0.010606060606060607, 1: 1}.............\n",
      "[CV 5/10; 7/100] END class_weight={0: 0.010606060606060607, 1: 1};, score=(train=0.879, test=0.836) total time=   8.3s\n",
      "[CV 9/10; 13/100] START class_weight={0: 0.011212121212121211, 1: 1}............\n",
      "[CV 9/10; 13/100] END class_weight={0: 0.011212121212121211, 1: 1};, score=(train=0.880, test=0.848) total time=   8.4s\n",
      "[CV 1/10; 20/100] START class_weight={0: 0.01191919191919192, 1: 1}.............\n",
      "[CV 1/10; 20/100] END class_weight={0: 0.01191919191919192, 1: 1};, score=(train=0.877, test=0.860) total time=  10.8s\n",
      "[CV 9/10; 26/100] START class_weight={0: 0.012525252525252526, 1: 1}............\n",
      "[CV 9/10; 26/100] END class_weight={0: 0.012525252525252526, 1: 1};, score=(train=0.880, test=0.838) total time=  12.8s\n",
      "[CV 6/10; 35/100] START class_weight={0: 0.013434343434343434, 1: 1}............\n",
      "[CV 6/10; 35/100] END class_weight={0: 0.013434343434343434, 1: 1};, score=(train=0.880, test=0.832) total time=  11.7s\n",
      "[CV 7/10; 43/100] START class_weight={0: 0.014242424242424242, 1: 1}............\n",
      "[CV 7/10; 43/100] END class_weight={0: 0.014242424242424242, 1: 1};, score=(train=0.878, test=0.862) total time=  10.7s\n",
      "[CV 4/10; 50/100] START class_weight={0: 0.014949494949494949, 1: 1}............\n",
      "[CV 4/10; 50/100] END class_weight={0: 0.014949494949494949, 1: 1};, score=(train=0.881, test=0.841) total time=  10.2s\n",
      "[CV 3/10; 57/100] START class_weight={0: 0.015656565656565657, 1: 1}............\n",
      "[CV 3/10; 57/100] END class_weight={0: 0.015656565656565657, 1: 1};, score=(train=0.879, test=0.834) total time=   9.3s\n",
      "[CV 8/10; 63/100] START class_weight={0: 0.016262626262626263, 1: 1}............\n",
      "[CV 8/10; 63/100] END class_weight={0: 0.016262626262626263, 1: 1};, score=(train=0.880, test=0.872) total time=   9.0s\n",
      "[CV 5/10; 69/100] START class_weight={0: 0.01686868686868687, 1: 1}.............\n",
      "[CV 5/10; 69/100] END class_weight={0: 0.01686868686868687, 1: 1};, score=(train=0.883, test=0.836) total time=   8.1s\n",
      "[CV 6/10; 74/100] START class_weight={0: 0.017373737373737375, 1: 1}............\n",
      "[CV 6/10; 74/100] END class_weight={0: 0.017373737373737375, 1: 1};, score=(train=0.881, test=0.832) total time=  12.4s\n",
      "[CV 8/10; 82/100] START class_weight={0: 0.01818181818181818, 1: 1}.............\n",
      "[CV 8/10; 82/100] END class_weight={0: 0.01818181818181818, 1: 1};, score=(train=0.879, test=0.880) total time=  10.5s\n",
      "[CV 1/10; 89/100] START class_weight={0: 0.01888888888888889, 1: 1}.............\n",
      "[CV 1/10; 89/100] END class_weight={0: 0.01888888888888889, 1: 1};, score=(train=0.879, test=0.854) total time=  10.1s\n",
      "[CV 2/10; 96/100] START class_weight={0: 0.019595959595959597, 1: 1}............\n",
      "[CV 2/10; 96/100] END class_weight={0: 0.019595959595959597, 1: 1};, score=(train=0.885, test=0.846) total time=   9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10; 4/10] START class_weight={0: 0.0023333333333333335, 1: 1}............\n",
      "[CV 10/10; 4/10] END class_weight={0: 0.0023333333333333335, 1: 1};, score=(train=0.876, test=0.853) total time=   8.9s\n",
      "[CV 4/10; 2/100] START class_weight={0: 0.001090909090909091, 1: 1}.............\n",
      "[CV 4/10; 2/100] END class_weight={0: 0.001090909090909091, 1: 1};, score=(train=0.878, test=0.835) total time=   9.2s\n",
      "[CV 3/10; 12/100] START class_weight={0: 0.002, 1: 1}...........................\n",
      "[CV 3/10; 12/100] END class_weight={0: 0.002, 1: 1};, score=(train=0.880, test=0.838) total time=   8.2s\n",
      "[CV 2/10; 18/100] START class_weight={0: 0.0025454545454545456, 1: 1}...........\n",
      "[CV 2/10; 18/100] END class_weight={0: 0.0025454545454545456, 1: 1};, score=(train=0.883, test=0.836) total time=  10.0s\n",
      "[CV 6/10; 25/100] START class_weight={0: 0.003181818181818182, 1: 1}............\n",
      "[CV 6/10; 25/100] END class_weight={0: 0.003181818181818182, 1: 1};, score=(train=0.876, test=0.834) total time=   8.2s\n",
      "[CV 7/10; 31/100] START class_weight={0: 0.0037272727272727275, 1: 1}...........\n",
      "[CV 7/10; 31/100] END class_weight={0: 0.0037272727272727275, 1: 1};, score=(train=0.877, test=0.868) total time=   8.1s\n",
      "[CV 5/10; 37/100] START class_weight={0: 0.0042727272727272735, 1: 1}...........\n",
      "[CV 5/10; 37/100] END class_weight={0: 0.0042727272727272735, 1: 1};, score=(train=0.881, test=0.846) total time=   6.7s\n",
      "[CV 10/10; 41/100] START class_weight={0: 0.004636363636363636, 1: 1}...........\n",
      "[CV 10/10; 41/100] END class_weight={0: 0.004636363636363636, 1: 1};, score=(train=0.879, test=0.853) total time=   8.0s\n",
      "[CV 5/10; 48/100] START class_weight={0: 0.0052727272727272735, 1: 1}...........\n",
      "[CV 5/10; 48/100] END class_weight={0: 0.0052727272727272735, 1: 1};, score=(train=0.879, test=0.840) total time=   8.2s\n",
      "[CV 9/10; 54/100] START class_weight={0: 0.005818181818181819, 1: 1}............\n",
      "[CV 9/10; 54/100] END class_weight={0: 0.005818181818181819, 1: 1};, score=(train=0.880, test=0.846) total time=   8.7s\n",
      "[CV 8/10; 60/100] START class_weight={0: 0.006363636363636364, 1: 1}............\n",
      "[CV 8/10; 60/100] END class_weight={0: 0.006363636363636364, 1: 1};, score=(train=0.876, test=0.860) total time=   7.0s\n",
      "[CV 9/10; 65/100] START class_weight={0: 0.006818181818181819, 1: 1}............\n",
      "[CV 9/10; 65/100] END class_weight={0: 0.006818181818181819, 1: 1};, score=(train=0.880, test=0.846) total time=   8.9s\n",
      "[CV 2/10; 72/100] START class_weight={0: 0.007454545454545455, 1: 1}............\n",
      "[CV 2/10; 72/100] END class_weight={0: 0.007454545454545455, 1: 1};, score=(train=0.879, test=0.834) total time=   9.6s\n",
      "[CV 7/10; 78/100] START class_weight={0: 0.008, 1: 1}...........................\n",
      "[CV 7/10; 78/100] END class_weight={0: 0.008, 1: 1};, score=(train=0.877, test=0.866) total time=   8.2s\n",
      "[CV 8/10; 84/100] START class_weight={0: 0.008545454545454547, 1: 1}............\n",
      "[CV 8/10; 84/100] END class_weight={0: 0.008545454545454547, 1: 1};, score=(train=0.877, test=0.868) total time=  11.6s\n",
      "[CV 10/10; 92/100] START class_weight={0: 0.009272727272727273, 1: 1}...........\n",
      "[CV 10/10; 92/100] END class_weight={0: 0.009272727272727273, 1: 1};, score=(train=0.874, test=0.847) total time=   9.0s\n",
      "[CV 1/10; 99/100] START class_weight={0: 0.009909090909090909, 1: 1}............\n",
      "[CV 1/10; 99/100] END class_weight={0: 0.009909090909090909, 1: 1};, score=(train=0.878, test=0.855) total time=   8.5s\n",
      "[CV 7/10; 5/100] START class_weight={0: 0.010404040404040405, 1: 1}.............\n",
      "[CV 7/10; 5/100] END class_weight={0: 0.010404040404040405, 1: 1};, score=(train=0.876, test=0.865) total time=  10.0s\n",
      "[CV 9/10; 11/100] START class_weight={0: 0.01101010101010101, 1: 1}.............\n",
      "[CV 9/10; 11/100] END class_weight={0: 0.01101010101010101, 1: 1};, score=(train=0.881, test=0.843) total time=   9.1s\n",
      "[CV 10/10; 16/100] START class_weight={0: 0.011515151515151515, 1: 1}...........\n",
      "[CV 10/10; 16/100] END class_weight={0: 0.011515151515151515, 1: 1};, score=(train=0.876, test=0.867) total time=  11.0s\n",
      "[CV 6/10; 24/100] START class_weight={0: 0.012323232323232323, 1: 1}............\n",
      "[CV 6/10; 24/100] END class_weight={0: 0.012323232323232323, 1: 1};, score=(train=0.880, test=0.834) total time=   8.0s\n",
      "[CV 10/10; 28/100] START class_weight={0: 0.012727272727272728, 1: 1}...........\n",
      "[CV 10/10; 28/100] END class_weight={0: 0.012727272727272728, 1: 1};, score=(train=0.874, test=0.856) total time=   9.0s\n",
      "[CV 9/10; 34/100] START class_weight={0: 0.013333333333333332, 1: 1}............\n",
      "[CV 9/10; 34/100] END class_weight={0: 0.013333333333333332, 1: 1};, score=(train=0.880, test=0.837) total time=  11.7s\n",
      "[CV 9/10; 42/100] START class_weight={0: 0.014141414141414142, 1: 1}............\n",
      "[CV 9/10; 42/100] END class_weight={0: 0.014141414141414142, 1: 1};, score=(train=0.880, test=0.837) total time=   8.9s\n",
      "[CV 8/10; 48/100] START class_weight={0: 0.014747474747474749, 1: 1}............\n",
      "[CV 8/10; 48/100] END class_weight={0: 0.014747474747474749, 1: 1};, score=(train=0.880, test=0.883) total time=   9.7s\n",
      "[CV 9/10; 54/100] START class_weight={0: 0.015353535353535354, 1: 1}............\n",
      "[CV 9/10; 54/100] END class_weight={0: 0.015353535353535354, 1: 1};, score=(train=0.880, test=0.837) total time=  11.9s\n",
      "[CV 7/10; 62/100] START class_weight={0: 0.01616161616161616, 1: 1}.............\n",
      "[CV 7/10; 62/100] END class_weight={0: 0.01616161616161616, 1: 1};, score=(train=0.880, test=0.867) total time=   9.3s\n",
      "[CV 6/10; 68/100] START class_weight={0: 0.016767676767676768, 1: 1}............\n",
      "[CV 6/10; 68/100] END class_weight={0: 0.016767676767676768, 1: 1};, score=(train=0.881, test=0.832) total time=   8.4s\n",
      "[CV 1/10; 74/100] START class_weight={0: 0.017373737373737375, 1: 1}............\n",
      "[CV 1/10; 74/100] END class_weight={0: 0.017373737373737375, 1: 1};, score=(train=0.880, test=0.861) total time=  10.5s\n",
      "[CV 9/10; 80/100] START class_weight={0: 0.017979797979797978, 1: 1}............\n",
      "[CV 9/10; 80/100] END class_weight={0: 0.017979797979797978, 1: 1};, score=(train=0.883, test=0.842) total time=   9.8s\n",
      "[CV 2/10; 87/100] START class_weight={0: 0.01868686868686869, 1: 1}.............\n",
      "[CV 2/10; 87/100] END class_weight={0: 0.01868686868686869, 1: 1};, score=(train=0.885, test=0.846) total time=  10.8s\n",
      "[CV 6/10; 94/100] START class_weight={0: 0.019393939393939394, 1: 1}............\n",
      "[CV 6/10; 94/100] END class_weight={0: 0.019393939393939394, 1: 1};, score=(train=0.881, test=0.832) total time=  11.6s\n",
      "[CV 4/10; 5/10] START class_weight={0: 0.002777777777777778, 1: 1}..............\n",
      "[CV 4/10; 5/10] END class_weight={0: 0.002777777777777778, 1: 1};, score=(train=0.878, test=0.839) total time=   8.9s\n",
      "[CV 2/10; 2/100] START class_weight={0: 0.001090909090909091, 1: 1}.............\n",
      "[CV 2/10; 2/100] END class_weight={0: 0.001090909090909091, 1: 1};, score=(train=0.880, test=0.836) total time=   9.2s\n",
      "[CV 7/10; 12/100] START class_weight={0: 0.002, 1: 1}...........................\n",
      "[CV 7/10; 12/100] END class_weight={0: 0.002, 1: 1};, score=(train=0.874, test=0.863) total time=   8.9s\n",
      "[CV 7/10; 18/100] START class_weight={0: 0.0025454545454545456, 1: 1}...........\n",
      "[CV 7/10; 18/100] END class_weight={0: 0.0025454545454545456, 1: 1};, score=(train=0.875, test=0.866) total time=   9.1s\n",
      "[CV 7/10; 25/100] START class_weight={0: 0.003181818181818182, 1: 1}............\n",
      "[CV 7/10; 25/100] END class_weight={0: 0.003181818181818182, 1: 1};, score=(train=0.875, test=0.856) total time=   8.3s\n",
      "[CV 10/10; 31/100] START class_weight={0: 0.0037272727272727275, 1: 1}..........\n",
      "[CV 10/10; 31/100] END class_weight={0: 0.0037272727272727275, 1: 1};, score=(train=0.879, test=0.851) total time=  10.4s\n",
      "[CV 7/10; 39/100] START class_weight={0: 0.004454545454545455, 1: 1}............\n",
      "[CV 7/10; 39/100] END class_weight={0: 0.004454545454545455, 1: 1};, score=(train=0.877, test=0.868) total time=   9.3s\n",
      "[CV 6/10; 46/100] START class_weight={0: 0.005090909090909091, 1: 1}............\n",
      "[CV 6/10; 46/100] END class_weight={0: 0.005090909090909091, 1: 1};, score=(train=0.880, test=0.831) total time=   8.6s\n",
      "[CV 9/10; 52/100] START class_weight={0: 0.005636363636363636, 1: 1}............\n",
      "[CV 9/10; 52/100] END class_weight={0: 0.005636363636363636, 1: 1};, score=(train=0.881, test=0.842) total time=  11.7s\n",
      "[CV 1/10; 61/100] START class_weight={0: 0.006454545454545455, 1: 1}............\n",
      "[CV 1/10; 61/100] END class_weight={0: 0.006454545454545455, 1: 1};, score=(train=0.878, test=0.841) total time=  11.0s\n",
      "[CV 6/10; 69/100] START class_weight={0: 0.0071818181818181824, 1: 1}...........\n",
      "[CV 6/10; 69/100] END class_weight={0: 0.0071818181818181824, 1: 1};, score=(train=0.879, test=0.837) total time=  10.1s\n",
      "[CV 10/10; 75/100] START class_weight={0: 0.007727272727272728, 1: 1}...........\n",
      "[CV 10/10; 75/100] END class_weight={0: 0.007727272727272728, 1: 1};, score=(train=0.874, test=0.848) total time=   9.2s\n",
      "[CV 6/10; 82/100] START class_weight={0: 0.008363636363636365, 1: 1}............\n",
      "[CV 6/10; 82/100] END class_weight={0: 0.008363636363636365, 1: 1};, score=(train=0.879, test=0.837) total time=   8.2s\n",
      "[CV 5/10; 88/100] START class_weight={0: 0.008909090909090908, 1: 1}............\n",
      "[CV 5/10; 88/100] END class_weight={0: 0.008909090909090908, 1: 1};, score=(train=0.880, test=0.831) total time=  10.1s\n",
      "[CV 6/10; 95/100] START class_weight={0: 0.009545454545454548, 1: 1}............\n",
      "[CV 6/10; 95/100] END class_weight={0: 0.009545454545454548, 1: 1};, score=(train=0.878, test=0.839) total time=  10.4s\n",
      "[CV 2/10; 2/100] START class_weight={0: 0.010101010101010102, 1: 1}.............\n",
      "[CV 2/10; 2/100] END class_weight={0: 0.010101010101010102, 1: 1};, score=(train=0.880, test=0.841) total time=   9.9s\n",
      "[CV 6/10; 10/100] START class_weight={0: 0.01090909090909091, 1: 1}.............\n",
      "[CV 6/10; 10/100] END class_weight={0: 0.01090909090909091, 1: 1};, score=(train=0.876, test=0.833) total time=   9.0s\n",
      "[CV 4/10; 16/100] START class_weight={0: 0.011515151515151515, 1: 1}............\n",
      "[CV 4/10; 16/100] END class_weight={0: 0.011515151515151515, 1: 1};, score=(train=0.876, test=0.836) total time=  10.2s\n",
      "[CV 1/10; 23/100] START class_weight={0: 0.012222222222222223, 1: 1}............\n",
      "[CV 1/10; 23/100] END class_weight={0: 0.012222222222222223, 1: 1};, score=(train=0.877, test=0.864) total time=  11.9s\n",
      "[CV 5/10; 31/100] START class_weight={0: 0.013030303030303031, 1: 1}............\n",
      "[CV 5/10; 31/100] END class_weight={0: 0.013030303030303031, 1: 1};, score=(train=0.879, test=0.824) total time=   8.7s\n",
      "[CV 10/10; 36/100] START class_weight={0: 0.013535353535353536, 1: 1}...........\n",
      "[CV 10/10; 36/100] END class_weight={0: 0.013535353535353536, 1: 1};, score=(train=0.878, test=0.861) total time=   9.2s\n",
      "[CV 1/10; 43/100] START class_weight={0: 0.014242424242424242, 1: 1}............\n",
      "[CV 1/10; 43/100] END class_weight={0: 0.014242424242424242, 1: 1};, score=(train=0.878, test=0.861) total time=   9.2s\n",
      "[CV 3/10; 49/100] START class_weight={0: 0.014848484848484849, 1: 1}............\n",
      "[CV 3/10; 49/100] END class_weight={0: 0.014848484848484849, 1: 1};, score=(train=0.876, test=0.838) total time=  10.7s\n",
      "[CV 3/10; 56/100] START class_weight={0: 0.015555555555555555, 1: 1}............\n",
      "[CV 3/10; 56/100] END class_weight={0: 0.015555555555555555, 1: 1};, score=(train=0.876, test=0.838) total time=  10.8s\n",
      "[CV 9/10; 62/100] START class_weight={0: 0.01616161616161616, 1: 1}.............\n",
      "[CV 9/10; 62/100] END class_weight={0: 0.01616161616161616, 1: 1};, score=(train=0.883, test=0.843) total time=   9.1s\n",
      "[CV 5/10; 68/100] START class_weight={0: 0.016767676767676768, 1: 1}............\n",
      "[CV 5/10; 68/100] END class_weight={0: 0.016767676767676768, 1: 1};, score=(train=0.883, test=0.832) total time=   8.5s\n",
      "[CV 2/10; 74/100] START class_weight={0: 0.017373737373737375, 1: 1}............\n",
      "[CV 2/10; 74/100] END class_weight={0: 0.017373737373737375, 1: 1};, score=(train=0.884, test=0.842) total time=  10.5s\n",
      "[CV 7/10; 80/100] START class_weight={0: 0.017979797979797978, 1: 1}............\n",
      "[CV 7/10; 80/100] END class_weight={0: 0.017979797979797978, 1: 1};, score=(train=0.881, test=0.853) total time=   8.3s\n",
      "[CV 4/10; 86/100] START class_weight={0: 0.018585858585858588, 1: 1}............\n",
      "[CV 4/10; 86/100] END class_weight={0: 0.018585858585858588, 1: 1};, score=(train=0.884, test=0.844) total time=  11.7s\n",
      "[CV 4/10; 94/100] START class_weight={0: 0.019393939393939394, 1: 1}............\n",
      "[CV 4/10; 94/100] END class_weight={0: 0.019393939393939394, 1: 1};, score=(train=0.882, test=0.838) total time=  11.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10; 1/10] START class_weight={0: 0.001, 1: 1}.............................\n",
      "[CV 9/10; 1/10] END class_weight={0: 0.001, 1: 1};, score=(train=0.878, test=0.833) total time=   7.3s\n",
      "[CV 3/10; 9/10] START class_weight={0: 0.004555555555555556, 1: 1}..............\n",
      "[CV 3/10; 9/10] END class_weight={0: 0.004555555555555556, 1: 1};, score=(train=0.878, test=0.843) total time=   6.1s\n",
      "[CV 2/10; 5/100] START class_weight={0: 0.0013636363636363637, 1: 1}............\n",
      "[CV 2/10; 5/100] END class_weight={0: 0.0013636363636363637, 1: 1};, score=(train=0.882, test=0.842) total time=  10.1s\n",
      "[CV 3/10; 13/100] START class_weight={0: 0.002090909090909091, 1: 1}............\n",
      "[CV 3/10; 13/100] END class_weight={0: 0.002090909090909091, 1: 1};, score=(train=0.879, test=0.833) total time=   8.1s\n",
      "[CV 1/10; 19/100] START class_weight={0: 0.0026363636363636363, 1: 1}...........\n",
      "[CV 1/10; 19/100] END class_weight={0: 0.0026363636363636363, 1: 1};, score=(train=0.883, test=0.836) total time=   9.6s\n",
      "[CV 4/10; 26/100] START class_weight={0: 0.003272727272727273, 1: 1}............\n",
      "[CV 4/10; 26/100] END class_weight={0: 0.003272727272727273, 1: 1};, score=(train=0.877, test=0.838) total time=   8.7s\n",
      "[CV 6/10; 32/100] START class_weight={0: 0.0038181818181818187, 1: 1}...........\n",
      "[CV 6/10; 32/100] END class_weight={0: 0.0038181818181818187, 1: 1};, score=(train=0.880, test=0.833) total time=   8.4s\n",
      "[CV 4/10; 38/100] START class_weight={0: 0.004363636363636364, 1: 1}............\n",
      "[CV 4/10; 38/100] END class_weight={0: 0.004363636363636364, 1: 1};, score=(train=0.879, test=0.850) total time=   9.8s\n",
      "[CV 4/10; 45/100] START class_weight={0: 0.005, 1: 1}...........................\n",
      "[CV 4/10; 45/100] END class_weight={0: 0.005, 1: 1};, score=(train=0.879, test=0.849) total time=   7.9s\n",
      "[CV 9/10; 50/100] START class_weight={0: 0.005454545454545455, 1: 1}............\n",
      "[CV 9/10; 50/100] END class_weight={0: 0.005454545454545455, 1: 1};, score=(train=0.880, test=0.846) total time=   7.9s\n",
      "[CV 3/10; 57/100] START class_weight={0: 0.006090909090909091, 1: 1}............\n",
      "[CV 3/10; 57/100] END class_weight={0: 0.006090909090909091, 1: 1};, score=(train=0.881, test=0.843) total time=  11.2s\n",
      "[CV 2/10; 65/100] START class_weight={0: 0.006818181818181819, 1: 1}............\n",
      "[CV 2/10; 65/100] END class_weight={0: 0.006818181818181819, 1: 1};, score=(train=0.881, test=0.825) total time=   9.2s\n",
      "[CV 6/10; 71/100] START class_weight={0: 0.007363636363636364, 1: 1}............\n",
      "[CV 6/10; 71/100] END class_weight={0: 0.007363636363636364, 1: 1};, score=(train=0.879, test=0.837) total time=   9.2s\n",
      "[CV 1/10; 78/100] START class_weight={0: 0.008, 1: 1}...........................\n",
      "[CV 1/10; 78/100] END class_weight={0: 0.008, 1: 1};, score=(train=0.877, test=0.843) total time=  10.0s\n",
      "[CV 3/10; 85/100] START class_weight={0: 0.008636363636363636, 1: 1}............\n",
      "[CV 3/10; 85/100] END class_weight={0: 0.008636363636363636, 1: 1};, score=(train=0.880, test=0.844) total time=   7.0s\n",
      "[CV 1/10; 90/100] START class_weight={0: 0.00909090909090909, 1: 1}.............\n",
      "[CV 1/10; 90/100] END class_weight={0: 0.00909090909090909, 1: 1};, score=(train=0.879, test=0.844) total time=   9.0s\n",
      "[CV 3/10; 96/100] START class_weight={0: 0.009636363636363637, 1: 1}............\n",
      "[CV 3/10; 96/100] END class_weight={0: 0.009636363636363637, 1: 1};, score=(train=0.879, test=0.827) total time=   9.4s\n",
      "[CV 2/10; 3/100] START class_weight={0: 0.010202020202020202, 1: 1}.............\n",
      "[CV 2/10; 3/100] END class_weight={0: 0.010202020202020202, 1: 1};, score=(train=0.880, test=0.840) total time=  10.3s\n",
      "[CV 6/10; 11/100] START class_weight={0: 0.01101010101010101, 1: 1}.............\n",
      "[CV 6/10; 11/100] END class_weight={0: 0.01101010101010101, 1: 1};, score=(train=0.877, test=0.836) total time=  11.8s\n",
      "[CV 6/10; 19/100] START class_weight={0: 0.011818181818181818, 1: 1}............\n",
      "[CV 6/10; 19/100] END class_weight={0: 0.011818181818181818, 1: 1};, score=(train=0.881, test=0.826) total time=  12.2s\n",
      "[CV 4/10; 26/100] START class_weight={0: 0.012525252525252526, 1: 1}............\n",
      "[CV 4/10; 26/100] END class_weight={0: 0.012525252525252526, 1: 1};, score=(train=0.876, test=0.832) total time=   8.9s\n",
      "[CV 4/10; 32/100] START class_weight={0: 0.013131313131313133, 1: 1}............\n",
      "[CV 4/10; 32/100] END class_weight={0: 0.013131313131313133, 1: 1};, score=(train=0.878, test=0.835) total time=   8.8s\n",
      "[CV 5/10; 38/100] START class_weight={0: 0.013737373737373737, 1: 1}............\n",
      "[CV 5/10; 38/100] END class_weight={0: 0.013737373737373737, 1: 1};, score=(train=0.882, test=0.837) total time=   8.1s\n",
      "[CV 9/10; 43/100] START class_weight={0: 0.014242424242424242, 1: 1}............\n",
      "[CV 9/10; 43/100] END class_weight={0: 0.014242424242424242, 1: 1};, score=(train=0.880, test=0.837) total time=  10.9s\n",
      "[CV 1/10; 51/100] START class_weight={0: 0.01505050505050505, 1: 1}.............\n",
      "[CV 1/10; 51/100] END class_weight={0: 0.01505050505050505, 1: 1};, score=(train=0.880, test=0.861) total time=   9.7s\n",
      "[CV 10/10; 56/100] START class_weight={0: 0.015555555555555555, 1: 1}...........\n",
      "[CV 10/10; 56/100] END class_weight={0: 0.015555555555555555, 1: 1};, score=(train=0.881, test=0.866) total time=   9.4s\n",
      "[CV 1/10; 63/100] START class_weight={0: 0.016262626262626263, 1: 1}............\n",
      "[CV 1/10; 63/100] END class_weight={0: 0.016262626262626263, 1: 1};, score=(train=0.880, test=0.861) total time=  10.2s\n",
      "[CV 10/10; 69/100] START class_weight={0: 0.01686868686868687, 1: 1}............\n",
      "[CV 10/10; 69/100] END class_weight={0: 0.01686868686868687, 1: 1};, score=(train=0.879, test=0.869) total time=   7.6s\n",
      "[CV 4/10; 74/100] START class_weight={0: 0.017373737373737375, 1: 1}............\n",
      "[CV 4/10; 74/100] END class_weight={0: 0.017373737373737375, 1: 1};, score=(train=0.884, test=0.844) total time=  11.7s\n",
      "[CV 2/10; 82/100] START class_weight={0: 0.01818181818181818, 1: 1}.............\n",
      "[CV 2/10; 82/100] END class_weight={0: 0.01818181818181818, 1: 1};, score=(train=0.885, test=0.847) total time=   9.0s\n",
      "[CV 8/10; 87/100] START class_weight={0: 0.01868686868686869, 1: 1}.............\n",
      "[CV 8/10; 87/100] END class_weight={0: 0.01868686868686869, 1: 1};, score=(train=0.875, test=0.874) total time=  11.6s\n",
      "[CV 9/10; 95/100] START class_weight={0: 0.019494949494949496, 1: 1}............\n",
      "[CV 9/10; 95/100] END class_weight={0: 0.019494949494949496, 1: 1};, score=(train=0.883, test=0.845) total time=   9.8s\n",
      "[CV 8/10; 3/10] START class_weight={0: 0.001888888888888889, 1: 1}..............\n",
      "[CV 8/10; 3/10] END class_weight={0: 0.001888888888888889, 1: 1};, score=(train=0.877, test=0.862) total time=   6.7s\n",
      "[CV 10/10; 8/10] START class_weight={0: 0.004111111111111111, 1: 1}.............\n",
      "[CV 10/10; 8/10] END class_weight={0: 0.004111111111111111, 1: 1};, score=(train=0.879, test=0.851) total time=   6.7s\n",
      "[CV 7/10; 6/100] START class_weight={0: 0.0014545454545454547, 1: 1}............\n",
      "[CV 7/10; 6/100] END class_weight={0: 0.0014545454545454547, 1: 1};, score=(train=0.876, test=0.858) total time=   6.7s\n",
      "[CV 10/10; 8/100] START class_weight={0: 0.0016363636363636363, 1: 1}...........\n",
      "[CV 10/10; 8/100] END class_weight={0: 0.0016363636363636363, 1: 1};, score=(train=0.876, test=0.847) total time=   7.6s\n",
      "[CV 3/10; 15/100] START class_weight={0: 0.0022727272727272726, 1: 1}...........\n",
      "[CV 3/10; 15/100] END class_weight={0: 0.0022727272727272726, 1: 1};, score=(train=0.879, test=0.834) total time=   8.9s\n",
      "[CV 1/10; 22/100] START class_weight={0: 0.0029090909090909093, 1: 1}...........\n",
      "[CV 1/10; 22/100] END class_weight={0: 0.0029090909090909093, 1: 1};, score=(train=0.881, test=0.840) total time=   6.6s\n",
      "[CV 7/10; 27/100] START class_weight={0: 0.003363636363636364, 1: 1}............\n",
      "[CV 7/10; 27/100] END class_weight={0: 0.003363636363636364, 1: 1};, score=(train=0.877, test=0.863) total time=   7.9s\n",
      "[CV 9/10; 33/100] START class_weight={0: 0.003909090909090909, 1: 1}............\n",
      "[CV 9/10; 33/100] END class_weight={0: 0.003909090909090909, 1: 1};, score=(train=0.881, test=0.835) total time=   8.4s\n",
      "[CV 10/10; 39/100] START class_weight={0: 0.004454545454545455, 1: 1}...........\n",
      "[CV 10/10; 39/100] END class_weight={0: 0.004454545454545455, 1: 1};, score=(train=0.878, test=0.855) total time=   8.4s\n",
      "[CV 4/10; 46/100] START class_weight={0: 0.005090909090909091, 1: 1}............\n",
      "[CV 4/10; 46/100] END class_weight={0: 0.005090909090909091, 1: 1};, score=(train=0.879, test=0.843) total time=  10.1s\n",
      "[CV 9/10; 53/100] START class_weight={0: 0.0057272727272727275, 1: 1}...........\n",
      "[CV 9/10; 53/100] END class_weight={0: 0.0057272727272727275, 1: 1};, score=(train=0.880, test=0.848) total time=  12.8s\n",
      "[CV 4/10; 63/100] START class_weight={0: 0.006636363636363637, 1: 1}............\n",
      "[CV 4/10; 63/100] END class_weight={0: 0.006636363636363637, 1: 1};, score=(train=0.879, test=0.836) total time=   7.4s\n",
      "[CV 8/10; 68/100] START class_weight={0: 0.007090909090909091, 1: 1}............\n",
      "[CV 8/10; 68/100] END class_weight={0: 0.007090909090909091, 1: 1};, score=(train=0.877, test=0.860) total time=   6.5s\n",
      "[CV 8/10; 72/100] START class_weight={0: 0.007454545454545455, 1: 1}............\n",
      "[CV 8/10; 72/100] END class_weight={0: 0.007454545454545455, 1: 1};, score=(train=0.874, test=0.866) total time=   7.3s\n",
      "[CV 7/10; 77/100] START class_weight={0: 0.00790909090909091, 1: 1}.............\n",
      "[CV 7/10; 77/100] END class_weight={0: 0.00790909090909091, 1: 1};, score=(train=0.877, test=0.864) total time=   8.2s\n",
      "[CV 9/10; 83/100] START class_weight={0: 0.008454545454545454, 1: 1}............\n",
      "[CV 9/10; 83/100] END class_weight={0: 0.008454545454545454, 1: 1};, score=(train=0.880, test=0.848) total time=   8.4s\n",
      "[CV 5/10; 89/100] START class_weight={0: 0.009000000000000001, 1: 1}............\n",
      "[CV 5/10; 89/100] END class_weight={0: 0.009000000000000001, 1: 1};, score=(train=0.880, test=0.831) total time=   7.5s\n",
      "[CV 1/10; 95/100] START class_weight={0: 0.009545454545454548, 1: 1}............\n",
      "[CV 1/10; 95/100] END class_weight={0: 0.009545454545454548, 1: 1};, score=(train=0.878, test=0.855) total time=   8.9s\n",
      "[CV 3/10; 1/100] START class_weight={0: 0.01, 1: 1}.............................\n",
      "[CV 3/10; 1/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.879, test=0.835) total time=   7.8s\n",
      "[CV 7/10; 7/100] START class_weight={0: 0.010606060606060607, 1: 1}.............\n",
      "[CV 7/10; 7/100] END class_weight={0: 0.010606060606060607, 1: 1};, score=(train=0.876, test=0.864) total time=   9.0s\n",
      "[CV 2/10; 14/100] START class_weight={0: 0.011313131313131313, 1: 1}............\n",
      "[CV 2/10; 14/100] END class_weight={0: 0.011313131313131313, 1: 1};, score=(train=0.878, test=0.850) total time=   8.5s\n",
      "[CV 6/10; 20/100] START class_weight={0: 0.01191919191919192, 1: 1}.............\n",
      "[CV 6/10; 20/100] END class_weight={0: 0.01191919191919192, 1: 1};, score=(train=0.882, test=0.835) total time=   9.7s\n",
      "[CV 8/10; 26/100] START class_weight={0: 0.012525252525252526, 1: 1}............\n",
      "[CV 8/10; 26/100] END class_weight={0: 0.012525252525252526, 1: 1};, score=(train=0.879, test=0.885) total time=  14.1s\n",
      "[CV 4/10; 36/100] START class_weight={0: 0.013535353535353536, 1: 1}............\n",
      "[CV 4/10; 36/100] END class_weight={0: 0.013535353535353536, 1: 1};, score=(train=0.879, test=0.838) total time=  10.6s\n",
      "[CV 5/10; 43/100] START class_weight={0: 0.014242424242424242, 1: 1}............\n",
      "[CV 5/10; 43/100] END class_weight={0: 0.014242424242424242, 1: 1};, score=(train=0.879, test=0.824) total time=   7.9s\n",
      "[CV 7/10; 48/100] START class_weight={0: 0.014747474747474749, 1: 1}............\n",
      "[CV 7/10; 48/100] END class_weight={0: 0.014747474747474749, 1: 1};, score=(train=0.880, test=0.867) total time=   9.7s\n",
      "[CV 7/10; 54/100] START class_weight={0: 0.015353535353535354, 1: 1}............\n",
      "[CV 7/10; 54/100] END class_weight={0: 0.015353535353535354, 1: 1};, score=(train=0.880, test=0.866) total time=   9.3s\n",
      "[CV 9/10; 60/100] START class_weight={0: 0.01595959595959596, 1: 1}.............\n",
      "[CV 9/10; 60/100] END class_weight={0: 0.01595959595959596, 1: 1};, score=(train=0.881, test=0.854) total time=   9.8s\n",
      "[CV 3/10; 67/100] START class_weight={0: 0.016666666666666666, 1: 1}............\n",
      "[CV 3/10; 67/100] END class_weight={0: 0.016666666666666666, 1: 1};, score=(train=0.876, test=0.838) total time=   8.6s\n",
      "[CV 7/10; 72/100] START class_weight={0: 0.01717171717171717, 1: 1}.............\n",
      "[CV 7/10; 72/100] END class_weight={0: 0.01717171717171717, 1: 1};, score=(train=0.878, test=0.862) total time=   9.4s\n",
      "[CV 9/10; 78/100] START class_weight={0: 0.017777777777777778, 1: 1}............\n",
      "[CV 9/10; 78/100] END class_weight={0: 0.017777777777777778, 1: 1};, score=(train=0.880, test=0.853) total time=   8.6s\n",
      "[CV 8/10; 84/100] START class_weight={0: 0.018383838383838384, 1: 1}............\n",
      "[CV 8/10; 84/100] END class_weight={0: 0.018383838383838384, 1: 1};, score=(train=0.878, test=0.884) total time=   8.3s\n",
      "[CV 1/10; 90/100] START class_weight={0: 0.01898989898989899, 1: 1}.............\n",
      "[CV 1/10; 90/100] END class_weight={0: 0.01898989898989899, 1: 1};, score=(train=0.880, test=0.857) total time=   8.0s\n",
      "[CV 4/10; 95/100] START class_weight={0: 0.019494949494949496, 1: 1}............\n",
      "[CV 4/10; 95/100] END class_weight={0: 0.019494949494949496, 1: 1};, score=(train=0.881, test=0.842) total time=  10.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 7/10] START class_weight={0: 0.003666666666666667, 1: 1}..............\n",
      "[CV 4/10; 7/10] END class_weight={0: 0.003666666666666667, 1: 1};, score=(train=0.880, test=0.849) total time=   8.4s\n",
      "[CV 6/10; 1/100] START class_weight={0: 0.001, 1: 1}............................\n",
      "[CV 6/10; 1/100] END class_weight={0: 0.001, 1: 1};, score=(train=0.882, test=0.829) total time=   7.9s\n",
      "[CV 6/10; 10/100] START class_weight={0: 0.0018181818181818182, 1: 1}...........\n",
      "[CV 6/10; 10/100] END class_weight={0: 0.0018181818181818182, 1: 1};, score=(train=0.881, test=0.825) total time=   7.5s\n",
      "[CV 10/10; 15/100] START class_weight={0: 0.0022727272727272726, 1: 1}..........\n",
      "[CV 10/10; 15/100] END class_weight={0: 0.0022727272727272726, 1: 1};, score=(train=0.876, test=0.853) total time=   8.1s\n",
      "[CV 2/10; 22/100] START class_weight={0: 0.0029090909090909093, 1: 1}...........\n",
      "[CV 2/10; 22/100] END class_weight={0: 0.0029090909090909093, 1: 1};, score=(train=0.882, test=0.842) total time=  10.7s\n",
      "[CV 1/10; 31/100] START class_weight={0: 0.0037272727272727275, 1: 1}...........\n",
      "[CV 1/10; 31/100] END class_weight={0: 0.0037272727272727275, 1: 1};, score=(train=0.879, test=0.838) total time=   7.8s\n",
      "[CV 8/10; 36/100] START class_weight={0: 0.004181818181818182, 1: 1}............\n",
      "[CV 8/10; 36/100] END class_weight={0: 0.004181818181818182, 1: 1};, score=(train=0.878, test=0.869) total time=   9.7s\n",
      "[CV 10/10; 43/100] START class_weight={0: 0.004818181818181819, 1: 1}...........\n",
      "[CV 10/10; 43/100] END class_weight={0: 0.004818181818181819, 1: 1};, score=(train=0.879, test=0.857) total time=  10.4s\n",
      "[CV 4/10; 52/100] START class_weight={0: 0.005636363636363636, 1: 1}............\n",
      "[CV 4/10; 52/100] END class_weight={0: 0.005636363636363636, 1: 1};, score=(train=0.879, test=0.843) total time=   6.8s\n",
      "[CV 1/10; 57/100] START class_weight={0: 0.006090909090909091, 1: 1}............\n",
      "[CV 1/10; 57/100] END class_weight={0: 0.006090909090909091, 1: 1};, score=(train=0.877, test=0.846) total time=   9.7s\n",
      "[CV 3/10; 64/100] START class_weight={0: 0.006727272727272728, 1: 1}............\n",
      "[CV 3/10; 64/100] END class_weight={0: 0.006727272727272728, 1: 1};, score=(train=0.881, test=0.843) total time=   7.9s\n",
      "[CV 10/10; 69/100] START class_weight={0: 0.0071818181818181824, 1: 1}..........\n",
      "[CV 10/10; 69/100] END class_weight={0: 0.0071818181818181824, 1: 1};, score=(train=0.876, test=0.854) total time=  12.1s\n",
      "[CV 10/10; 77/100] START class_weight={0: 0.00790909090909091, 1: 1}............\n",
      "[CV 10/10; 77/100] END class_weight={0: 0.00790909090909091, 1: 1};, score=(train=0.876, test=0.849) total time=   8.9s\n",
      "[CV 4/10; 84/100] START class_weight={0: 0.008545454545454547, 1: 1}............\n",
      "[CV 4/10; 84/100] END class_weight={0: 0.008545454545454547, 1: 1};, score=(train=0.877, test=0.841) total time=  10.7s\n",
      "[CV 2/10; 92/100] START class_weight={0: 0.009272727272727273, 1: 1}............\n",
      "[CV 2/10; 92/100] END class_weight={0: 0.009272727272727273, 1: 1};, score=(train=0.879, test=0.834) total time=   6.9s\n",
      "[CV 2/10; 97/100] START class_weight={0: 0.009727272727272727, 1: 1}............\n",
      "[CV 2/10; 97/100] END class_weight={0: 0.009727272727272727, 1: 1};, score=(train=0.880, test=0.840) total time=   8.9s\n",
      "[CV 1/10; 3/100] START class_weight={0: 0.010202020202020202, 1: 1}.............\n",
      "[CV 1/10; 3/100] END class_weight={0: 0.010202020202020202, 1: 1};, score=(train=0.878, test=0.855) total time=   9.9s\n",
      "[CV 4/10; 10/100] START class_weight={0: 0.01090909090909091, 1: 1}.............\n",
      "[CV 4/10; 10/100] END class_weight={0: 0.01090909090909091, 1: 1};, score=(train=0.876, test=0.836) total time=  10.4s\n",
      "[CV 1/10; 18/100] START class_weight={0: 0.011717171717171718, 1: 1}............\n",
      "[CV 1/10; 18/100] END class_weight={0: 0.011717171717171718, 1: 1};, score=(train=0.878, test=0.867) total time=  10.3s\n",
      "[CV 10/10; 24/100] START class_weight={0: 0.012323232323232323, 1: 1}...........\n",
      "[CV 10/10; 24/100] END class_weight={0: 0.012323232323232323, 1: 1};, score=(train=0.878, test=0.864) total time=  13.6s\n",
      "[CV 1/10; 33/100] START class_weight={0: 0.013232323232323233, 1: 1}............\n",
      "[CV 1/10; 33/100] END class_weight={0: 0.013232323232323233, 1: 1};, score=(train=0.878, test=0.867) total time=   8.6s\n",
      "[CV 10/10; 38/100] START class_weight={0: 0.013737373737373737, 1: 1}...........\n",
      "[CV 10/10; 38/100] END class_weight={0: 0.013737373737373737, 1: 1};, score=(train=0.878, test=0.861) total time=   7.9s\n",
      "[CV 5/10; 44/100] START class_weight={0: 0.014343434343434344, 1: 1}............\n",
      "[CV 5/10; 44/100] END class_weight={0: 0.014343434343434344, 1: 1};, score=(train=0.882, test=0.837) total time=   8.8s\n",
      "[CV 2/10; 50/100] START class_weight={0: 0.014949494949494949, 1: 1}............\n",
      "[CV 2/10; 50/100] END class_weight={0: 0.014949494949494949, 1: 1};, score=(train=0.884, test=0.842) total time=  11.5s\n",
      "[CV 8/10; 57/100] START class_weight={0: 0.015656565656565657, 1: 1}............\n",
      "[CV 8/10; 57/100] END class_weight={0: 0.015656565656565657, 1: 1};, score=(train=0.880, test=0.883) total time=  10.1s\n",
      "[CV 5/10; 64/100] START class_weight={0: 0.016363636363636365, 1: 1}............\n",
      "[CV 5/10; 64/100] END class_weight={0: 0.016363636363636365, 1: 1};, score=(train=0.879, test=0.824) total time=   8.6s\n",
      "[CV 4/10; 70/100] START class_weight={0: 0.016969696969696968, 1: 1}............\n",
      "[CV 4/10; 70/100] END class_weight={0: 0.016969696969696968, 1: 1};, score=(train=0.882, test=0.837) total time=  11.8s\n",
      "[CV 6/10; 77/100] START class_weight={0: 0.017676767676767676, 1: 1}............\n",
      "[CV 6/10; 77/100] END class_weight={0: 0.017676767676767676, 1: 1};, score=(train=0.881, test=0.830) total time=  10.2s\n",
      "[CV 3/10; 84/100] START class_weight={0: 0.018383838383838384, 1: 1}............\n",
      "[CV 3/10; 84/100] END class_weight={0: 0.018383838383838384, 1: 1};, score=(train=0.879, test=0.830) total time=   7.8s\n",
      "[CV 2/10; 89/100] START class_weight={0: 0.01888888888888889, 1: 1}.............\n",
      "[CV 2/10; 89/100] END class_weight={0: 0.01888888888888889, 1: 1};, score=(train=0.883, test=0.842) total time=   9.3s\n",
      "[CV 5/10; 95/100] START class_weight={0: 0.019494949494949496, 1: 1}............\n",
      "[CV 5/10; 95/100] END class_weight={0: 0.019494949494949496, 1: 1};, score=(train=0.883, test=0.833) total time=  10.6s\n",
      "[CV 1/10; 4/10] START class_weight={0: 0.0023333333333333335, 1: 1}.............\n",
      "[CV 1/10; 4/10] END class_weight={0: 0.0023333333333333335, 1: 1};, score=(train=0.881, test=0.841) total time=   7.2s\n",
      "[CV 10/10; 9/10] START class_weight={0: 0.004555555555555556, 1: 1}.............\n",
      "[CV 10/10; 9/10] END class_weight={0: 0.004555555555555556, 1: 1};, score=(train=0.879, test=0.857) total time=   6.2s\n",
      "[CV 3/10; 6/100] START class_weight={0: 0.0014545454545454547, 1: 1}............\n",
      "[CV 3/10; 6/100] END class_weight={0: 0.0014545454545454547, 1: 1};, score=(train=0.880, test=0.835) total time=   7.8s\n",
      "[CV 2/10; 11/100] START class_weight={0: 0.0019090909090909093, 1: 1}...........\n",
      "[CV 2/10; 11/100] END class_weight={0: 0.0019090909090909093, 1: 1};, score=(train=0.881, test=0.838) total time=   7.5s\n",
      "[CV 9/10; 16/100] START class_weight={0: 0.0023636363636363638, 1: 1}...........\n",
      "[CV 9/10; 16/100] END class_weight={0: 0.0023636363636363638, 1: 1};, score=(train=0.879, test=0.836) total time=   7.7s\n",
      "[CV 4/10; 22/100] START class_weight={0: 0.0029090909090909093, 1: 1}...........\n",
      "[CV 4/10; 22/100] END class_weight={0: 0.0029090909090909093, 1: 1};, score=(train=0.877, test=0.836) total time=  11.1s\n",
      "[CV 3/10; 31/100] START class_weight={0: 0.0037272727272727275, 1: 1}...........\n",
      "[CV 3/10; 31/100] END class_weight={0: 0.0037272727272727275, 1: 1};, score=(train=0.879, test=0.842) total time=   8.6s\n",
      "[CV 4/10; 37/100] START class_weight={0: 0.0042727272727272735, 1: 1}...........\n",
      "[CV 4/10; 37/100] END class_weight={0: 0.0042727272727272735, 1: 1};, score=(train=0.879, test=0.850) total time=   7.1s\n",
      "[CV 6/10; 42/100] START class_weight={0: 0.0047272727272727275, 1: 1}...........\n",
      "[CV 6/10; 42/100] END class_weight={0: 0.0047272727272727275, 1: 1};, score=(train=0.880, test=0.835) total time=   8.0s\n",
      "[CV 7/10; 48/100] START class_weight={0: 0.0052727272727272735, 1: 1}...........\n",
      "[CV 7/10; 48/100] END class_weight={0: 0.0052727272727272735, 1: 1};, score=(train=0.876, test=0.861) total time=   7.6s\n",
      "[CV 5/10; 54/100] START class_weight={0: 0.005818181818181819, 1: 1}............\n",
      "[CV 5/10; 54/100] END class_weight={0: 0.005818181818181819, 1: 1};, score=(train=0.880, test=0.834) total time=   9.7s\n",
      "[CV 4/10; 61/100] START class_weight={0: 0.006454545454545455, 1: 1}............\n",
      "[CV 4/10; 61/100] END class_weight={0: 0.006454545454545455, 1: 1};, score=(train=0.879, test=0.836) total time=  11.0s\n",
      "[CV 7/10; 69/100] START class_weight={0: 0.0071818181818181824, 1: 1}...........\n",
      "[CV 7/10; 69/100] END class_weight={0: 0.0071818181818181824, 1: 1};, score=(train=0.876, test=0.867) total time=  10.3s\n",
      "[CV 3/10; 76/100] START class_weight={0: 0.007818181818181818, 1: 1}............\n",
      "[CV 3/10; 76/100] END class_weight={0: 0.007818181818181818, 1: 1};, score=(train=0.880, test=0.846) total time=   8.3s\n",
      "[CV 4/10; 82/100] START class_weight={0: 0.008363636363636365, 1: 1}............\n",
      "[CV 4/10; 82/100] END class_weight={0: 0.008363636363636365, 1: 1};, score=(train=0.877, test=0.841) total time=   9.5s\n",
      "[CV 10/10; 88/100] START class_weight={0: 0.008909090909090908, 1: 1}...........\n",
      "[CV 10/10; 88/100] END class_weight={0: 0.008909090909090908, 1: 1};, score=(train=0.876, test=0.850) total time=   9.8s\n",
      "[CV 8/10; 95/100] START class_weight={0: 0.009545454545454548, 1: 1}............\n",
      "[CV 8/10; 95/100] END class_weight={0: 0.009545454545454548, 1: 1};, score=(train=0.877, test=0.863) total time=   8.1s\n",
      "[CV 9/10; 100/100] START class_weight={0: 0.01, 1: 1}...........................\n",
      "[CV 9/10; 100/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.880, test=0.848) total time=   5.9s\n",
      "[CV 9/10; 6/100] START class_weight={0: 0.010505050505050505, 1: 1}.............\n",
      "[CV 9/10; 6/100] END class_weight={0: 0.010505050505050505, 1: 1};, score=(train=0.880, test=0.850) total time=  10.2s\n",
      "[CV 6/10; 12/100] START class_weight={0: 0.011111111111111112, 1: 1}............\n",
      "[CV 6/10; 12/100] END class_weight={0: 0.011111111111111112, 1: 1};, score=(train=0.879, test=0.829) total time=   7.3s\n",
      "[CV 6/10; 15/100] START class_weight={0: 0.011414141414141415, 1: 1}............\n",
      "[CV 6/10; 15/100] END class_weight={0: 0.011414141414141415, 1: 1};, score=(train=0.879, test=0.829) total time=   7.9s\n",
      "[CV 10/10; 20/100] START class_weight={0: 0.01191919191919192, 1: 1}............\n",
      "[CV 10/10; 20/100] END class_weight={0: 0.01191919191919192, 1: 1};, score=(train=0.880, test=0.866) total time=   9.7s\n",
      "[CV 3/10; 27/100] START class_weight={0: 0.012626262626262626, 1: 1}............\n",
      "[CV 3/10; 27/100] END class_weight={0: 0.012626262626262626, 1: 1};, score=(train=0.879, test=0.830) total time=   7.5s\n",
      "[CV 6/10; 32/100] START class_weight={0: 0.013131313131313133, 1: 1}............\n",
      "[CV 6/10; 32/100] END class_weight={0: 0.013131313131313133, 1: 1};, score=(train=0.880, test=0.839) total time=   7.6s\n",
      "[CV 7/10; 37/100] START class_weight={0: 0.013636363636363637, 1: 1}............\n",
      "[CV 7/10; 37/100] END class_weight={0: 0.013636363636363637, 1: 1};, score=(train=0.878, test=0.862) total time=  12.0s\n",
      "[CV 7/10; 45/100] START class_weight={0: 0.014444444444444444, 1: 1}............\n",
      "[CV 7/10; 45/100] END class_weight={0: 0.014444444444444444, 1: 1};, score=(train=0.878, test=0.862) total time=  11.9s\n",
      "[CV 8/10; 52/100] START class_weight={0: 0.015151515151515152, 1: 1}............\n",
      "[CV 8/10; 52/100] END class_weight={0: 0.015151515151515152, 1: 1};, score=(train=0.880, test=0.883) total time=   9.1s\n",
      "[CV 1/10; 59/100] START class_weight={0: 0.015858585858585857, 1: 1}............\n",
      "[CV 1/10; 59/100] END class_weight={0: 0.015858585858585857, 1: 1};, score=(train=0.881, test=0.859) total time=   9.2s\n",
      "[CV 5/10; 65/100] START class_weight={0: 0.016464646464646467, 1: 1}............\n",
      "[CV 5/10; 65/100] END class_weight={0: 0.016464646464646467, 1: 1};, score=(train=0.883, test=0.832) total time=   8.5s\n",
      "[CV 4/10; 71/100] START class_weight={0: 0.01707070707070707, 1: 1}.............\n",
      "[CV 4/10; 71/100] END class_weight={0: 0.01707070707070707, 1: 1};, score=(train=0.881, test=0.841) total time=  10.5s\n",
      "[CV 8/10; 77/100] START class_weight={0: 0.017676767676767676, 1: 1}............\n",
      "[CV 8/10; 77/100] END class_weight={0: 0.017676767676767676, 1: 1};, score=(train=0.877, test=0.872) total time=   9.0s\n",
      "[CV 7/10; 83/100] START class_weight={0: 0.018282828282828283, 1: 1}............\n",
      "[CV 7/10; 83/100] END class_weight={0: 0.018282828282828283, 1: 1};, score=(train=0.878, test=0.860) total time=   9.1s\n",
      "[CV 5/10; 89/100] START class_weight={0: 0.01888888888888889, 1: 1}.............\n",
      "[CV 5/10; 89/100] END class_weight={0: 0.01888888888888889, 1: 1};, score=(train=0.883, test=0.833) total time=  11.0s\n",
      "[CV 7/10; 96/100] START class_weight={0: 0.019595959595959597, 1: 1}............\n",
      "[CV 7/10; 96/100] END class_weight={0: 0.019595959595959597, 1: 1};, score=(train=0.879, test=0.851) total time=   8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10; 1/10] START class_weight={0: 0.001, 1: 1}.............................\n",
      "[CV 8/10; 1/10] END class_weight={0: 0.001, 1: 1};, score=(train=0.874, test=0.865) total time=   8.3s\n",
      "[CV 10/10; 10/10] START class_weight={0: 0.005, 1: 1}...........................\n",
      "[CV 10/10; 10/10] END class_weight={0: 0.005, 1: 1};, score=(train=0.879, test=0.858) total time=   5.5s\n",
      "[CV 3/10; 7/100] START class_weight={0: 0.0015454545454545456, 1: 1}............\n",
      "[CV 3/10; 7/100] END class_weight={0: 0.0015454545454545456, 1: 1};, score=(train=0.880, test=0.835) total time=   7.5s\n",
      "[CV 8/10; 10/100] START class_weight={0: 0.0018181818181818182, 1: 1}...........\n",
      "[CV 8/10; 10/100] END class_weight={0: 0.0018181818181818182, 1: 1};, score=(train=0.874, test=0.861) total time=   9.8s\n",
      "[CV 5/10; 18/100] START class_weight={0: 0.0025454545454545456, 1: 1}...........\n",
      "[CV 5/10; 18/100] END class_weight={0: 0.0025454545454545456, 1: 1};, score=(train=0.877, test=0.836) total time=   8.8s\n",
      "[CV 3/10; 25/100] START class_weight={0: 0.003181818181818182, 1: 1}............\n",
      "[CV 3/10; 25/100] END class_weight={0: 0.003181818181818182, 1: 1};, score=(train=0.878, test=0.839) total time=   7.2s\n",
      "[CV 3/10; 30/100] START class_weight={0: 0.003636363636363637, 1: 1}............\n",
      "[CV 3/10; 30/100] END class_weight={0: 0.003636363636363637, 1: 1};, score=(train=0.879, test=0.842) total time=   6.9s\n",
      "[CV 3/10; 35/100] START class_weight={0: 0.004090909090909091, 1: 1}............\n",
      "[CV 3/10; 35/100] END class_weight={0: 0.004090909090909091, 1: 1};, score=(train=0.879, test=0.841) total time=   7.4s\n",
      "[CV 10/10; 40/100] START class_weight={0: 0.004545454545454545, 1: 1}...........\n",
      "[CV 10/10; 40/100] END class_weight={0: 0.004545454545454545, 1: 1};, score=(train=0.879, test=0.853) total time=   7.5s\n",
      "[CV 9/10; 46/100] START class_weight={0: 0.005090909090909091, 1: 1}............\n",
      "[CV 9/10; 46/100] END class_weight={0: 0.005090909090909091, 1: 1};, score=(train=0.881, test=0.848) total time=   9.1s\n",
      "[CV 4/10; 53/100] START class_weight={0: 0.0057272727272727275, 1: 1}...........\n",
      "[CV 4/10; 53/100] END class_weight={0: 0.0057272727272727275, 1: 1};, score=(train=0.879, test=0.843) total time=   9.1s\n",
      "[CV 9/10; 59/100] START class_weight={0: 0.006272727272727274, 1: 1}............\n",
      "[CV 9/10; 59/100] END class_weight={0: 0.006272727272727274, 1: 1};, score=(train=0.880, test=0.846) total time=  10.3s\n",
      "[CV 2/10; 67/100] START class_weight={0: 0.007, 1: 1}...........................\n",
      "[CV 2/10; 67/100] END class_weight={0: 0.007, 1: 1};, score=(train=0.880, test=0.825) total time=   8.6s\n",
      "[CV 7/10; 73/100] START class_weight={0: 0.007545454545454546, 1: 1}............\n",
      "[CV 7/10; 73/100] END class_weight={0: 0.007545454545454546, 1: 1};, score=(train=0.877, test=0.866) total time=   8.8s\n",
      "[CV 1/10; 80/100] START class_weight={0: 0.008181818181818182, 1: 1}............\n",
      "[CV 1/10; 80/100] END class_weight={0: 0.008181818181818182, 1: 1};, score=(train=0.877, test=0.846) total time=  11.1s\n",
      "[CV 7/10; 87/100] START class_weight={0: 0.008818181818181819, 1: 1}............\n",
      "[CV 7/10; 87/100] END class_weight={0: 0.008818181818181819, 1: 1};, score=(train=0.879, test=0.864) total time=   8.6s\n",
      "[CV 7/10; 93/100] START class_weight={0: 0.009363636363636366, 1: 1}............\n",
      "[CV 7/10; 93/100] END class_weight={0: 0.009363636363636366, 1: 1};, score=(train=0.879, test=0.875) total time=  11.3s\n",
      "[CV 4/10; 1/100] START class_weight={0: 0.01, 1: 1}.............................\n",
      "[CV 4/10; 1/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.876, test=0.840) total time=  10.2s\n",
      "[CV 3/10; 11/100] START class_weight={0: 0.01101010101010101, 1: 1}.............\n",
      "[CV 3/10; 11/100] END class_weight={0: 0.01101010101010101, 1: 1};, score=(train=0.879, test=0.828) total time=   9.1s\n",
      "[CV 9/10; 16/100] START class_weight={0: 0.011515151515151515, 1: 1}............\n",
      "[CV 9/10; 16/100] END class_weight={0: 0.011515151515151515, 1: 1};, score=(train=0.880, test=0.848) total time=   8.9s\n",
      "[CV 6/10; 22/100] START class_weight={0: 0.012121212121212121, 1: 1}............\n",
      "[CV 6/10; 22/100] END class_weight={0: 0.012121212121212121, 1: 1};, score=(train=0.880, test=0.832) total time=   8.4s\n",
      "[CV 8/10; 27/100] START class_weight={0: 0.012626262626262626, 1: 1}............\n",
      "[CV 8/10; 27/100] END class_weight={0: 0.012626262626262626, 1: 1};, score=(train=0.878, test=0.882) total time=  12.3s\n",
      "[CV 10/10; 35/100] START class_weight={0: 0.013434343434343434, 1: 1}...........\n",
      "[CV 10/10; 35/100] END class_weight={0: 0.013434343434343434, 1: 1};, score=(train=0.878, test=0.865) total time=   7.8s\n",
      "[CV 2/10; 41/100] START class_weight={0: 0.01404040404040404, 1: 1}.............\n",
      "[CV 2/10; 41/100] END class_weight={0: 0.01404040404040404, 1: 1};, score=(train=0.883, test=0.847) total time=  11.8s\n",
      "[CV 4/10; 49/100] START class_weight={0: 0.014848484848484849, 1: 1}............\n",
      "[CV 4/10; 49/100] END class_weight={0: 0.014848484848484849, 1: 1};, score=(train=0.882, test=0.837) total time=  12.4s\n",
      "[CV 4/10; 57/100] START class_weight={0: 0.015656565656565657, 1: 1}............\n",
      "[CV 4/10; 57/100] END class_weight={0: 0.015656565656565657, 1: 1};, score=(train=0.884, test=0.844) total time=   9.8s\n",
      "[CV 10/10; 63/100] START class_weight={0: 0.016262626262626263, 1: 1}...........\n",
      "[CV 10/10; 63/100] END class_weight={0: 0.016262626262626263, 1: 1};, score=(train=0.879, test=0.869) total time=  11.3s\n",
      "[CV 9/10; 70/100] START class_weight={0: 0.016969696969696968, 1: 1}............\n",
      "[CV 9/10; 70/100] END class_weight={0: 0.016969696969696968, 1: 1};, score=(train=0.881, test=0.854) total time=   9.3s\n",
      "[CV 3/10; 77/100] START class_weight={0: 0.017676767676767676, 1: 1}............\n",
      "[CV 3/10; 77/100] END class_weight={0: 0.017676767676767676, 1: 1};, score=(train=0.876, test=0.838) total time=  12.2s\n",
      "[CV 3/10; 85/100] START class_weight={0: 0.018484848484848486, 1: 1}............\n",
      "[CV 3/10; 85/100] END class_weight={0: 0.018484848484848486, 1: 1};, score=(train=0.879, test=0.830) total time=   7.7s\n",
      "[CV 9/10; 89/100] START class_weight={0: 0.01888888888888889, 1: 1}.............\n",
      "[CV 9/10; 89/100] END class_weight={0: 0.01888888888888889, 1: 1};, score=(train=0.883, test=0.845) total time=   8.7s\n",
      "[CV 10/10; 95/100] START class_weight={0: 0.019494949494949496, 1: 1}...........\n",
      "[CV 10/10; 95/100] END class_weight={0: 0.019494949494949496, 1: 1};, score=(train=0.881, test=0.868) total time=  10.4s\n",
      "[CV 7/10; 6/10] START class_weight={0: 0.0032222222222222222, 1: 1}.............\n",
      "[CV 7/10; 6/10] END class_weight={0: 0.0032222222222222222, 1: 1};, score=(train=0.876, test=0.863) total time=   9.0s\n",
      "[CV 1/10; 3/100] START class_weight={0: 0.0011818181818181819, 1: 1}............\n",
      "[CV 1/10; 3/100] END class_weight={0: 0.0011818181818181819, 1: 1};, score=(train=0.875, test=0.843) total time=   8.0s\n",
      "[CV 1/10; 11/100] START class_weight={0: 0.0019090909090909093, 1: 1}...........\n",
      "[CV 1/10; 11/100] END class_weight={0: 0.0019090909090909093, 1: 1};, score=(train=0.882, test=0.842) total time=   7.9s\n",
      "[CV 8/10; 16/100] START class_weight={0: 0.0023636363636363638, 1: 1}...........\n",
      "[CV 8/10; 16/100] END class_weight={0: 0.0023636363636363638, 1: 1};, score=(train=0.878, test=0.865) total time=   7.2s\n",
      "[CV 9/10; 21/100] START class_weight={0: 0.0028181818181818186, 1: 1}...........\n",
      "[CV 9/10; 21/100] END class_weight={0: 0.0028181818181818186, 1: 1};, score=(train=0.880, test=0.851) total time=   8.3s\n",
      "[CV 5/10; 28/100] START class_weight={0: 0.003454545454545455, 1: 1}............\n",
      "[CV 5/10; 28/100] END class_weight={0: 0.003454545454545455, 1: 1};, score=(train=0.880, test=0.837) total time=   7.3s\n",
      "[CV 2/10; 34/100] START class_weight={0: 0.004, 1: 1}...........................\n",
      "[CV 2/10; 34/100] END class_weight={0: 0.004, 1: 1};, score=(train=0.880, test=0.827) total time=   7.5s\n",
      "[CV 1/10; 40/100] START class_weight={0: 0.004545454545454545, 1: 1}............\n",
      "[CV 1/10; 40/100] END class_weight={0: 0.004545454545454545, 1: 1};, score=(train=0.881, test=0.838) total time=   6.7s\n",
      "[CV 10/10; 44/100] START class_weight={0: 0.00490909090909091, 1: 1}............\n",
      "[CV 10/10; 44/100] END class_weight={0: 0.00490909090909091, 1: 1};, score=(train=0.878, test=0.855) total time=   8.3s\n",
      "[CV 8/10; 50/100] START class_weight={0: 0.005454545454545455, 1: 1}............\n",
      "[CV 8/10; 50/100] END class_weight={0: 0.005454545454545455, 1: 1};, score=(train=0.877, test=0.862) total time=   7.0s\n",
      "[CV 2/10; 56/100] START class_weight={0: 0.006, 1: 1}...........................\n",
      "[CV 2/10; 56/100] END class_weight={0: 0.006, 1: 1};, score=(train=0.881, test=0.825) total time=   7.7s\n",
      "[CV 4/10; 62/100] START class_weight={0: 0.006545454545454546, 1: 1}............\n",
      "[CV 4/10; 62/100] END class_weight={0: 0.006545454545454546, 1: 1};, score=(train=0.879, test=0.836) total time=   7.9s\n",
      "[CV 6/10; 67/100] START class_weight={0: 0.007, 1: 1}...........................\n",
      "[CV 6/10; 67/100] END class_weight={0: 0.007, 1: 1};, score=(train=0.879, test=0.838) total time=  11.0s\n",
      "[CV 7/10; 75/100] START class_weight={0: 0.007727272727272728, 1: 1}............\n",
      "[CV 7/10; 75/100] END class_weight={0: 0.007727272727272728, 1: 1};, score=(train=0.877, test=0.864) total time=   8.1s\n",
      "[CV 9/10; 81/100] START class_weight={0: 0.008272727272727274, 1: 1}............\n",
      "[CV 9/10; 81/100] END class_weight={0: 0.008272727272727274, 1: 1};, score=(train=0.881, test=0.843) total time=  10.2s\n",
      "[CV 9/10; 88/100] START class_weight={0: 0.008909090909090908, 1: 1}............\n",
      "[CV 9/10; 88/100] END class_weight={0: 0.008909090909090908, 1: 1};, score=(train=0.880, test=0.848) total time=   7.5s\n",
      "[CV 1/10; 94/100] START class_weight={0: 0.009454545454545455, 1: 1}............\n",
      "[CV 1/10; 94/100] END class_weight={0: 0.009454545454545455, 1: 1};, score=(train=0.878, test=0.855) total time=   7.1s\n",
      "[CV 10/10; 98/100] START class_weight={0: 0.00981818181818182, 1: 1}............\n",
      "[CV 10/10; 98/100] END class_weight={0: 0.00981818181818182, 1: 1};, score=(train=0.876, test=0.864) total time=   8.0s\n",
      "[CV 1/10; 5/100] START class_weight={0: 0.010404040404040405, 1: 1}.............\n",
      "[CV 1/10; 5/100] END class_weight={0: 0.010404040404040405, 1: 1};, score=(train=0.878, test=0.855) total time=   9.5s\n",
      "[CV 7/10; 10/100] START class_weight={0: 0.01090909090909091, 1: 1}.............\n",
      "[CV 7/10; 10/100] END class_weight={0: 0.01090909090909091, 1: 1};, score=(train=0.876, test=0.864) total time=  13.0s\n",
      "[CV 9/10; 19/100] START class_weight={0: 0.011818181818181818, 1: 1}............\n",
      "[CV 9/10; 19/100] END class_weight={0: 0.011818181818181818, 1: 1};, score=(train=0.879, test=0.839) total time=  10.2s\n",
      "[CV 1/10; 26/100] START class_weight={0: 0.012525252525252526, 1: 1}............\n",
      "[CV 1/10; 26/100] END class_weight={0: 0.012525252525252526, 1: 1};, score=(train=0.877, test=0.864) total time=   9.3s\n",
      "[CV 3/10; 32/100] START class_weight={0: 0.013131313131313133, 1: 1}............\n",
      "[CV 3/10; 32/100] END class_weight={0: 0.013131313131313133, 1: 1};, score=(train=0.876, test=0.838) total time=  12.1s\n",
      "[CV 9/10; 39/100] START class_weight={0: 0.013838383838383839, 1: 1}............\n",
      "[CV 9/10; 39/100] END class_weight={0: 0.013838383838383839, 1: 1};, score=(train=0.880, test=0.837) total time=  11.1s\n",
      "[CV 6/10; 46/100] START class_weight={0: 0.014545454545454545, 1: 1}............\n",
      "[CV 6/10; 46/100] END class_weight={0: 0.014545454545454545, 1: 1};, score=(train=0.881, test=0.826) total time=   7.1s\n",
      "[CV 8/10; 51/100] START class_weight={0: 0.01505050505050505, 1: 1}.............\n",
      "[CV 8/10; 51/100] END class_weight={0: 0.01505050505050505, 1: 1};, score=(train=0.880, test=0.883) total time=   9.7s\n",
      "[CV 2/10; 58/100] START class_weight={0: 0.01575757575757576, 1: 1}.............\n",
      "[CV 2/10; 58/100] END class_weight={0: 0.01575757575757576, 1: 1};, score=(train=0.884, test=0.844) total time=  11.4s\n",
      "[CV 2/10; 65/100] START class_weight={0: 0.016464646464646467, 1: 1}............\n",
      "[CV 2/10; 65/100] END class_weight={0: 0.016464646464646467, 1: 1};, score=(train=0.878, test=0.843) total time=   8.8s\n",
      "[CV 2/10; 71/100] START class_weight={0: 0.01707070707070707, 1: 1}.............\n",
      "[CV 2/10; 71/100] END class_weight={0: 0.01707070707070707, 1: 1};, score=(train=0.878, test=0.843) total time=   9.3s\n",
      "[CV 10/10; 76/100] START class_weight={0: 0.017575757575757578, 1: 1}...........\n",
      "[CV 10/10; 76/100] END class_weight={0: 0.017575757575757578, 1: 1};, score=(train=0.879, test=0.869) total time=   8.2s\n",
      "[CV 5/10; 82/100] START class_weight={0: 0.01818181818181818, 1: 1}.............\n",
      "[CV 5/10; 82/100] END class_weight={0: 0.01818181818181818, 1: 1};, score=(train=0.881, test=0.826) total time=   9.2s\n",
      "[CV 4/10; 88/100] START class_weight={0: 0.018787878787878787, 1: 1}............\n",
      "[CV 4/10; 88/100] END class_weight={0: 0.018787878787878787, 1: 1};, score=(train=0.882, test=0.838) total time=  12.0s\n",
      "[CV 3/10; 96/100] START class_weight={0: 0.019595959595959597, 1: 1}............\n",
      "[CV 3/10; 96/100] END class_weight={0: 0.019595959595959597, 1: 1};, score=(train=0.882, test=0.829) total time=  10.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 2/10] START class_weight={0: 0.0014444444444444444, 1: 1}.............\n",
      "[CV 7/10; 2/10] END class_weight={0: 0.0014444444444444444, 1: 1};, score=(train=0.876, test=0.858) total time=   9.9s\n",
      "[CV 8/10; 2/100] START class_weight={0: 0.001090909090909091, 1: 1}.............\n",
      "[CV 8/10; 2/100] END class_weight={0: 0.001090909090909091, 1: 1};, score=(train=0.875, test=0.866) total time=   7.0s\n",
      "[CV 3/10; 8/100] START class_weight={0: 0.0016363636363636363, 1: 1}............\n",
      "[CV 3/10; 8/100] END class_weight={0: 0.0016363636363636363, 1: 1};, score=(train=0.879, test=0.838) total time=   6.3s\n",
      "[CV 2/10; 14/100] START class_weight={0: 0.002181818181818182, 1: 1}............\n",
      "[CV 2/10; 14/100] END class_weight={0: 0.002181818181818182, 1: 1};, score=(train=0.882, test=0.850) total time=   6.6s\n",
      "[CV 10/10; 19/100] START class_weight={0: 0.0026363636363636363, 1: 1}..........\n",
      "[CV 10/10; 19/100] END class_weight={0: 0.0026363636363636363, 1: 1};, score=(train=0.875, test=0.847) total time=   9.0s\n",
      "[CV 10/10; 26/100] START class_weight={0: 0.003272727272727273, 1: 1}...........\n",
      "[CV 10/10; 26/100] END class_weight={0: 0.003272727272727273, 1: 1};, score=(train=0.879, test=0.851) total time=   8.1s\n",
      "[CV 3/10; 33/100] START class_weight={0: 0.003909090909090909, 1: 1}............\n",
      "[CV 3/10; 33/100] END class_weight={0: 0.003909090909090909, 1: 1};, score=(train=0.880, test=0.841) total time=   7.4s\n",
      "[CV 8/10; 38/100] START class_weight={0: 0.004363636363636364, 1: 1}............\n",
      "[CV 8/10; 38/100] END class_weight={0: 0.004363636363636364, 1: 1};, score=(train=0.878, test=0.869) total time=   7.3s\n",
      "[CV 7/10; 43/100] START class_weight={0: 0.004818181818181819, 1: 1}............\n",
      "[CV 7/10; 43/100] END class_weight={0: 0.004818181818181819, 1: 1};, score=(train=0.876, test=0.861) total time=  10.3s\n",
      "[CV 3/10; 51/100] START class_weight={0: 0.005545454545454546, 1: 1}............\n",
      "[CV 3/10; 51/100] END class_weight={0: 0.005545454545454546, 1: 1};, score=(train=0.879, test=0.846) total time=   9.2s\n",
      "[CV 3/10; 58/100] START class_weight={0: 0.006181818181818182, 1: 1}............\n",
      "[CV 3/10; 58/100] END class_weight={0: 0.006181818181818182, 1: 1};, score=(train=0.881, test=0.845) total time=   7.9s\n",
      "[CV 10/10; 63/100] START class_weight={0: 0.006636363636363637, 1: 1}...........\n",
      "[CV 10/10; 63/100] END class_weight={0: 0.006636363636363637, 1: 1};, score=(train=0.879, test=0.858) total time=  10.2s\n",
      "[CV 1/10; 71/100] START class_weight={0: 0.007363636363636364, 1: 1}............\n",
      "[CV 1/10; 71/100] END class_weight={0: 0.007363636363636364, 1: 1};, score=(train=0.877, test=0.846) total time=   8.2s\n",
      "[CV 9/10; 76/100] START class_weight={0: 0.007818181818181818, 1: 1}............\n",
      "[CV 9/10; 76/100] END class_weight={0: 0.007818181818181818, 1: 1};, score=(train=0.881, test=0.842) total time=   7.6s\n",
      "[CV 5/10; 82/100] START class_weight={0: 0.008363636363636365, 1: 1}............\n",
      "[CV 5/10; 82/100] END class_weight={0: 0.008363636363636365, 1: 1};, score=(train=0.880, test=0.831) total time=   8.0s\n",
      "[CV 6/10; 88/100] START class_weight={0: 0.008909090909090908, 1: 1}............\n",
      "[CV 6/10; 88/100] END class_weight={0: 0.008909090909090908, 1: 1};, score=(train=0.878, test=0.839) total time=   9.6s\n",
      "[CV 3/10; 95/100] START class_weight={0: 0.009545454545454548, 1: 1}............\n",
      "[CV 3/10; 95/100] END class_weight={0: 0.009545454545454548, 1: 1};, score=(train=0.879, test=0.830) total time=   9.2s\n",
      "[CV 6/10; 1/100] START class_weight={0: 0.01, 1: 1}.............................\n",
      "[CV 6/10; 1/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.879, test=0.839) total time=   9.6s\n",
      "[CV 8/10; 9/100] START class_weight={0: 0.010808080808080808, 1: 1}.............\n",
      "[CV 8/10; 9/100] END class_weight={0: 0.010808080808080808, 1: 1};, score=(train=0.878, test=0.868) total time=   8.0s\n",
      "[CV 8/10; 14/100] START class_weight={0: 0.011313131313131313, 1: 1}............\n",
      "[CV 8/10; 14/100] END class_weight={0: 0.011313131313131313, 1: 1};, score=(train=0.878, test=0.868) total time=   9.9s\n",
      "[CV 3/10; 21/100] START class_weight={0: 0.012020202020202021, 1: 1}............\n",
      "[CV 3/10; 21/100] END class_weight={0: 0.012020202020202021, 1: 1};, score=(train=0.879, test=0.827) total time=   9.6s\n",
      "[CV 10/10; 27/100] START class_weight={0: 0.012626262626262626, 1: 1}...........\n",
      "[CV 10/10; 27/100] END class_weight={0: 0.012626262626262626, 1: 1};, score=(train=0.878, test=0.865) total time=   9.6s\n",
      "[CV 3/10; 34/100] START class_weight={0: 0.013333333333333332, 1: 1}............\n",
      "[CV 3/10; 34/100] END class_weight={0: 0.013333333333333332, 1: 1};, score=(train=0.876, test=0.838) total time=   6.8s\n",
      "[CV 1/10; 39/100] START class_weight={0: 0.013838383838383839, 1: 1}............\n",
      "[CV 1/10; 39/100] END class_weight={0: 0.013838383838383839, 1: 1};, score=(train=0.879, test=0.869) total time=  11.7s\n",
      "[CV 4/10; 46/100] START class_weight={0: 0.014545454545454545, 1: 1}............\n",
      "[CV 4/10; 46/100] END class_weight={0: 0.014545454545454545, 1: 1};, score=(train=0.882, test=0.837) total time=   8.7s\n",
      "[CV 2/10; 52/100] START class_weight={0: 0.015151515151515152, 1: 1}............\n",
      "[CV 2/10; 52/100] END class_weight={0: 0.015151515151515152, 1: 1};, score=(train=0.884, test=0.844) total time=   9.3s\n",
      "[CV 6/10; 58/100] START class_weight={0: 0.01575757575757576, 1: 1}.............\n",
      "[CV 6/10; 58/100] END class_weight={0: 0.01575757575757576, 1: 1};, score=(train=0.881, test=0.826) total time=   8.8s\n",
      "[CV 1/10; 64/100] START class_weight={0: 0.016363636363636365, 1: 1}............\n",
      "[CV 1/10; 64/100] END class_weight={0: 0.016363636363636365, 1: 1};, score=(train=0.878, test=0.851) total time=   8.8s\n",
      "[CV 2/10; 70/100] START class_weight={0: 0.016969696969696968, 1: 1}............\n",
      "[CV 2/10; 70/100] END class_weight={0: 0.016969696969696968, 1: 1};, score=(train=0.884, test=0.844) total time=  10.8s\n",
      "[CV 9/10; 76/100] START class_weight={0: 0.017575757575757578, 1: 1}............\n",
      "[CV 9/10; 76/100] END class_weight={0: 0.017575757575757578, 1: 1};, score=(train=0.880, test=0.853) total time=  10.5s\n",
      "[CV 6/10; 83/100] START class_weight={0: 0.018282828282828283, 1: 1}............\n",
      "[CV 6/10; 83/100] END class_weight={0: 0.018282828282828283, 1: 1};, score=(train=0.881, test=0.830) total time=  11.5s\n",
      "[CV 1/10; 91/100] START class_weight={0: 0.01909090909090909, 1: 1}.............\n",
      "[CV 1/10; 91/100] END class_weight={0: 0.01909090909090909, 1: 1};, score=(train=0.879, test=0.859) total time=   9.8s\n",
      "[CV 3/10; 97/100] START class_weight={0: 0.0196969696969697, 1: 1}..............\n",
      "[CV 3/10; 97/100] END class_weight={0: 0.0196969696969697, 1: 1};, score=(train=0.882, test=0.833) total time=   8.0s\n",
      "[CV 5/10; 2/10] START class_weight={0: 0.0014444444444444444, 1: 1}.............\n",
      "[CV 5/10; 2/10] END class_weight={0: 0.0014444444444444444, 1: 1};, score=(train=0.883, test=0.827) total time=   7.0s\n",
      "[CV 2/10; 9/10] START class_weight={0: 0.004555555555555556, 1: 1}..............\n",
      "[CV 2/10; 9/10] END class_weight={0: 0.004555555555555556, 1: 1};, score=(train=0.879, test=0.836) total time=   6.5s\n",
      "[CV 8/10; 5/100] START class_weight={0: 0.0013636363636363637, 1: 1}............\n",
      "[CV 8/10; 5/100] END class_weight={0: 0.0013636363636363637, 1: 1};, score=(train=0.876, test=0.876) total time=   7.1s\n",
      "[CV 3/10; 9/100] START class_weight={0: 0.0017272727272727275, 1: 1}............\n",
      "[CV 3/10; 9/100] END class_weight={0: 0.0017272727272727275, 1: 1};, score=(train=0.879, test=0.836) total time=   7.7s\n",
      "[CV 6/10; 15/100] START class_weight={0: 0.0022727272727272726, 1: 1}...........\n",
      "[CV 6/10; 15/100] END class_weight={0: 0.0022727272727272726, 1: 1};, score=(train=0.879, test=0.834) total time=   8.8s\n",
      "[CV 8/10; 22/100] START class_weight={0: 0.0029090909090909093, 1: 1}...........\n",
      "[CV 8/10; 22/100] END class_weight={0: 0.0029090909090909093, 1: 1};, score=(train=0.878, test=0.866) total time=   8.7s\n",
      "[CV 6/10; 29/100] START class_weight={0: 0.0035454545454545456, 1: 1}...........\n",
      "[CV 6/10; 29/100] END class_weight={0: 0.0035454545454545456, 1: 1};, score=(train=0.880, test=0.833) total time=  10.1s\n",
      "[CV 3/10; 37/100] START class_weight={0: 0.0042727272727272735, 1: 1}...........\n",
      "[CV 3/10; 37/100] END class_weight={0: 0.0042727272727272735, 1: 1};, score=(train=0.879, test=0.841) total time=   7.7s\n",
      "[CV 4/10; 43/100] START class_weight={0: 0.004818181818181819, 1: 1}............\n",
      "[CV 4/10; 43/100] END class_weight={0: 0.004818181818181819, 1: 1};, score=(train=0.879, test=0.850) total time=   7.8s\n",
      "[CV 10/10; 48/100] START class_weight={0: 0.0052727272727272735, 1: 1}..........\n",
      "[CV 10/10; 48/100] END class_weight={0: 0.0052727272727272735, 1: 1};, score=(train=0.880, test=0.859) total time=   9.9s\n",
      "[CV 3/10; 56/100] START class_weight={0: 0.006, 1: 1}...........................\n",
      "[CV 3/10; 56/100] END class_weight={0: 0.006, 1: 1};, score=(train=0.879, test=0.846) total time=   8.9s\n",
      "[CV 1/10; 63/100] START class_weight={0: 0.006636363636363637, 1: 1}............\n",
      "[CV 1/10; 63/100] END class_weight={0: 0.006636363636363637, 1: 1};, score=(train=0.878, test=0.838) total time=   7.8s\n",
      "[CV 9/10; 68/100] START class_weight={0: 0.007090909090909091, 1: 1}............\n",
      "[CV 9/10; 68/100] END class_weight={0: 0.007090909090909091, 1: 1};, score=(train=0.882, test=0.843) total time=   9.9s\n",
      "[CV 6/10; 75/100] START class_weight={0: 0.007727272727272728, 1: 1}............\n",
      "[CV 6/10; 75/100] END class_weight={0: 0.007727272727272728, 1: 1};, score=(train=0.879, test=0.837) total time=   8.3s\n",
      "[CV 6/10; 81/100] START class_weight={0: 0.008272727272727274, 1: 1}............\n",
      "[CV 6/10; 81/100] END class_weight={0: 0.008272727272727274, 1: 1};, score=(train=0.880, test=0.835) total time=   7.2s\n",
      "[CV 7/10; 86/100] START class_weight={0: 0.008727272727272728, 1: 1}............\n",
      "[CV 7/10; 86/100] END class_weight={0: 0.008727272727272728, 1: 1};, score=(train=0.877, test=0.862) total time=   7.0s\n",
      "[CV 7/10; 90/100] START class_weight={0: 0.00909090909090909, 1: 1}.............\n",
      "[CV 7/10; 90/100] END class_weight={0: 0.00909090909090909, 1: 1};, score=(train=0.877, test=0.862) total time=   8.4s\n",
      "[CV 6/10; 96/100] START class_weight={0: 0.009636363636363637, 1: 1}............\n",
      "[CV 6/10; 96/100] END class_weight={0: 0.009636363636363637, 1: 1};, score=(train=0.879, test=0.839) total time=   8.9s\n",
      "[CV 7/10; 2/100] START class_weight={0: 0.010101010101010102, 1: 1}.............\n",
      "[CV 7/10; 2/100] END class_weight={0: 0.010101010101010102, 1: 1};, score=(train=0.876, test=0.865) total time=   8.9s\n",
      "[CV 9/10; 8/100] START class_weight={0: 0.010707070707070707, 1: 1}.............\n",
      "[CV 9/10; 8/100] END class_weight={0: 0.010707070707070707, 1: 1};, score=(train=0.881, test=0.843) total time=  13.2s\n",
      "[CV 5/10; 19/100] START class_weight={0: 0.011818181818181818, 1: 1}............\n",
      "[CV 5/10; 19/100] END class_weight={0: 0.011818181818181818, 1: 1};, score=(train=0.876, test=0.841) total time=  10.9s\n",
      "[CV 10/10; 25/100] START class_weight={0: 0.012424242424242424, 1: 1}...........\n",
      "[CV 10/10; 25/100] END class_weight={0: 0.012424242424242424, 1: 1};, score=(train=0.876, test=0.864) total time=  10.5s\n",
      "[CV 5/10; 32/100] START class_weight={0: 0.013131313131313133, 1: 1}............\n",
      "[CV 5/10; 32/100] END class_weight={0: 0.013131313131313133, 1: 1};, score=(train=0.880, test=0.829) total time=  11.7s\n",
      "[CV 1/10; 40/100] START class_weight={0: 0.013939393939393939, 1: 1}............\n",
      "[CV 1/10; 40/100] END class_weight={0: 0.013939393939393939, 1: 1};, score=(train=0.878, test=0.859) total time=   9.4s\n",
      "[CV 3/10; 46/100] START class_weight={0: 0.014545454545454545, 1: 1}............\n",
      "[CV 3/10; 46/100] END class_weight={0: 0.014545454545454545, 1: 1};, score=(train=0.876, test=0.838) total time=  10.2s\n",
      "[CV 7/10; 52/100] START class_weight={0: 0.015151515151515152, 1: 1}............\n",
      "[CV 7/10; 52/100] END class_weight={0: 0.015151515151515152, 1: 1};, score=(train=0.880, test=0.865) total time=   8.9s\n",
      "[CV 9/10; 58/100] START class_weight={0: 0.01575757575757576, 1: 1}.............\n",
      "[CV 9/10; 58/100] END class_weight={0: 0.01575757575757576, 1: 1};, score=(train=0.881, test=0.854) total time=   9.5s\n",
      "[CV 4/10; 65/100] START class_weight={0: 0.016464646464646467, 1: 1}............\n",
      "[CV 4/10; 65/100] END class_weight={0: 0.016464646464646467, 1: 1};, score=(train=0.881, test=0.841) total time=  10.4s\n",
      "[CV 1/10; 72/100] START class_weight={0: 0.01717171717171717, 1: 1}.............\n",
      "[CV 1/10; 72/100] END class_weight={0: 0.01717171717171717, 1: 1};, score=(train=0.880, test=0.861) total time=   8.2s\n",
      "[CV 5/10; 77/100] START class_weight={0: 0.017676767676767676, 1: 1}............\n",
      "[CV 5/10; 77/100] END class_weight={0: 0.017676767676767676, 1: 1};, score=(train=0.883, test=0.832) total time=   8.6s\n",
      "[CV 2/10; 83/100] START class_weight={0: 0.018282828282828283, 1: 1}............\n",
      "[CV 2/10; 83/100] END class_weight={0: 0.018282828282828283, 1: 1};, score=(train=0.883, test=0.842) total time=  12.0s\n",
      "[CV 10/10; 90/100] START class_weight={0: 0.01898989898989899, 1: 1}............\n",
      "[CV 10/10; 90/100] END class_weight={0: 0.01898989898989899, 1: 1};, score=(train=0.879, test=0.869) total time=   8.9s\n",
      "[CV 8/10; 96/100] START class_weight={0: 0.019595959595959597, 1: 1}............\n",
      "[CV 8/10; 96/100] END class_weight={0: 0.019595959595959597, 1: 1};, score=(train=0.878, test=0.884) total time=   8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10; 7/10] START class_weight={0: 0.003666666666666667, 1: 1}..............\n",
      "[CV 3/10; 7/10] END class_weight={0: 0.003666666666666667, 1: 1};, score=(train=0.880, test=0.841) total time=   8.4s\n",
      "[CV 9/10; 2/100] START class_weight={0: 0.001090909090909091, 1: 1}.............\n",
      "[CV 9/10; 2/100] END class_weight={0: 0.001090909090909091, 1: 1};, score=(train=0.877, test=0.839) total time=   6.6s\n",
      "[CV 7/10; 7/100] START class_weight={0: 0.0015454545454545456, 1: 1}............\n",
      "[CV 7/10; 7/100] END class_weight={0: 0.0015454545454545456, 1: 1};, score=(train=0.875, test=0.857) total time=   8.0s\n",
      "[CV 9/10; 14/100] START class_weight={0: 0.002181818181818182, 1: 1}............\n",
      "[CV 9/10; 14/100] END class_weight={0: 0.002181818181818182, 1: 1};, score=(train=0.881, test=0.850) total time=   9.7s\n",
      "[CV 2/10; 23/100] START class_weight={0: 0.003, 1: 1}...........................\n",
      "[CV 2/10; 23/100] END class_weight={0: 0.003, 1: 1};, score=(train=0.882, test=0.836) total time=   8.6s\n",
      "[CV 1/10; 29/100] START class_weight={0: 0.0035454545454545456, 1: 1}...........\n",
      "[CV 1/10; 29/100] END class_weight={0: 0.0035454545454545456, 1: 1};, score=(train=0.882, test=0.833) total time=   7.7s\n",
      "[CV 9/10; 34/100] START class_weight={0: 0.004, 1: 1}...........................\n",
      "[CV 9/10; 34/100] END class_weight={0: 0.004, 1: 1};, score=(train=0.881, test=0.835) total time=  10.5s\n",
      "[CV 10/10; 42/100] START class_weight={0: 0.0047272727272727275, 1: 1}..........\n",
      "[CV 10/10; 42/100] END class_weight={0: 0.0047272727272727275, 1: 1};, score=(train=0.879, test=0.853) total time=   9.7s\n",
      "[CV 3/10; 50/100] START class_weight={0: 0.005454545454545455, 1: 1}............\n",
      "[CV 3/10; 50/100] END class_weight={0: 0.005454545454545455, 1: 1};, score=(train=0.881, test=0.843) total time=   8.9s\n",
      "[CV 7/10; 56/100] START class_weight={0: 0.006, 1: 1}...........................\n",
      "[CV 7/10; 56/100] END class_weight={0: 0.006, 1: 1};, score=(train=0.877, test=0.864) total time=   7.6s\n",
      "[CV 5/10; 62/100] START class_weight={0: 0.006545454545454546, 1: 1}............\n",
      "[CV 5/10; 62/100] END class_weight={0: 0.006545454545454546, 1: 1};, score=(train=0.880, test=0.833) total time=   6.7s\n",
      "[CV 7/10; 66/100] START class_weight={0: 0.00690909090909091, 1: 1}.............\n",
      "[CV 7/10; 66/100] END class_weight={0: 0.00690909090909091, 1: 1};, score=(train=0.877, test=0.866) total time=   6.4s\n",
      "[CV 3/10; 71/100] START class_weight={0: 0.007363636363636364, 1: 1}............\n",
      "[CV 3/10; 71/100] END class_weight={0: 0.007363636363636364, 1: 1};, score=(train=0.881, test=0.843) total time=   7.6s\n",
      "[CV 7/10; 76/100] START class_weight={0: 0.007818181818181818, 1: 1}............\n",
      "[CV 7/10; 76/100] END class_weight={0: 0.007818181818181818, 1: 1};, score=(train=0.877, test=0.862) total time=   9.5s\n",
      "[CV 5/10; 83/100] START class_weight={0: 0.008454545454545454, 1: 1}............\n",
      "[CV 5/10; 83/100] END class_weight={0: 0.008454545454545454, 1: 1};, score=(train=0.880, test=0.831) total time=   9.5s\n",
      "[CV 2/10; 90/100] START class_weight={0: 0.00909090909090909, 1: 1}.............\n",
      "[CV 2/10; 90/100] END class_weight={0: 0.00909090909090909, 1: 1};, score=(train=0.879, test=0.858) total time=   9.2s\n",
      "[CV 5/10; 96/100] START class_weight={0: 0.009636363636363637, 1: 1}............\n",
      "[CV 5/10; 96/100] END class_weight={0: 0.009636363636363637, 1: 1};, score=(train=0.877, test=0.838) total time=   7.9s\n",
      "[CV 9/10; 1/100] START class_weight={0: 0.01, 1: 1}.............................\n",
      "[CV 9/10; 1/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.880, test=0.848) total time=   8.4s\n",
      "[CV 8/10; 7/100] START class_weight={0: 0.010606060606060607, 1: 1}.............\n",
      "[CV 8/10; 7/100] END class_weight={0: 0.010606060606060607, 1: 1};, score=(train=0.878, test=0.860) total time=   8.6s\n",
      "[CV 4/10; 14/100] START class_weight={0: 0.011313131313131313, 1: 1}............\n",
      "[CV 4/10; 14/100] END class_weight={0: 0.011313131313131313, 1: 1};, score=(train=0.875, test=0.830) total time=   8.4s\n",
      "[CV 8/10; 20/100] START class_weight={0: 0.01191919191919192, 1: 1}.............\n",
      "[CV 8/10; 20/100] END class_weight={0: 0.01191919191919192, 1: 1};, score=(train=0.879, test=0.887) total time=   9.2s\n",
      "[CV 1/10; 27/100] START class_weight={0: 0.012626262626262626, 1: 1}............\n",
      "[CV 1/10; 27/100] END class_weight={0: 0.012626262626262626, 1: 1};, score=(train=0.878, test=0.867) total time=  11.6s\n",
      "[CV 7/10; 34/100] START class_weight={0: 0.013333333333333332, 1: 1}............\n",
      "[CV 7/10; 34/100] END class_weight={0: 0.013333333333333332, 1: 1};, score=(train=0.879, test=0.866) total time=  11.4s\n",
      "[CV 7/10; 42/100] START class_weight={0: 0.014141414141414142, 1: 1}............\n",
      "[CV 7/10; 42/100] END class_weight={0: 0.014141414141414142, 1: 1};, score=(train=0.880, test=0.867) total time=  10.0s\n",
      "[CV 6/10; 49/100] START class_weight={0: 0.014848484848484849, 1: 1}............\n",
      "[CV 6/10; 49/100] END class_weight={0: 0.014848484848484849, 1: 1};, score=(train=0.881, test=0.830) total time=   9.1s\n",
      "[CV 1/10; 55/100] START class_weight={0: 0.015454545454545455, 1: 1}............\n",
      "[CV 1/10; 55/100] END class_weight={0: 0.015454545454545455, 1: 1};, score=(train=0.878, test=0.851) total time=  10.2s\n",
      "[CV 1/10; 62/100] START class_weight={0: 0.01616161616161616, 1: 1}.............\n",
      "[CV 1/10; 62/100] END class_weight={0: 0.01616161616161616, 1: 1};, score=(train=0.881, test=0.859) total time=  10.9s\n",
      "[CV 1/10; 69/100] START class_weight={0: 0.01686868686868687, 1: 1}.............\n",
      "[CV 1/10; 69/100] END class_weight={0: 0.01686868686868687, 1: 1};, score=(train=0.880, test=0.861) total time=   8.2s\n",
      "[CV 5/10; 74/100] START class_weight={0: 0.017373737373737375, 1: 1}............\n",
      "[CV 5/10; 74/100] END class_weight={0: 0.017373737373737375, 1: 1};, score=(train=0.881, test=0.830) total time=   8.1s\n",
      "[CV 5/10; 79/100] START class_weight={0: 0.01787878787878788, 1: 1}.............\n",
      "[CV 5/10; 79/100] END class_weight={0: 0.01787878787878788, 1: 1};, score=(train=0.880, test=0.829) total time=   7.2s\n",
      "[CV 6/10; 84/100] START class_weight={0: 0.018383838383838384, 1: 1}............\n",
      "[CV 6/10; 84/100] END class_weight={0: 0.018383838383838384, 1: 1};, score=(train=0.881, test=0.826) total time=   7.8s\n",
      "[CV 4/10; 89/100] START class_weight={0: 0.01888888888888889, 1: 1}.............\n",
      "[CV 4/10; 89/100] END class_weight={0: 0.01888888888888889, 1: 1};, score=(train=0.881, test=0.842) total time=  10.4s\n",
      "[CV 4/10; 96/100] START class_weight={0: 0.019595959595959597, 1: 1}............\n",
      "[CV 4/10; 96/100] END class_weight={0: 0.019595959595959597, 1: 1};, score=(train=0.882, test=0.838) total time=   9.8s\n",
      "[CV 8/10; 5/10] START class_weight={0: 0.002777777777777778, 1: 1}..............\n",
      "[CV 8/10; 5/10] END class_weight={0: 0.002777777777777778, 1: 1};, score=(train=0.878, test=0.865) total time=   8.9s\n",
      "[CV 10/10; 1/100] START class_weight={0: 0.001, 1: 1}...........................\n",
      "[CV 10/10; 1/100] END class_weight={0: 0.001, 1: 1};, score=(train=0.879, test=0.847) total time=   8.3s\n",
      "[CV 6/10; 11/100] START class_weight={0: 0.0019090909090909093, 1: 1}...........\n",
      "[CV 6/10; 11/100] END class_weight={0: 0.0019090909090909093, 1: 1};, score=(train=0.881, test=0.824) total time=   8.3s\n",
      "[CV 10/10; 17/100] START class_weight={0: 0.002454545454545455, 1: 1}...........\n",
      "[CV 10/10; 17/100] END class_weight={0: 0.002454545454545455, 1: 1};, score=(train=0.876, test=0.847) total time=   8.0s\n",
      "[CV 7/10; 23/100] START class_weight={0: 0.003, 1: 1}...........................\n",
      "[CV 7/10; 23/100] END class_weight={0: 0.003, 1: 1};, score=(train=0.875, test=0.856) total time=   8.4s\n",
      "[CV 10/10; 29/100] START class_weight={0: 0.0035454545454545456, 1: 1}..........\n",
      "[CV 10/10; 29/100] END class_weight={0: 0.0035454545454545456, 1: 1};, score=(train=0.879, test=0.851) total time=  11.8s\n",
      "[CV 1/10; 39/100] START class_weight={0: 0.004454545454545455, 1: 1}............\n",
      "[CV 1/10; 39/100] END class_weight={0: 0.004454545454545455, 1: 1};, score=(train=0.878, test=0.832) total time=  10.5s\n",
      "[CV 10/10; 46/100] START class_weight={0: 0.005090909090909091, 1: 1}...........\n",
      "[CV 10/10; 46/100] END class_weight={0: 0.005090909090909091, 1: 1};, score=(train=0.879, test=0.858) total time=   7.0s\n",
      "[CV 9/10; 51/100] START class_weight={0: 0.005545454545454546, 1: 1}............\n",
      "[CV 9/10; 51/100] END class_weight={0: 0.005545454545454546, 1: 1};, score=(train=0.882, test=0.843) total time=   8.0s\n",
      "[CV 1/10; 58/100] START class_weight={0: 0.006181818181818182, 1: 1}............\n",
      "[CV 1/10; 58/100] END class_weight={0: 0.006181818181818182, 1: 1};, score=(train=0.878, test=0.838) total time=  11.3s\n",
      "[CV 1/10; 66/100] START class_weight={0: 0.00690909090909091, 1: 1}.............\n",
      "[CV 1/10; 66/100] END class_weight={0: 0.00690909090909091, 1: 1};, score=(train=0.878, test=0.841) total time=  11.4s\n",
      "[CV 3/10; 74/100] START class_weight={0: 0.007636363636363637, 1: 1}............\n",
      "[CV 3/10; 74/100] END class_weight={0: 0.007636363636363637, 1: 1};, score=(train=0.881, test=0.843) total time=   9.6s\n",
      "[CV 3/10; 81/100] START class_weight={0: 0.008272727272727274, 1: 1}............\n",
      "[CV 3/10; 81/100] END class_weight={0: 0.008272727272727274, 1: 1};, score=(train=0.879, test=0.846) total time=   7.5s\n",
      "[CV 8/10; 86/100] START class_weight={0: 0.008727272727272728, 1: 1}............\n",
      "[CV 8/10; 86/100] END class_weight={0: 0.008727272727272728, 1: 1};, score=(train=0.878, test=0.860) total time=   7.3s\n",
      "[CV 10/10; 90/100] START class_weight={0: 0.00909090909090909, 1: 1}............\n",
      "[CV 10/10; 90/100] END class_weight={0: 0.00909090909090909, 1: 1};, score=(train=0.877, test=0.848) total time=   8.6s\n",
      "[CV 5/10; 97/100] START class_weight={0: 0.009727272727272727, 1: 1}............\n",
      "[CV 5/10; 97/100] END class_weight={0: 0.009727272727272727, 1: 1};, score=(train=0.878, test=0.833) total time=  10.6s\n",
      "[CV 6/10; 5/100] START class_weight={0: 0.010404040404040405, 1: 1}.............\n",
      "[CV 6/10; 5/100] END class_weight={0: 0.010404040404040405, 1: 1};, score=(train=0.879, test=0.839) total time=  11.5s\n",
      "[CV 4/10; 13/100] START class_weight={0: 0.011212121212121211, 1: 1}............\n",
      "[CV 4/10; 13/100] END class_weight={0: 0.011212121212121211, 1: 1};, score=(train=0.876, test=0.836) total time=   8.7s\n",
      "[CV 2/10; 18/100] START class_weight={0: 0.011717171717171718, 1: 1}............\n",
      "[CV 2/10; 18/100] END class_weight={0: 0.011717171717171718, 1: 1};, score=(train=0.877, test=0.849) total time=  11.5s\n",
      "[CV 4/10; 25/100] START class_weight={0: 0.012424242424242424, 1: 1}............\n",
      "[CV 4/10; 25/100] END class_weight={0: 0.012424242424242424, 1: 1};, score=(train=0.876, test=0.836) total time=  12.1s\n",
      "[CV 8/10; 32/100] START class_weight={0: 0.013131313131313133, 1: 1}............\n",
      "[CV 8/10; 32/100] END class_weight={0: 0.013131313131313133, 1: 1};, score=(train=0.879, test=0.885) total time=  10.2s\n",
      "[CV 4/10; 39/100] START class_weight={0: 0.013838383838383839, 1: 1}............\n",
      "[CV 4/10; 39/100] END class_weight={0: 0.013838383838383839, 1: 1};, score=(train=0.881, test=0.846) total time=  12.1s\n",
      "[CV 9/10; 46/100] START class_weight={0: 0.014545454545454545, 1: 1}............\n",
      "[CV 9/10; 46/100] END class_weight={0: 0.014545454545454545, 1: 1};, score=(train=0.880, test=0.837) total time=   9.2s\n",
      "[CV 10/10; 52/100] START class_weight={0: 0.015151515151515152, 1: 1}...........\n",
      "[CV 10/10; 52/100] END class_weight={0: 0.015151515151515152, 1: 1};, score=(train=0.879, test=0.869) total time=  11.2s\n",
      "[CV 4/10; 60/100] START class_weight={0: 0.01595959595959596, 1: 1}.............\n",
      "[CV 4/10; 60/100] END class_weight={0: 0.01595959595959596, 1: 1};, score=(train=0.883, test=0.848) total time=  11.0s\n",
      "[CV 4/10; 67/100] START class_weight={0: 0.016666666666666666, 1: 1}............\n",
      "[CV 4/10; 67/100] END class_weight={0: 0.016666666666666666, 1: 1};, score=(train=0.881, test=0.842) total time=  11.1s\n",
      "[CV 3/10; 75/100] START class_weight={0: 0.017474747474747476, 1: 1}............\n",
      "[CV 3/10; 75/100] END class_weight={0: 0.017474747474747476, 1: 1};, score=(train=0.879, test=0.830) total time=  11.0s\n",
      "[CV 4/10; 82/100] START class_weight={0: 0.01818181818181818, 1: 1}.............\n",
      "[CV 4/10; 82/100] END class_weight={0: 0.01818181818181818, 1: 1};, score=(train=0.882, test=0.838) total time=  12.4s\n",
      "[CV 4/10; 90/100] START class_weight={0: 0.01898989898989899, 1: 1}.............\n",
      "[CV 4/10; 90/100] END class_weight={0: 0.01898989898989899, 1: 1};, score=(train=0.883, test=0.848) total time=   9.6s\n",
      "[CV 6/10; 96/100] START class_weight={0: 0.019595959595959597, 1: 1}............\n",
      "[CV 6/10; 96/100] END class_weight={0: 0.019595959595959597, 1: 1};, score=(train=0.881, test=0.826) total time=   9.4s\n",
      "[CV 10/10; 3/10] START class_weight={0: 0.001888888888888889, 1: 1}.............\n",
      "[CV 10/10; 3/10] END class_weight={0: 0.001888888888888889, 1: 1};, score=(train=0.877, test=0.848) total time=   7.1s\n",
      "[CV 8/10; 10/10] START class_weight={0: 0.005, 1: 1}............................\n",
      "[CV 8/10; 10/10] END class_weight={0: 0.005, 1: 1};, score=(train=0.877, test=0.862) total time=   6.0s\n",
      "[CV 4/10; 7/100] START class_weight={0: 0.0015454545454545456, 1: 1}............\n",
      "[CV 4/10; 7/100] END class_weight={0: 0.0015454545454545456, 1: 1};, score=(train=0.878, test=0.828) total time=   7.3s\n",
      "[CV 10/10; 9/100] START class_weight={0: 0.0017272727272727275, 1: 1}...........\n",
      "[CV 10/10; 9/100] END class_weight={0: 0.0017272727272727275, 1: 1};, score=(train=0.879, test=0.849) total time=   7.6s\n",
      "[CV 7/10; 16/100] START class_weight={0: 0.0023636363636363638, 1: 1}...........\n",
      "[CV 7/10; 16/100] END class_weight={0: 0.0023636363636363638, 1: 1};, score=(train=0.878, test=0.861) total time=   9.4s\n",
      "[CV 2/10; 24/100] START class_weight={0: 0.003090909090909091, 1: 1}............\n",
      "[CV 2/10; 24/100] END class_weight={0: 0.003090909090909091, 1: 1};, score=(train=0.883, test=0.852) total time=   9.7s\n",
      "[CV 5/10; 31/100] START class_weight={0: 0.0037272727272727275, 1: 1}...........\n",
      "[CV 5/10; 31/100] END class_weight={0: 0.0037272727272727275, 1: 1};, score=(train=0.880, test=0.837) total time=   7.1s\n",
      "[CV 4/10; 36/100] START class_weight={0: 0.004181818181818182, 1: 1}............\n",
      "[CV 4/10; 36/100] END class_weight={0: 0.004181818181818182, 1: 1};, score=(train=0.879, test=0.849) total time=   8.3s\n",
      "[CV 4/10; 42/100] START class_weight={0: 0.0047272727272727275, 1: 1}...........\n",
      "[CV 4/10; 42/100] END class_weight={0: 0.0047272727272727275, 1: 1};, score=(train=0.879, test=0.850) total time=   8.6s\n",
      "[CV 2/10; 49/100] START class_weight={0: 0.005363636363636364, 1: 1}............\n",
      "[CV 2/10; 49/100] END class_weight={0: 0.005363636363636364, 1: 1};, score=(train=0.879, test=0.830) total time=  11.5s\n",
      "[CV 5/10; 57/100] START class_weight={0: 0.006090909090909091, 1: 1}............\n",
      "[CV 5/10; 57/100] END class_weight={0: 0.006090909090909091, 1: 1};, score=(train=0.880, test=0.834) total time=  10.1s\n",
      "[CV 6/10; 64/100] START class_weight={0: 0.006727272727272728, 1: 1}............\n",
      "[CV 6/10; 64/100] END class_weight={0: 0.006727272727272728, 1: 1};, score=(train=0.879, test=0.837) total time=   9.0s\n",
      "[CV 8/10; 70/100] START class_weight={0: 0.007272727272727274, 1: 1}............\n",
      "[CV 8/10; 70/100] END class_weight={0: 0.007272727272727274, 1: 1};, score=(train=0.875, test=0.873) total time=   9.6s\n",
      "[CV 8/10; 77/100] START class_weight={0: 0.00790909090909091, 1: 1}.............\n",
      "[CV 8/10; 77/100] END class_weight={0: 0.00790909090909091, 1: 1};, score=(train=0.874, test=0.866) total time=   8.6s\n",
      "[CV 1/10; 84/100] START class_weight={0: 0.008545454545454547, 1: 1}............\n",
      "[CV 1/10; 84/100] END class_weight={0: 0.008545454545454547, 1: 1};, score=(train=0.878, test=0.843) total time=  10.6s\n",
      "[CV 4/10; 91/100] START class_weight={0: 0.009181818181818183, 1: 1}............\n",
      "[CV 4/10; 91/100] END class_weight={0: 0.009181818181818183, 1: 1};, score=(train=0.879, test=0.833) total time=  10.4s\n",
      "[CV 6/10; 98/100] START class_weight={0: 0.00981818181818182, 1: 1}.............\n",
      "[CV 6/10; 98/100] END class_weight={0: 0.00981818181818182, 1: 1};, score=(train=0.879, test=0.839) total time=   8.5s\n",
      "[CV 5/10; 5/100] START class_weight={0: 0.010404040404040405, 1: 1}.............\n",
      "[CV 5/10; 5/100] END class_weight={0: 0.010404040404040405, 1: 1};, score=(train=0.879, test=0.836) total time=  10.9s\n",
      "[CV 10/10; 12/100] START class_weight={0: 0.011111111111111112, 1: 1}...........\n",
      "[CV 10/10; 12/100] END class_weight={0: 0.011111111111111112, 1: 1};, score=(train=0.878, test=0.865) total time=  10.1s\n",
      "[CV 9/10; 18/100] START class_weight={0: 0.011717171717171718, 1: 1}............\n",
      "[CV 9/10; 18/100] END class_weight={0: 0.011717171717171718, 1: 1};, score=(train=0.879, test=0.837) total time=  11.5s\n",
      "[CV 8/10; 25/100] START class_weight={0: 0.012424242424242424, 1: 1}............\n",
      "[CV 8/10; 25/100] END class_weight={0: 0.012424242424242424, 1: 1};, score=(train=0.880, test=0.883) total time=   7.7s\n",
      "[CV 9/10; 30/100] START class_weight={0: 0.01292929292929293, 1: 1}.............\n",
      "[CV 9/10; 30/100] END class_weight={0: 0.01292929292929293, 1: 1};, score=(train=0.880, test=0.842) total time=  12.2s\n",
      "[CV 7/10; 38/100] START class_weight={0: 0.013737373737373737, 1: 1}............\n",
      "[CV 7/10; 38/100] END class_weight={0: 0.013737373737373737, 1: 1};, score=(train=0.877, test=0.862) total time=  11.6s\n",
      "[CV 10/10; 45/100] START class_weight={0: 0.014444444444444444, 1: 1}...........\n",
      "[CV 10/10; 45/100] END class_weight={0: 0.014444444444444444, 1: 1};, score=(train=0.878, test=0.861) total time=   9.4s\n",
      "[CV 3/10; 52/100] START class_weight={0: 0.015151515151515152, 1: 1}............\n",
      "[CV 3/10; 52/100] END class_weight={0: 0.015151515151515152, 1: 1};, score=(train=0.876, test=0.838) total time=   8.1s\n",
      "[CV 7/10; 57/100] START class_weight={0: 0.015656565656565657, 1: 1}............\n",
      "[CV 7/10; 57/100] END class_weight={0: 0.015656565656565657, 1: 1};, score=(train=0.878, test=0.861) total time=  11.1s\n",
      "[CV 9/10; 64/100] START class_weight={0: 0.016363636363636365, 1: 1}............\n",
      "[CV 9/10; 64/100] END class_weight={0: 0.016363636363636365, 1: 1};, score=(train=0.881, test=0.854) total time=  10.9s\n",
      "[CV 8/10; 71/100] START class_weight={0: 0.01707070707070707, 1: 1}.............\n",
      "[CV 8/10; 71/100] END class_weight={0: 0.01707070707070707, 1: 1};, score=(train=0.877, test=0.872) total time=   9.4s\n",
      "[CV 9/10; 77/100] START class_weight={0: 0.017676767676767676, 1: 1}............\n",
      "[CV 9/10; 77/100] END class_weight={0: 0.017676767676767676, 1: 1};, score=(train=0.883, test=0.845) total time=   9.2s\n",
      "[CV 10/10; 83/100] START class_weight={0: 0.018282828282828283, 1: 1}...........\n",
      "[CV 10/10; 83/100] END class_weight={0: 0.018282828282828283, 1: 1};, score=(train=0.881, test=0.868) total time=   9.4s\n",
      "[CV 7/10; 89/100] START class_weight={0: 0.01888888888888889, 1: 1}.............\n",
      "[CV 7/10; 89/100] END class_weight={0: 0.01888888888888889, 1: 1};, score=(train=0.880, test=0.852) total time=  10.9s\n",
      "[CV 10/10; 96/100] START class_weight={0: 0.019595959595959597, 1: 1}...........\n",
      "[CV 10/10; 96/100] END class_weight={0: 0.019595959595959597, 1: 1};, score=(train=0.879, test=0.869) total time=   8.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 4/10] START class_weight={0: 0.0023333333333333335, 1: 1}.............\n",
      "[CV 4/10; 4/10] END class_weight={0: 0.0023333333333333335, 1: 1};, score=(train=0.877, test=0.840) total time=  10.6s\n",
      "[CV 5/10; 3/100] START class_weight={0: 0.0011818181818181819, 1: 1}............\n",
      "[CV 5/10; 3/100] END class_weight={0: 0.0011818181818181819, 1: 1};, score=(train=0.876, test=0.842) total time=   8.7s\n",
      "[CV 9/10; 11/100] START class_weight={0: 0.0019090909090909093, 1: 1}...........\n",
      "[CV 9/10; 11/100] END class_weight={0: 0.0019090909090909093, 1: 1};, score=(train=0.880, test=0.832) total time=   6.9s\n",
      "[CV 1/10; 16/100] START class_weight={0: 0.0023636363636363638, 1: 1}...........\n",
      "[CV 1/10; 16/100] END class_weight={0: 0.0023636363636363638, 1: 1};, score=(train=0.882, test=0.844) total time=   6.7s\n",
      "[CV 2/10; 21/100] START class_weight={0: 0.0028181818181818186, 1: 1}...........\n",
      "[CV 2/10; 21/100] END class_weight={0: 0.0028181818181818186, 1: 1};, score=(train=0.882, test=0.832) total time=  10.4s\n",
      "[CV 2/10; 29/100] START class_weight={0: 0.0035454545454545456, 1: 1}...........\n",
      "[CV 2/10; 29/100] END class_weight={0: 0.0035454545454545456, 1: 1};, score=(train=0.880, test=0.841) total time=  12.0s\n",
      "[CV 5/10; 38/100] START class_weight={0: 0.004363636363636364, 1: 1}............\n",
      "[CV 5/10; 38/100] END class_weight={0: 0.004363636363636364, 1: 1};, score=(train=0.880, test=0.846) total time=   8.0s\n",
      "[CV 6/10; 44/100] START class_weight={0: 0.00490909090909091, 1: 1}.............\n",
      "[CV 6/10; 44/100] END class_weight={0: 0.00490909090909091, 1: 1};, score=(train=0.880, test=0.835) total time=   9.7s\n",
      "[CV 8/10; 51/100] START class_weight={0: 0.005545454545454546, 1: 1}............\n",
      "[CV 8/10; 51/100] END class_weight={0: 0.005545454545454546, 1: 1};, score=(train=0.877, test=0.865) total time=   9.1s\n",
      "[CV 4/10; 58/100] START class_weight={0: 0.006181818181818182, 1: 1}............\n",
      "[CV 4/10; 58/100] END class_weight={0: 0.006181818181818182, 1: 1};, score=(train=0.879, test=0.837) total time=   7.6s\n",
      "[CV 8/10; 63/100] START class_weight={0: 0.006636363636363637, 1: 1}............\n",
      "[CV 8/10; 63/100] END class_weight={0: 0.006636363636363637, 1: 1};, score=(train=0.877, test=0.863) total time=   7.3s\n",
      "[CV 4/10; 69/100] START class_weight={0: 0.0071818181818181824, 1: 1}...........\n",
      "[CV 4/10; 69/100] END class_weight={0: 0.0071818181818181824, 1: 1};, score=(train=0.879, test=0.836) total time=   9.5s\n",
      "[CV 8/10; 75/100] START class_weight={0: 0.007727272727272728, 1: 1}............\n",
      "[CV 8/10; 75/100] END class_weight={0: 0.007727272727272728, 1: 1};, score=(train=0.875, test=0.873) total time=   9.7s\n",
      "[CV 7/10; 82/100] START class_weight={0: 0.008363636363636365, 1: 1}............\n",
      "[CV 7/10; 82/100] END class_weight={0: 0.008363636363636365, 1: 1};, score=(train=0.877, test=0.864) total time=   7.0s\n",
      "[CV 9/10; 87/100] START class_weight={0: 0.008818181818181819, 1: 1}............\n",
      "[CV 9/10; 87/100] END class_weight={0: 0.008818181818181819, 1: 1};, score=(train=0.880, test=0.850) total time=   9.9s\n",
      "[CV 5/10; 94/100] START class_weight={0: 0.009454545454545455, 1: 1}............\n",
      "[CV 5/10; 94/100] END class_weight={0: 0.009454545454545455, 1: 1};, score=(train=0.877, test=0.839) total time=  11.4s\n",
      "[CV 10/10; 1/100] START class_weight={0: 0.01, 1: 1}............................\n",
      "[CV 10/10; 1/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.876, test=0.867) total time=   8.7s\n",
      "[CV 5/10; 8/100] START class_weight={0: 0.010707070707070707, 1: 1}.............\n",
      "[CV 5/10; 8/100] END class_weight={0: 0.010707070707070707, 1: 1};, score=(train=0.877, test=0.839) total time=  11.6s\n",
      "[CV 7/10; 17/100] START class_weight={0: 0.011616161616161616, 1: 1}............\n",
      "[CV 7/10; 17/100] END class_weight={0: 0.011616161616161616, 1: 1};, score=(train=0.878, test=0.862) total time=   9.9s\n",
      "[CV 2/10; 24/100] START class_weight={0: 0.012323232323232323, 1: 1}............\n",
      "[CV 2/10; 24/100] END class_weight={0: 0.012323232323232323, 1: 1};, score=(train=0.877, test=0.849) total time=   9.7s\n",
      "[CV 8/10; 30/100] START class_weight={0: 0.01292929292929293, 1: 1}.............\n",
      "[CV 8/10; 30/100] END class_weight={0: 0.01292929292929293, 1: 1};, score=(train=0.878, test=0.882) total time=  10.5s\n",
      "[CV 2/10; 37/100] START class_weight={0: 0.013636363636363637, 1: 1}............\n",
      "[CV 2/10; 37/100] END class_weight={0: 0.013636363636363637, 1: 1};, score=(train=0.884, test=0.845) total time=  11.5s\n",
      "[CV 8/10; 44/100] START class_weight={0: 0.014343434343434344, 1: 1}............\n",
      "[CV 8/10; 44/100] END class_weight={0: 0.014343434343434344, 1: 1};, score=(train=0.880, test=0.884) total time=   9.0s\n",
      "[CV 10/10; 50/100] START class_weight={0: 0.014949494949494949, 1: 1}...........\n",
      "[CV 10/10; 50/100] END class_weight={0: 0.014949494949494949, 1: 1};, score=(train=0.878, test=0.861) total time=   8.6s\n",
      "[CV 4/10; 56/100] START class_weight={0: 0.015555555555555555, 1: 1}............\n",
      "[CV 4/10; 56/100] END class_weight={0: 0.015555555555555555, 1: 1};, score=(train=0.884, test=0.844) total time=  10.6s\n",
      "[CV 6/10; 63/100] START class_weight={0: 0.016262626262626263, 1: 1}............\n",
      "[CV 6/10; 63/100] END class_weight={0: 0.016262626262626263, 1: 1};, score=(train=0.881, test=0.826) total time=  11.8s\n",
      "[CV 3/10; 71/100] START class_weight={0: 0.01707070707070707, 1: 1}.............\n",
      "[CV 3/10; 71/100] END class_weight={0: 0.01707070707070707, 1: 1};, score=(train=0.876, test=0.838) total time=   9.0s\n",
      "[CV 6/10; 76/100] START class_weight={0: 0.017575757575757578, 1: 1}............\n",
      "[CV 6/10; 76/100] END class_weight={0: 0.017575757575757578, 1: 1};, score=(train=0.881, test=0.826) total time=   9.4s\n",
      "[CV 9/10; 82/100] START class_weight={0: 0.01818181818181818, 1: 1}.............\n",
      "[CV 9/10; 82/100] END class_weight={0: 0.01818181818181818, 1: 1};, score=(train=0.880, test=0.853) total time=  11.2s\n",
      "[CV 5/10; 90/100] START class_weight={0: 0.01898989898989899, 1: 1}.............\n",
      "[CV 5/10; 90/100] END class_weight={0: 0.01898989898989899, 1: 1};, score=(train=0.881, test=0.828) total time=   9.0s\n",
      "[CV 5/10; 96/100] START class_weight={0: 0.019595959595959597, 1: 1}............\n",
      "[CV 5/10; 96/100] END class_weight={0: 0.019595959595959597, 1: 1};, score=(train=0.881, test=0.828) total time=   9.8s\n",
      "[CV 6/10; 6/10] START class_weight={0: 0.0032222222222222222, 1: 1}.............\n",
      "[CV 6/10; 6/10] END class_weight={0: 0.0032222222222222222, 1: 1};, score=(train=0.878, test=0.836) total time=   7.1s\n",
      "[CV 2/10; 10/10] START class_weight={0: 0.005, 1: 1}............................\n",
      "[CV 2/10; 10/10] END class_weight={0: 0.005, 1: 1};, score=(train=0.879, test=0.830) total time=   6.0s\n",
      "[CV 1/10; 6/100] START class_weight={0: 0.0014545454545454547, 1: 1}............\n",
      "[CV 1/10; 6/100] END class_weight={0: 0.0014545454545454547, 1: 1};, score=(train=0.877, test=0.835) total time=   8.1s\n",
      "[CV 5/10; 11/100] START class_weight={0: 0.0019090909090909093, 1: 1}...........\n",
      "[CV 5/10; 11/100] END class_weight={0: 0.0019090909090909093, 1: 1};, score=(train=0.880, test=0.833) total time=   6.6s\n",
      "[CV 5/10; 15/100] START class_weight={0: 0.0022727272727272726, 1: 1}...........\n",
      "[CV 5/10; 15/100] END class_weight={0: 0.0022727272727272726, 1: 1};, score=(train=0.878, test=0.838) total time=   8.0s\n",
      "[CV 10/10; 21/100] START class_weight={0: 0.0028181818181818186, 1: 1}..........\n",
      "[CV 10/10; 21/100] END class_weight={0: 0.0028181818181818186, 1: 1};, score=(train=0.875, test=0.846) total time=   7.6s\n",
      "[CV 9/10; 27/100] START class_weight={0: 0.003363636363636364, 1: 1}............\n",
      "[CV 9/10; 27/100] END class_weight={0: 0.003363636363636364, 1: 1};, score=(train=0.882, test=0.831) total time=  10.5s\n",
      "[CV 1/10; 36/100] START class_weight={0: 0.004181818181818182, 1: 1}............\n",
      "[CV 1/10; 36/100] END class_weight={0: 0.004181818181818182, 1: 1};, score=(train=0.879, test=0.838) total time=   9.0s\n",
      "[CV 9/10; 42/100] START class_weight={0: 0.0047272727272727275, 1: 1}...........\n",
      "[CV 9/10; 42/100] END class_weight={0: 0.0047272727272727275, 1: 1};, score=(train=0.882, test=0.839) total time=   7.9s\n",
      "[CV 4/10; 49/100] START class_weight={0: 0.005363636363636364, 1: 1}............\n",
      "[CV 4/10; 49/100] END class_weight={0: 0.005363636363636364, 1: 1};, score=(train=0.879, test=0.847) total time=   8.1s\n",
      "[CV 3/10; 55/100] START class_weight={0: 0.00590909090909091, 1: 1}.............\n",
      "[CV 3/10; 55/100] END class_weight={0: 0.00590909090909091, 1: 1};, score=(train=0.881, test=0.843) total time=   7.9s\n",
      "[CV 7/10; 60/100] START class_weight={0: 0.006363636363636364, 1: 1}............\n",
      "[CV 7/10; 60/100] END class_weight={0: 0.006363636363636364, 1: 1};, score=(train=0.877, test=0.862) total time=   6.4s\n",
      "[CV 3/10; 65/100] START class_weight={0: 0.006818181818181819, 1: 1}............\n",
      "[CV 3/10; 65/100] END class_weight={0: 0.006818181818181819, 1: 1};, score=(train=0.881, test=0.843) total time=   6.7s\n",
      "[CV 4/10; 70/100] START class_weight={0: 0.007272727272727274, 1: 1}............\n",
      "[CV 4/10; 70/100] END class_weight={0: 0.007272727272727274, 1: 1};, score=(train=0.877, test=0.841) total time=   9.6s\n",
      "[CV 8/10; 76/100] START class_weight={0: 0.007818181818181818, 1: 1}............\n",
      "[CV 8/10; 76/100] END class_weight={0: 0.007818181818181818, 1: 1};, score=(train=0.874, test=0.866) total time=   9.7s\n",
      "[CV 7/10; 83/100] START class_weight={0: 0.008454545454545454, 1: 1}............\n",
      "[CV 7/10; 83/100] END class_weight={0: 0.008454545454545454, 1: 1};, score=(train=0.877, test=0.866) total time=  12.2s\n",
      "[CV 7/10; 92/100] START class_weight={0: 0.009272727272727273, 1: 1}............\n",
      "[CV 7/10; 92/100] END class_weight={0: 0.009272727272727273, 1: 1};, score=(train=0.880, test=0.872) total time=  11.5s\n",
      "[CV 9/10; 99/100] START class_weight={0: 0.009909090909090909, 1: 1}............\n",
      "[CV 9/10; 99/100] END class_weight={0: 0.009909090909090909, 1: 1};, score=(train=0.881, test=0.843) total time=   6.9s\n",
      "[CV 2/10; 6/100] START class_weight={0: 0.010505050505050505, 1: 1}.............\n",
      "[CV 2/10; 6/100] END class_weight={0: 0.010505050505050505, 1: 1};, score=(train=0.880, test=0.840) total time=  12.9s\n",
      "[CV 8/10; 13/100] START class_weight={0: 0.011212121212121211, 1: 1}............\n",
      "[CV 8/10; 13/100] END class_weight={0: 0.011212121212121211, 1: 1};, score=(train=0.878, test=0.860) total time=  12.2s\n",
      "[CV 4/10; 20/100] START class_weight={0: 0.01191919191919192, 1: 1}.............\n",
      "[CV 4/10; 20/100] END class_weight={0: 0.01191919191919192, 1: 1};, score=(train=0.876, test=0.836) total time=  11.9s\n",
      "[CV 4/10; 28/100] START class_weight={0: 0.012727272727272728, 1: 1}............\n",
      "[CV 4/10; 28/100] END class_weight={0: 0.012727272727272728, 1: 1};, score=(train=0.878, test=0.835) total time=  11.1s\n",
      "[CV 3/10; 35/100] START class_weight={0: 0.013434343434343434, 1: 1}............\n",
      "[CV 3/10; 35/100] END class_weight={0: 0.013434343434343434, 1: 1};, score=(train=0.876, test=0.838) total time=   8.1s\n",
      "[CV 9/10; 40/100] START class_weight={0: 0.013939393939393939, 1: 1}............\n",
      "[CV 9/10; 40/100] END class_weight={0: 0.013939393939393939, 1: 1};, score=(train=0.880, test=0.837) total time=   9.9s\n",
      "[CV 5/10; 47/100] START class_weight={0: 0.014646464646464647, 1: 1}............\n",
      "[CV 5/10; 47/100] END class_weight={0: 0.014646464646464647, 1: 1};, score=(train=0.880, test=0.829) total time=  10.2s\n",
      "[CV 10/10; 53/100] START class_weight={0: 0.015252525252525254, 1: 1}...........\n",
      "[CV 10/10; 53/100] END class_weight={0: 0.015252525252525254, 1: 1};, score=(train=0.881, test=0.867) total time=   8.7s\n",
      "[CV 6/10; 59/100] START class_weight={0: 0.015858585858585857, 1: 1}............\n",
      "[CV 6/10; 59/100] END class_weight={0: 0.015858585858585857, 1: 1};, score=(train=0.881, test=0.830) total time=   7.9s\n",
      "[CV 6/10; 65/100] START class_weight={0: 0.016464646464646467, 1: 1}............\n",
      "[CV 6/10; 65/100] END class_weight={0: 0.016464646464646467, 1: 1};, score=(train=0.881, test=0.830) total time=   9.3s\n",
      "[CV 7/10; 71/100] START class_weight={0: 0.01707070707070707, 1: 1}.............\n",
      "[CV 7/10; 71/100] END class_weight={0: 0.01707070707070707, 1: 1};, score=(train=0.878, test=0.862) total time=   8.7s\n",
      "[CV 2/10; 77/100] START class_weight={0: 0.017676767676767676, 1: 1}............\n",
      "[CV 2/10; 77/100] END class_weight={0: 0.017676767676767676, 1: 1};, score=(train=0.883, test=0.847) total time=   9.5s\n",
      "[CV 3/10; 83/100] START class_weight={0: 0.018282828282828283, 1: 1}............\n",
      "[CV 3/10; 83/100] END class_weight={0: 0.018282828282828283, 1: 1};, score=(train=0.876, test=0.838) total time=   9.3s\n",
      "[CV 10/10; 88/100] START class_weight={0: 0.018787878787878787, 1: 1}...........\n",
      "[CV 10/10; 88/100] END class_weight={0: 0.018787878787878787, 1: 1};, score=(train=0.879, test=0.869) total time=   9.4s\n",
      "[CV 7/10; 95/100] START class_weight={0: 0.019494949494949496, 1: 1}............\n",
      "[CV 7/10; 95/100] END class_weight={0: 0.019494949494949496, 1: 1};, score=(train=0.880, test=0.852) total time=  11.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 1/10] START class_weight={0: 0.001, 1: 1}.............................\n",
      "[CV 4/10; 1/10] END class_weight={0: 0.001, 1: 1};, score=(train=0.876, test=0.845) total time=  10.0s\n",
      "[CV 6/10; 2/100] START class_weight={0: 0.001090909090909091, 1: 1}.............\n",
      "[CV 6/10; 2/100] END class_weight={0: 0.001090909090909091, 1: 1};, score=(train=0.880, test=0.831) total time=   8.7s\n",
      "[CV 7/10; 11/100] START class_weight={0: 0.0019090909090909093, 1: 1}...........\n",
      "[CV 7/10; 11/100] END class_weight={0: 0.0019090909090909093, 1: 1};, score=(train=0.874, test=0.858) total time=   7.9s\n",
      "[CV 9/10; 17/100] START class_weight={0: 0.002454545454545455, 1: 1}............\n",
      "[CV 9/10; 17/100] END class_weight={0: 0.002454545454545455, 1: 1};, score=(train=0.879, test=0.836) total time=   9.4s\n",
      "[CV 1/10; 25/100] START class_weight={0: 0.003181818181818182, 1: 1}............\n",
      "[CV 1/10; 25/100] END class_weight={0: 0.003181818181818182, 1: 1};, score=(train=0.882, test=0.843) total time=   8.5s\n",
      "[CV 2/10; 31/100] START class_weight={0: 0.0037272727272727275, 1: 1}...........\n",
      "[CV 2/10; 31/100] END class_weight={0: 0.0037272727272727275, 1: 1};, score=(train=0.882, test=0.823) total time=  10.9s\n",
      "[CV 4/10; 39/100] START class_weight={0: 0.004454545454545455, 1: 1}............\n",
      "[CV 4/10; 39/100] END class_weight={0: 0.004454545454545455, 1: 1};, score=(train=0.878, test=0.853) total time=   7.1s\n",
      "[CV 3/10; 44/100] START class_weight={0: 0.00490909090909091, 1: 1}.............\n",
      "[CV 3/10; 44/100] END class_weight={0: 0.00490909090909091, 1: 1};, score=(train=0.881, test=0.838) total time=   7.5s\n",
      "[CV 6/10; 49/100] START class_weight={0: 0.005363636363636364, 1: 1}............\n",
      "[CV 6/10; 49/100] END class_weight={0: 0.005363636363636364, 1: 1};, score=(train=0.879, test=0.838) total time=   7.1s\n",
      "[CV 2/10; 55/100] START class_weight={0: 0.00590909090909091, 1: 1}.............\n",
      "[CV 2/10; 55/100] END class_weight={0: 0.00590909090909091, 1: 1};, score=(train=0.881, test=0.825) total time=   9.7s\n",
      "[CV 3/10; 62/100] START class_weight={0: 0.006545454545454546, 1: 1}............\n",
      "[CV 3/10; 62/100] END class_weight={0: 0.006545454545454546, 1: 1};, score=(train=0.881, test=0.843) total time=   8.1s\n",
      "[CV 2/10; 68/100] START class_weight={0: 0.007090909090909091, 1: 1}............\n",
      "[CV 2/10; 68/100] END class_weight={0: 0.007090909090909091, 1: 1};, score=(train=0.879, test=0.857) total time=   9.0s\n",
      "[CV 5/10; 74/100] START class_weight={0: 0.007636363636363637, 1: 1}............\n",
      "[CV 5/10; 74/100] END class_weight={0: 0.007636363636363637, 1: 1};, score=(train=0.880, test=0.831) total time=   8.1s\n",
      "[CV 3/10; 80/100] START class_weight={0: 0.008181818181818182, 1: 1}............\n",
      "[CV 3/10; 80/100] END class_weight={0: 0.008181818181818182, 1: 1};, score=(train=0.881, test=0.843) total time=   8.3s\n",
      "[CV 10/10; 85/100] START class_weight={0: 0.008636363636363636, 1: 1}...........\n",
      "[CV 10/10; 85/100] END class_weight={0: 0.008636363636363636, 1: 1};, score=(train=0.877, test=0.850) total time=  10.7s\n",
      "[CV 6/10; 93/100] START class_weight={0: 0.009363636363636366, 1: 1}............\n",
      "[CV 6/10; 93/100] END class_weight={0: 0.009363636363636366, 1: 1};, score=(train=0.879, test=0.839) total time=  10.7s\n",
      "[CV 4/10; 100/100] START class_weight={0: 0.01, 1: 1}...........................\n",
      "[CV 4/10; 100/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.876, test=0.840) total time=   6.6s\n",
      "[CV 7/10; 6/100] START class_weight={0: 0.010505050505050505, 1: 1}.............\n",
      "[CV 7/10; 6/100] END class_weight={0: 0.010505050505050505, 1: 1};, score=(train=0.880, test=0.869) total time=   9.8s\n",
      "[CV 2/10; 12/100] START class_weight={0: 0.011111111111111112, 1: 1}............\n",
      "[CV 2/10; 12/100] END class_weight={0: 0.011111111111111112, 1: 1};, score=(train=0.877, test=0.849) total time=   9.3s\n",
      "[CV 5/10; 17/100] START class_weight={0: 0.011616161616161616, 1: 1}............\n",
      "[CV 5/10; 17/100] END class_weight={0: 0.011616161616161616, 1: 1};, score=(train=0.878, test=0.841) total time=   9.6s\n",
      "[CV 7/10; 23/100] START class_weight={0: 0.012222222222222223, 1: 1}............\n",
      "[CV 7/10; 23/100] END class_weight={0: 0.012222222222222223, 1: 1};, score=(train=0.878, test=0.862) total time=   9.7s\n",
      "[CV 4/10; 30/100] START class_weight={0: 0.01292929292929293, 1: 1}.............\n",
      "[CV 4/10; 30/100] END class_weight={0: 0.01292929292929293, 1: 1};, score=(train=0.882, test=0.843) total time=  11.5s\n",
      "[CV 9/10; 37/100] START class_weight={0: 0.013636363636363637, 1: 1}............\n",
      "[CV 9/10; 37/100] END class_weight={0: 0.013636363636363637, 1: 1};, score=(train=0.880, test=0.837) total time=   9.2s\n",
      "[CV 2/10; 44/100] START class_weight={0: 0.014343434343434344, 1: 1}............\n",
      "[CV 2/10; 44/100] END class_weight={0: 0.014343434343434344, 1: 1};, score=(train=0.884, test=0.842) total time=  12.2s\n",
      "[CV 7/10; 51/100] START class_weight={0: 0.01505050505050505, 1: 1}.............\n",
      "[CV 7/10; 51/100] END class_weight={0: 0.01505050505050505, 1: 1};, score=(train=0.878, test=0.862) total time=  11.1s\n",
      "[CV 8/10; 58/100] START class_weight={0: 0.01575757575757576, 1: 1}.............\n",
      "[CV 8/10; 58/100] END class_weight={0: 0.01575757575757576, 1: 1};, score=(train=0.880, test=0.883) total time=  10.1s\n",
      "[CV 3/10; 65/100] START class_weight={0: 0.016464646464646467, 1: 1}............\n",
      "[CV 3/10; 65/100] END class_weight={0: 0.016464646464646467, 1: 1};, score=(train=0.876, test=0.838) total time=   8.0s\n",
      "[CV 6/10; 70/100] START class_weight={0: 0.016969696969696968, 1: 1}............\n",
      "[CV 6/10; 70/100] END class_weight={0: 0.016969696969696968, 1: 1};, score=(train=0.881, test=0.826) total time=  10.6s\n",
      "[CV 4/10; 77/100] START class_weight={0: 0.017676767676767676, 1: 1}............\n",
      "[CV 4/10; 77/100] END class_weight={0: 0.017676767676767676, 1: 1};, score=(train=0.881, test=0.842) total time=   9.9s\n",
      "[CV 9/10; 83/100] START class_weight={0: 0.018282828282828283, 1: 1}............\n",
      "[CV 9/10; 83/100] END class_weight={0: 0.018282828282828283, 1: 1};, score=(train=0.883, test=0.845) total time=  11.6s\n",
      "[CV 4/10; 91/100] START class_weight={0: 0.01909090909090909, 1: 1}.............\n",
      "[CV 4/10; 91/100] END class_weight={0: 0.01909090909090909, 1: 1};, score=(train=0.881, test=0.842) total time=   9.6s\n",
      "[CV 6/10; 97/100] START class_weight={0: 0.0196969696969697, 1: 1}..............\n",
      "[CV 6/10; 97/100] END class_weight={0: 0.0196969696969697, 1: 1};, score=(train=0.881, test=0.832) total time=   8.2s\n",
      "[CV 9/10; 4/10] START class_weight={0: 0.0023333333333333335, 1: 1}.............\n",
      "[CV 9/10; 4/10] END class_weight={0: 0.0023333333333333335, 1: 1};, score=(train=0.881, test=0.850) total time=   9.7s\n",
      "[CV 10/10; 2/100] START class_weight={0: 0.001090909090909091, 1: 1}............\n",
      "[CV 10/10; 2/100] END class_weight={0: 0.001090909090909091, 1: 1};, score=(train=0.879, test=0.852) total time=   8.8s\n",
      "[CV 2/10; 12/100] START class_weight={0: 0.002, 1: 1}...........................\n",
      "[CV 2/10; 12/100] END class_weight={0: 0.002, 1: 1};, score=(train=0.882, test=0.841) total time=   8.3s\n",
      "[CV 3/10; 18/100] START class_weight={0: 0.0025454545454545456, 1: 1}...........\n",
      "[CV 3/10; 18/100] END class_weight={0: 0.0025454545454545456, 1: 1};, score=(train=0.878, test=0.839) total time=   6.9s\n",
      "[CV 5/10; 22/100] START class_weight={0: 0.0029090909090909093, 1: 1}...........\n",
      "[CV 5/10; 22/100] END class_weight={0: 0.0029090909090909093, 1: 1};, score=(train=0.878, test=0.830) total time=   6.9s\n",
      "[CV 8/10; 27/100] START class_weight={0: 0.003363636363636364, 1: 1}............\n",
      "[CV 8/10; 27/100] END class_weight={0: 0.003363636363636364, 1: 1};, score=(train=0.878, test=0.871) total time=   9.7s\n",
      "[CV 2/10; 35/100] START class_weight={0: 0.004090909090909091, 1: 1}............\n",
      "[CV 2/10; 35/100] END class_weight={0: 0.004090909090909091, 1: 1};, score=(train=0.879, test=0.835) total time=   8.9s\n",
      "[CV 1/10; 42/100] START class_weight={0: 0.0047272727272727275, 1: 1}...........\n",
      "[CV 1/10; 42/100] END class_weight={0: 0.0047272727272727275, 1: 1};, score=(train=0.881, test=0.840) total time=   8.3s\n",
      "[CV 6/10; 48/100] START class_weight={0: 0.0052727272727272735, 1: 1}...........\n",
      "[CV 6/10; 48/100] END class_weight={0: 0.0052727272727272735, 1: 1};, score=(train=0.879, test=0.836) total time=   7.0s\n",
      "[CV 7/10; 53/100] START class_weight={0: 0.0057272727272727275, 1: 1}...........\n",
      "[CV 7/10; 53/100] END class_weight={0: 0.0057272727272727275, 1: 1};, score=(train=0.878, test=0.865) total time=   8.2s\n",
      "[CV 7/10; 59/100] START class_weight={0: 0.006272727272727274, 1: 1}............\n",
      "[CV 7/10; 59/100] END class_weight={0: 0.006272727272727274, 1: 1};, score=(train=0.876, test=0.867) total time=   7.7s\n",
      "[CV 4/10; 65/100] START class_weight={0: 0.006818181818181819, 1: 1}............\n",
      "[CV 4/10; 65/100] END class_weight={0: 0.006818181818181819, 1: 1};, score=(train=0.879, test=0.836) total time=   9.5s\n",
      "[CV 10/10; 71/100] START class_weight={0: 0.007363636363636364, 1: 1}...........\n",
      "[CV 10/10; 71/100] END class_weight={0: 0.007363636363636364, 1: 1};, score=(train=0.876, test=0.849) total time=  11.1s\n",
      "[CV 9/10; 79/100] START class_weight={0: 0.008090909090909091, 1: 1}............\n",
      "[CV 9/10; 79/100] END class_weight={0: 0.008090909090909091, 1: 1};, score=(train=0.881, test=0.842) total time=   8.7s\n",
      "[CV 8/10; 85/100] START class_weight={0: 0.008636363636363636, 1: 1}............\n",
      "[CV 8/10; 85/100] END class_weight={0: 0.008636363636363636, 1: 1};, score=(train=0.877, test=0.858) total time=   9.5s\n",
      "[CV 6/10; 92/100] START class_weight={0: 0.009272727272727273, 1: 1}............\n",
      "[CV 6/10; 92/100] END class_weight={0: 0.009272727272727273, 1: 1};, score=(train=0.879, test=0.839) total time=   9.0s\n",
      "[CV 8/10; 98/100] START class_weight={0: 0.00981818181818182, 1: 1}.............\n",
      "[CV 8/10; 98/100] END class_weight={0: 0.00981818181818182, 1: 1};, score=(train=0.876, test=0.873) total time=   8.3s\n",
      "[CV 3/10; 5/100] START class_weight={0: 0.010404040404040405, 1: 1}.............\n",
      "[CV 3/10; 5/100] END class_weight={0: 0.010404040404040405, 1: 1};, score=(train=0.879, test=0.828) total time=   9.5s\n",
      "[CV 8/10; 10/100] START class_weight={0: 0.01090909090909091, 1: 1}.............\n",
      "[CV 8/10; 10/100] END class_weight={0: 0.01090909090909091, 1: 1};, score=(train=0.878, test=0.860) total time=   8.9s\n",
      "[CV 10/10; 15/100] START class_weight={0: 0.011414141414141415, 1: 1}...........\n",
      "[CV 10/10; 15/100] END class_weight={0: 0.011414141414141415, 1: 1};, score=(train=0.878, test=0.865) total time=  11.2s\n",
      "[CV 3/10; 24/100] START class_weight={0: 0.012323232323232323, 1: 1}............\n",
      "[CV 3/10; 24/100] END class_weight={0: 0.012323232323232323, 1: 1};, score=(train=0.879, test=0.830) total time=   9.3s\n",
      "[CV 3/10; 30/100] START class_weight={0: 0.01292929292929293, 1: 1}.............\n",
      "[CV 3/10; 30/100] END class_weight={0: 0.01292929292929293, 1: 1};, score=(train=0.879, test=0.830) total time=   8.3s\n",
      "[CV 5/10; 35/100] START class_weight={0: 0.013434343434343434, 1: 1}............\n",
      "[CV 5/10; 35/100] END class_weight={0: 0.013434343434343434, 1: 1};, score=(train=0.882, test=0.837) total time=   9.1s\n",
      "[CV 6/10; 41/100] START class_weight={0: 0.01404040404040404, 1: 1}.............\n",
      "[CV 6/10; 41/100] END class_weight={0: 0.01404040404040404, 1: 1};, score=(train=0.881, test=0.830) total time=   9.2s\n",
      "[CV 4/10; 47/100] START class_weight={0: 0.014646464646464647, 1: 1}............\n",
      "[CV 4/10; 47/100] END class_weight={0: 0.014646464646464647, 1: 1};, score=(train=0.881, test=0.841) total time=   8.8s\n",
      "[CV 2/10; 53/100] START class_weight={0: 0.015252525252525254, 1: 1}............\n",
      "[CV 2/10; 53/100] END class_weight={0: 0.015252525252525254, 1: 1};, score=(train=0.883, test=0.847) total time=  10.2s\n",
      "[CV 5/10; 59/100] START class_weight={0: 0.015858585858585857, 1: 1}............\n",
      "[CV 5/10; 59/100] END class_weight={0: 0.015858585858585857, 1: 1};, score=(train=0.882, test=0.833) total time=   9.5s\n",
      "[CV 9/10; 65/100] START class_weight={0: 0.016464646464646467, 1: 1}............\n",
      "[CV 9/10; 65/100] END class_weight={0: 0.016464646464646467, 1: 1};, score=(train=0.881, test=0.854) total time=   9.1s\n",
      "[CV 3/10; 72/100] START class_weight={0: 0.01717171717171717, 1: 1}.............\n",
      "[CV 3/10; 72/100] END class_weight={0: 0.01717171717171717, 1: 1};, score=(train=0.879, test=0.830) total time=  10.3s\n",
      "[CV 6/10; 78/100] START class_weight={0: 0.017777777777777778, 1: 1}............\n",
      "[CV 6/10; 78/100] END class_weight={0: 0.017777777777777778, 1: 1};, score=(train=0.881, test=0.826) total time=   9.5s\n",
      "[CV 2/10; 85/100] START class_weight={0: 0.018484848484848486, 1: 1}............\n",
      "[CV 2/10; 85/100] END class_weight={0: 0.018484848484848486, 1: 1};, score=(train=0.885, test=0.846) total time=  10.5s\n",
      "[CV 5/10; 91/100] START class_weight={0: 0.01909090909090909, 1: 1}.............\n",
      "[CV 5/10; 91/100] END class_weight={0: 0.01909090909090909, 1: 1};, score=(train=0.881, test=0.831) total time=   8.7s\n",
      "[CV 5/10; 97/100] START class_weight={0: 0.0196969696969697, 1: 1}..............\n",
      "[CV 5/10; 97/100] END class_weight={0: 0.0196969696969697, 1: 1};, score=(train=0.881, test=0.831) total time=   8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10; 1/10] START class_weight={0: 0.001, 1: 1}.............................\n",
      "[CV 2/10; 1/10] END class_weight={0: 0.001, 1: 1};, score=(train=0.880, test=0.838) total time=   7.4s\n",
      "[CV 1/10; 9/10] START class_weight={0: 0.004555555555555556, 1: 1}..............\n",
      "[CV 1/10; 9/10] END class_weight={0: 0.004555555555555556, 1: 1};, score=(train=0.881, test=0.832) total time=   6.0s\n",
      "[CV 9/10; 4/100] START class_weight={0: 0.0012727272727272728, 1: 1}............\n",
      "[CV 9/10; 4/100] END class_weight={0: 0.0012727272727272728, 1: 1};, score=(train=0.879, test=0.843) total time=   6.5s\n",
      "[CV 9/10; 7/100] START class_weight={0: 0.0015454545454545456, 1: 1}............\n",
      "[CV 9/10; 7/100] END class_weight={0: 0.0015454545454545456, 1: 1};, score=(train=0.878, test=0.830) total time=   5.9s\n",
      "[CV 9/10; 13/100] START class_weight={0: 0.002090909090909091, 1: 1}............\n",
      "[CV 9/10; 13/100] END class_weight={0: 0.002090909090909091, 1: 1};, score=(train=0.881, test=0.850) total time=   7.6s\n",
      "[CV 7/10; 20/100] START class_weight={0: 0.0027272727272727275, 1: 1}...........\n",
      "[CV 7/10; 20/100] END class_weight={0: 0.0027272727272727275, 1: 1};, score=(train=0.875, test=0.866) total time=  10.6s\n",
      "[CV 2/10; 28/100] START class_weight={0: 0.003454545454545455, 1: 1}............\n",
      "[CV 2/10; 28/100] END class_weight={0: 0.003454545454545455, 1: 1};, score=(train=0.880, test=0.846) total time=  11.0s\n",
      "[CV 5/10; 36/100] START class_weight={0: 0.004181818181818182, 1: 1}............\n",
      "[CV 5/10; 36/100] END class_weight={0: 0.004181818181818182, 1: 1};, score=(train=0.880, test=0.836) total time=   8.2s\n",
      "[CV 5/10; 42/100] START class_weight={0: 0.0047272727272727275, 1: 1}...........\n",
      "[CV 5/10; 42/100] END class_weight={0: 0.0047272727272727275, 1: 1};, score=(train=0.881, test=0.839) total time=   6.9s\n",
      "[CV 1/10; 48/100] START class_weight={0: 0.0052727272727272735, 1: 1}...........\n",
      "[CV 1/10; 48/100] END class_weight={0: 0.0052727272727272735, 1: 1};, score=(train=0.879, test=0.847) total time=   7.3s\n",
      "[CV 3/10; 53/100] START class_weight={0: 0.0057272727272727275, 1: 1}...........\n",
      "[CV 3/10; 53/100] END class_weight={0: 0.0057272727272727275, 1: 1};, score=(train=0.880, test=0.846) total time=   6.6s\n",
      "[CV 2/10; 58/100] START class_weight={0: 0.006181818181818182, 1: 1}............\n",
      "[CV 2/10; 58/100] END class_weight={0: 0.006181818181818182, 1: 1};, score=(train=0.882, test=0.830) total time=   6.5s\n",
      "[CV 8/10; 62/100] START class_weight={0: 0.006545454545454546, 1: 1}............\n",
      "[CV 8/10; 62/100] END class_weight={0: 0.006545454545454546, 1: 1};, score=(train=0.877, test=0.863) total time=   6.5s\n",
      "[CV 3/10; 67/100] START class_weight={0: 0.007, 1: 1}...........................\n",
      "[CV 3/10; 67/100] END class_weight={0: 0.007, 1: 1};, score=(train=0.881, test=0.843) total time=   7.7s\n",
      "[CV 3/10; 73/100] START class_weight={0: 0.007545454545454546, 1: 1}............\n",
      "[CV 3/10; 73/100] END class_weight={0: 0.007545454545454546, 1: 1};, score=(train=0.880, test=0.844) total time=   9.5s\n",
      "[CV 8/10; 79/100] START class_weight={0: 0.008090909090909091, 1: 1}............\n",
      "[CV 8/10; 79/100] END class_weight={0: 0.008090909090909091, 1: 1};, score=(train=0.874, test=0.869) total time=   7.3s\n",
      "[CV 10/10; 84/100] START class_weight={0: 0.008545454545454547, 1: 1}...........\n",
      "[CV 10/10; 84/100] END class_weight={0: 0.008545454545454547, 1: 1};, score=(train=0.876, test=0.849) total time=   9.1s\n",
      "[CV 8/10; 90/100] START class_weight={0: 0.00909090909090909, 1: 1}.............\n",
      "[CV 8/10; 90/100] END class_weight={0: 0.00909090909090909, 1: 1};, score=(train=0.877, test=0.856) total time=   8.3s\n",
      "[CV 10/10; 96/100] START class_weight={0: 0.009636363636363637, 1: 1}...........\n",
      "[CV 10/10; 96/100] END class_weight={0: 0.009636363636363637, 1: 1};, score=(train=0.882, test=0.869) total time=   9.3s\n",
      "[CV 3/10; 3/100] START class_weight={0: 0.010202020202020202, 1: 1}.............\n",
      "[CV 3/10; 3/100] END class_weight={0: 0.010202020202020202, 1: 1};, score=(train=0.879, test=0.827) total time=  10.1s\n",
      "[CV 7/10; 11/100] START class_weight={0: 0.01101010101010101, 1: 1}.............\n",
      "[CV 7/10; 11/100] END class_weight={0: 0.01101010101010101, 1: 1};, score=(train=0.878, test=0.862) total time=   8.1s\n",
      "[CV 9/10; 15/100] START class_weight={0: 0.011414141414141415, 1: 1}............\n",
      "[CV 9/10; 15/100] END class_weight={0: 0.011414141414141415, 1: 1};, score=(train=0.880, test=0.850) total time=   7.4s\n",
      "[CV 9/10; 20/100] START class_weight={0: 0.01191919191919192, 1: 1}.............\n",
      "[CV 9/10; 20/100] END class_weight={0: 0.01191919191919192, 1: 1};, score=(train=0.879, test=0.837) total time=  10.8s\n",
      "[CV 2/10; 28/100] START class_weight={0: 0.012727272727272728, 1: 1}............\n",
      "[CV 2/10; 28/100] END class_weight={0: 0.012727272727272728, 1: 1};, score=(train=0.878, test=0.850) total time=   8.0s\n",
      "[CV 4/10; 33/100] START class_weight={0: 0.013232323232323233, 1: 1}............\n",
      "[CV 4/10; 33/100] END class_weight={0: 0.013232323232323233, 1: 1};, score=(train=0.881, test=0.846) total time=  11.7s\n",
      "[CV 1/10; 41/100] START class_weight={0: 0.01404040404040404, 1: 1}.............\n",
      "[CV 1/10; 41/100] END class_weight={0: 0.01404040404040404, 1: 1};, score=(train=0.878, test=0.859) total time=  10.0s\n",
      "[CV 7/10; 47/100] START class_weight={0: 0.014646464646464647, 1: 1}............\n",
      "[CV 7/10; 47/100] END class_weight={0: 0.014646464646464647, 1: 1};, score=(train=0.878, test=0.862) total time=  10.1s\n",
      "[CV 9/10; 53/100] START class_weight={0: 0.015252525252525254, 1: 1}............\n",
      "[CV 9/10; 53/100] END class_weight={0: 0.015252525252525254, 1: 1};, score=(train=0.880, test=0.837) total time=  10.0s\n",
      "[CV 1/10; 61/100] START class_weight={0: 0.01606060606060606, 1: 1}.............\n",
      "[CV 1/10; 61/100] END class_weight={0: 0.01606060606060606, 1: 1};, score=(train=0.878, test=0.851) total time=  12.5s\n",
      "[CV 2/10; 69/100] START class_weight={0: 0.01686868686868687, 1: 1}.............\n",
      "[CV 2/10; 69/100] END class_weight={0: 0.01686868686868687, 1: 1};, score=(train=0.884, test=0.843) total time=  12.0s\n",
      "[CV 7/10; 76/100] START class_weight={0: 0.017575757575757578, 1: 1}............\n",
      "[CV 7/10; 76/100] END class_weight={0: 0.017575757575757578, 1: 1};, score=(train=0.881, test=0.853) total time=  11.3s\n",
      "[CV 2/10; 84/100] START class_weight={0: 0.018383838383838384, 1: 1}............\n",
      "[CV 2/10; 84/100] END class_weight={0: 0.018383838383838384, 1: 1};, score=(train=0.885, test=0.846) total time=   9.9s\n",
      "[CV 8/10; 90/100] START class_weight={0: 0.01898989898989899, 1: 1}.............\n",
      "[CV 8/10; 90/100] END class_weight={0: 0.01898989898989899, 1: 1};, score=(train=0.878, test=0.884) total time=  10.1s\n",
      "[CV 1/10; 97/100] START class_weight={0: 0.0196969696969697, 1: 1}..............\n",
      "[CV 1/10; 97/100] END class_weight={0: 0.0196969696969697, 1: 1};, score=(train=0.880, test=0.859) total time=   9.3s\n",
      "[CV 1/10; 5/10] START class_weight={0: 0.002777777777777778, 1: 1}..............\n",
      "[CV 1/10; 5/10] END class_weight={0: 0.002777777777777778, 1: 1};, score=(train=0.882, test=0.833) total time=  10.1s\n",
      "[CV 6/10; 3/100] START class_weight={0: 0.0011818181818181819, 1: 1}............\n",
      "[CV 6/10; 3/100] END class_weight={0: 0.0011818181818181819, 1: 1};, score=(train=0.884, test=0.825) total time=  10.4s\n",
      "[CV 6/10; 13/100] START class_weight={0: 0.002090909090909091, 1: 1}............\n",
      "[CV 6/10; 13/100] END class_weight={0: 0.002090909090909091, 1: 1};, score=(train=0.877, test=0.836) total time=   8.1s\n",
      "[CV 6/10; 19/100] START class_weight={0: 0.0026363636363636363, 1: 1}...........\n",
      "[CV 6/10; 19/100] END class_weight={0: 0.0026363636363636363, 1: 1};, score=(train=0.879, test=0.831) total time=   7.4s\n",
      "[CV 9/10; 24/100] START class_weight={0: 0.003090909090909091, 1: 1}............\n",
      "[CV 9/10; 24/100] END class_weight={0: 0.003090909090909091, 1: 1};, score=(train=0.881, test=0.854) total time=  10.4s\n",
      "[CV 8/10; 32/100] START class_weight={0: 0.0038181818181818187, 1: 1}...........\n",
      "[CV 8/10; 32/100] END class_weight={0: 0.0038181818181818187, 1: 1};, score=(train=0.878, test=0.869) total time=   9.2s\n",
      "[CV 9/10; 39/100] START class_weight={0: 0.004454545454545455, 1: 1}............\n",
      "[CV 9/10; 39/100] END class_weight={0: 0.004454545454545455, 1: 1};, score=(train=0.882, test=0.845) total time=   9.1s\n",
      "[CV 2/10; 46/100] START class_weight={0: 0.005090909090909091, 1: 1}............\n",
      "[CV 2/10; 46/100] END class_weight={0: 0.005090909090909091, 1: 1};, score=(train=0.879, test=0.830) total time=   7.9s\n",
      "[CV 1/10; 52/100] START class_weight={0: 0.005636363636363636, 1: 1}............\n",
      "[CV 1/10; 52/100] END class_weight={0: 0.005636363636363636, 1: 1};, score=(train=0.879, test=0.847) total time=   7.9s\n",
      "[CV 7/10; 57/100] START class_weight={0: 0.006090909090909091, 1: 1}............\n",
      "[CV 7/10; 57/100] END class_weight={0: 0.006090909090909091, 1: 1};, score=(train=0.877, test=0.864) total time=   6.9s\n",
      "[CV 9/10; 62/100] START class_weight={0: 0.006545454545454546, 1: 1}............\n",
      "[CV 9/10; 62/100] END class_weight={0: 0.006545454545454546, 1: 1};, score=(train=0.882, test=0.843) total time=   9.9s\n",
      "[CV 3/10; 70/100] START class_weight={0: 0.007272727272727274, 1: 1}............\n",
      "[CV 3/10; 70/100] END class_weight={0: 0.007272727272727274, 1: 1};, score=(train=0.881, test=0.843) total time=   8.4s\n",
      "[CV 9/10; 75/100] START class_weight={0: 0.007727272727272728, 1: 1}............\n",
      "[CV 9/10; 75/100] END class_weight={0: 0.007727272727272728, 1: 1};, score=(train=0.882, test=0.844) total time=   9.5s\n",
      "[CV 9/10; 82/100] START class_weight={0: 0.008363636363636365, 1: 1}............\n",
      "[CV 9/10; 82/100] END class_weight={0: 0.008363636363636365, 1: 1};, score=(train=0.881, test=0.843) total time=   9.8s\n",
      "[CV 4/10; 89/100] START class_weight={0: 0.009000000000000001, 1: 1}............\n",
      "[CV 4/10; 89/100] END class_weight={0: 0.009000000000000001, 1: 1};, score=(train=0.879, test=0.833) total time=   9.9s\n",
      "[CV 1/10; 96/100] START class_weight={0: 0.009636363636363637, 1: 1}............\n",
      "[CV 1/10; 96/100] END class_weight={0: 0.009636363636363637, 1: 1};, score=(train=0.878, test=0.848) total time=  10.3s\n",
      "[CV 5/10; 3/100] START class_weight={0: 0.010202020202020202, 1: 1}.............\n",
      "[CV 5/10; 3/100] END class_weight={0: 0.010202020202020202, 1: 1};, score=(train=0.877, test=0.839) total time=   8.8s\n",
      "[CV 8/10; 8/100] START class_weight={0: 0.010707070707070707, 1: 1}.............\n",
      "[CV 8/10; 8/100] END class_weight={0: 0.010707070707070707, 1: 1};, score=(train=0.878, test=0.868) total time=   9.7s\n",
      "[CV 7/10; 15/100] START class_weight={0: 0.011414141414141415, 1: 1}............\n",
      "[CV 7/10; 15/100] END class_weight={0: 0.011414141414141415, 1: 1};, score=(train=0.878, test=0.862) total time=   9.6s\n",
      "[CV 5/10; 22/100] START class_weight={0: 0.012121212121212121, 1: 1}............\n",
      "[CV 5/10; 22/100] END class_weight={0: 0.012121212121212121, 1: 1};, score=(train=0.876, test=0.841) total time=  11.5s\n",
      "[CV 5/10; 30/100] START class_weight={0: 0.01292929292929293, 1: 1}.............\n",
      "[CV 5/10; 30/100] END class_weight={0: 0.01292929292929293, 1: 1};, score=(train=0.880, test=0.834) total time=   9.6s\n",
      "[CV 5/10; 36/100] START class_weight={0: 0.013535353535353536, 1: 1}............\n",
      "[CV 5/10; 36/100] END class_weight={0: 0.013535353535353536, 1: 1};, score=(train=0.882, test=0.839) total time=   9.4s\n",
      "[CV 5/10; 42/100] START class_weight={0: 0.014141414141414142, 1: 1}............\n",
      "[CV 5/10; 42/100] END class_weight={0: 0.014141414141414142, 1: 1};, score=(train=0.882, test=0.839) total time=  11.9s\n",
      "[CV 3/10; 50/100] START class_weight={0: 0.014949494949494949, 1: 1}............\n",
      "[CV 3/10; 50/100] END class_weight={0: 0.014949494949494949, 1: 1};, score=(train=0.876, test=0.838) total time=   7.8s\n",
      "[CV 4/10; 55/100] START class_weight={0: 0.015454545454545455, 1: 1}............\n",
      "[CV 4/10; 55/100] END class_weight={0: 0.015454545454545455, 1: 1};, score=(train=0.882, test=0.837) total time=  12.3s\n",
      "[CV 4/10; 63/100] START class_weight={0: 0.016262626262626263, 1: 1}............\n",
      "[CV 4/10; 63/100] END class_weight={0: 0.016262626262626263, 1: 1};, score=(train=0.884, test=0.844) total time=  10.5s\n",
      "[CV 5/10; 70/100] START class_weight={0: 0.016969696969696968, 1: 1}............\n",
      "[CV 5/10; 70/100] END class_weight={0: 0.016969696969696968, 1: 1};, score=(train=0.880, test=0.824) total time=   9.5s\n",
      "[CV 5/10; 76/100] START class_weight={0: 0.017575757575757578, 1: 1}............\n",
      "[CV 5/10; 76/100] END class_weight={0: 0.017575757575757578, 1: 1};, score=(train=0.881, test=0.826) total time=   7.9s\n",
      "[CV 8/10; 81/100] START class_weight={0: 0.01808080808080808, 1: 1}.............\n",
      "[CV 8/10; 81/100] END class_weight={0: 0.01808080808080808, 1: 1};, score=(train=0.880, test=0.873) total time=   9.7s\n",
      "[CV 7/10; 88/100] START class_weight={0: 0.018787878787878787, 1: 1}............\n",
      "[CV 7/10; 88/100] END class_weight={0: 0.018787878787878787, 1: 1};, score=(train=0.878, test=0.851) total time=  11.2s\n",
      "[CV 1/10; 96/100] START class_weight={0: 0.019595959595959597, 1: 1}............\n",
      "[CV 1/10; 96/100] END class_weight={0: 0.019595959595959597, 1: 1};, score=(train=0.880, test=0.857) total time=  11.8s\n",
      "[CV 3/10; 4/10] START class_weight={0: 0.0023333333333333335, 1: 1}.............\n",
      "[CV 3/10; 4/10] END class_weight={0: 0.0023333333333333335, 1: 1};, score=(train=0.880, test=0.836) total time=   9.9s\n",
      "[CV 2/10; 3/100] START class_weight={0: 0.0011818181818181819, 1: 1}............\n",
      "[CV 2/10; 3/100] END class_weight={0: 0.0011818181818181819, 1: 1};, score=(train=0.880, test=0.834) total time=   7.2s\n",
      "[CV 2/10; 9/100] START class_weight={0: 0.0017272727272727275, 1: 1}............\n",
      "[CV 2/10; 9/100] END class_weight={0: 0.0017272727272727275, 1: 1};, score=(train=0.881, test=0.841) total time=   8.1s\n",
      "[CV 6/10; 16/100] START class_weight={0: 0.0023636363636363638, 1: 1}...........\n",
      "[CV 6/10; 16/100] END class_weight={0: 0.0023636363636363638, 1: 1};, score=(train=0.880, test=0.832) total time=  11.0s\n",
      "[CV 5/10; 25/100] START class_weight={0: 0.003181818181818182, 1: 1}............\n",
      "[CV 5/10; 25/100] END class_weight={0: 0.003181818181818182, 1: 1};, score=(train=0.880, test=0.837) total time=   8.6s\n",
      "[CV 8/10; 31/100] START class_weight={0: 0.0037272727272727275, 1: 1}...........\n",
      "[CV 8/10; 31/100] END class_weight={0: 0.0037272727272727275, 1: 1};, score=(train=0.877, test=0.864) total time=   9.4s\n",
      "[CV 7/10; 38/100] START class_weight={0: 0.004363636363636364, 1: 1}............\n",
      "[CV 7/10; 38/100] END class_weight={0: 0.004363636363636364, 1: 1};, score=(train=0.876, test=0.861) total time=   7.3s\n",
      "[CV 8/10; 43/100] START class_weight={0: 0.004818181818181819, 1: 1}............\n",
      "[CV 8/10; 43/100] END class_weight={0: 0.004818181818181819, 1: 1};, score=(train=0.877, test=0.864) total time=   8.2s\n",
      "[CV 8/10; 49/100] START class_weight={0: 0.005363636363636364, 1: 1}............\n",
      "[CV 8/10; 49/100] END class_weight={0: 0.005363636363636364, 1: 1};, score=(train=0.877, test=0.862) total time=  10.2s\n",
      "[CV 6/10; 57/100] START class_weight={0: 0.006090909090909091, 1: 1}............\n",
      "[CV 6/10; 57/100] END class_weight={0: 0.006090909090909091, 1: 1};, score=(train=0.879, test=0.841) total time=  10.4s\n",
      "[CV 9/10; 64/100] START class_weight={0: 0.006727272727272728, 1: 1}............\n",
      "[CV 9/10; 64/100] END class_weight={0: 0.006727272727272728, 1: 1};, score=(train=0.880, test=0.846) total time=  11.6s\n",
      "[CV 5/10; 73/100] START class_weight={0: 0.007545454545454546, 1: 1}............\n",
      "[CV 5/10; 73/100] END class_weight={0: 0.007545454545454546, 1: 1};, score=(train=0.880, test=0.832) total time=   9.7s\n",
      "[CV 2/10; 80/100] START class_weight={0: 0.008181818181818182, 1: 1}............\n",
      "[CV 2/10; 80/100] END class_weight={0: 0.008181818181818182, 1: 1};, score=(train=0.879, test=0.858) total time=   8.0s\n",
      "[CV 4/10; 85/100] START class_weight={0: 0.008636363636363636, 1: 1}............\n",
      "[CV 4/10; 85/100] END class_weight={0: 0.008636363636363636, 1: 1};, score=(train=0.877, test=0.841) total time=   9.4s\n",
      "[CV 1/10; 92/100] START class_weight={0: 0.009272727272727273, 1: 1}............\n",
      "[CV 1/10; 92/100] END class_weight={0: 0.009272727272727273, 1: 1};, score=(train=0.878, test=0.847) total time=  11.5s\n",
      "[CV 6/10; 99/100] START class_weight={0: 0.009909090909090909, 1: 1}............\n",
      "[CV 6/10; 99/100] END class_weight={0: 0.009909090909090909, 1: 1};, score=(train=0.878, test=0.839) total time=   7.1s\n",
      "[CV 10/10; 5/100] START class_weight={0: 0.010404040404040405, 1: 1}............\n",
      "[CV 10/10; 5/100] END class_weight={0: 0.010404040404040405, 1: 1};, score=(train=0.876, test=0.867) total time=   9.5s\n",
      "[CV 2/10; 10/100] START class_weight={0: 0.01090909090909091, 1: 1}.............\n",
      "[CV 2/10; 10/100] END class_weight={0: 0.01090909090909091, 1: 1};, score=(train=0.876, test=0.851) total time=   7.3s\n",
      "[CV 7/10; 14/100] START class_weight={0: 0.011313131313131313, 1: 1}............\n",
      "[CV 7/10; 14/100] END class_weight={0: 0.011313131313131313, 1: 1};, score=(train=0.877, test=0.862) total time=  12.7s\n",
      "[CV 8/10; 23/100] START class_weight={0: 0.012222222222222223, 1: 1}............\n",
      "[CV 8/10; 23/100] END class_weight={0: 0.012222222222222223, 1: 1};, score=(train=0.879, test=0.885) total time=   9.2s\n",
      "[CV 1/10; 29/100] START class_weight={0: 0.012828282828282828, 1: 1}............\n",
      "[CV 1/10; 29/100] END class_weight={0: 0.012828282828282828, 1: 1};, score=(train=0.877, test=0.864) total time=  10.9s\n",
      "[CV 7/10; 36/100] START class_weight={0: 0.013535353535353536, 1: 1}............\n",
      "[CV 7/10; 36/100] END class_weight={0: 0.013535353535353536, 1: 1};, score=(train=0.880, test=0.867) total time=   8.8s\n",
      "[CV 4/10; 42/100] START class_weight={0: 0.014141414141414142, 1: 1}............\n",
      "[CV 4/10; 42/100] END class_weight={0: 0.014141414141414142, 1: 1};, score=(train=0.879, test=0.838) total time=   8.6s\n",
      "[CV 1/10; 48/100] START class_weight={0: 0.014747474747474749, 1: 1}............\n",
      "[CV 1/10; 48/100] END class_weight={0: 0.014747474747474749, 1: 1};, score=(train=0.880, test=0.861) total time=  10.6s\n",
      "[CV 10/10; 54/100] START class_weight={0: 0.015353535353535354, 1: 1}...........\n",
      "[CV 10/10; 54/100] END class_weight={0: 0.015353535353535354, 1: 1};, score=(train=0.879, test=0.869) total time=  10.7s\n",
      "[CV 9/10; 61/100] START class_weight={0: 0.01606060606060606, 1: 1}.............\n",
      "[CV 9/10; 61/100] END class_weight={0: 0.01606060606060606, 1: 1};, score=(train=0.882, test=0.840) total time=  11.5s\n",
      "[CV 9/10; 69/100] START class_weight={0: 0.01686868686868687, 1: 1}.............\n",
      "[CV 9/10; 69/100] END class_weight={0: 0.01686868686868687, 1: 1};, score=(train=0.881, test=0.854) total time=  10.7s\n",
      "[CV 2/10; 76/100] START class_weight={0: 0.017575757575757578, 1: 1}............\n",
      "[CV 2/10; 76/100] END class_weight={0: 0.017575757575757578, 1: 1};, score=(train=0.884, test=0.844) total time=  10.8s\n",
      "[CV 5/10; 83/100] START class_weight={0: 0.018282828282828283, 1: 1}............\n",
      "[CV 5/10; 83/100] END class_weight={0: 0.018282828282828283, 1: 1};, score=(train=0.883, test=0.832) total time=  11.7s\n",
      "[CV 2/10; 91/100] START class_weight={0: 0.01909090909090909, 1: 1}.............\n",
      "[CV 2/10; 91/100] END class_weight={0: 0.01909090909090909, 1: 1};, score=(train=0.885, test=0.846) total time=   9.8s\n",
      "[CV 4/10; 97/100] START class_weight={0: 0.0196969696969697, 1: 1}..............\n",
      "[CV 4/10; 97/100] END class_weight={0: 0.0196969696969697, 1: 1};, score=(train=0.881, test=0.842) total time=   9.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10; 5/10] START class_weight={0: 0.002777777777777778, 1: 1}..............\n",
      "[CV 9/10; 5/10] END class_weight={0: 0.002777777777777778, 1: 1};, score=(train=0.880, test=0.851) total time=   7.7s\n",
      "[CV 9/10; 10/10] START class_weight={0: 0.005, 1: 1}............................\n",
      "[CV 9/10; 10/10] END class_weight={0: 0.005, 1: 1};, score=(train=0.881, test=0.848) total time=   5.7s\n",
      "[CV 1/10; 7/100] START class_weight={0: 0.0015454545454545456, 1: 1}............\n",
      "[CV 1/10; 7/100] END class_weight={0: 0.0015454545454545456, 1: 1};, score=(train=0.879, test=0.841) total time=  10.2s\n",
      "[CV 7/10; 13/100] START class_weight={0: 0.002090909090909091, 1: 1}............\n",
      "[CV 7/10; 13/100] END class_weight={0: 0.002090909090909091, 1: 1};, score=(train=0.872, test=0.864) total time=  10.0s\n",
      "[CV 2/10; 20/100] START class_weight={0: 0.0027272727272727275, 1: 1}...........\n",
      "[CV 2/10; 20/100] END class_weight={0: 0.0027272727272727275, 1: 1};, score=(train=0.883, test=0.836) total time=   8.8s\n",
      "[CV 3/10; 27/100] START class_weight={0: 0.003363636363636364, 1: 1}............\n",
      "[CV 3/10; 27/100] END class_weight={0: 0.003363636363636364, 1: 1};, score=(train=0.879, test=0.838) total time=   9.1s\n",
      "[CV 10/10; 33/100] START class_weight={0: 0.003909090909090909, 1: 1}...........\n",
      "[CV 10/10; 33/100] END class_weight={0: 0.003909090909090909, 1: 1};, score=(train=0.879, test=0.851) total time=   8.9s\n",
      "[CV 6/10; 40/100] START class_weight={0: 0.004545454545454545, 1: 1}............\n",
      "[CV 6/10; 40/100] END class_weight={0: 0.004545454545454545, 1: 1};, score=(train=0.880, test=0.833) total time=   9.2s\n",
      "[CV 5/10; 47/100] START class_weight={0: 0.005181818181818182, 1: 1}............\n",
      "[CV 5/10; 47/100] END class_weight={0: 0.005181818181818182, 1: 1};, score=(train=0.879, test=0.840) total time=   6.1s\n",
      "[CV 5/10; 51/100] START class_weight={0: 0.005545454545454546, 1: 1}............\n",
      "[CV 5/10; 51/100] END class_weight={0: 0.005545454545454546, 1: 1};, score=(train=0.880, test=0.835) total time=   6.9s\n",
      "[CV 2/10; 57/100] START class_weight={0: 0.006090909090909091, 1: 1}............\n",
      "[CV 2/10; 57/100] END class_weight={0: 0.006090909090909091, 1: 1};, score=(train=0.880, test=0.825) total time=   9.5s\n",
      "[CV 9/10; 63/100] START class_weight={0: 0.006636363636363637, 1: 1}............\n",
      "[CV 9/10; 63/100] END class_weight={0: 0.006636363636363637, 1: 1};, score=(train=0.882, test=0.841) total time=   9.3s\n",
      "[CV 5/10; 70/100] START class_weight={0: 0.007272727272727274, 1: 1}............\n",
      "[CV 5/10; 70/100] END class_weight={0: 0.007272727272727274, 1: 1};, score=(train=0.880, test=0.833) total time=  10.2s\n",
      "[CV 3/10; 77/100] START class_weight={0: 0.00790909090909091, 1: 1}.............\n",
      "[CV 3/10; 77/100] END class_weight={0: 0.00790909090909091, 1: 1};, score=(train=0.880, test=0.844) total time=   9.5s\n",
      "[CV 2/10; 84/100] START class_weight={0: 0.008545454545454547, 1: 1}............\n",
      "[CV 2/10; 84/100] END class_weight={0: 0.008545454545454547, 1: 1};, score=(train=0.879, test=0.857) total time=   9.7s\n",
      "[CV 9/10; 90/100] START class_weight={0: 0.00909090909090909, 1: 1}.............\n",
      "[CV 9/10; 90/100] END class_weight={0: 0.00909090909090909, 1: 1};, score=(train=0.881, test=0.845) total time=  10.9s\n",
      "[CV 5/10; 98/100] START class_weight={0: 0.00981818181818182, 1: 1}.............\n",
      "[CV 5/10; 98/100] END class_weight={0: 0.00981818181818182, 1: 1};, score=(train=0.878, test=0.833) total time=   8.7s\n",
      "[CV 4/10; 5/100] START class_weight={0: 0.010404040404040405, 1: 1}.............\n",
      "[CV 4/10; 5/100] END class_weight={0: 0.010404040404040405, 1: 1};, score=(train=0.876, test=0.840) total time=   8.3s\n",
      "[CV 3/10; 8/100] START class_weight={0: 0.010707070707070707, 1: 1}.............\n",
      "[CV 3/10; 8/100] END class_weight={0: 0.010707070707070707, 1: 1};, score=(train=0.879, test=0.828) total time=   8.3s\n",
      "[CV 3/10; 14/100] START class_weight={0: 0.011313131313131313, 1: 1}............\n",
      "[CV 3/10; 14/100] END class_weight={0: 0.011313131313131313, 1: 1};, score=(train=0.879, test=0.828) total time=   9.2s\n",
      "[CV 1/10; 21/100] START class_weight={0: 0.012020202020202021, 1: 1}............\n",
      "[CV 1/10; 21/100] END class_weight={0: 0.012020202020202021, 1: 1};, score=(train=0.878, test=0.867) total time=   9.8s\n",
      "[CV 6/10; 27/100] START class_weight={0: 0.012626262626262626, 1: 1}............\n",
      "[CV 6/10; 27/100] END class_weight={0: 0.012626262626262626, 1: 1};, score=(train=0.880, test=0.834) total time=   8.7s\n",
      "[CV 3/10; 33/100] START class_weight={0: 0.013232323232323233, 1: 1}............\n",
      "[CV 3/10; 33/100] END class_weight={0: 0.013232323232323233, 1: 1};, score=(train=0.879, test=0.830) total time=   9.2s\n",
      "[CV 6/10; 39/100] START class_weight={0: 0.013838383838383839, 1: 1}............\n",
      "[CV 6/10; 39/100] END class_weight={0: 0.013838383838383839, 1: 1};, score=(train=0.881, test=0.826) total time=   9.8s\n",
      "[CV 1/10; 46/100] START class_weight={0: 0.014545454545454545, 1: 1}............\n",
      "[CV 1/10; 46/100] END class_weight={0: 0.014545454545454545, 1: 1};, score=(train=0.878, test=0.861) total time=  11.0s\n",
      "[CV 4/10; 53/100] START class_weight={0: 0.015252525252525254, 1: 1}............\n",
      "[CV 4/10; 53/100] END class_weight={0: 0.015252525252525254, 1: 1};, score=(train=0.881, test=0.841) total time=  10.6s\n",
      "[CV 3/10; 60/100] START class_weight={0: 0.01595959595959596, 1: 1}.............\n",
      "[CV 3/10; 60/100] END class_weight={0: 0.01595959595959596, 1: 1};, score=(train=0.879, test=0.834) total time=  11.6s\n",
      "[CV 6/10; 67/100] START class_weight={0: 0.016666666666666666, 1: 1}............\n",
      "[CV 6/10; 67/100] END class_weight={0: 0.016666666666666666, 1: 1};, score=(train=0.881, test=0.830) total time=   7.9s\n",
      "[CV 9/10; 72/100] START class_weight={0: 0.01717171717171717, 1: 1}.............\n",
      "[CV 9/10; 72/100] END class_weight={0: 0.01717171717171717, 1: 1};, score=(train=0.881, test=0.854) total time=   8.8s\n",
      "[CV 7/10; 78/100] START class_weight={0: 0.017777777777777778, 1: 1}............\n",
      "[CV 7/10; 78/100] END class_weight={0: 0.017777777777777778, 1: 1};, score=(train=0.878, test=0.862) total time=   8.7s\n",
      "[CV 7/10; 84/100] START class_weight={0: 0.018383838383838384, 1: 1}............\n",
      "[CV 7/10; 84/100] END class_weight={0: 0.018383838383838384, 1: 1};, score=(train=0.877, test=0.859) total time=  11.1s\n",
      "[CV 10/10; 91/100] START class_weight={0: 0.01909090909090909, 1: 1}............\n",
      "[CV 10/10; 91/100] END class_weight={0: 0.01909090909090909, 1: 1};, score=(train=0.879, test=0.869) total time=   9.8s\n",
      "[CV 1/10; 98/100] START class_weight={0: 0.0197979797979798, 1: 1}..............\n",
      "[CV 1/10; 98/100] END class_weight={0: 0.0197979797979798, 1: 1};, score=(train=0.877, test=0.856) total time=   7.6s\n",
      "[CV 2/10; 6/10] START class_weight={0: 0.0032222222222222222, 1: 1}.............\n",
      "[CV 2/10; 6/10] END class_weight={0: 0.0032222222222222222, 1: 1};, score=(train=0.880, test=0.846) total time=   8.8s\n",
      "[CV 7/10; 2/100] START class_weight={0: 0.001090909090909091, 1: 1}.............\n",
      "[CV 7/10; 2/100] END class_weight={0: 0.001090909090909091, 1: 1};, score=(train=0.874, test=0.853) total time=   7.9s\n",
      "[CV 9/10; 10/100] START class_weight={0: 0.0018181818181818182, 1: 1}...........\n",
      "[CV 9/10; 10/100] END class_weight={0: 0.0018181818181818182, 1: 1};, score=(train=0.879, test=0.842) total time=   7.8s\n",
      "[CV 5/10; 16/100] START class_weight={0: 0.0023636363636363638, 1: 1}...........\n",
      "[CV 5/10; 16/100] END class_weight={0: 0.0023636363636363638, 1: 1};, score=(train=0.878, test=0.838) total time=   8.2s\n",
      "[CV 7/10; 22/100] START class_weight={0: 0.0029090909090909093, 1: 1}...........\n",
      "[CV 7/10; 22/100] END class_weight={0: 0.0029090909090909093, 1: 1};, score=(train=0.876, test=0.863) total time=   8.9s\n",
      "[CV 7/10; 29/100] START class_weight={0: 0.0035454545454545456, 1: 1}...........\n",
      "[CV 7/10; 29/100] END class_weight={0: 0.0035454545454545456, 1: 1};, score=(train=0.877, test=0.868) total time=   8.7s\n",
      "[CV 3/10; 36/100] START class_weight={0: 0.004181818181818182, 1: 1}............\n",
      "[CV 3/10; 36/100] END class_weight={0: 0.004181818181818182, 1: 1};, score=(train=0.879, test=0.842) total time=   8.5s\n",
      "[CV 8/10; 42/100] START class_weight={0: 0.0047272727272727275, 1: 1}...........\n",
      "[CV 8/10; 42/100] END class_weight={0: 0.0047272727272727275, 1: 1};, score=(train=0.878, test=0.866) total time=   8.5s\n",
      "[CV 1/10; 49/100] START class_weight={0: 0.005363636363636364, 1: 1}............\n",
      "[CV 1/10; 49/100] END class_weight={0: 0.005363636363636364, 1: 1};, score=(train=0.879, test=0.847) total time=   9.1s\n",
      "[CV 8/10; 55/100] START class_weight={0: 0.00590909090909091, 1: 1}.............\n",
      "[CV 8/10; 55/100] END class_weight={0: 0.00590909090909091, 1: 1};, score=(train=0.877, test=0.862) total time=   7.3s\n",
      "[CV 3/10; 61/100] START class_weight={0: 0.006454545454545455, 1: 1}............\n",
      "[CV 3/10; 61/100] END class_weight={0: 0.006454545454545455, 1: 1};, score=(train=0.881, test=0.843) total time=   7.8s\n",
      "[CV 9/10; 66/100] START class_weight={0: 0.00690909090909091, 1: 1}.............\n",
      "[CV 9/10; 66/100] END class_weight={0: 0.00690909090909091, 1: 1};, score=(train=0.880, test=0.846) total time=   8.7s\n",
      "[CV 6/10; 73/100] START class_weight={0: 0.007545454545454546, 1: 1}............\n",
      "[CV 6/10; 73/100] END class_weight={0: 0.007545454545454546, 1: 1};, score=(train=0.879, test=0.837) total time=   7.1s\n",
      "[CV 3/10; 78/100] START class_weight={0: 0.008, 1: 1}...........................\n",
      "[CV 3/10; 78/100] END class_weight={0: 0.008, 1: 1};, score=(train=0.880, test=0.844) total time=  11.1s\n",
      "[CV 6/10; 86/100] START class_weight={0: 0.008727272727272728, 1: 1}............\n",
      "[CV 6/10; 86/100] END class_weight={0: 0.008727272727272728, 1: 1};, score=(train=0.879, test=0.836) total time=   7.9s\n",
      "[CV 5/10; 91/100] START class_weight={0: 0.009181818181818183, 1: 1}............\n",
      "[CV 5/10; 91/100] END class_weight={0: 0.009181818181818183, 1: 1};, score=(train=0.877, test=0.839) total time=   8.8s\n",
      "[CV 8/10; 97/100] START class_weight={0: 0.009727272727272727, 1: 1}............\n",
      "[CV 8/10; 97/100] END class_weight={0: 0.009727272727272727, 1: 1};, score=(train=0.878, test=0.868) total time=   8.9s\n",
      "[CV 3/10; 4/100] START class_weight={0: 0.010303030303030303, 1: 1}.............\n",
      "[CV 3/10; 4/100] END class_weight={0: 0.010303030303030303, 1: 1};, score=(train=0.879, test=0.835) total time=   9.9s\n",
      "[CV 2/10; 11/100] START class_weight={0: 0.01101010101010101, 1: 1}.............\n",
      "[CV 2/10; 11/100] END class_weight={0: 0.01101010101010101, 1: 1};, score=(train=0.881, test=0.855) total time=  11.2s\n",
      "[CV 7/10; 18/100] START class_weight={0: 0.011717171717171718, 1: 1}............\n",
      "[CV 7/10; 18/100] END class_weight={0: 0.011717171717171718, 1: 1};, score=(train=0.880, test=0.867) total time=  10.3s\n",
      "[CV 3/10; 25/100] START class_weight={0: 0.012424242424242424, 1: 1}............\n",
      "[CV 3/10; 25/100] END class_weight={0: 0.012424242424242424, 1: 1};, score=(train=0.876, test=0.838) total time=  10.1s\n",
      "[CV 8/10; 31/100] START class_weight={0: 0.013030303030303031, 1: 1}............\n",
      "[CV 8/10; 31/100] END class_weight={0: 0.013030303030303031, 1: 1};, score=(train=0.880, test=0.883) total time=  10.2s\n",
      "[CV 4/10; 38/100] START class_weight={0: 0.013737373737373737, 1: 1}............\n",
      "[CV 4/10; 38/100] END class_weight={0: 0.013737373737373737, 1: 1};, score=(train=0.878, test=0.835) total time=  13.2s\n",
      "[CV 5/10; 46/100] START class_weight={0: 0.014545454545454545, 1: 1}............\n",
      "[CV 5/10; 46/100] END class_weight={0: 0.014545454545454545, 1: 1};, score=(train=0.879, test=0.824) total time=  10.9s\n",
      "[CV 7/10; 53/100] START class_weight={0: 0.015252525252525254, 1: 1}............\n",
      "[CV 7/10; 53/100] END class_weight={0: 0.015252525252525254, 1: 1};, score=(train=0.878, test=0.860) total time=   9.1s\n",
      "[CV 3/10; 59/100] START class_weight={0: 0.015858585858585857, 1: 1}............\n",
      "[CV 3/10; 59/100] END class_weight={0: 0.015858585858585857, 1: 1};, score=(train=0.876, test=0.838) total time=   8.0s\n",
      "[CV 1/10; 65/100] START class_weight={0: 0.016464646464646467, 1: 1}............\n",
      "[CV 1/10; 65/100] END class_weight={0: 0.016464646464646467, 1: 1};, score=(train=0.881, test=0.859) total time=   8.5s\n",
      "[CV 8/10; 70/100] START class_weight={0: 0.016969696969696968, 1: 1}............\n",
      "[CV 8/10; 70/100] END class_weight={0: 0.016969696969696968, 1: 1};, score=(train=0.879, test=0.880) total time=   9.8s\n",
      "[CV 1/10; 77/100] START class_weight={0: 0.017676767676767676, 1: 1}............\n",
      "[CV 1/10; 77/100] END class_weight={0: 0.017676767676767676, 1: 1};, score=(train=0.881, test=0.859) total time=   9.3s\n",
      "[CV 10/10; 82/100] START class_weight={0: 0.01818181818181818, 1: 1}............\n",
      "[CV 10/10; 82/100] END class_weight={0: 0.01818181818181818, 1: 1};, score=(train=0.879, test=0.869) total time=  12.0s\n",
      "[CV 9/10; 90/100] START class_weight={0: 0.01898989898989899, 1: 1}.............\n",
      "[CV 9/10; 90/100] END class_weight={0: 0.01898989898989899, 1: 1};, score=(train=0.880, test=0.853) total time=   9.5s\n",
      "[CV 9/10; 96/100] START class_weight={0: 0.019595959595959597, 1: 1}............\n",
      "[CV 9/10; 96/100] END class_weight={0: 0.019595959595959597, 1: 1};, score=(train=0.880, test=0.853) total time=   9.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 6/10] START class_weight={0: 0.0032222222222222222, 1: 1}.............\n",
      "[CV 4/10; 6/10] END class_weight={0: 0.0032222222222222222, 1: 1};, score=(train=0.875, test=0.840) total time=  10.1s\n",
      "[CV 8/10; 3/100] START class_weight={0: 0.0011818181818181819, 1: 1}............\n",
      "[CV 8/10; 3/100] END class_weight={0: 0.0011818181818181819, 1: 1};, score=(train=0.874, test=0.862) total time=   8.9s\n",
      "[CV 8/10; 11/100] START class_weight={0: 0.0019090909090909093, 1: 1}...........\n",
      "[CV 8/10; 11/100] END class_weight={0: 0.0019090909090909093, 1: 1};, score=(train=0.877, test=0.862) total time=   7.9s\n",
      "[CV 6/10; 17/100] START class_weight={0: 0.002454545454545455, 1: 1}............\n",
      "[CV 6/10; 17/100] END class_weight={0: 0.002454545454545455, 1: 1};, score=(train=0.880, test=0.830) total time=   9.0s\n",
      "[CV 3/10; 24/100] START class_weight={0: 0.003090909090909091, 1: 1}............\n",
      "[CV 3/10; 24/100] END class_weight={0: 0.003090909090909091, 1: 1};, score=(train=0.879, test=0.840) total time=   8.2s\n",
      "[CV 8/10; 30/100] START class_weight={0: 0.003636363636363637, 1: 1}............\n",
      "[CV 8/10; 30/100] END class_weight={0: 0.003636363636363637, 1: 1};, score=(train=0.878, test=0.868) total time=  10.1s\n",
      "[CV 2/10; 38/100] START class_weight={0: 0.004363636363636364, 1: 1}............\n",
      "[CV 2/10; 38/100] END class_weight={0: 0.004363636363636364, 1: 1};, score=(train=0.880, test=0.834) total time=   8.8s\n",
      "[CV 8/10; 44/100] START class_weight={0: 0.00490909090909091, 1: 1}.............\n",
      "[CV 8/10; 44/100] END class_weight={0: 0.00490909090909091, 1: 1};, score=(train=0.878, test=0.863) total time=   7.2s\n",
      "[CV 10/10; 49/100] START class_weight={0: 0.005363636363636364, 1: 1}...........\n",
      "[CV 10/10; 49/100] END class_weight={0: 0.005363636363636364, 1: 1};, score=(train=0.878, test=0.860) total time=   9.5s\n",
      "[CV 4/10; 57/100] START class_weight={0: 0.006090909090909091, 1: 1}............\n",
      "[CV 4/10; 57/100] END class_weight={0: 0.006090909090909091, 1: 1};, score=(train=0.879, test=0.843) total time=   8.4s\n",
      "[CV 6/10; 63/100] START class_weight={0: 0.006636363636363637, 1: 1}............\n",
      "[CV 6/10; 63/100] END class_weight={0: 0.006636363636363637, 1: 1};, score=(train=0.879, test=0.837) total time=  11.2s\n",
      "[CV 9/10; 70/100] START class_weight={0: 0.007272727272727274, 1: 1}............\n",
      "[CV 9/10; 70/100] END class_weight={0: 0.007272727272727274, 1: 1};, score=(train=0.880, test=0.846) total time=   8.9s\n",
      "[CV 1/10; 77/100] START class_weight={0: 0.00790909090909091, 1: 1}.............\n",
      "[CV 1/10; 77/100] END class_weight={0: 0.00790909090909091, 1: 1};, score=(train=0.877, test=0.846) total time=   8.8s\n",
      "[CV 3/10; 83/100] START class_weight={0: 0.008454545454545454, 1: 1}............\n",
      "[CV 3/10; 83/100] END class_weight={0: 0.008454545454545454, 1: 1};, score=(train=0.880, test=0.845) total time=  10.0s\n",
      "[CV 3/10; 90/100] START class_weight={0: 0.00909090909090909, 1: 1}.............\n",
      "[CV 3/10; 90/100] END class_weight={0: 0.00909090909090909, 1: 1};, score=(train=0.880, test=0.845) total time=   9.4s\n",
      "[CV 1/10; 97/100] START class_weight={0: 0.009727272727272727, 1: 1}............\n",
      "[CV 1/10; 97/100] END class_weight={0: 0.009727272727272727, 1: 1};, score=(train=0.878, test=0.855) total time=   8.8s\n",
      "[CV 6/10; 2/100] START class_weight={0: 0.010101010101010102, 1: 1}.............\n",
      "[CV 6/10; 2/100] END class_weight={0: 0.010101010101010102, 1: 1};, score=(train=0.879, test=0.839) total time=   7.5s\n",
      "[CV 6/10; 7/100] START class_weight={0: 0.010606060606060607, 1: 1}.............\n",
      "[CV 6/10; 7/100] END class_weight={0: 0.010606060606060607, 1: 1};, score=(train=0.879, test=0.839) total time=   8.8s\n",
      "[CV 1/10; 14/100] START class_weight={0: 0.011313131313131313, 1: 1}............\n",
      "[CV 1/10; 14/100] END class_weight={0: 0.011313131313131313, 1: 1};, score=(train=0.877, test=0.860) total time=   8.4s\n",
      "[CV 2/10; 20/100] START class_weight={0: 0.01191919191919192, 1: 1}.............\n",
      "[CV 2/10; 20/100] END class_weight={0: 0.01191919191919192, 1: 1};, score=(train=0.878, test=0.850) total time=   9.4s\n",
      "[CV 5/10; 26/100] START class_weight={0: 0.012525252525252526, 1: 1}............\n",
      "[CV 5/10; 26/100] END class_weight={0: 0.012525252525252526, 1: 1};, score=(train=0.878, test=0.841) total time=  12.2s\n",
      "[CV 2/10; 34/100] START class_weight={0: 0.013333333333333332, 1: 1}............\n",
      "[CV 2/10; 34/100] END class_weight={0: 0.013333333333333332, 1: 1};, score=(train=0.884, test=0.846) total time=  13.9s\n",
      "[CV 6/10; 43/100] START class_weight={0: 0.014242424242424242, 1: 1}............\n",
      "[CV 6/10; 43/100] END class_weight={0: 0.014242424242424242, 1: 1};, score=(train=0.881, test=0.830) total time=   9.4s\n",
      "[CV 7/10; 49/100] START class_weight={0: 0.014848484848484849, 1: 1}............\n",
      "[CV 7/10; 49/100] END class_weight={0: 0.014848484848484849, 1: 1};, score=(train=0.878, test=0.862) total time=   8.8s\n",
      "[CV 6/10; 55/100] START class_weight={0: 0.015454545454545455, 1: 1}............\n",
      "[CV 6/10; 55/100] END class_weight={0: 0.015454545454545455, 1: 1};, score=(train=0.881, test=0.830) total time=   9.5s\n",
      "[CV 6/10; 61/100] START class_weight={0: 0.01606060606060606, 1: 1}.............\n",
      "[CV 6/10; 61/100] END class_weight={0: 0.01606060606060606, 1: 1};, score=(train=0.881, test=0.830) total time=  10.0s\n",
      "[CV 5/10; 67/100] START class_weight={0: 0.016666666666666666, 1: 1}............\n",
      "[CV 5/10; 67/100] END class_weight={0: 0.016666666666666666, 1: 1};, score=(train=0.880, test=0.824) total time=   9.2s\n",
      "[CV 7/10; 73/100] START class_weight={0: 0.017272727272727273, 1: 1}............\n",
      "[CV 7/10; 73/100] END class_weight={0: 0.017272727272727273, 1: 1};, score=(train=0.881, test=0.853) total time=   8.9s\n",
      "[CV 3/10; 79/100] START class_weight={0: 0.01787878787878788, 1: 1}.............\n",
      "[CV 3/10; 79/100] END class_weight={0: 0.01787878787878788, 1: 1};, score=(train=0.879, test=0.830) total time=   7.4s\n",
      "[CV 5/10; 84/100] START class_weight={0: 0.018383838383838384, 1: 1}............\n",
      "[CV 5/10; 84/100] END class_weight={0: 0.018383838383838384, 1: 1};, score=(train=0.881, test=0.826) total time=  11.6s\n",
      "[CV 1/10; 92/100] START class_weight={0: 0.01919191919191919, 1: 1}.............\n",
      "[CV 1/10; 92/100] END class_weight={0: 0.01919191919191919, 1: 1};, score=(train=0.877, test=0.856) total time=  10.4s\n",
      "[CV 5/10; 98/100] START class_weight={0: 0.0197979797979798, 1: 1}..............\n",
      "[CV 5/10; 98/100] END class_weight={0: 0.0197979797979798, 1: 1};, score=(train=0.881, test=0.831) total time=   7.6s\n",
      "[CV 8/10; 2/10] START class_weight={0: 0.0014444444444444444, 1: 1}.............\n",
      "[CV 8/10; 2/10] END class_weight={0: 0.0014444444444444444, 1: 1};, score=(train=0.877, test=0.866) total time=   7.5s\n",
      "[CV 3/10; 10/10] START class_weight={0: 0.005, 1: 1}............................\n",
      "[CV 3/10; 10/10] END class_weight={0: 0.005, 1: 1};, score=(train=0.881, test=0.836) total time=   6.1s\n",
      "[CV 6/10; 6/100] START class_weight={0: 0.0014545454545454547, 1: 1}............\n",
      "[CV 6/10; 6/100] END class_weight={0: 0.0014545454545454547, 1: 1};, score=(train=0.881, test=0.825) total time=   9.1s\n",
      "[CV 8/10; 12/100] START class_weight={0: 0.002, 1: 1}...........................\n",
      "[CV 8/10; 12/100] END class_weight={0: 0.002, 1: 1};, score=(train=0.877, test=0.866) total time=   6.6s\n",
      "[CV 2/10; 16/100] START class_weight={0: 0.0023636363636363638, 1: 1}...........\n",
      "[CV 2/10; 16/100] END class_weight={0: 0.0023636363636363638, 1: 1};, score=(train=0.882, test=0.832) total time=   8.2s\n",
      "[CV 9/10; 22/100] START class_weight={0: 0.0029090909090909093, 1: 1}...........\n",
      "[CV 9/10; 22/100] END class_weight={0: 0.0029090909090909093, 1: 1};, score=(train=0.881, test=0.833) total time=   7.8s\n",
      "[CV 7/10; 28/100] START class_weight={0: 0.003454545454545455, 1: 1}............\n",
      "[CV 7/10; 28/100] END class_weight={0: 0.003454545454545455, 1: 1};, score=(train=0.877, test=0.863) total time=   8.6s\n",
      "[CV 8/10; 34/100] START class_weight={0: 0.004, 1: 1}...........................\n",
      "[CV 8/10; 34/100] END class_weight={0: 0.004, 1: 1};, score=(train=0.878, test=0.864) total time=   6.3s\n",
      "[CV 3/10; 40/100] START class_weight={0: 0.004545454545454545, 1: 1}............\n",
      "[CV 3/10; 40/100] END class_weight={0: 0.004545454545454545, 1: 1};, score=(train=0.880, test=0.839) total time=   9.0s\n",
      "[CV 4/10; 47/100] START class_weight={0: 0.005181818181818182, 1: 1}............\n",
      "[CV 4/10; 47/100] END class_weight={0: 0.005181818181818182, 1: 1};, score=(train=0.879, test=0.843) total time=   9.4s\n",
      "[CV 10/10; 53/100] START class_weight={0: 0.0057272727272727275, 1: 1}..........\n",
      "[CV 10/10; 53/100] END class_weight={0: 0.0057272727272727275, 1: 1};, score=(train=0.880, test=0.859) total time=   9.2s\n",
      "[CV 5/10; 60/100] START class_weight={0: 0.006363636363636364, 1: 1}............\n",
      "[CV 5/10; 60/100] END class_weight={0: 0.006363636363636364, 1: 1};, score=(train=0.880, test=0.834) total time=   9.4s\n",
      "[CV 10/10; 66/100] START class_weight={0: 0.00690909090909091, 1: 1}............\n",
      "[CV 10/10; 66/100] END class_weight={0: 0.00690909090909091, 1: 1};, score=(train=0.876, test=0.854) total time=   8.2s\n",
      "[CV 1/10; 73/100] START class_weight={0: 0.007545454545454546, 1: 1}............\n",
      "[CV 1/10; 73/100] END class_weight={0: 0.007545454545454546, 1: 1};, score=(train=0.877, test=0.843) total time=   9.0s\n",
      "[CV 2/10; 79/100] START class_weight={0: 0.008090909090909091, 1: 1}............\n",
      "[CV 2/10; 79/100] END class_weight={0: 0.008090909090909091, 1: 1};, score=(train=0.880, test=0.836) total time=   9.0s\n",
      "[CV 9/10; 85/100] START class_weight={0: 0.008636363636363636, 1: 1}............\n",
      "[CV 9/10; 85/100] END class_weight={0: 0.008636363636363636, 1: 1};, score=(train=0.880, test=0.850) total time=   8.9s\n",
      "[CV 8/10; 91/100] START class_weight={0: 0.009181818181818183, 1: 1}............\n",
      "[CV 8/10; 91/100] END class_weight={0: 0.009181818181818183, 1: 1};, score=(train=0.877, test=0.856) total time=   8.9s\n",
      "[CV 9/10; 97/100] START class_weight={0: 0.009727272727272727, 1: 1}............\n",
      "[CV 9/10; 97/100] END class_weight={0: 0.009727272727272727, 1: 1};, score=(train=0.880, test=0.850) total time=   9.1s\n",
      "[CV 7/10; 4/100] START class_weight={0: 0.010303030303030303, 1: 1}.............\n",
      "[CV 7/10; 4/100] END class_weight={0: 0.010303030303030303, 1: 1};, score=(train=0.876, test=0.864) total time=   9.6s\n",
      "[CV 5/10; 10/100] START class_weight={0: 0.01090909090909091, 1: 1}.............\n",
      "[CV 5/10; 10/100] END class_weight={0: 0.01090909090909091, 1: 1};, score=(train=0.879, test=0.836) total time=  11.1s\n",
      "[CV 4/10; 18/100] START class_weight={0: 0.011717171717171718, 1: 1}............\n",
      "[CV 4/10; 18/100] END class_weight={0: 0.011717171717171718, 1: 1};, score=(train=0.876, test=0.838) total time=   9.6s\n",
      "[CV 1/10; 25/100] START class_weight={0: 0.012424242424242424, 1: 1}............\n",
      "[CV 1/10; 25/100] END class_weight={0: 0.012424242424242424, 1: 1};, score=(train=0.877, test=0.864) total time=  10.4s\n",
      "[CV 7/10; 31/100] START class_weight={0: 0.013030303030303031, 1: 1}............\n",
      "[CV 7/10; 31/100] END class_weight={0: 0.013030303030303031, 1: 1};, score=(train=0.878, test=0.862) total time=   9.8s\n",
      "[CV 8/10; 37/100] START class_weight={0: 0.013636363636363637, 1: 1}............\n",
      "[CV 8/10; 37/100] END class_weight={0: 0.013636363636363637, 1: 1};, score=(train=0.880, test=0.883) total time=   7.9s\n",
      "[CV 10/10; 42/100] START class_weight={0: 0.014141414141414142, 1: 1}...........\n",
      "[CV 10/10; 42/100] END class_weight={0: 0.014141414141414142, 1: 1};, score=(train=0.878, test=0.861) total time=  10.8s\n",
      "[CV 1/10; 50/100] START class_weight={0: 0.014949494949494949, 1: 1}............\n",
      "[CV 1/10; 50/100] END class_weight={0: 0.014949494949494949, 1: 1};, score=(train=0.881, test=0.859) total time=  12.4s\n",
      "[CV 9/10; 57/100] START class_weight={0: 0.015656565656565657, 1: 1}............\n",
      "[CV 9/10; 57/100] END class_weight={0: 0.015656565656565657, 1: 1};, score=(train=0.880, test=0.837) total time=   8.8s\n",
      "[CV 9/10; 63/100] START class_weight={0: 0.016262626262626263, 1: 1}............\n",
      "[CV 9/10; 63/100] END class_weight={0: 0.016262626262626263, 1: 1};, score=(train=0.881, test=0.854) total time=  11.3s\n",
      "[CV 10/10; 70/100] START class_weight={0: 0.016969696969696968, 1: 1}...........\n",
      "[CV 10/10; 70/100] END class_weight={0: 0.016969696969696968, 1: 1};, score=(train=0.879, test=0.869) total time=  11.2s\n",
      "[CV 1/10; 78/100] START class_weight={0: 0.017777777777777778, 1: 1}............\n",
      "[CV 1/10; 78/100] END class_weight={0: 0.017777777777777778, 1: 1};, score=(train=0.879, test=0.852) total time=   9.9s\n",
      "[CV 9/10; 84/100] START class_weight={0: 0.018383838383838384, 1: 1}............\n",
      "[CV 9/10; 84/100] END class_weight={0: 0.018383838383838384, 1: 1};, score=(train=0.880, test=0.853) total time=   8.2s\n",
      "[CV 8/10; 89/100] START class_weight={0: 0.01888888888888889, 1: 1}.............\n",
      "[CV 8/10; 89/100] END class_weight={0: 0.01888888888888889, 1: 1};, score=(train=0.878, test=0.880) total time=  11.2s\n",
      "[CV 2/10; 97/100] START class_weight={0: 0.0196969696969697, 1: 1}..............\n",
      "[CV 2/10; 97/100] END class_weight={0: 0.0196969696969697, 1: 1};, score=(train=0.885, test=0.846) total time=  10.2s\n",
      "[CV 5/10; 6/10] START class_weight={0: 0.0032222222222222222, 1: 1}.............\n",
      "[CV 5/10; 6/10] END class_weight={0: 0.0032222222222222222, 1: 1};, score=(train=0.880, test=0.837) total time=   6.3s\n",
      "[CV 8/10; 8/10] START class_weight={0: 0.004111111111111111, 1: 1}..............\n",
      "[CV 8/10; 8/10] END class_weight={0: 0.004111111111111111, 1: 1};, score=(train=0.878, test=0.869) total time=   6.2s\n",
      "[CV 8/10; 4/100] START class_weight={0: 0.0012727272727272728, 1: 1}............\n",
      "[CV 8/10; 4/100] END class_weight={0: 0.0012727272727272728, 1: 1};, score=(train=0.876, test=0.861) total time=   6.8s\n",
      "[CV 2/10; 8/100] START class_weight={0: 0.0016363636363636363, 1: 1}............\n",
      "[CV 2/10; 8/100] END class_weight={0: 0.0016363636363636363, 1: 1};, score=(train=0.882, test=0.839) total time=   9.1s\n",
      "[CV 2/10; 17/100] START class_weight={0: 0.002454545454545455, 1: 1}............\n",
      "[CV 2/10; 17/100] END class_weight={0: 0.002454545454545455, 1: 1};, score=(train=0.883, test=0.836) total time=  10.2s\n",
      "[CV 2/10; 25/100] START class_weight={0: 0.003181818181818182, 1: 1}............\n",
      "[CV 2/10; 25/100] END class_weight={0: 0.003181818181818182, 1: 1};, score=(train=0.880, test=0.841) total time=   9.0s\n",
      "[CV 1/10; 32/100] START class_weight={0: 0.0038181818181818187, 1: 1}...........\n",
      "[CV 1/10; 32/100] END class_weight={0: 0.0038181818181818187, 1: 1};, score=(train=0.881, test=0.841) total time=   8.7s\n",
      "[CV 9/10; 37/100] START class_weight={0: 0.0042727272727272735, 1: 1}...........\n",
      "[CV 9/10; 37/100] END class_weight={0: 0.0042727272727272735, 1: 1};, score=(train=0.879, test=0.840) total time=   8.5s\n",
      "[CV 5/10; 44/100] START class_weight={0: 0.00490909090909091, 1: 1}.............\n",
      "[CV 5/10; 44/100] END class_weight={0: 0.00490909090909091, 1: 1};, score=(train=0.880, test=0.834) total time=   8.4s\n",
      "[CV 5/10; 50/100] START class_weight={0: 0.005454545454545455, 1: 1}............\n",
      "[CV 5/10; 50/100] END class_weight={0: 0.005454545454545455, 1: 1};, score=(train=0.880, test=0.835) total time=   8.3s\n",
      "[CV 4/10; 56/100] START class_weight={0: 0.006, 1: 1}...........................\n",
      "[CV 4/10; 56/100] END class_weight={0: 0.006, 1: 1};, score=(train=0.879, test=0.843) total time=   8.2s\n",
      "[CV 10/10; 62/100] START class_weight={0: 0.006545454545454546, 1: 1}...........\n",
      "[CV 10/10; 62/100] END class_weight={0: 0.006545454545454546, 1: 1};, score=(train=0.879, test=0.858) total time=   9.3s\n",
      "[CV 8/10; 69/100] START class_weight={0: 0.0071818181818181824, 1: 1}...........\n",
      "[CV 8/10; 69/100] END class_weight={0: 0.0071818181818181824, 1: 1};, score=(train=0.878, test=0.865) total time=   8.0s\n",
      "[CV 5/10; 75/100] START class_weight={0: 0.007727272727272728, 1: 1}............\n",
      "[CV 5/10; 75/100] END class_weight={0: 0.007727272727272728, 1: 1};, score=(train=0.880, test=0.833) total time=   9.2s\n",
      "[CV 1/10; 82/100] START class_weight={0: 0.008363636363636365, 1: 1}............\n",
      "[CV 1/10; 82/100] END class_weight={0: 0.008363636363636365, 1: 1};, score=(train=0.877, test=0.846) total time=   9.8s\n",
      "[CV 7/10; 88/100] START class_weight={0: 0.008909090909090908, 1: 1}............\n",
      "[CV 7/10; 88/100] END class_weight={0: 0.008909090909090908, 1: 1};, score=(train=0.878, test=0.866) total time=   9.7s\n",
      "[CV 4/10; 95/100] START class_weight={0: 0.009545454545454548, 1: 1}............\n",
      "[CV 4/10; 95/100] END class_weight={0: 0.009545454545454548, 1: 1};, score=(train=0.876, test=0.837) total time=   8.7s\n",
      "[CV 5/10; 1/100] START class_weight={0: 0.01, 1: 1}.............................\n",
      "[CV 5/10; 1/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.879, test=0.836) total time=   8.7s\n",
      "[CV 1/10; 8/100] START class_weight={0: 0.010707070707070707, 1: 1}.............\n",
      "[CV 1/10; 8/100] END class_weight={0: 0.010707070707070707, 1: 1};, score=(train=0.877, test=0.850) total time=  10.1s\n",
      "[CV 8/10; 15/100] START class_weight={0: 0.011414141414141415, 1: 1}............\n",
      "[CV 8/10; 15/100] END class_weight={0: 0.011414141414141415, 1: 1};, score=(train=0.878, test=0.868) total time=   9.3s\n",
      "[CV 4/10; 22/100] START class_weight={0: 0.012121212121212121, 1: 1}............\n",
      "[CV 4/10; 22/100] END class_weight={0: 0.012121212121212121, 1: 1};, score=(train=0.876, test=0.836) total time=  11.0s\n",
      "[CV 4/10; 29/100] START class_weight={0: 0.012828282828282828, 1: 1}............\n",
      "[CV 4/10; 29/100] END class_weight={0: 0.012828282828282828, 1: 1};, score=(train=0.882, test=0.843) total time=   8.8s\n",
      "[CV 1/10; 35/100] START class_weight={0: 0.013434343434343434, 1: 1}............\n",
      "[CV 1/10; 35/100] END class_weight={0: 0.013434343434343434, 1: 1};, score=(train=0.877, test=0.864) total time=   9.3s\n",
      "[CV 5/10; 41/100] START class_weight={0: 0.01404040404040404, 1: 1}.............\n",
      "[CV 5/10; 41/100] END class_weight={0: 0.01404040404040404, 1: 1};, score=(train=0.882, test=0.837) total time=   9.9s\n",
      "[CV 10/10; 47/100] START class_weight={0: 0.014646464646464647, 1: 1}...........\n",
      "[CV 10/10; 47/100] END class_weight={0: 0.014646464646464647, 1: 1};, score=(train=0.878, test=0.865) total time=   8.3s\n",
      "[CV 5/10; 53/100] START class_weight={0: 0.015252525252525254, 1: 1}............\n",
      "[CV 5/10; 53/100] END class_weight={0: 0.015252525252525254, 1: 1};, score=(train=0.880, test=0.829) total time=  10.3s\n",
      "[CV 10/10; 59/100] START class_weight={0: 0.015858585858585857, 1: 1}...........\n",
      "[CV 10/10; 59/100] END class_weight={0: 0.015858585858585857, 1: 1};, score=(train=0.881, test=0.867) total time=   9.7s\n",
      "[CV 4/10; 66/100] START class_weight={0: 0.016565656565656565, 1: 1}............\n",
      "[CV 4/10; 66/100] END class_weight={0: 0.016565656565656565, 1: 1};, score=(train=0.883, test=0.848) total time=   9.7s\n",
      "[CV 6/10; 72/100] START class_weight={0: 0.01717171717171717, 1: 1}.............\n",
      "[CV 6/10; 72/100] END class_weight={0: 0.01717171717171717, 1: 1};, score=(train=0.881, test=0.826) total time=  11.7s\n",
      "[CV 3/10; 80/100] START class_weight={0: 0.017979797979797978, 1: 1}............\n",
      "[CV 3/10; 80/100] END class_weight={0: 0.017979797979797978, 1: 1};, score=(train=0.879, test=0.830) total time=   9.9s\n",
      "[CV 7/10; 86/100] START class_weight={0: 0.018585858585858588, 1: 1}............\n",
      "[CV 7/10; 86/100] END class_weight={0: 0.018585858585858588, 1: 1};, score=(train=0.878, test=0.860) total time=   8.7s\n",
      "[CV 6/10; 92/100] START class_weight={0: 0.01919191919191919, 1: 1}.............\n",
      "[CV 6/10; 92/100] END class_weight={0: 0.01919191919191919, 1: 1};, score=(train=0.881, test=0.830) total time=   9.2s\n",
      "[CV 6/10; 98/100] START class_weight={0: 0.0197979797979798, 1: 1}..............\n",
      "[CV 6/10; 98/100] END class_weight={0: 0.0197979797979798, 1: 1};, score=(train=0.881, test=0.830) total time=   7.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10; 1/10] START class_weight={0: 0.001, 1: 1}.............................\n",
      "[CV 1/10; 1/10] END class_weight={0: 0.001, 1: 1};, score=(train=0.875, test=0.845) total time=   5.9s\n",
      "[CV 5/10; 7/10] START class_weight={0: 0.003666666666666667, 1: 1}..............\n",
      "[CV 5/10; 7/10] END class_weight={0: 0.003666666666666667, 1: 1};, score=(train=0.880, test=0.837) total time=   6.6s\n",
      "[CV 10/10; 3/100] START class_weight={0: 0.0011818181818181819, 1: 1}...........\n",
      "[CV 10/10; 3/100] END class_weight={0: 0.0011818181818181819, 1: 1};, score=(train=0.878, test=0.846) total time=   9.2s\n",
      "[CV 10/10; 12/100] START class_weight={0: 0.002, 1: 1}..........................\n",
      "[CV 10/10; 12/100] END class_weight={0: 0.002, 1: 1};, score=(train=0.881, test=0.835) total time=   8.5s\n",
      "[CV 10/10; 18/100] START class_weight={0: 0.0025454545454545456, 1: 1}..........\n",
      "[CV 10/10; 18/100] END class_weight={0: 0.0025454545454545456, 1: 1};, score=(train=0.875, test=0.845) total time=   8.1s\n",
      "[CV 10/10; 24/100] START class_weight={0: 0.003090909090909091, 1: 1}...........\n",
      "[CV 10/10; 24/100] END class_weight={0: 0.003090909090909091, 1: 1};, score=(train=0.880, test=0.864) total time=   9.0s\n",
      "[CV 6/10; 31/100] START class_weight={0: 0.0037272727272727275, 1: 1}...........\n",
      "[CV 6/10; 31/100] END class_weight={0: 0.0037272727272727275, 1: 1};, score=(train=0.880, test=0.833) total time=  11.8s\n",
      "[CV 4/10; 40/100] START class_weight={0: 0.004545454545454545, 1: 1}............\n",
      "[CV 4/10; 40/100] END class_weight={0: 0.004545454545454545, 1: 1};, score=(train=0.879, test=0.849) total time=   9.8s\n",
      "[CV 9/10; 47/100] START class_weight={0: 0.005181818181818182, 1: 1}............\n",
      "[CV 9/10; 47/100] END class_weight={0: 0.005181818181818182, 1: 1};, score=(train=0.882, test=0.839) total time=  10.4s\n",
      "[CV 4/10; 55/100] START class_weight={0: 0.00590909090909091, 1: 1}.............\n",
      "[CV 4/10; 55/100] END class_weight={0: 0.00590909090909091, 1: 1};, score=(train=0.879, test=0.843) total time=   8.3s\n",
      "[CV 7/10; 61/100] START class_weight={0: 0.006454545454545455, 1: 1}............\n",
      "[CV 7/10; 61/100] END class_weight={0: 0.006454545454545455, 1: 1};, score=(train=0.876, test=0.867) total time=   7.6s\n",
      "[CV 5/10; 66/100] START class_weight={0: 0.00690909090909091, 1: 1}.............\n",
      "[CV 5/10; 66/100] END class_weight={0: 0.00690909090909091, 1: 1};, score=(train=0.880, test=0.831) total time=   8.2s\n",
      "[CV 2/10; 73/100] START class_weight={0: 0.007545454545454546, 1: 1}............\n",
      "[CV 2/10; 73/100] END class_weight={0: 0.007545454545454546, 1: 1};, score=(train=0.879, test=0.857) total time=   8.3s\n",
      "[CV 8/10; 78/100] START class_weight={0: 0.008, 1: 1}...........................\n",
      "[CV 8/10; 78/100] END class_weight={0: 0.008, 1: 1};, score=(train=0.874, test=0.869) total time=   8.4s\n",
      "[CV 9/10; 84/100] START class_weight={0: 0.008545454545454547, 1: 1}............\n",
      "[CV 9/10; 84/100] END class_weight={0: 0.008545454545454547, 1: 1};, score=(train=0.881, test=0.843) total time=  10.5s\n",
      "[CV 4/10; 92/100] START class_weight={0: 0.009272727272727273, 1: 1}............\n",
      "[CV 4/10; 92/100] END class_weight={0: 0.009272727272727273, 1: 1};, score=(train=0.879, test=0.833) total time=  10.2s\n",
      "[CV 4/10; 99/100] START class_weight={0: 0.009909090909090909, 1: 1}............\n",
      "[CV 4/10; 99/100] END class_weight={0: 0.009909090909090909, 1: 1};, score=(train=0.879, test=0.843) total time=   7.2s\n",
      "[CV 9/10; 4/100] START class_weight={0: 0.010303030303030303, 1: 1}.............\n",
      "[CV 9/10; 4/100] END class_weight={0: 0.010303030303030303, 1: 1};, score=(train=0.880, test=0.848) total time=   8.4s\n",
      "[CV 10/10; 8/100] START class_weight={0: 0.010707070707070707, 1: 1}............\n",
      "[CV 10/10; 8/100] END class_weight={0: 0.010707070707070707, 1: 1};, score=(train=0.879, test=0.868) total time=   9.0s\n",
      "[CV 1/10; 15/100] START class_weight={0: 0.011414141414141415, 1: 1}............\n",
      "[CV 1/10; 15/100] END class_weight={0: 0.011414141414141415, 1: 1};, score=(train=0.878, test=0.864) total time=   8.8s\n",
      "[CV 2/10; 21/100] START class_weight={0: 0.012020202020202021, 1: 1}............\n",
      "[CV 2/10; 21/100] END class_weight={0: 0.012020202020202021, 1: 1};, score=(train=0.877, test=0.849) total time=  10.4s\n",
      "[CV 1/10; 28/100] START class_weight={0: 0.012727272727272728, 1: 1}............\n",
      "[CV 1/10; 28/100] END class_weight={0: 0.012727272727272728, 1: 1};, score=(train=0.877, test=0.864) total time=   9.2s\n",
      "[CV 1/10; 34/100] START class_weight={0: 0.013333333333333332, 1: 1}............\n",
      "[CV 1/10; 34/100] END class_weight={0: 0.013333333333333332, 1: 1};, score=(train=0.877, test=0.864) total time=   9.2s\n",
      "[CV 2/10; 40/100] START class_weight={0: 0.013939393939393939, 1: 1}............\n",
      "[CV 2/10; 40/100] END class_weight={0: 0.013939393939393939, 1: 1};, score=(train=0.884, test=0.844) total time=  11.5s\n",
      "[CV 6/10; 47/100] START class_weight={0: 0.014646464646464647, 1: 1}............\n",
      "[CV 6/10; 47/100] END class_weight={0: 0.014646464646464647, 1: 1};, score=(train=0.881, test=0.830) total time=   8.2s\n",
      "[CV 1/10; 53/100] START class_weight={0: 0.015252525252525254, 1: 1}............\n",
      "[CV 1/10; 53/100] END class_weight={0: 0.015252525252525254, 1: 1};, score=(train=0.881, test=0.859) total time=  10.7s\n",
      "[CV 7/10; 59/100] START class_weight={0: 0.015858585858585857, 1: 1}............\n",
      "[CV 7/10; 59/100] END class_weight={0: 0.015858585858585857, 1: 1};, score=(train=0.881, test=0.853) total time=   9.2s\n",
      "[CV 10/10; 65/100] START class_weight={0: 0.016464646464646467, 1: 1}...........\n",
      "[CV 10/10; 65/100] END class_weight={0: 0.016464646464646467, 1: 1};, score=(train=0.881, test=0.867) total time=   9.2s\n",
      "[CV 5/10; 72/100] START class_weight={0: 0.01717171717171717, 1: 1}.............\n",
      "[CV 5/10; 72/100] END class_weight={0: 0.01717171717171717, 1: 1};, score=(train=0.880, test=0.824) total time=  10.8s\n",
      "[CV 2/10; 79/100] START class_weight={0: 0.01787878787878788, 1: 1}.............\n",
      "[CV 2/10; 79/100] END class_weight={0: 0.01787878787878788, 1: 1};, score=(train=0.885, test=0.846) total time=   7.9s\n",
      "[CV 10/10; 84/100] START class_weight={0: 0.018383838383838384, 1: 1}...........\n",
      "[CV 10/10; 84/100] END class_weight={0: 0.018383838383838384, 1: 1};, score=(train=0.879, test=0.869) total time=  11.1s\n",
      "[CV 8/10; 91/100] START class_weight={0: 0.01909090909090909, 1: 1}.............\n",
      "[CV 8/10; 91/100] END class_weight={0: 0.01909090909090909, 1: 1};, score=(train=0.879, test=0.884) total time=   9.2s\n",
      "[CV 9/10; 97/100] START class_weight={0: 0.0196969696969697, 1: 1}..............\n",
      "[CV 9/10; 97/100] END class_weight={0: 0.0196969696969697, 1: 1};, score=(train=0.883, test=0.842) total time=   9.2s\n",
      "[CV 1/10; 6/10] START class_weight={0: 0.0032222222222222222, 1: 1}.............\n",
      "[CV 1/10; 6/10] END class_weight={0: 0.0032222222222222222, 1: 1};, score=(train=0.881, test=0.840) total time=   6.8s\n",
      "[CV 6/10; 8/10] START class_weight={0: 0.004111111111111111, 1: 1}..............\n",
      "[CV 6/10; 8/10] END class_weight={0: 0.004111111111111111, 1: 1};, score=(train=0.880, test=0.833) total time=   6.3s\n",
      "[CV 10/10; 4/100] START class_weight={0: 0.0012727272727272728, 1: 1}...........\n",
      "[CV 10/10; 4/100] END class_weight={0: 0.0012727272727272728, 1: 1};, score=(train=0.878, test=0.846) total time=   9.2s\n",
      "[CV 1/10; 13/100] START class_weight={0: 0.002090909090909091, 1: 1}............\n",
      "[CV 1/10; 13/100] END class_weight={0: 0.002090909090909091, 1: 1};, score=(train=0.883, test=0.845) total time=   9.9s\n",
      "[CV 8/10; 19/100] START class_weight={0: 0.0026363636363636363, 1: 1}...........\n",
      "[CV 8/10; 19/100] END class_weight={0: 0.0026363636363636363, 1: 1};, score=(train=0.878, test=0.865) total time=   8.1s\n",
      "[CV 3/10; 26/100] START class_weight={0: 0.003272727272727273, 1: 1}............\n",
      "[CV 3/10; 26/100] END class_weight={0: 0.003272727272727273, 1: 1};, score=(train=0.878, test=0.840) total time=   8.3s\n",
      "[CV 4/10; 32/100] START class_weight={0: 0.0038181818181818187, 1: 1}...........\n",
      "[CV 4/10; 32/100] END class_weight={0: 0.0038181818181818187, 1: 1};, score=(train=0.879, test=0.854) total time=   9.5s\n",
      "[CV 5/10; 39/100] START class_weight={0: 0.004454545454545455, 1: 1}............\n",
      "[CV 5/10; 39/100] END class_weight={0: 0.004454545454545455, 1: 1};, score=(train=0.879, test=0.841) total time=   8.6s\n",
      "[CV 1/10; 46/100] START class_weight={0: 0.005090909090909091, 1: 1}............\n",
      "[CV 1/10; 46/100] END class_weight={0: 0.005090909090909091, 1: 1};, score=(train=0.879, test=0.842) total time=   9.3s\n",
      "[CV 10/10; 52/100] START class_weight={0: 0.005636363636363636, 1: 1}...........\n",
      "[CV 10/10; 52/100] END class_weight={0: 0.005636363636363636, 1: 1};, score=(train=0.879, test=0.858) total time=   9.5s\n",
      "[CV 3/10; 59/100] START class_weight={0: 0.006272727272727274, 1: 1}............\n",
      "[CV 3/10; 59/100] END class_weight={0: 0.006272727272727274, 1: 1};, score=(train=0.881, test=0.843) total time=   7.8s\n",
      "[CV 10/10; 64/100] START class_weight={0: 0.006727272727272728, 1: 1}...........\n",
      "[CV 10/10; 64/100] END class_weight={0: 0.006727272727272728, 1: 1};, score=(train=0.878, test=0.860) total time=   9.4s\n",
      "[CV 8/10; 71/100] START class_weight={0: 0.007363636363636364, 1: 1}............\n",
      "[CV 8/10; 71/100] END class_weight={0: 0.007363636363636364, 1: 1};, score=(train=0.873, test=0.865) total time=  11.0s\n",
      "[CV 10/10; 79/100] START class_weight={0: 0.008090909090909091, 1: 1}...........\n",
      "[CV 10/10; 79/100] END class_weight={0: 0.008090909090909091, 1: 1};, score=(train=0.876, test=0.849) total time=  11.4s\n",
      "[CV 8/10; 87/100] START class_weight={0: 0.008818181818181819, 1: 1}............\n",
      "[CV 8/10; 87/100] END class_weight={0: 0.008818181818181819, 1: 1};, score=(train=0.877, test=0.858) total time=   7.9s\n",
      "[CV 1/10; 93/100] START class_weight={0: 0.009363636363636366, 1: 1}............\n",
      "[CV 1/10; 93/100] END class_weight={0: 0.009363636363636366, 1: 1};, score=(train=0.878, test=0.855) total time=  10.3s\n",
      "[CV 7/10; 99/100] START class_weight={0: 0.009909090909090909, 1: 1}............\n",
      "[CV 7/10; 99/100] END class_weight={0: 0.009909090909090909, 1: 1};, score=(train=0.878, test=0.857) total time=   6.9s\n",
      "[CV 9/10; 5/100] START class_weight={0: 0.010404040404040405, 1: 1}.............\n",
      "[CV 9/10; 5/100] END class_weight={0: 0.010404040404040405, 1: 1};, score=(train=0.880, test=0.848) total time=   9.4s\n",
      "[CV 10/10; 10/100] START class_weight={0: 0.01090909090909091, 1: 1}............\n",
      "[CV 10/10; 10/100] END class_weight={0: 0.01090909090909091, 1: 1};, score=(train=0.876, test=0.867) total time=   8.8s\n",
      "[CV 3/10; 16/100] START class_weight={0: 0.011515151515151515, 1: 1}............\n",
      "[CV 3/10; 16/100] END class_weight={0: 0.011515151515151515, 1: 1};, score=(train=0.879, test=0.831) total time=   8.0s\n",
      "[CV 4/10; 21/100] START class_weight={0: 0.012020202020202021, 1: 1}............\n",
      "[CV 4/10; 21/100] END class_weight={0: 0.012020202020202021, 1: 1};, score=(train=0.876, test=0.838) total time=   9.9s\n",
      "[CV 5/10; 28/100] START class_weight={0: 0.012727272727272728, 1: 1}............\n",
      "[CV 5/10; 28/100] END class_weight={0: 0.012727272727272728, 1: 1};, score=(train=0.879, test=0.824) total time=  11.2s\n",
      "[CV 8/10; 35/100] START class_weight={0: 0.013434343434343434, 1: 1}............\n",
      "[CV 8/10; 35/100] END class_weight={0: 0.013434343434343434, 1: 1};, score=(train=0.880, test=0.878) total time=   8.6s\n",
      "[CV 3/10; 41/100] START class_weight={0: 0.01404040404040404, 1: 1}.............\n",
      "[CV 3/10; 41/100] END class_weight={0: 0.01404040404040404, 1: 1};, score=(train=0.879, test=0.830) total time=  10.1s\n",
      "[CV 3/10; 48/100] START class_weight={0: 0.014747474747474749, 1: 1}............\n",
      "[CV 3/10; 48/100] END class_weight={0: 0.014747474747474749, 1: 1};, score=(train=0.879, test=0.834) total time=   9.1s\n",
      "[CV 2/10; 54/100] START class_weight={0: 0.015353535353535354, 1: 1}............\n",
      "[CV 2/10; 54/100] END class_weight={0: 0.015353535353535354, 1: 1};, score=(train=0.878, test=0.843) total time=  10.0s\n",
      "[CV 7/10; 60/100] START class_weight={0: 0.01595959595959596, 1: 1}.............\n",
      "[CV 7/10; 60/100] END class_weight={0: 0.01595959595959596, 1: 1};, score=(train=0.878, test=0.862) total time=   9.7s\n",
      "[CV 10/10; 66/100] START class_weight={0: 0.016565656565656565, 1: 1}...........\n",
      "[CV 10/10; 66/100] END class_weight={0: 0.016565656565656565, 1: 1};, score=(train=0.879, test=0.869) total time=   9.3s\n",
      "[CV 10/10; 72/100] START class_weight={0: 0.01717171717171717, 1: 1}............\n",
      "[CV 10/10; 72/100] END class_weight={0: 0.01717171717171717, 1: 1};, score=(train=0.879, test=0.869) total time=   9.6s\n",
      "[CV 1/10; 79/100] START class_weight={0: 0.01787878787878788, 1: 1}.............\n",
      "[CV 1/10; 79/100] END class_weight={0: 0.01787878787878788, 1: 1};, score=(train=0.880, test=0.859) total time=  12.4s\n",
      "[CV 9/10; 86/100] START class_weight={0: 0.018585858585858588, 1: 1}............\n",
      "[CV 9/10; 86/100] END class_weight={0: 0.018585858585858588, 1: 1};, score=(train=0.883, test=0.842) total time=   8.5s\n",
      "[CV 4/10; 92/100] START class_weight={0: 0.01919191919191919, 1: 1}.............\n",
      "[CV 4/10; 92/100] END class_weight={0: 0.01919191919191919, 1: 1};, score=(train=0.884, test=0.844) total time=   9.1s\n",
      "[CV 3/10; 98/100] START class_weight={0: 0.0197979797979798, 1: 1}..............\n",
      "[CV 3/10; 98/100] END class_weight={0: 0.0197979797979798, 1: 1};, score=(train=0.882, test=0.833) total time=   8.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10; 5/10] START class_weight={0: 0.002777777777777778, 1: 1}..............\n",
      "[CV 3/10; 5/10] END class_weight={0: 0.002777777777777778, 1: 1};, score=(train=0.880, test=0.840) total time=   6.7s\n",
      "[CV 1/10; 8/10] START class_weight={0: 0.004111111111111111, 1: 1}..............\n",
      "[CV 1/10; 8/10] END class_weight={0: 0.004111111111111111, 1: 1};, score=(train=0.881, test=0.841) total time=   6.5s\n",
      "[CV 7/10; 4/100] START class_weight={0: 0.0012727272727272728, 1: 1}............\n",
      "[CV 7/10; 4/100] END class_weight={0: 0.0012727272727272728, 1: 1};, score=(train=0.872, test=0.846) total time=   8.4s\n",
      "[CV 1/10; 12/100] START class_weight={0: 0.002, 1: 1}...........................\n",
      "[CV 1/10; 12/100] END class_weight={0: 0.002, 1: 1};, score=(train=0.881, test=0.841) total time=  11.6s\n",
      "[CV 4/10; 20/100] START class_weight={0: 0.0027272727272727275, 1: 1}...........\n",
      "[CV 4/10; 20/100] END class_weight={0: 0.0027272727272727275, 1: 1};, score=(train=0.877, test=0.842) total time=   9.3s\n",
      "[CV 4/10; 27/100] START class_weight={0: 0.003363636363636364, 1: 1}............\n",
      "[CV 4/10; 27/100] END class_weight={0: 0.003363636363636364, 1: 1};, score=(train=0.880, test=0.849) total time=   9.1s\n",
      "[CV 1/10; 34/100] START class_weight={0: 0.004, 1: 1}...........................\n",
      "[CV 1/10; 34/100] END class_weight={0: 0.004, 1: 1};, score=(train=0.878, test=0.832) total time=  11.3s\n",
      "[CV 9/10; 41/100] START class_weight={0: 0.004636363636363636, 1: 1}............\n",
      "[CV 9/10; 41/100] END class_weight={0: 0.004636363636363636, 1: 1};, score=(train=0.881, test=0.848) total time=   7.4s\n",
      "[CV 10/10; 47/100] START class_weight={0: 0.005181818181818182, 1: 1}...........\n",
      "[CV 10/10; 47/100] END class_weight={0: 0.005181818181818182, 1: 1};, score=(train=0.879, test=0.858) total time=   8.9s\n",
      "[CV 8/10; 54/100] START class_weight={0: 0.005818181818181819, 1: 1}............\n",
      "[CV 8/10; 54/100] END class_weight={0: 0.005818181818181819, 1: 1};, score=(train=0.877, test=0.862) total time=   8.4s\n",
      "[CV 9/10; 60/100] START class_weight={0: 0.006363636363636364, 1: 1}............\n",
      "[CV 9/10; 60/100] END class_weight={0: 0.006363636363636364, 1: 1};, score=(train=0.880, test=0.846) total time=   9.9s\n",
      "[CV 5/10; 68/100] START class_weight={0: 0.007090909090909091, 1: 1}............\n",
      "[CV 5/10; 68/100] END class_weight={0: 0.007090909090909091, 1: 1};, score=(train=0.880, test=0.833) total time=   8.5s\n",
      "[CV 8/10; 74/100] START class_weight={0: 0.007636363636363637, 1: 1}............\n",
      "[CV 8/10; 74/100] END class_weight={0: 0.007636363636363637, 1: 1};, score=(train=0.874, test=0.869) total time=   9.8s\n",
      "[CV 7/10; 81/100] START class_weight={0: 0.008272727272727274, 1: 1}............\n",
      "[CV 7/10; 81/100] END class_weight={0: 0.008272727272727274, 1: 1};, score=(train=0.877, test=0.862) total time=   8.5s\n",
      "[CV 5/10; 87/100] START class_weight={0: 0.008818181818181819, 1: 1}............\n",
      "[CV 5/10; 87/100] END class_weight={0: 0.008818181818181819, 1: 1};, score=(train=0.880, test=0.832) total time=  10.2s\n",
      "[CV 3/10; 94/100] START class_weight={0: 0.009454545454545455, 1: 1}............\n",
      "[CV 3/10; 94/100] END class_weight={0: 0.009454545454545455, 1: 1};, score=(train=0.879, test=0.846) total time=   8.7s\n",
      "[CV 1/10; 100/100] START class_weight={0: 0.01, 1: 1}...........................\n",
      "[CV 1/10; 100/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.879, test=0.844) total time=   7.1s\n",
      "[CV 6/10; 6/100] START class_weight={0: 0.010505050505050505, 1: 1}.............\n",
      "[CV 6/10; 6/100] END class_weight={0: 0.010505050505050505, 1: 1};, score=(train=0.878, test=0.839) total time=   8.0s\n",
      "[CV 2/10; 8/100] START class_weight={0: 0.010707070707070707, 1: 1}.............\n",
      "[CV 2/10; 8/100] END class_weight={0: 0.010707070707070707, 1: 1};, score=(train=0.881, test=0.853) total time=   9.6s\n",
      "[CV 3/10; 15/100] START class_weight={0: 0.011414141414141415, 1: 1}............\n",
      "[CV 3/10; 15/100] END class_weight={0: 0.011414141414141415, 1: 1};, score=(train=0.879, test=0.827) total time=   9.5s\n",
      "[CV 9/10; 21/100] START class_weight={0: 0.012020202020202021, 1: 1}............\n",
      "[CV 9/10; 21/100] END class_weight={0: 0.012020202020202021, 1: 1};, score=(train=0.880, test=0.838) total time=  10.0s\n",
      "[CV 6/10; 28/100] START class_weight={0: 0.012727272727272728, 1: 1}............\n",
      "[CV 6/10; 28/100] END class_weight={0: 0.012727272727272728, 1: 1};, score=(train=0.880, test=0.832) total time=  11.4s\n",
      "[CV 1/10; 36/100] START class_weight={0: 0.013535353535353536, 1: 1}............\n",
      "[CV 1/10; 36/100] END class_weight={0: 0.013535353535353536, 1: 1};, score=(train=0.878, test=0.867) total time=  11.6s\n",
      "[CV 10/10; 43/100] START class_weight={0: 0.014242424242424242, 1: 1}...........\n",
      "[CV 10/10; 43/100] END class_weight={0: 0.014242424242424242, 1: 1};, score=(train=0.878, test=0.861) total time=   7.8s\n",
      "[CV 10/10; 48/100] START class_weight={0: 0.014747474747474749, 1: 1}...........\n",
      "[CV 10/10; 48/100] END class_weight={0: 0.014747474747474749, 1: 1};, score=(train=0.878, test=0.861) total time=  10.0s\n",
      "[CV 5/10; 55/100] START class_weight={0: 0.015454545454545455, 1: 1}............\n",
      "[CV 5/10; 55/100] END class_weight={0: 0.015454545454545455, 1: 1};, score=(train=0.879, test=0.824) total time=  10.1s\n",
      "[CV 10/10; 61/100] START class_weight={0: 0.01606060606060606, 1: 1}............\n",
      "[CV 10/10; 61/100] END class_weight={0: 0.01606060606060606, 1: 1};, score=(train=0.882, test=0.868) total time=  11.8s\n",
      "[CV 1/10; 70/100] START class_weight={0: 0.016969696969696968, 1: 1}............\n",
      "[CV 1/10; 70/100] END class_weight={0: 0.016969696969696968, 1: 1};, score=(train=0.878, test=0.851) total time=  12.6s\n",
      "[CV 7/10; 77/100] START class_weight={0: 0.017676767676767676, 1: 1}............\n",
      "[CV 7/10; 77/100] END class_weight={0: 0.017676767676767676, 1: 1};, score=(train=0.881, test=0.853) total time=   9.8s\n",
      "[CV 1/10; 84/100] START class_weight={0: 0.018383838383838384, 1: 1}............\n",
      "[CV 1/10; 84/100] END class_weight={0: 0.018383838383838384, 1: 1};, score=(train=0.880, test=0.857) total time=   9.1s\n",
      "[CV 10/10; 89/100] START class_weight={0: 0.01888888888888889, 1: 1}............\n",
      "[CV 10/10; 89/100] END class_weight={0: 0.01888888888888889, 1: 1};, score=(train=0.881, test=0.868) total time=  12.1s\n",
      "[CV 7/10; 97/100] START class_weight={0: 0.0196969696969697, 1: 1}..............\n",
      "[CV 7/10; 97/100] END class_weight={0: 0.0196969696969697, 1: 1};, score=(train=0.878, test=0.851) total time=   9.7s\n",
      "[CV 5/10; 1/10] START class_weight={0: 0.001, 1: 1}.............................\n",
      "[CV 5/10; 1/10] END class_weight={0: 0.001, 1: 1};, score=(train=0.878, test=0.831) total time=   6.0s\n",
      "[CV 7/10; 7/10] START class_weight={0: 0.003666666666666667, 1: 1}..............\n",
      "[CV 7/10; 7/10] END class_weight={0: 0.003666666666666667, 1: 1};, score=(train=0.877, test=0.870) total time=   6.3s\n",
      "[CV 9/10; 3/100] START class_weight={0: 0.0011818181818181819, 1: 1}............\n",
      "[CV 9/10; 3/100] END class_weight={0: 0.0011818181818181819, 1: 1};, score=(train=0.877, test=0.840) total time=   7.5s\n",
      "[CV 4/10; 9/100] START class_weight={0: 0.0017272727272727275, 1: 1}............\n",
      "[CV 4/10; 9/100] END class_weight={0: 0.0017272727272727275, 1: 1};, score=(train=0.878, test=0.834) total time=  10.5s\n",
      "[CV 6/10; 18/100] START class_weight={0: 0.0025454545454545456, 1: 1}...........\n",
      "[CV 6/10; 18/100] END class_weight={0: 0.0025454545454545456, 1: 1};, score=(train=0.880, test=0.832) total time=   7.9s\n",
      "[CV 4/10; 24/100] START class_weight={0: 0.003090909090909091, 1: 1}............\n",
      "[CV 4/10; 24/100] END class_weight={0: 0.003090909090909091, 1: 1};, score=(train=0.877, test=0.850) total time=   8.3s\n",
      "[CV 7/10; 30/100] START class_weight={0: 0.003636363636363637, 1: 1}............\n",
      "[CV 7/10; 30/100] END class_weight={0: 0.003636363636363637, 1: 1};, score=(train=0.878, test=0.860) total time=   9.4s\n",
      "[CV 7/10; 37/100] START class_weight={0: 0.0042727272727272735, 1: 1}...........\n",
      "[CV 7/10; 37/100] END class_weight={0: 0.0042727272727272735, 1: 1};, score=(train=0.876, test=0.861) total time=  10.4s\n",
      "[CV 10/10; 45/100] START class_weight={0: 0.005, 1: 1}..........................\n",
      "[CV 10/10; 45/100] END class_weight={0: 0.005, 1: 1};, score=(train=0.879, test=0.858) total time=  11.2s\n",
      "[CV 4/10; 54/100] START class_weight={0: 0.005818181818181819, 1: 1}............\n",
      "[CV 4/10; 54/100] END class_weight={0: 0.005818181818181819, 1: 1};, score=(train=0.879, test=0.847) total time=  10.6s\n",
      "[CV 2/10; 62/100] START class_weight={0: 0.006545454545454546, 1: 1}............\n",
      "[CV 2/10; 62/100] END class_weight={0: 0.006545454545454546, 1: 1};, score=(train=0.880, test=0.825) total time=   8.6s\n",
      "[CV 3/10; 68/100] START class_weight={0: 0.007090909090909091, 1: 1}............\n",
      "[CV 3/10; 68/100] END class_weight={0: 0.007090909090909091, 1: 1};, score=(train=0.880, test=0.844) total time=   8.0s\n",
      "[CV 1/10; 74/100] START class_weight={0: 0.007636363636363637, 1: 1}............\n",
      "[CV 1/10; 74/100] END class_weight={0: 0.007636363636363637, 1: 1};, score=(train=0.877, test=0.844) total time=   9.1s\n",
      "[CV 4/10; 80/100] START class_weight={0: 0.008181818181818182, 1: 1}............\n",
      "[CV 4/10; 80/100] END class_weight={0: 0.008181818181818182, 1: 1};, score=(train=0.877, test=0.841) total time=  11.6s\n",
      "[CV 4/10; 88/100] START class_weight={0: 0.008909090909090908, 1: 1}............\n",
      "[CV 4/10; 88/100] END class_weight={0: 0.008909090909090908, 1: 1};, score=(train=0.879, test=0.833) total time=  12.2s\n",
      "[CV 2/10; 96/100] START class_weight={0: 0.009636363636363637, 1: 1}............\n",
      "[CV 2/10; 96/100] END class_weight={0: 0.009636363636363637, 1: 1};, score=(train=0.881, test=0.848) total time=  10.7s\n",
      "[CV 1/10; 4/100] START class_weight={0: 0.010303030303030303, 1: 1}.............\n",
      "[CV 1/10; 4/100] END class_weight={0: 0.010303030303030303, 1: 1};, score=(train=0.879, test=0.844) total time=   9.0s\n",
      "[CV 3/10; 9/100] START class_weight={0: 0.010808080808080808, 1: 1}.............\n",
      "[CV 3/10; 9/100] END class_weight={0: 0.010808080808080808, 1: 1};, score=(train=0.879, test=0.827) total time=   9.7s\n",
      "[CV 2/10; 16/100] START class_weight={0: 0.011515151515151515, 1: 1}............\n",
      "[CV 2/10; 16/100] END class_weight={0: 0.011515151515151515, 1: 1};, score=(train=0.878, test=0.850) total time=   9.0s\n",
      "[CV 3/10; 22/100] START class_weight={0: 0.012121212121212121, 1: 1}............\n",
      "[CV 3/10; 22/100] END class_weight={0: 0.012121212121212121, 1: 1};, score=(train=0.876, test=0.838) total time=   7.0s\n",
      "[CV 2/10; 27/100] START class_weight={0: 0.012626262626262626, 1: 1}............\n",
      "[CV 2/10; 27/100] END class_weight={0: 0.012626262626262626, 1: 1};, score=(train=0.877, test=0.849) total time=  10.6s\n",
      "[CV 10/10; 33/100] START class_weight={0: 0.013232323232323233, 1: 1}...........\n",
      "[CV 10/10; 33/100] END class_weight={0: 0.013232323232323233, 1: 1};, score=(train=0.877, test=0.860) total time=   8.0s\n",
      "[CV 7/10; 39/100] START class_weight={0: 0.013838383838383839, 1: 1}............\n",
      "[CV 7/10; 39/100] END class_weight={0: 0.013838383838383839, 1: 1};, score=(train=0.878, test=0.862) total time=  11.3s\n",
      "[CV 8/10; 46/100] START class_weight={0: 0.014545454545454545, 1: 1}............\n",
      "[CV 8/10; 46/100] END class_weight={0: 0.014545454545454545, 1: 1};, score=(train=0.880, test=0.883) total time=  11.1s\n",
      "[CV 3/10; 54/100] START class_weight={0: 0.015353535353535354, 1: 1}............\n",
      "[CV 3/10; 54/100] END class_weight={0: 0.015353535353535354, 1: 1};, score=(train=0.879, test=0.834) total time=  10.7s\n",
      "[CV 5/10; 61/100] START class_weight={0: 0.01606060606060606, 1: 1}.............\n",
      "[CV 5/10; 61/100] END class_weight={0: 0.01606060606060606, 1: 1};, score=(train=0.879, test=0.824) total time=   8.7s\n",
      "[CV 8/10; 66/100] START class_weight={0: 0.016565656565656565, 1: 1}............\n",
      "[CV 8/10; 66/100] END class_weight={0: 0.016565656565656565, 1: 1};, score=(train=0.877, test=0.872) total time=   9.9s\n",
      "[CV 4/10; 73/100] START class_weight={0: 0.017272727272727273, 1: 1}............\n",
      "[CV 4/10; 73/100] END class_weight={0: 0.017272727272727273, 1: 1};, score=(train=0.881, test=0.842) total time=   9.8s\n",
      "[CV 6/10; 79/100] START class_weight={0: 0.01787878787878788, 1: 1}.............\n",
      "[CV 6/10; 79/100] END class_weight={0: 0.01787878787878788, 1: 1};, score=(train=0.881, test=0.830) total time=  10.1s\n",
      "[CV 9/10; 85/100] START class_weight={0: 0.018484848484848486, 1: 1}............\n",
      "[CV 9/10; 85/100] END class_weight={0: 0.018484848484848486, 1: 1};, score=(train=0.883, test=0.842) total time=   9.8s\n",
      "[CV 5/10; 92/100] START class_weight={0: 0.01919191919191919, 1: 1}.............\n",
      "[CV 5/10; 92/100] END class_weight={0: 0.01919191919191919, 1: 1};, score=(train=0.881, test=0.831) total time=   8.9s\n",
      "[CV 4/10; 98/100] START class_weight={0: 0.0197979797979798, 1: 1}..............\n",
      "[CV 4/10; 98/100] END class_weight={0: 0.0197979797979798, 1: 1};, score=(train=0.884, test=0.844) total time=   8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 4/10] START class_weight={0: 0.0023333333333333335, 1: 1}.............\n",
      "[CV 7/10; 4/10] END class_weight={0: 0.0023333333333333335, 1: 1};, score=(train=0.876, test=0.851) total time=   9.0s\n",
      "[CV 5/10; 2/100] START class_weight={0: 0.001090909090909091, 1: 1}.............\n",
      "[CV 5/10; 2/100] END class_weight={0: 0.001090909090909091, 1: 1};, score=(train=0.876, test=0.853) total time=   7.7s\n",
      "[CV 9/10; 9/100] START class_weight={0: 0.0017272727272727275, 1: 1}............\n",
      "[CV 9/10; 9/100] END class_weight={0: 0.0017272727272727275, 1: 1};, score=(train=0.878, test=0.832) total time=   9.2s\n",
      "[CV 1/10; 18/100] START class_weight={0: 0.0025454545454545456, 1: 1}...........\n",
      "[CV 1/10; 18/100] END class_weight={0: 0.0025454545454545456, 1: 1};, score=(train=0.883, test=0.846) total time=   8.0s\n",
      "[CV 5/10; 23/100] START class_weight={0: 0.003, 1: 1}...........................\n",
      "[CV 5/10; 23/100] END class_weight={0: 0.003, 1: 1};, score=(train=0.878, test=0.831) total time=   6.5s\n",
      "[CV 1/10; 28/100] START class_weight={0: 0.003454545454545455, 1: 1}............\n",
      "[CV 1/10; 28/100] END class_weight={0: 0.003454545454545455, 1: 1};, score=(train=0.881, test=0.840) total time=   6.5s\n",
      "[CV 8/10; 33/100] START class_weight={0: 0.003909090909090909, 1: 1}............\n",
      "[CV 8/10; 33/100] END class_weight={0: 0.003909090909090909, 1: 1};, score=(train=0.877, test=0.864) total time=   7.8s\n",
      "[CV 8/10; 39/100] START class_weight={0: 0.004454545454545455, 1: 1}............\n",
      "[CV 8/10; 39/100] END class_weight={0: 0.004454545454545455, 1: 1};, score=(train=0.878, test=0.864) total time=   8.7s\n",
      "[CV 9/10; 45/100] START class_weight={0: 0.005, 1: 1}...........................\n",
      "[CV 9/10; 45/100] END class_weight={0: 0.005, 1: 1};, score=(train=0.881, test=0.848) total time=   8.6s\n",
      "[CV 2/10; 52/100] START class_weight={0: 0.005636363636363636, 1: 1}............\n",
      "[CV 2/10; 52/100] END class_weight={0: 0.005636363636363636, 1: 1};, score=(train=0.880, test=0.825) total time=  10.6s\n",
      "[CV 6/10; 59/100] START class_weight={0: 0.006272727272727274, 1: 1}............\n",
      "[CV 6/10; 59/100] END class_weight={0: 0.006272727272727274, 1: 1};, score=(train=0.879, test=0.836) total time=   8.6s\n",
      "[CV 7/10; 65/100] START class_weight={0: 0.006818181818181819, 1: 1}............\n",
      "[CV 7/10; 65/100] END class_weight={0: 0.006818181818181819, 1: 1};, score=(train=0.877, test=0.864) total time=   9.5s\n",
      "[CV 7/10; 72/100] START class_weight={0: 0.007454545454545455, 1: 1}............\n",
      "[CV 7/10; 72/100] END class_weight={0: 0.007454545454545455, 1: 1};, score=(train=0.877, test=0.864) total time=   8.5s\n",
      "[CV 5/10; 78/100] START class_weight={0: 0.008, 1: 1}...........................\n",
      "[CV 5/10; 78/100] END class_weight={0: 0.008, 1: 1};, score=(train=0.880, test=0.831) total time=  10.3s\n",
      "[CV 5/10; 86/100] START class_weight={0: 0.008727272727272728, 1: 1}............\n",
      "[CV 5/10; 86/100] END class_weight={0: 0.008727272727272728, 1: 1};, score=(train=0.880, test=0.831) total time=  10.3s\n",
      "[CV 4/10; 93/100] START class_weight={0: 0.009363636363636366, 1: 1}............\n",
      "[CV 4/10; 93/100] END class_weight={0: 0.009363636363636366, 1: 1};, score=(train=0.879, test=0.833) total time=  11.9s\n",
      "[CV 8/10; 100/100] START class_weight={0: 0.01, 1: 1}...........................\n",
      "[CV 8/10; 100/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.878, test=0.860) total time=   6.4s\n",
      "[CV 4/10; 7/100] START class_weight={0: 0.010606060606060607, 1: 1}.............\n",
      "[CV 4/10; 7/100] END class_weight={0: 0.010606060606060607, 1: 1};, score=(train=0.876, test=0.836) total time=   8.7s\n",
      "[CV 6/10; 9/100] START class_weight={0: 0.010808080808080808, 1: 1}.............\n",
      "[CV 6/10; 9/100] END class_weight={0: 0.010808080808080808, 1: 1};, score=(train=0.879, test=0.829) total time=   8.7s\n",
      "[CV 4/10; 15/100] START class_weight={0: 0.011414141414141415, 1: 1}............\n",
      "[CV 4/10; 15/100] END class_weight={0: 0.011414141414141415, 1: 1};, score=(train=0.876, test=0.838) total time=   9.7s\n",
      "[CV 10/10; 21/100] START class_weight={0: 0.012020202020202021, 1: 1}...........\n",
      "[CV 10/10; 21/100] END class_weight={0: 0.012020202020202021, 1: 1};, score=(train=0.878, test=0.865) total time=  11.5s\n",
      "[CV 1/10; 30/100] START class_weight={0: 0.01292929292929293, 1: 1}.............\n",
      "[CV 1/10; 30/100] END class_weight={0: 0.01292929292929293, 1: 1};, score=(train=0.878, test=0.866) total time=  11.3s\n",
      "[CV 5/10; 37/100] START class_weight={0: 0.013636363636363637, 1: 1}............\n",
      "[CV 5/10; 37/100] END class_weight={0: 0.013636363636363637, 1: 1};, score=(train=0.879, test=0.824) total time=   7.2s\n",
      "[CV 8/10; 41/100] START class_weight={0: 0.01404040404040404, 1: 1}.............\n",
      "[CV 8/10; 41/100] END class_weight={0: 0.01404040404040404, 1: 1};, score=(train=0.880, test=0.884) total time=   9.5s\n",
      "[CV 9/10; 47/100] START class_weight={0: 0.014646464646464647, 1: 1}............\n",
      "[CV 9/10; 47/100] END class_weight={0: 0.014646464646464647, 1: 1};, score=(train=0.880, test=0.837) total time=  10.0s\n",
      "[CV 5/10; 54/100] START class_weight={0: 0.015353535353535354, 1: 1}............\n",
      "[CV 5/10; 54/100] END class_weight={0: 0.015353535353535354, 1: 1};, score=(train=0.882, test=0.839) total time=   8.9s\n",
      "[CV 5/10; 60/100] START class_weight={0: 0.01595959595959596, 1: 1}.............\n",
      "[CV 5/10; 60/100] END class_weight={0: 0.01595959595959596, 1: 1};, score=(train=0.882, test=0.839) total time=  10.4s\n",
      "[CV 1/10; 67/100] START class_weight={0: 0.016666666666666666, 1: 1}............\n",
      "[CV 1/10; 67/100] END class_weight={0: 0.016666666666666666, 1: 1};, score=(train=0.878, test=0.851) total time=   9.0s\n",
      "[CV 8/10; 72/100] START class_weight={0: 0.01717171717171717, 1: 1}.............\n",
      "[CV 8/10; 72/100] END class_weight={0: 0.01717171717171717, 1: 1};, score=(train=0.879, test=0.880) total time=   8.7s\n",
      "[CV 5/10; 78/100] START class_weight={0: 0.017777777777777778, 1: 1}............\n",
      "[CV 5/10; 78/100] END class_weight={0: 0.017777777777777778, 1: 1};, score=(train=0.881, test=0.826) total time=   9.8s\n",
      "[CV 5/10; 85/100] START class_weight={0: 0.018484848484848486, 1: 1}............\n",
      "[CV 5/10; 85/100] END class_weight={0: 0.018484848484848486, 1: 1};, score=(train=0.880, test=0.829) total time=   9.3s\n",
      "[CV 3/10; 91/100] START class_weight={0: 0.01909090909090909, 1: 1}.............\n",
      "[CV 3/10; 91/100] END class_weight={0: 0.01909090909090909, 1: 1};, score=(train=0.880, test=0.828) total time=  10.2s\n",
      "[CV 8/10; 97/100] START class_weight={0: 0.0196969696969697, 1: 1}..............\n",
      "[CV 8/10; 97/100] END class_weight={0: 0.0196969696969697, 1: 1};, score=(train=0.879, test=0.885) total time=   9.8s\n",
      "[CV 7/10; 3/10] START class_weight={0: 0.001888888888888889, 1: 1}..............\n",
      "[CV 7/10; 3/10] END class_weight={0: 0.001888888888888889, 1: 1};, score=(train=0.873, test=0.854) total time=   8.4s\n",
      "[CV 7/10; 1/100] START class_weight={0: 0.001, 1: 1}............................\n",
      "[CV 7/10; 1/100] END class_weight={0: 0.001, 1: 1};, score=(train=0.873, test=0.846) total time=   9.2s\n",
      "[CV 9/10; 12/100] START class_weight={0: 0.002, 1: 1}...........................\n",
      "[CV 9/10; 12/100] END class_weight={0: 0.002, 1: 1};, score=(train=0.879, test=0.836) total time=   9.5s\n",
      "[CV 5/10; 19/100] START class_weight={0: 0.0026363636363636363, 1: 1}...........\n",
      "[CV 5/10; 19/100] END class_weight={0: 0.0026363636363636363, 1: 1};, score=(train=0.879, test=0.839) total time=   9.6s\n",
      "[CV 6/10; 26/100] START class_weight={0: 0.003272727272727273, 1: 1}............\n",
      "[CV 6/10; 26/100] END class_weight={0: 0.003272727272727273, 1: 1};, score=(train=0.876, test=0.834) total time=  11.4s\n",
      "[CV 6/10; 34/100] START class_weight={0: 0.004, 1: 1}...........................\n",
      "[CV 6/10; 34/100] END class_weight={0: 0.004, 1: 1};, score=(train=0.880, test=0.832) total time=  10.2s\n",
      "[CV 3/10; 42/100] START class_weight={0: 0.0047272727272727275, 1: 1}...........\n",
      "[CV 3/10; 42/100] END class_weight={0: 0.0047272727272727275, 1: 1};, score=(train=0.879, test=0.844) total time=   7.7s\n",
      "[CV 4/10; 48/100] START class_weight={0: 0.0052727272727272735, 1: 1}...........\n",
      "[CV 4/10; 48/100] END class_weight={0: 0.0052727272727272735, 1: 1};, score=(train=0.879, test=0.843) total time=   7.9s\n",
      "[CV 6/10; 54/100] START class_weight={0: 0.005818181818181819, 1: 1}............\n",
      "[CV 6/10; 54/100] END class_weight={0: 0.005818181818181819, 1: 1};, score=(train=0.880, test=0.838) total time=  10.1s\n",
      "[CV 8/10; 61/100] START class_weight={0: 0.006454545454545455, 1: 1}............\n",
      "[CV 8/10; 61/100] END class_weight={0: 0.006454545454545455, 1: 1};, score=(train=0.876, test=0.860) total time=  10.5s\n",
      "[CV 5/10; 69/100] START class_weight={0: 0.0071818181818181824, 1: 1}...........\n",
      "[CV 5/10; 69/100] END class_weight={0: 0.0071818181818181824, 1: 1};, score=(train=0.880, test=0.831) total time=  11.6s\n",
      "[CV 10/10; 76/100] START class_weight={0: 0.007818181818181818, 1: 1}...........\n",
      "[CV 10/10; 76/100] END class_weight={0: 0.007818181818181818, 1: 1};, score=(train=0.876, test=0.849) total time=   9.6s\n",
      "[CV 8/10; 83/100] START class_weight={0: 0.008454545454545454, 1: 1}............\n",
      "[CV 8/10; 83/100] END class_weight={0: 0.008454545454545454, 1: 1};, score=(train=0.874, test=0.869) total time=   9.5s\n",
      "[CV 4/10; 90/100] START class_weight={0: 0.00909090909090909, 1: 1}.............\n",
      "[CV 4/10; 90/100] END class_weight={0: 0.00909090909090909, 1: 1};, score=(train=0.879, test=0.833) total time=  12.3s\n",
      "[CV 2/10; 99/100] START class_weight={0: 0.009909090909090909, 1: 1}............\n",
      "[CV 2/10; 99/100] END class_weight={0: 0.009909090909090909, 1: 1};, score=(train=0.881, test=0.853) total time=   8.3s\n",
      "[CV 8/10; 5/100] START class_weight={0: 0.010404040404040405, 1: 1}.............\n",
      "[CV 8/10; 5/100] END class_weight={0: 0.010404040404040405, 1: 1};, score=(train=0.878, test=0.860) total time=   9.2s\n",
      "[CV 1/10; 10/100] START class_weight={0: 0.01090909090909091, 1: 1}.............\n",
      "[CV 1/10; 10/100] END class_weight={0: 0.01090909090909091, 1: 1};, score=(train=0.878, test=0.844) total time=  10.8s\n",
      "[CV 6/10; 17/100] START class_weight={0: 0.011616161616161616, 1: 1}............\n",
      "[CV 6/10; 17/100] END class_weight={0: 0.011616161616161616, 1: 1};, score=(train=0.882, test=0.835) total time=   7.2s\n",
      "[CV 1/10; 22/100] START class_weight={0: 0.012121212121212121, 1: 1}............\n",
      "[CV 1/10; 22/100] END class_weight={0: 0.012121212121212121, 1: 1};, score=(train=0.877, test=0.864) total time=  11.7s\n",
      "[CV 8/10; 29/100] START class_weight={0: 0.012828282828282828, 1: 1}............\n",
      "[CV 8/10; 29/100] END class_weight={0: 0.012828282828282828, 1: 1};, score=(train=0.879, test=0.885) total time=   8.9s\n",
      "[CV 9/10; 35/100] START class_weight={0: 0.013434343434343434, 1: 1}............\n",
      "[CV 9/10; 35/100] END class_weight={0: 0.013434343434343434, 1: 1};, score=(train=0.880, test=0.837) total time=   9.0s\n",
      "[CV 7/10; 41/100] START class_weight={0: 0.01404040404040404, 1: 1}.............\n",
      "[CV 7/10; 41/100] END class_weight={0: 0.01404040404040404, 1: 1};, score=(train=0.878, test=0.862) total time=   8.7s\n",
      "[CV 2/10; 47/100] START class_weight={0: 0.014646464646464647, 1: 1}............\n",
      "[CV 2/10; 47/100] END class_weight={0: 0.014646464646464647, 1: 1};, score=(train=0.883, test=0.847) total time=  12.0s\n",
      "[CV 3/10; 55/100] START class_weight={0: 0.015454545454545455, 1: 1}............\n",
      "[CV 3/10; 55/100] END class_weight={0: 0.015454545454545455, 1: 1};, score=(train=0.876, test=0.838) total time=   9.7s\n",
      "[CV 4/10; 61/100] START class_weight={0: 0.01606060606060606, 1: 1}.............\n",
      "[CV 4/10; 61/100] END class_weight={0: 0.01606060606060606, 1: 1};, score=(train=0.881, test=0.842) total time=  11.9s\n",
      "[CV 3/10; 69/100] START class_weight={0: 0.01686868686868687, 1: 1}.............\n",
      "[CV 3/10; 69/100] END class_weight={0: 0.01686868686868687, 1: 1};, score=(train=0.879, test=0.830) total time=  11.7s\n",
      "[CV 8/10; 76/100] START class_weight={0: 0.017575757575757578, 1: 1}............\n",
      "[CV 8/10; 76/100] END class_weight={0: 0.017575757575757578, 1: 1};, score=(train=0.879, test=0.880) total time=   9.8s\n",
      "[CV 4/10; 83/100] START class_weight={0: 0.018282828282828283, 1: 1}............\n",
      "[CV 4/10; 83/100] END class_weight={0: 0.018282828282828283, 1: 1};, score=(train=0.881, test=0.842) total time=  13.3s\n",
      "[CV 9/10; 91/100] START class_weight={0: 0.01909090909090909, 1: 1}.............\n",
      "[CV 9/10; 91/100] END class_weight={0: 0.01909090909090909, 1: 1};, score=(train=0.883, test=0.842) total time=   9.5s\n",
      "[CV 10/10; 97/100] START class_weight={0: 0.0196969696969697, 1: 1}.............\n",
      "[CV 10/10; 97/100] END class_weight={0: 0.0196969696969697, 1: 1};, score=(train=0.879, test=0.869) total time=   9.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10; 4/10] START class_weight={0: 0.0023333333333333335, 1: 1}.............\n",
      "[CV 6/10; 4/10] END class_weight={0: 0.0023333333333333335, 1: 1};, score=(train=0.880, test=0.830) total time=   6.5s\n",
      "[CV 10/10; 7/10] START class_weight={0: 0.003666666666666667, 1: 1}.............\n",
      "[CV 10/10; 7/10] END class_weight={0: 0.003666666666666667, 1: 1};, score=(train=0.879, test=0.858) total time=   6.5s\n",
      "[CV 5/10; 4/100] START class_weight={0: 0.0012727272727272728, 1: 1}............\n",
      "[CV 5/10; 4/100] END class_weight={0: 0.0012727272727272728, 1: 1};, score=(train=0.876, test=0.829) total time=   7.1s\n",
      "[CV 7/10; 8/100] START class_weight={0: 0.0016363636363636363, 1: 1}............\n",
      "[CV 7/10; 8/100] END class_weight={0: 0.0016363636363636363, 1: 1};, score=(train=0.875, test=0.858) total time=   8.1s\n",
      "[CV 8/10; 15/100] START class_weight={0: 0.0022727272727272726, 1: 1}...........\n",
      "[CV 8/10; 15/100] END class_weight={0: 0.0022727272727272726, 1: 1};, score=(train=0.879, test=0.865) total time=   7.6s\n",
      "[CV 7/10; 21/100] START class_weight={0: 0.0028181818181818186, 1: 1}...........\n",
      "[CV 7/10; 21/100] END class_weight={0: 0.0028181818181818186, 1: 1};, score=(train=0.876, test=0.863) total time=   8.7s\n",
      "[CV 8/10; 28/100] START class_weight={0: 0.003454545454545455, 1: 1}............\n",
      "[CV 8/10; 28/100] END class_weight={0: 0.003454545454545455, 1: 1};, score=(train=0.877, test=0.864) total time=   8.2s\n",
      "[CV 7/10; 34/100] START class_weight={0: 0.004, 1: 1}...........................\n",
      "[CV 7/10; 34/100] END class_weight={0: 0.004, 1: 1};, score=(train=0.877, test=0.865) total time=   7.8s\n",
      "[CV 1/10; 41/100] START class_weight={0: 0.004636363636363636, 1: 1}............\n",
      "[CV 1/10; 41/100] END class_weight={0: 0.004636363636363636, 1: 1};, score=(train=0.879, test=0.838) total time=   7.0s\n",
      "[CV 1/10; 47/100] START class_weight={0: 0.005181818181818182, 1: 1}............\n",
      "[CV 1/10; 47/100] END class_weight={0: 0.005181818181818182, 1: 1};, score=(train=0.879, test=0.847) total time=   9.6s\n",
      "[CV 3/10; 54/100] START class_weight={0: 0.005818181818181819, 1: 1}............\n",
      "[CV 3/10; 54/100] END class_weight={0: 0.005818181818181819, 1: 1};, score=(train=0.881, test=0.843) total time=   8.8s\n",
      "[CV 2/10; 60/100] START class_weight={0: 0.006363636363636364, 1: 1}............\n",
      "[CV 2/10; 60/100] END class_weight={0: 0.006363636363636364, 1: 1};, score=(train=0.881, test=0.825) total time=   9.9s\n",
      "[CV 7/10; 67/100] START class_weight={0: 0.007, 1: 1}...........................\n",
      "[CV 7/10; 67/100] END class_weight={0: 0.007, 1: 1};, score=(train=0.877, test=0.864) total time=   8.2s\n",
      "[CV 8/10; 73/100] START class_weight={0: 0.007545454545454546, 1: 1}............\n",
      "[CV 8/10; 73/100] END class_weight={0: 0.007545454545454546, 1: 1};, score=(train=0.874, test=0.869) total time=   9.5s\n",
      "[CV 5/10; 80/100] START class_weight={0: 0.008181818181818182, 1: 1}............\n",
      "[CV 5/10; 80/100] END class_weight={0: 0.008181818181818182, 1: 1};, score=(train=0.880, test=0.832) total time=  10.9s\n",
      "[CV 10/10; 87/100] START class_weight={0: 0.008818181818181819, 1: 1}...........\n",
      "[CV 10/10; 87/100] END class_weight={0: 0.008818181818181819, 1: 1};, score=(train=0.877, test=0.853) total time=   8.6s\n",
      "[CV 10/10; 93/100] START class_weight={0: 0.009363636363636366, 1: 1}...........\n",
      "[CV 10/10; 93/100] END class_weight={0: 0.009363636363636366, 1: 1};, score=(train=0.876, test=0.867) total time=   9.6s\n",
      "[CV 10/10; 99/100] START class_weight={0: 0.009909090909090909, 1: 1}...........\n",
      "[CV 10/10; 99/100] END class_weight={0: 0.009909090909090909, 1: 1};, score=(train=0.878, test=0.865) total time=   7.4s\n",
      "[CV 8/10; 6/100] START class_weight={0: 0.010505050505050505, 1: 1}.............\n",
      "[CV 8/10; 6/100] END class_weight={0: 0.010505050505050505, 1: 1};, score=(train=0.878, test=0.868) total time=  12.1s\n",
      "[CV 5/10; 13/100] START class_weight={0: 0.011212121212121211, 1: 1}............\n",
      "[CV 5/10; 13/100] END class_weight={0: 0.011212121212121211, 1: 1};, score=(train=0.878, test=0.833) total time=  10.6s\n",
      "[CV 10/10; 19/100] START class_weight={0: 0.011818181818181818, 1: 1}...........\n",
      "[CV 10/10; 19/100] END class_weight={0: 0.011818181818181818, 1: 1};, score=(train=0.874, test=0.857) total time=   8.8s\n",
      "[CV 6/10; 25/100] START class_weight={0: 0.012424242424242424, 1: 1}............\n",
      "[CV 6/10; 25/100] END class_weight={0: 0.012424242424242424, 1: 1};, score=(train=0.880, test=0.832) total time=   9.6s\n",
      "[CV 10/10; 31/100] START class_weight={0: 0.013030303030303031, 1: 1}...........\n",
      "[CV 10/10; 31/100] END class_weight={0: 0.013030303030303031, 1: 1};, score=(train=0.877, test=0.860) total time=   9.9s\n",
      "[CV 3/10; 38/100] START class_weight={0: 0.013737373737373737, 1: 1}............\n",
      "[CV 3/10; 38/100] END class_weight={0: 0.013737373737373737, 1: 1};, score=(train=0.876, test=0.838) total time=  10.4s\n",
      "[CV 10/10; 44/100] START class_weight={0: 0.014343434343434344, 1: 1}...........\n",
      "[CV 10/10; 44/100] END class_weight={0: 0.014343434343434344, 1: 1};, score=(train=0.878, test=0.861) total time=   8.2s\n",
      "[CV 7/10; 50/100] START class_weight={0: 0.014949494949494949, 1: 1}............\n",
      "[CV 7/10; 50/100] END class_weight={0: 0.014949494949494949, 1: 1};, score=(train=0.877, test=0.862) total time=   7.8s\n",
      "[CV 8/10; 55/100] START class_weight={0: 0.015454545454545455, 1: 1}............\n",
      "[CV 8/10; 55/100] END class_weight={0: 0.015454545454545455, 1: 1};, score=(train=0.880, test=0.883) total time=   9.4s\n",
      "[CV 7/10; 61/100] START class_weight={0: 0.01606060606060606, 1: 1}.............\n",
      "[CV 7/10; 61/100] END class_weight={0: 0.01606060606060606, 1: 1};, score=(train=0.881, test=0.853) total time=  10.0s\n",
      "[CV 7/10; 67/100] START class_weight={0: 0.016666666666666666, 1: 1}............\n",
      "[CV 7/10; 67/100] END class_weight={0: 0.016666666666666666, 1: 1};, score=(train=0.881, test=0.853) total time=   8.3s\n",
      "[CV 3/10; 73/100] START class_weight={0: 0.017272727272727273, 1: 1}............\n",
      "[CV 3/10; 73/100] END class_weight={0: 0.017272727272727273, 1: 1};, score=(train=0.879, test=0.830) total time=  10.6s\n",
      "[CV 9/10; 79/100] START class_weight={0: 0.01787878787878788, 1: 1}.............\n",
      "[CV 9/10; 79/100] END class_weight={0: 0.01787878787878788, 1: 1};, score=(train=0.882, test=0.840) total time=   9.8s\n",
      "[CV 1/10; 86/100] START class_weight={0: 0.018585858585858588, 1: 1}............\n",
      "[CV 1/10; 86/100] END class_weight={0: 0.018585858585858588, 1: 1};, score=(train=0.879, test=0.860) total time=  11.4s\n",
      "[CV 5/10; 93/100] START class_weight={0: 0.019292929292929292, 1: 1}............\n",
      "[CV 5/10; 93/100] END class_weight={0: 0.019292929292929292, 1: 1};, score=(train=0.883, test=0.838) total time=   7.5s\n",
      "[CV 8/10; 98/100] START class_weight={0: 0.0197979797979798, 1: 1}..............\n",
      "[CV 8/10; 98/100] END class_weight={0: 0.0197979797979798, 1: 1};, score=(train=0.879, test=0.885) total time=   8.4s\n",
      "[CV 6/10; 3/10] START class_weight={0: 0.001888888888888889, 1: 1}..............\n",
      "[CV 6/10; 3/10] END class_weight={0: 0.001888888888888889, 1: 1};, score=(train=0.882, test=0.834) total time=   6.9s\n",
      "[CV 4/10; 9/10] START class_weight={0: 0.004555555555555556, 1: 1}..............\n",
      "[CV 4/10; 9/10] END class_weight={0: 0.004555555555555556, 1: 1};, score=(train=0.878, test=0.853) total time=   6.6s\n",
      "[CV 2/10; 7/100] START class_weight={0: 0.0015454545454545456, 1: 1}............\n",
      "[CV 2/10; 7/100] END class_weight={0: 0.0015454545454545456, 1: 1};, score=(train=0.882, test=0.847) total time=   7.5s\n",
      "[CV 5/10; 10/100] START class_weight={0: 0.0018181818181818182, 1: 1}...........\n",
      "[CV 5/10; 10/100] END class_weight={0: 0.0018181818181818182, 1: 1};, score=(train=0.878, test=0.828) total time=   6.6s\n",
      "[CV 10/10; 14/100] START class_weight={0: 0.002181818181818182, 1: 1}...........\n",
      "[CV 10/10; 14/100] END class_weight={0: 0.002181818181818182, 1: 1};, score=(train=0.876, test=0.853) total time=   9.5s\n",
      "[CV 6/10; 22/100] START class_weight={0: 0.0029090909090909093, 1: 1}...........\n",
      "[CV 6/10; 22/100] END class_weight={0: 0.0029090909090909093, 1: 1};, score=(train=0.880, test=0.830) total time=   7.3s\n",
      "[CV 10/10; 27/100] START class_weight={0: 0.003363636363636364, 1: 1}...........\n",
      "[CV 10/10; 27/100] END class_weight={0: 0.003363636363636364, 1: 1};, score=(train=0.878, test=0.855) total time=   9.3s\n",
      "[CV 4/10; 35/100] START class_weight={0: 0.004090909090909091, 1: 1}............\n",
      "[CV 4/10; 35/100] END class_weight={0: 0.004090909090909091, 1: 1};, score=(train=0.879, test=0.849) total time=  10.1s\n",
      "[CV 2/10; 43/100] START class_weight={0: 0.004818181818181819, 1: 1}............\n",
      "[CV 2/10; 43/100] END class_weight={0: 0.004818181818181819, 1: 1};, score=(train=0.880, test=0.833) total time=   9.8s\n",
      "[CV 4/10; 50/100] START class_weight={0: 0.005454545454545455, 1: 1}............\n",
      "[CV 4/10; 50/100] END class_weight={0: 0.005454545454545455, 1: 1};, score=(train=0.879, test=0.843) total time=   8.3s\n",
      "[CV 8/10; 56/100] START class_weight={0: 0.006, 1: 1}...........................\n",
      "[CV 8/10; 56/100] END class_weight={0: 0.006, 1: 1};, score=(train=0.877, test=0.863) total time=   8.6s\n",
      "[CV 5/10; 63/100] START class_weight={0: 0.006636363636363637, 1: 1}............\n",
      "[CV 5/10; 63/100] END class_weight={0: 0.006636363636363637, 1: 1};, score=(train=0.880, test=0.833) total time=   9.3s\n",
      "[CV 1/10; 70/100] START class_weight={0: 0.007272727272727274, 1: 1}............\n",
      "[CV 1/10; 70/100] END class_weight={0: 0.007272727272727274, 1: 1};, score=(train=0.877, test=0.846) total time=   9.6s\n",
      "[CV 5/10; 76/100] START class_weight={0: 0.007818181818181818, 1: 1}............\n",
      "[CV 5/10; 76/100] END class_weight={0: 0.007818181818181818, 1: 1};, score=(train=0.880, test=0.831) total time=   9.3s\n",
      "[CV 1/10; 83/100] START class_weight={0: 0.008454545454545454, 1: 1}............\n",
      "[CV 1/10; 83/100] END class_weight={0: 0.008454545454545454, 1: 1};, score=(train=0.878, test=0.843) total time=  10.2s\n",
      "[CV 10/10; 89/100] START class_weight={0: 0.009000000000000001, 1: 1}...........\n",
      "[CV 10/10; 89/100] END class_weight={0: 0.009000000000000001, 1: 1};, score=(train=0.874, test=0.845) total time=   9.5s\n",
      "[CV 9/10; 96/100] START class_weight={0: 0.009636363636363637, 1: 1}............\n",
      "[CV 9/10; 96/100] END class_weight={0: 0.009636363636363637, 1: 1};, score=(train=0.881, test=0.841) total time=  10.1s\n",
      "[CV 8/10; 3/100] START class_weight={0: 0.010202020202020202, 1: 1}.............\n",
      "[CV 8/10; 3/100] END class_weight={0: 0.010202020202020202, 1: 1};, score=(train=0.878, test=0.868) total time=   8.8s\n",
      "[CV 5/10; 9/100] START class_weight={0: 0.010808080808080808, 1: 1}.............\n",
      "[CV 5/10; 9/100] END class_weight={0: 0.010808080808080808, 1: 1};, score=(train=0.877, test=0.839) total time=   9.9s\n",
      "[CV 8/10; 16/100] START class_weight={0: 0.011515151515151515, 1: 1}............\n",
      "[CV 8/10; 16/100] END class_weight={0: 0.011515151515151515, 1: 1};, score=(train=0.878, test=0.860) total time=  10.0s\n",
      "[CV 2/10; 23/100] START class_weight={0: 0.012222222222222223, 1: 1}............\n",
      "[CV 2/10; 23/100] END class_weight={0: 0.012222222222222223, 1: 1};, score=(train=0.878, test=0.850) total time=   9.9s\n",
      "[CV 5/10; 29/100] START class_weight={0: 0.012828282828282828, 1: 1}............\n",
      "[CV 5/10; 29/100] END class_weight={0: 0.012828282828282828, 1: 1};, score=(train=0.880, test=0.829) total time=  10.5s\n",
      "[CV 9/10; 36/100] START class_weight={0: 0.013535353535353536, 1: 1}............\n",
      "[CV 9/10; 36/100] END class_weight={0: 0.013535353535353536, 1: 1};, score=(train=0.880, test=0.837) total time=  10.7s\n",
      "[CV 1/10; 44/100] START class_weight={0: 0.014343434343434344, 1: 1}............\n",
      "[CV 1/10; 44/100] END class_weight={0: 0.014343434343434344, 1: 1};, score=(train=0.880, test=0.870) total time=  10.0s\n",
      "[CV 5/10; 50/100] START class_weight={0: 0.014949494949494949, 1: 1}............\n",
      "[CV 5/10; 50/100] END class_weight={0: 0.014949494949494949, 1: 1};, score=(train=0.880, test=0.829) total time=   7.7s\n",
      "[CV 7/10; 55/100] START class_weight={0: 0.015454545454545455, 1: 1}............\n",
      "[CV 7/10; 55/100] END class_weight={0: 0.015454545454545455, 1: 1};, score=(train=0.878, test=0.861) total time=   8.1s\n",
      "[CV 6/10; 60/100] START class_weight={0: 0.01595959595959596, 1: 1}.............\n",
      "[CV 6/10; 60/100] END class_weight={0: 0.01595959595959596, 1: 1};, score=(train=0.881, test=0.826) total time=   8.5s\n",
      "[CV 3/10; 66/100] START class_weight={0: 0.016565656565656565, 1: 1}............\n",
      "[CV 3/10; 66/100] END class_weight={0: 0.016565656565656565, 1: 1};, score=(train=0.879, test=0.830) total time=  11.2s\n",
      "[CV 6/10; 73/100] START class_weight={0: 0.017272727272727273, 1: 1}............\n",
      "[CV 6/10; 73/100] END class_weight={0: 0.017272727272727273, 1: 1};, score=(train=0.881, test=0.830) total time=  11.5s\n",
      "[CV 8/10; 80/100] START class_weight={0: 0.017979797979797978, 1: 1}............\n",
      "[CV 8/10; 80/100] END class_weight={0: 0.017979797979797978, 1: 1};, score=(train=0.880, test=0.872) total time=  10.4s\n",
      "[CV 5/10; 87/100] START class_weight={0: 0.01868686868686869, 1: 1}.............\n",
      "[CV 5/10; 87/100] END class_weight={0: 0.01868686868686869, 1: 1};, score=(train=0.883, test=0.836) total time=   7.1s\n",
      "[CV 3/10; 92/100] START class_weight={0: 0.01919191919191919, 1: 1}.............\n",
      "[CV 3/10; 92/100] END class_weight={0: 0.01919191919191919, 1: 1};, score=(train=0.882, test=0.833) total time=   9.8s\n",
      "[CV 9/10; 98/100] START class_weight={0: 0.0197979797979798, 1: 1}..............\n",
      "[CV 9/10; 98/100] END class_weight={0: 0.0197979797979798, 1: 1};, score=(train=0.883, test=0.842) total time=   8.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 2/10] START class_weight={0: 0.0014444444444444444, 1: 1}.............\n",
      "[CV 4/10; 2/10] END class_weight={0: 0.0014444444444444444, 1: 1};, score=(train=0.879, test=0.826) total time=   7.4s\n",
      "[CV 6/10; 9/10] START class_weight={0: 0.004555555555555556, 1: 1}..............\n",
      "[CV 6/10; 9/10] END class_weight={0: 0.004555555555555556, 1: 1};, score=(train=0.880, test=0.833) total time=   6.5s\n",
      "[CV 9/10; 6/100] START class_weight={0: 0.0014545454545454547, 1: 1}............\n",
      "[CV 9/10; 6/100] END class_weight={0: 0.0014545454545454547, 1: 1};, score=(train=0.878, test=0.833) total time=   6.7s\n",
      "[CV 1/10; 9/100] START class_weight={0: 0.0017272727272727275, 1: 1}............\n",
      "[CV 1/10; 9/100] END class_weight={0: 0.0017272727272727275, 1: 1};, score=(train=0.882, test=0.839) total time=   6.6s\n",
      "[CV 5/10; 14/100] START class_weight={0: 0.002181818181818182, 1: 1}............\n",
      "[CV 5/10; 14/100] END class_weight={0: 0.002181818181818182, 1: 1};, score=(train=0.878, test=0.836) total time=   6.3s\n",
      "[CV 3/10; 20/100] START class_weight={0: 0.0027272727272727275, 1: 1}...........\n",
      "[CV 3/10; 20/100] END class_weight={0: 0.0027272727272727275, 1: 1};, score=(train=0.878, test=0.839) total time=   7.4s\n",
      "[CV 2/10; 26/100] START class_weight={0: 0.003272727272727273, 1: 1}............\n",
      "[CV 2/10; 26/100] END class_weight={0: 0.003272727272727273, 1: 1};, score=(train=0.881, test=0.836) total time=   9.3s\n",
      "[CV 4/10; 33/100] START class_weight={0: 0.003909090909090909, 1: 1}............\n",
      "[CV 4/10; 33/100] END class_weight={0: 0.003909090909090909, 1: 1};, score=(train=0.880, test=0.854) total time=   7.1s\n",
      "[CV 3/10; 38/100] START class_weight={0: 0.004363636363636364, 1: 1}............\n",
      "[CV 3/10; 38/100] END class_weight={0: 0.004363636363636364, 1: 1};, score=(train=0.880, test=0.846) total time=  10.2s\n",
      "[CV 7/10; 45/100] START class_weight={0: 0.005, 1: 1}...........................\n",
      "[CV 7/10; 45/100] END class_weight={0: 0.005, 1: 1};, score=(train=0.876, test=0.861) total time=   8.1s\n",
      "[CV 6/10; 51/100] START class_weight={0: 0.005545454545454546, 1: 1}............\n",
      "[CV 6/10; 51/100] END class_weight={0: 0.005545454545454546, 1: 1};, score=(train=0.879, test=0.836) total time=   6.9s\n",
      "[CV 9/10; 56/100] START class_weight={0: 0.006, 1: 1}...........................\n",
      "[CV 9/10; 56/100] END class_weight={0: 0.006, 1: 1};, score=(train=0.882, test=0.843) total time=   7.6s\n",
      "[CV 6/10; 62/100] START class_weight={0: 0.006545454545454546, 1: 1}............\n",
      "[CV 6/10; 62/100] END class_weight={0: 0.006545454545454546, 1: 1};, score=(train=0.879, test=0.837) total time=   8.5s\n",
      "[CV 7/10; 68/100] START class_weight={0: 0.007090909090909091, 1: 1}............\n",
      "[CV 7/10; 68/100] END class_weight={0: 0.007090909090909091, 1: 1};, score=(train=0.877, test=0.864) total time=   8.1s\n",
      "[CV 4/10; 74/100] START class_weight={0: 0.007636363636363637, 1: 1}............\n",
      "[CV 4/10; 74/100] END class_weight={0: 0.007636363636363637, 1: 1};, score=(train=0.877, test=0.841) total time=   8.9s\n",
      "[CV 7/10; 80/100] START class_weight={0: 0.008181818181818182, 1: 1}............\n",
      "[CV 7/10; 80/100] END class_weight={0: 0.008181818181818182, 1: 1};, score=(train=0.877, test=0.862) total time=   7.7s\n",
      "[CV 4/10; 86/100] START class_weight={0: 0.008727272727272728, 1: 1}............\n",
      "[CV 4/10; 86/100] END class_weight={0: 0.008727272727272728, 1: 1};, score=(train=0.877, test=0.841) total time=   9.1s\n",
      "[CV 3/10; 92/100] START class_weight={0: 0.009272727272727273, 1: 1}............\n",
      "[CV 3/10; 92/100] END class_weight={0: 0.009272727272727273, 1: 1};, score=(train=0.879, test=0.846) total time=   7.4s\n",
      "[CV 6/10; 97/100] START class_weight={0: 0.009727272727272727, 1: 1}............\n",
      "[CV 6/10; 97/100] END class_weight={0: 0.009727272727272727, 1: 1};, score=(train=0.878, test=0.839) total time=   8.7s\n",
      "[CV 4/10; 3/100] START class_weight={0: 0.010202020202020202, 1: 1}.............\n",
      "[CV 4/10; 3/100] END class_weight={0: 0.010202020202020202, 1: 1};, score=(train=0.879, test=0.843) total time=  10.4s\n",
      "[CV 3/10; 12/100] START class_weight={0: 0.011111111111111112, 1: 1}............\n",
      "[CV 3/10; 12/100] END class_weight={0: 0.011111111111111112, 1: 1};, score=(train=0.879, test=0.827) total time=  11.2s\n",
      "[CV 4/10; 19/100] START class_weight={0: 0.011818181818181818, 1: 1}............\n",
      "[CV 4/10; 19/100] END class_weight={0: 0.011818181818181818, 1: 1};, score=(train=0.876, test=0.836) total time=   8.5s\n",
      "[CV 5/10; 24/100] START class_weight={0: 0.012323232323232323, 1: 1}............\n",
      "[CV 5/10; 24/100] END class_weight={0: 0.012323232323232323, 1: 1};, score=(train=0.878, test=0.841) total time=   9.4s\n",
      "[CV 6/10; 30/100] START class_weight={0: 0.01292929292929293, 1: 1}.............\n",
      "[CV 6/10; 30/100] END class_weight={0: 0.01292929292929293, 1: 1};, score=(train=0.880, test=0.834) total time=   7.4s\n",
      "[CV 8/10; 34/100] START class_weight={0: 0.013333333333333332, 1: 1}............\n",
      "[CV 8/10; 34/100] END class_weight={0: 0.013333333333333332, 1: 1};, score=(train=0.880, test=0.883) total time=   8.7s\n",
      "[CV 10/10; 40/100] START class_weight={0: 0.013939393939393939, 1: 1}...........\n",
      "[CV 10/10; 40/100] END class_weight={0: 0.013939393939393939, 1: 1};, score=(train=0.878, test=0.861) total time=   9.7s\n",
      "[CV 3/10; 47/100] START class_weight={0: 0.014646464646464647, 1: 1}............\n",
      "[CV 3/10; 47/100] END class_weight={0: 0.014646464646464647, 1: 1};, score=(train=0.876, test=0.838) total time=   9.2s\n",
      "[CV 3/10; 53/100] START class_weight={0: 0.015252525252525254, 1: 1}............\n",
      "[CV 3/10; 53/100] END class_weight={0: 0.015252525252525254, 1: 1};, score=(train=0.876, test=0.838) total time=  10.2s\n",
      "[CV 8/10; 59/100] START class_weight={0: 0.015858585858585857, 1: 1}............\n",
      "[CV 8/10; 59/100] END class_weight={0: 0.015858585858585857, 1: 1};, score=(train=0.880, test=0.878) total time=   9.7s\n",
      "[CV 2/10; 66/100] START class_weight={0: 0.016565656565656565, 1: 1}............\n",
      "[CV 2/10; 66/100] END class_weight={0: 0.016565656565656565, 1: 1};, score=(train=0.878, test=0.843) total time=  10.9s\n",
      "[CV 1/10; 73/100] START class_weight={0: 0.017272727272727273, 1: 1}............\n",
      "[CV 1/10; 73/100] END class_weight={0: 0.017272727272727273, 1: 1};, score=(train=0.880, test=0.859) total time=  10.3s\n",
      "[CV 8/10; 79/100] START class_weight={0: 0.01787878787878788, 1: 1}.............\n",
      "[CV 8/10; 79/100] END class_weight={0: 0.01787878787878788, 1: 1};, score=(train=0.880, test=0.872) total time=  10.4s\n",
      "[CV 8/10; 86/100] START class_weight={0: 0.018585858585858588, 1: 1}............\n",
      "[CV 8/10; 86/100] END class_weight={0: 0.018585858585858588, 1: 1};, score=(train=0.879, test=0.884) total time=  10.3s\n",
      "[CV 4/10; 93/100] START class_weight={0: 0.019292929292929292, 1: 1}............\n",
      "[CV 4/10; 93/100] END class_weight={0: 0.019292929292929292, 1: 1};, score=(train=0.884, test=0.844) total time=   9.5s\n",
      "[CV 5/10; 99/100] START class_weight={0: 0.0198989898989899, 1: 1}..............\n",
      "[CV 5/10; 99/100] END class_weight={0: 0.0198989898989899, 1: 1};, score=(train=0.883, test=0.838) total time=   6.9s\n",
      "[CV 8/10; 6/10] START class_weight={0: 0.0032222222222222222, 1: 1}.............\n",
      "[CV 8/10; 6/10] END class_weight={0: 0.0032222222222222222, 1: 1};, score=(train=0.878, test=0.870) total time=   7.6s\n",
      "[CV 2/10; 1/100] START class_weight={0: 0.001, 1: 1}............................\n",
      "[CV 2/10; 1/100] END class_weight={0: 0.001, 1: 1};, score=(train=0.880, test=0.838) total time=   9.3s\n",
      "[CV 5/10; 12/100] START class_weight={0: 0.002, 1: 1}...........................\n",
      "[CV 5/10; 12/100] END class_weight={0: 0.002, 1: 1};, score=(train=0.878, test=0.836) total time=   9.2s\n",
      "[CV 8/10; 18/100] START class_weight={0: 0.0025454545454545456, 1: 1}...........\n",
      "[CV 8/10; 18/100] END class_weight={0: 0.0025454545454545456, 1: 1};, score=(train=0.878, test=0.865) total time=   8.8s\n",
      "[CV 4/10; 25/100] START class_weight={0: 0.003181818181818182, 1: 1}............\n",
      "[CV 4/10; 25/100] END class_weight={0: 0.003181818181818182, 1: 1};, score=(train=0.878, test=0.842) total time=  10.2s\n",
      "[CV 1/10; 33/100] START class_weight={0: 0.003909090909090909, 1: 1}............\n",
      "[CV 1/10; 33/100] END class_weight={0: 0.003909090909090909, 1: 1};, score=(train=0.880, test=0.833) total time=   8.3s\n",
      "[CV 3/10; 39/100] START class_weight={0: 0.004454545454545455, 1: 1}............\n",
      "[CV 3/10; 39/100] END class_weight={0: 0.004454545454545455, 1: 1};, score=(train=0.878, test=0.843) total time=   9.7s\n",
      "[CV 3/10; 46/100] START class_weight={0: 0.005090909090909091, 1: 1}............\n",
      "[CV 3/10; 46/100] END class_weight={0: 0.005090909090909091, 1: 1};, score=(train=0.879, test=0.842) total time=  10.3s\n",
      "[CV 2/10; 54/100] START class_weight={0: 0.005818181818181819, 1: 1}............\n",
      "[CV 2/10; 54/100] END class_weight={0: 0.005818181818181819, 1: 1};, score=(train=0.880, test=0.831) total time=  10.9s\n",
      "[CV 1/10; 62/100] START class_weight={0: 0.006545454545454546, 1: 1}............\n",
      "[CV 1/10; 62/100] END class_weight={0: 0.006545454545454546, 1: 1};, score=(train=0.877, test=0.846) total time=   8.4s\n",
      "[CV 9/10; 67/100] START class_weight={0: 0.007, 1: 1}...........................\n",
      "[CV 9/10; 67/100] END class_weight={0: 0.007, 1: 1};, score=(train=0.881, test=0.842) total time=   8.7s\n",
      "[CV 2/10; 74/100] START class_weight={0: 0.007636363636363637, 1: 1}............\n",
      "[CV 2/10; 74/100] END class_weight={0: 0.007636363636363637, 1: 1};, score=(train=0.879, test=0.857) total time=   7.4s\n",
      "[CV 4/10; 79/100] START class_weight={0: 0.008090909090909091, 1: 1}............\n",
      "[CV 4/10; 79/100] END class_weight={0: 0.008090909090909091, 1: 1};, score=(train=0.877, test=0.841) total time=   9.2s\n",
      "[CV 7/10; 85/100] START class_weight={0: 0.008636363636363636, 1: 1}............\n",
      "[CV 7/10; 85/100] END class_weight={0: 0.008636363636363636, 1: 1};, score=(train=0.877, test=0.862) total time=   8.9s\n",
      "[CV 7/10; 91/100] START class_weight={0: 0.009181818181818183, 1: 1}............\n",
      "[CV 7/10; 91/100] END class_weight={0: 0.009181818181818183, 1: 1};, score=(train=0.877, test=0.862) total time=   9.3s\n",
      "[CV 10/10; 97/100] START class_weight={0: 0.009727272727272727, 1: 1}...........\n",
      "[CV 10/10; 97/100] END class_weight={0: 0.009727272727272727, 1: 1};, score=(train=0.878, test=0.865) total time=   8.2s\n",
      "[CV 10/10; 3/100] START class_weight={0: 0.010202020202020202, 1: 1}............\n",
      "[CV 10/10; 3/100] END class_weight={0: 0.010202020202020202, 1: 1};, score=(train=0.878, test=0.865) total time=  11.0s\n",
      "[CV 8/10; 12/100] START class_weight={0: 0.011111111111111112, 1: 1}............\n",
      "[CV 8/10; 12/100] END class_weight={0: 0.011111111111111112, 1: 1};, score=(train=0.878, test=0.868) total time=   9.3s\n",
      "[CV 3/10; 18/100] START class_weight={0: 0.011717171717171718, 1: 1}............\n",
      "[CV 3/10; 18/100] END class_weight={0: 0.011717171717171718, 1: 1};, score=(train=0.879, test=0.827) total time=   8.7s\n",
      "[CV 5/10; 23/100] START class_weight={0: 0.012222222222222223, 1: 1}............\n",
      "[CV 5/10; 23/100] END class_weight={0: 0.012222222222222223, 1: 1};, score=(train=0.878, test=0.841) total time=   9.4s\n",
      "[CV 2/10; 29/100] START class_weight={0: 0.012828282828282828, 1: 1}............\n",
      "[CV 2/10; 29/100] END class_weight={0: 0.012828282828282828, 1: 1};, score=(train=0.878, test=0.850) total time=   9.0s\n",
      "[CV 2/10; 35/100] START class_weight={0: 0.013434343434343434, 1: 1}............\n",
      "[CV 2/10; 35/100] END class_weight={0: 0.013434343434343434, 1: 1};, score=(train=0.883, test=0.849) total time=  11.0s\n",
      "[CV 6/10; 42/100] START class_weight={0: 0.014141414141414142, 1: 1}............\n",
      "[CV 6/10; 42/100] END class_weight={0: 0.014141414141414142, 1: 1};, score=(train=0.881, test=0.826) total time=  13.2s\n",
      "[CV 6/10; 51/100] START class_weight={0: 0.01505050505050505, 1: 1}.............\n",
      "[CV 6/10; 51/100] END class_weight={0: 0.01505050505050505, 1: 1};, score=(train=0.881, test=0.826) total time=   9.1s\n",
      "[CV 5/10; 57/100] START class_weight={0: 0.015656565656565657, 1: 1}............\n",
      "[CV 5/10; 57/100] END class_weight={0: 0.015656565656565657, 1: 1};, score=(train=0.882, test=0.839) total time=   8.0s\n",
      "[CV 5/10; 62/100] START class_weight={0: 0.01616161616161616, 1: 1}.............\n",
      "[CV 5/10; 62/100] END class_weight={0: 0.01616161616161616, 1: 1};, score=(train=0.882, test=0.833) total time=   9.3s\n",
      "[CV 2/10; 68/100] START class_weight={0: 0.016767676767676768, 1: 1}............\n",
      "[CV 2/10; 68/100] END class_weight={0: 0.016767676767676768, 1: 1};, score=(train=0.884, test=0.842) total time=  10.1s\n",
      "[CV 4/10; 75/100] START class_weight={0: 0.017474747474747476, 1: 1}............\n",
      "[CV 4/10; 75/100] END class_weight={0: 0.017474747474747476, 1: 1};, score=(train=0.884, test=0.844) total time=  10.5s\n",
      "[CV 6/10; 82/100] START class_weight={0: 0.01818181818181818, 1: 1}.............\n",
      "[CV 6/10; 82/100] END class_weight={0: 0.01818181818181818, 1: 1};, score=(train=0.881, test=0.832) total time=  11.8s\n",
      "[CV 2/10; 90/100] START class_weight={0: 0.01898989898989899, 1: 1}.............\n",
      "[CV 2/10; 90/100] END class_weight={0: 0.01898989898989899, 1: 1};, score=(train=0.885, test=0.846) total time=  13.6s\n",
      "[CV 7/10; 98/100] START class_weight={0: 0.0197979797979798, 1: 1}..............\n",
      "[CV 7/10; 98/100] END class_weight={0: 0.0197979797979798, 1: 1};, score=(train=0.880, test=0.852) total time=   8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 3/10] START class_weight={0: 0.001888888888888889, 1: 1}..............\n",
      "[CV 4/10; 3/10] END class_weight={0: 0.001888888888888889, 1: 1};, score=(train=0.877, test=0.836) total time=   7.7s\n",
      "[CV 7/10; 10/10] START class_weight={0: 0.005, 1: 1}............................\n",
      "[CV 7/10; 10/10] END class_weight={0: 0.005, 1: 1};, score=(train=0.876, test=0.861) total time=   5.9s\n",
      "[CV 10/10; 6/100] START class_weight={0: 0.0014545454545454547, 1: 1}...........\n",
      "[CV 10/10; 6/100] END class_weight={0: 0.0014545454545454547, 1: 1};, score=(train=0.878, test=0.850) total time=  11.3s\n",
      "[CV 8/10; 13/100] START class_weight={0: 0.002090909090909091, 1: 1}............\n",
      "[CV 8/10; 13/100] END class_weight={0: 0.002090909090909091, 1: 1};, score=(train=0.878, test=0.862) total time=   9.0s\n",
      "[CV 5/10; 20/100] START class_weight={0: 0.0027272727272727275, 1: 1}...........\n",
      "[CV 5/10; 20/100] END class_weight={0: 0.0027272727272727275, 1: 1};, score=(train=0.877, test=0.830) total time=   9.4s\n",
      "[CV 5/10; 27/100] START class_weight={0: 0.003363636363636364, 1: 1}............\n",
      "[CV 5/10; 27/100] END class_weight={0: 0.003363636363636364, 1: 1};, score=(train=0.880, test=0.837) total time=   7.1s\n",
      "[CV 2/10; 33/100] START class_weight={0: 0.003909090909090909, 1: 1}............\n",
      "[CV 2/10; 33/100] END class_weight={0: 0.003909090909090909, 1: 1};, score=(train=0.880, test=0.837) total time=   7.6s\n",
      "[CV 6/10; 38/100] START class_weight={0: 0.004363636363636364, 1: 1}............\n",
      "[CV 6/10; 38/100] END class_weight={0: 0.004363636363636364, 1: 1};, score=(train=0.879, test=0.831) total time=   9.0s\n",
      "[CV 1/10; 45/100] START class_weight={0: 0.005, 1: 1}...........................\n",
      "[CV 1/10; 45/100] END class_weight={0: 0.005, 1: 1};, score=(train=0.879, test=0.842) total time=  11.5s\n",
      "[CV 6/10; 53/100] START class_weight={0: 0.0057272727272727275, 1: 1}...........\n",
      "[CV 6/10; 53/100] END class_weight={0: 0.0057272727272727275, 1: 1};, score=(train=0.879, test=0.836) total time=   9.6s\n",
      "[CV 4/10; 60/100] START class_weight={0: 0.006363636363636364, 1: 1}............\n",
      "[CV 4/10; 60/100] END class_weight={0: 0.006363636363636364, 1: 1};, score=(train=0.879, test=0.843) total time=   9.3s\n",
      "[CV 8/10; 66/100] START class_weight={0: 0.00690909090909091, 1: 1}.............\n",
      "[CV 8/10; 66/100] END class_weight={0: 0.00690909090909091, 1: 1};, score=(train=0.875, test=0.862) total time=   7.8s\n",
      "[CV 5/10; 72/100] START class_weight={0: 0.007454545454545455, 1: 1}............\n",
      "[CV 5/10; 72/100] END class_weight={0: 0.007454545454545455, 1: 1};, score=(train=0.880, test=0.831) total time=   9.7s\n",
      "[CV 3/10; 79/100] START class_weight={0: 0.008090909090909091, 1: 1}............\n",
      "[CV 3/10; 79/100] END class_weight={0: 0.008090909090909091, 1: 1};, score=(train=0.881, test=0.843) total time=   7.6s\n",
      "[CV 6/10; 84/100] START class_weight={0: 0.008545454545454547, 1: 1}............\n",
      "[CV 6/10; 84/100] END class_weight={0: 0.008545454545454547, 1: 1};, score=(train=0.879, test=0.836) total time=  10.2s\n",
      "[CV 9/10; 91/100] START class_weight={0: 0.009181818181818183, 1: 1}............\n",
      "[CV 9/10; 91/100] END class_weight={0: 0.009181818181818183, 1: 1};, score=(train=0.881, test=0.843) total time=   9.1s\n",
      "[CV 1/10; 98/100] START class_weight={0: 0.00981818181818182, 1: 1}.............\n",
      "[CV 1/10; 98/100] END class_weight={0: 0.00981818181818182, 1: 1};, score=(train=0.878, test=0.855) total time=   8.9s\n",
      "[CV 10/10; 4/100] START class_weight={0: 0.010303030303030303, 1: 1}............\n",
      "[CV 10/10; 4/100] END class_weight={0: 0.010303030303030303, 1: 1};, score=(train=0.876, test=0.867) total time=   8.5s\n",
      "[CV 4/10; 8/100] START class_weight={0: 0.010707070707070707, 1: 1}.............\n",
      "[CV 4/10; 8/100] END class_weight={0: 0.010707070707070707, 1: 1};, score=(train=0.875, test=0.830) total time=   9.2s\n",
      "[CV 9/10; 14/100] START class_weight={0: 0.011313131313131313, 1: 1}............\n",
      "[CV 9/10; 14/100] END class_weight={0: 0.011313131313131313, 1: 1};, score=(train=0.881, test=0.843) total time=   9.7s\n",
      "[CV 6/10; 21/100] START class_weight={0: 0.012020202020202021, 1: 1}............\n",
      "[CV 6/10; 21/100] END class_weight={0: 0.012020202020202021, 1: 1};, score=(train=0.881, test=0.830) total time=   6.6s\n",
      "[CV 3/10; 26/100] START class_weight={0: 0.012525252525252526, 1: 1}............\n",
      "[CV 3/10; 26/100] END class_weight={0: 0.012525252525252526, 1: 1};, score=(train=0.876, test=0.838) total time=   6.6s\n",
      "[CV 1/10; 31/100] START class_weight={0: 0.013030303030303031, 1: 1}............\n",
      "[CV 1/10; 31/100] END class_weight={0: 0.013030303030303031, 1: 1};, score=(train=0.877, test=0.864) total time=   7.9s\n",
      "[CV 3/10; 36/100] START class_weight={0: 0.013535353535353536, 1: 1}............\n",
      "[CV 3/10; 36/100] END class_weight={0: 0.013535353535353536, 1: 1};, score=(train=0.879, test=0.830) total time=  12.0s\n",
      "[CV 3/10; 44/100] START class_weight={0: 0.014343434343434344, 1: 1}............\n",
      "[CV 3/10; 44/100] END class_weight={0: 0.014343434343434344, 1: 1};, score=(train=0.876, test=0.838) total time=   8.9s\n",
      "[CV 10/10; 49/100] START class_weight={0: 0.014848484848484849, 1: 1}...........\n",
      "[CV 10/10; 49/100] END class_weight={0: 0.014848484848484849, 1: 1};, score=(train=0.878, test=0.861) total time=   9.7s\n",
      "[CV 5/10; 56/100] START class_weight={0: 0.015555555555555555, 1: 1}............\n",
      "[CV 5/10; 56/100] END class_weight={0: 0.015555555555555555, 1: 1};, score=(train=0.882, test=0.833) total time=   9.1s\n",
      "[CV 3/10; 62/100] START class_weight={0: 0.01616161616161616, 1: 1}.............\n",
      "[CV 3/10; 62/100] END class_weight={0: 0.01616161616161616, 1: 1};, score=(train=0.876, test=0.838) total time=   9.4s\n",
      "[CV 9/10; 67/100] START class_weight={0: 0.016666666666666666, 1: 1}............\n",
      "[CV 9/10; 67/100] END class_weight={0: 0.016666666666666666, 1: 1};, score=(train=0.882, test=0.840) total time=  12.6s\n",
      "[CV 10/10; 75/100] START class_weight={0: 0.017474747474747476, 1: 1}...........\n",
      "[CV 10/10; 75/100] END class_weight={0: 0.017474747474747476, 1: 1};, score=(train=0.879, test=0.869) total time=  10.6s\n",
      "[CV 1/10; 83/100] START class_weight={0: 0.018282828282828283, 1: 1}............\n",
      "[CV 1/10; 83/100] END class_weight={0: 0.018282828282828283, 1: 1};, score=(train=0.880, test=0.855) total time=   7.6s\n",
      "[CV 9/10; 87/100] START class_weight={0: 0.01868686868686869, 1: 1}.............\n",
      "[CV 9/10; 87/100] END class_weight={0: 0.01868686868686869, 1: 1};, score=(train=0.880, test=0.853) total time=   8.6s\n",
      "[CV 7/10; 93/100] START class_weight={0: 0.019292929292929292, 1: 1}............\n",
      "[CV 7/10; 93/100] END class_weight={0: 0.019292929292929292, 1: 1};, score=(train=0.879, test=0.851) total time=   8.2s\n",
      "[CV 1/10; 99/100] START class_weight={0: 0.0198989898989899, 1: 1}..............\n",
      "[CV 1/10; 99/100] END class_weight={0: 0.0198989898989899, 1: 1};, score=(train=0.877, test=0.856) total time=   8.2s\n",
      "[CV 5/10; 3/10] START class_weight={0: 0.001888888888888889, 1: 1}..............\n",
      "[CV 5/10; 3/10] END class_weight={0: 0.001888888888888889, 1: 1};, score=(train=0.878, test=0.828) total time=   6.0s\n",
      "[CV 8/10; 7/10] START class_weight={0: 0.003666666666666667, 1: 1}..............\n",
      "[CV 8/10; 7/10] END class_weight={0: 0.003666666666666667, 1: 1};, score=(train=0.877, test=0.865) total time=   7.1s\n",
      "[CV 6/10; 4/100] START class_weight={0: 0.0012727272727272728, 1: 1}............\n",
      "[CV 6/10; 4/100] END class_weight={0: 0.0012727272727272728, 1: 1};, score=(train=0.882, test=0.821) total time=   9.0s\n",
      "[CV 6/10; 12/100] START class_weight={0: 0.002, 1: 1}...........................\n",
      "[CV 6/10; 12/100] END class_weight={0: 0.002, 1: 1};, score=(train=0.878, test=0.832) total time=   8.9s\n",
      "[CV 9/10; 18/100] START class_weight={0: 0.0025454545454545456, 1: 1}...........\n",
      "[CV 9/10; 18/100] END class_weight={0: 0.0025454545454545456, 1: 1};, score=(train=0.878, test=0.853) total time=   7.9s\n",
      "[CV 8/10; 24/100] START class_weight={0: 0.003090909090909091, 1: 1}............\n",
      "[CV 8/10; 24/100] END class_weight={0: 0.003090909090909091, 1: 1};, score=(train=0.878, test=0.865) total time=   7.4s\n",
      "[CV 9/10; 29/100] START class_weight={0: 0.0035454545454545456, 1: 1}...........\n",
      "[CV 9/10; 29/100] END class_weight={0: 0.0035454545454545456, 1: 1};, score=(train=0.881, test=0.853) total time=   7.1s\n",
      "[CV 5/10; 35/100] START class_weight={0: 0.004090909090909091, 1: 1}............\n",
      "[CV 5/10; 35/100] END class_weight={0: 0.004090909090909091, 1: 1};, score=(train=0.880, test=0.836) total time=   9.2s\n",
      "[CV 2/10; 42/100] START class_weight={0: 0.0047272727272727275, 1: 1}...........\n",
      "[CV 2/10; 42/100] END class_weight={0: 0.0047272727272727275, 1: 1};, score=(train=0.880, test=0.826) total time=   9.0s\n",
      "[CV 9/10; 48/100] START class_weight={0: 0.0052727272727272735, 1: 1}...........\n",
      "[CV 9/10; 48/100] END class_weight={0: 0.0052727272727272735, 1: 1};, score=(train=0.882, test=0.839) total time=   8.2s\n",
      "[CV 1/10; 55/100] START class_weight={0: 0.00590909090909091, 1: 1}.............\n",
      "[CV 1/10; 55/100] END class_weight={0: 0.00590909090909091, 1: 1};, score=(train=0.877, test=0.846) total time=   8.9s\n",
      "[CV 5/10; 61/100] START class_weight={0: 0.006454545454545455, 1: 1}............\n",
      "[CV 5/10; 61/100] END class_weight={0: 0.006454545454545455, 1: 1};, score=(train=0.880, test=0.830) total time=   7.6s\n",
      "[CV 4/10; 66/100] START class_weight={0: 0.00690909090909091, 1: 1}.............\n",
      "[CV 4/10; 66/100] END class_weight={0: 0.00690909090909091, 1: 1};, score=(train=0.879, test=0.836) total time=   8.3s\n",
      "[CV 6/10; 72/100] START class_weight={0: 0.007454545454545455, 1: 1}............\n",
      "[CV 6/10; 72/100] END class_weight={0: 0.007454545454545455, 1: 1};, score=(train=0.879, test=0.838) total time=   9.4s\n",
      "[CV 7/10; 79/100] START class_weight={0: 0.008090909090909091, 1: 1}............\n",
      "[CV 7/10; 79/100] END class_weight={0: 0.008090909090909091, 1: 1};, score=(train=0.877, test=0.862) total time=   8.7s\n",
      "[CV 5/10; 85/100] START class_weight={0: 0.008636363636363636, 1: 1}............\n",
      "[CV 5/10; 85/100] END class_weight={0: 0.008636363636363636, 1: 1};, score=(train=0.880, test=0.832) total time=   8.2s\n",
      "[CV 3/10; 91/100] START class_weight={0: 0.009181818181818183, 1: 1}............\n",
      "[CV 3/10; 91/100] END class_weight={0: 0.009181818181818183, 1: 1};, score=(train=0.879, test=0.846) total time=   8.3s\n",
      "[CV 3/10; 97/100] START class_weight={0: 0.009727272727272727, 1: 1}............\n",
      "[CV 3/10; 97/100] END class_weight={0: 0.009727272727272727, 1: 1};, score=(train=0.879, test=0.827) total time=   8.5s\n",
      "[CV 8/10; 2/100] START class_weight={0: 0.010101010101010102, 1: 1}.............\n",
      "[CV 8/10; 2/100] END class_weight={0: 0.010101010101010102, 1: 1};, score=(train=0.878, test=0.860) total time=  10.0s\n",
      "[CV 4/10; 11/100] START class_weight={0: 0.01101010101010101, 1: 1}.............\n",
      "[CV 4/10; 11/100] END class_weight={0: 0.01101010101010101, 1: 1};, score=(train=0.875, test=0.830) total time=   8.8s\n",
      "[CV 1/10; 16/100] START class_weight={0: 0.011515151515151515, 1: 1}............\n",
      "[CV 1/10; 16/100] END class_weight={0: 0.011515151515151515, 1: 1};, score=(train=0.879, test=0.860) total time=  10.9s\n",
      "[CV 9/10; 23/100] START class_weight={0: 0.012222222222222223, 1: 1}............\n",
      "[CV 9/10; 23/100] END class_weight={0: 0.012222222222222223, 1: 1};, score=(train=0.879, test=0.837) total time=  10.7s\n",
      "[CV 2/10; 31/100] START class_weight={0: 0.013030303030303031, 1: 1}............\n",
      "[CV 2/10; 31/100] END class_weight={0: 0.013030303030303031, 1: 1};, score=(train=0.878, test=0.850) total time=  11.8s\n",
      "[CV 6/10; 38/100] START class_weight={0: 0.013737373737373737, 1: 1}............\n",
      "[CV 6/10; 38/100] END class_weight={0: 0.013737373737373737, 1: 1};, score=(train=0.881, test=0.830) total time=   8.3s\n",
      "[CV 4/10; 44/100] START class_weight={0: 0.014343434343434344, 1: 1}............\n",
      "[CV 4/10; 44/100] END class_weight={0: 0.014343434343434344, 1: 1};, score=(train=0.878, test=0.835) total time=   8.8s\n",
      "[CV 9/10; 49/100] START class_weight={0: 0.014848484848484849, 1: 1}............\n",
      "[CV 9/10; 49/100] END class_weight={0: 0.014848484848484849, 1: 1};, score=(train=0.880, test=0.837) total time=  10.4s\n",
      "[CV 7/10; 56/100] START class_weight={0: 0.015555555555555555, 1: 1}............\n",
      "[CV 7/10; 56/100] END class_weight={0: 0.015555555555555555, 1: 1};, score=(train=0.877, test=0.859) total time=  10.4s\n",
      "[CV 3/10; 63/100] START class_weight={0: 0.016262626262626263, 1: 1}............\n",
      "[CV 3/10; 63/100] END class_weight={0: 0.016262626262626263, 1: 1};, score=(train=0.879, test=0.834) total time=   9.1s\n",
      "[CV 10/10; 68/100] START class_weight={0: 0.016767676767676768, 1: 1}...........\n",
      "[CV 10/10; 68/100] END class_weight={0: 0.016767676767676768, 1: 1};, score=(train=0.881, test=0.865) total time=   9.9s\n",
      "[CV 7/10; 75/100] START class_weight={0: 0.017474747474747476, 1: 1}............\n",
      "[CV 7/10; 75/100] END class_weight={0: 0.017474747474747476, 1: 1};, score=(train=0.878, test=0.862) total time=   8.2s\n",
      "[CV 6/10; 80/100] START class_weight={0: 0.017979797979797978, 1: 1}............\n",
      "[CV 6/10; 80/100] END class_weight={0: 0.017979797979797978, 1: 1};, score=(train=0.881, test=0.832) total time=   9.1s\n",
      "[CV 6/10; 86/100] START class_weight={0: 0.018585858585858588, 1: 1}............\n",
      "[CV 6/10; 86/100] END class_weight={0: 0.018585858585858588, 1: 1};, score=(train=0.881, test=0.830) total time=   7.4s\n",
      "[CV 6/10; 91/100] START class_weight={0: 0.01909090909090909, 1: 1}.............\n",
      "[CV 6/10; 91/100] END class_weight={0: 0.01909090909090909, 1: 1};, score=(train=0.881, test=0.832) total time=  10.5s\n",
      "[CV 2/10; 98/100] START class_weight={0: 0.0197979797979798, 1: 1}..............\n",
      "[CV 2/10; 98/100] END class_weight={0: 0.0197979797979798, 1: 1};, score=(train=0.885, test=0.846) total time=   9.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10; 7/10] START class_weight={0: 0.003666666666666667, 1: 1}..............\n",
      "[CV 2/10; 7/10] END class_weight={0: 0.003666666666666667, 1: 1};, score=(train=0.882, test=0.834) total time=   8.4s\n",
      "[CV 5/10; 1/100] START class_weight={0: 0.001, 1: 1}............................\n",
      "[CV 5/10; 1/100] END class_weight={0: 0.001, 1: 1};, score=(train=0.878, test=0.831) total time=   8.7s\n",
      "[CV 4/10; 11/100] START class_weight={0: 0.0019090909090909093, 1: 1}...........\n",
      "[CV 4/10; 11/100] END class_weight={0: 0.0019090909090909093, 1: 1};, score=(train=0.878, test=0.836) total time=   9.0s\n",
      "[CV 4/10; 18/100] START class_weight={0: 0.0025454545454545456, 1: 1}...........\n",
      "[CV 4/10; 18/100] END class_weight={0: 0.0025454545454545456, 1: 1};, score=(train=0.877, test=0.842) total time=   8.5s\n",
      "[CV 5/10; 24/100] START class_weight={0: 0.003090909090909091, 1: 1}............\n",
      "[CV 5/10; 24/100] END class_weight={0: 0.003090909090909091, 1: 1};, score=(train=0.877, test=0.834) total time=   7.3s\n",
      "[CV 4/10; 29/100] START class_weight={0: 0.0035454545454545456, 1: 1}...........\n",
      "[CV 4/10; 29/100] END class_weight={0: 0.0035454545454545456, 1: 1};, score=(train=0.878, test=0.847) total time=   8.6s\n",
      "[CV 2/10; 36/100] START class_weight={0: 0.004181818181818182, 1: 1}............\n",
      "[CV 2/10; 36/100] END class_weight={0: 0.004181818181818182, 1: 1};, score=(train=0.880, test=0.831) total time=   8.0s\n",
      "[CV 8/10; 41/100] START class_weight={0: 0.004636363636363636, 1: 1}............\n",
      "[CV 8/10; 41/100] END class_weight={0: 0.004636363636363636, 1: 1};, score=(train=0.877, test=0.864) total time=   9.7s\n",
      "[CV 5/10; 49/100] START class_weight={0: 0.005363636363636364, 1: 1}............\n",
      "[CV 5/10; 49/100] END class_weight={0: 0.005363636363636364, 1: 1};, score=(train=0.880, test=0.835) total time=   8.2s\n",
      "[CV 5/10; 55/100] START class_weight={0: 0.00590909090909091, 1: 1}.............\n",
      "[CV 5/10; 55/100] END class_weight={0: 0.00590909090909091, 1: 1};, score=(train=0.880, test=0.834) total time=   7.7s\n",
      "[CV 10/10; 60/100] START class_weight={0: 0.006363636363636364, 1: 1}...........\n",
      "[CV 10/10; 60/100] END class_weight={0: 0.006363636363636364, 1: 1};, score=(train=0.879, test=0.858) total time=   9.4s\n",
      "[CV 8/10; 67/100] START class_weight={0: 0.007, 1: 1}...........................\n",
      "[CV 8/10; 67/100] END class_weight={0: 0.007, 1: 1};, score=(train=0.877, test=0.860) total time=   6.7s\n",
      "[CV 4/10; 72/100] START class_weight={0: 0.007454545454545455, 1: 1}............\n",
      "[CV 4/10; 72/100] END class_weight={0: 0.007454545454545455, 1: 1};, score=(train=0.877, test=0.841) total time=   9.1s\n",
      "[CV 6/10; 78/100] START class_weight={0: 0.008, 1: 1}...........................\n",
      "[CV 6/10; 78/100] END class_weight={0: 0.008, 1: 1};, score=(train=0.879, test=0.837) total time=  10.3s\n",
      "[CV 2/10; 86/100] START class_weight={0: 0.008727272727272728, 1: 1}............\n",
      "[CV 2/10; 86/100] END class_weight={0: 0.008727272727272728, 1: 1};, score=(train=0.879, test=0.858) total time=   8.8s\n",
      "[CV 10/10; 91/100] START class_weight={0: 0.009181818181818183, 1: 1}...........\n",
      "[CV 10/10; 91/100] END class_weight={0: 0.009181818181818183, 1: 1};, score=(train=0.877, test=0.848) total time=   8.0s\n",
      "[CV 7/10; 97/100] START class_weight={0: 0.009727272727272727, 1: 1}............\n",
      "[CV 7/10; 97/100] END class_weight={0: 0.009727272727272727, 1: 1};, score=(train=0.879, test=0.855) total time=   9.0s\n",
      "[CV 2/10; 4/100] START class_weight={0: 0.010303030303030303, 1: 1}.............\n",
      "[CV 2/10; 4/100] END class_weight={0: 0.010303030303030303, 1: 1};, score=(train=0.880, test=0.846) total time=   9.9s\n",
      "[CV 3/10; 10/100] START class_weight={0: 0.01090909090909091, 1: 1}.............\n",
      "[CV 3/10; 10/100] END class_weight={0: 0.01090909090909091, 1: 1};, score=(train=0.879, test=0.831) total time=  10.4s\n",
      "[CV 9/10; 17/100] START class_weight={0: 0.011616161616161616, 1: 1}............\n",
      "[CV 9/10; 17/100] END class_weight={0: 0.011616161616161616, 1: 1};, score=(train=0.881, test=0.843) total time=   9.3s\n",
      "[CV 4/10; 23/100] START class_weight={0: 0.012222222222222223, 1: 1}............\n",
      "[CV 4/10; 23/100] END class_weight={0: 0.012222222222222223, 1: 1};, score=(train=0.876, test=0.836) total time=   9.4s\n",
      "[CV 9/10; 29/100] START class_weight={0: 0.012828282828282828, 1: 1}............\n",
      "[CV 9/10; 29/100] END class_weight={0: 0.012828282828282828, 1: 1};, score=(train=0.879, test=0.837) total time=  10.8s\n",
      "[CV 3/10; 37/100] START class_weight={0: 0.013636363636363637, 1: 1}............\n",
      "[CV 3/10; 37/100] END class_weight={0: 0.013636363636363637, 1: 1};, score=(train=0.876, test=0.838) total time=   8.3s\n",
      "[CV 8/10; 42/100] START class_weight={0: 0.014141414141414142, 1: 1}............\n",
      "[CV 8/10; 42/100] END class_weight={0: 0.014141414141414142, 1: 1};, score=(train=0.880, test=0.883) total time=   9.0s\n",
      "[CV 6/10; 48/100] START class_weight={0: 0.014747474747474749, 1: 1}............\n",
      "[CV 6/10; 48/100] END class_weight={0: 0.014747474747474749, 1: 1};, score=(train=0.881, test=0.826) total time=   9.0s\n",
      "[CV 1/10; 54/100] START class_weight={0: 0.015353535353535354, 1: 1}............\n",
      "[CV 1/10; 54/100] END class_weight={0: 0.015353535353535354, 1: 1};, score=(train=0.880, test=0.861) total time=  10.7s\n",
      "[CV 2/10; 61/100] START class_weight={0: 0.01606060606060606, 1: 1}.............\n",
      "[CV 2/10; 61/100] END class_weight={0: 0.01606060606060606, 1: 1};, score=(train=0.884, test=0.843) total time=  10.9s\n",
      "[CV 1/10; 68/100] START class_weight={0: 0.016767676767676768, 1: 1}............\n",
      "[CV 1/10; 68/100] END class_weight={0: 0.016767676767676768, 1: 1};, score=(train=0.881, test=0.859) total time=  11.0s\n",
      "[CV 6/10; 75/100] START class_weight={0: 0.017474747474747476, 1: 1}............\n",
      "[CV 6/10; 75/100] END class_weight={0: 0.017474747474747476, 1: 1};, score=(train=0.881, test=0.826) total time=   9.5s\n",
      "[CV 3/10; 81/100] START class_weight={0: 0.01808080808080808, 1: 1}.............\n",
      "[CV 3/10; 81/100] END class_weight={0: 0.01808080808080808, 1: 1};, score=(train=0.879, test=0.830) total time=   7.7s\n",
      "[CV 3/10; 86/100] START class_weight={0: 0.018585858585858588, 1: 1}............\n",
      "[CV 3/10; 86/100] END class_weight={0: 0.018585858585858588, 1: 1};, score=(train=0.879, test=0.830) total time=   7.8s\n",
      "[CV 7/10; 91/100] START class_weight={0: 0.01909090909090909, 1: 1}.............\n",
      "[CV 7/10; 91/100] END class_weight={0: 0.01909090909090909, 1: 1};, score=(train=0.878, test=0.851) total time=  12.8s\n",
      "[CV 9/10; 99/100] START class_weight={0: 0.0198989898989899, 1: 1}..............\n",
      "[CV 9/10; 99/100] END class_weight={0: 0.0198989898989899, 1: 1};, score=(train=0.880, test=0.853) total time=   7.1s\n",
      "[CV 6/10; 1/10] START class_weight={0: 0.001, 1: 1}.............................\n",
      "[CV 6/10; 1/10] END class_weight={0: 0.001, 1: 1};, score=(train=0.882, test=0.829) total time=   7.0s\n",
      "[CV 3/10; 8/10] START class_weight={0: 0.004111111111111111, 1: 1}..............\n",
      "[CV 3/10; 8/10] END class_weight={0: 0.004111111111111111, 1: 1};, score=(train=0.879, test=0.841) total time=   6.6s\n",
      "[CV 3/10; 5/100] START class_weight={0: 0.0013636363636363637, 1: 1}............\n",
      "[CV 3/10; 5/100] END class_weight={0: 0.0013636363636363637, 1: 1};, score=(train=0.879, test=0.836) total time=   7.6s\n",
      "[CV 4/10; 10/100] START class_weight={0: 0.0018181818181818182, 1: 1}...........\n",
      "[CV 4/10; 10/100] END class_weight={0: 0.0018181818181818182, 1: 1};, score=(train=0.876, test=0.839) total time=   8.9s\n",
      "[CV 8/10; 17/100] START class_weight={0: 0.002454545454545455, 1: 1}............\n",
      "[CV 8/10; 17/100] END class_weight={0: 0.002454545454545455, 1: 1};, score=(train=0.878, test=0.866) total time=   8.5s\n",
      "[CV 10/10; 23/100] START class_weight={0: 0.003, 1: 1}..........................\n",
      "[CV 10/10; 23/100] END class_weight={0: 0.003, 1: 1};, score=(train=0.879, test=0.851) total time=   9.3s\n",
      "[CV 6/10; 30/100] START class_weight={0: 0.003636363636363637, 1: 1}............\n",
      "[CV 6/10; 30/100] END class_weight={0: 0.003636363636363637, 1: 1};, score=(train=0.880, test=0.832) total time=   9.8s\n",
      "[CV 6/10; 37/100] START class_weight={0: 0.0042727272727272735, 1: 1}...........\n",
      "[CV 6/10; 37/100] END class_weight={0: 0.0042727272727272735, 1: 1};, score=(train=0.880, test=0.833) total time=   8.7s\n",
      "[CV 1/10; 44/100] START class_weight={0: 0.00490909090909091, 1: 1}.............\n",
      "[CV 1/10; 44/100] END class_weight={0: 0.00490909090909091, 1: 1};, score=(train=0.879, test=0.848) total time=  11.0s\n",
      "[CV 7/10; 52/100] START class_weight={0: 0.005636363636363636, 1: 1}............\n",
      "[CV 7/10; 52/100] END class_weight={0: 0.005636363636363636, 1: 1};, score=(train=0.878, test=0.865) total time=   8.4s\n",
      "[CV 5/10; 58/100] START class_weight={0: 0.006181818181818182, 1: 1}............\n",
      "[CV 5/10; 58/100] END class_weight={0: 0.006181818181818182, 1: 1};, score=(train=0.880, test=0.834) total time=   8.8s\n",
      "[CV 7/10; 64/100] START class_weight={0: 0.006727272727272728, 1: 1}............\n",
      "[CV 7/10; 64/100] END class_weight={0: 0.006727272727272728, 1: 1};, score=(train=0.876, test=0.867) total time=   8.3s\n",
      "[CV 7/10; 70/100] START class_weight={0: 0.007272727272727274, 1: 1}............\n",
      "[CV 7/10; 70/100] END class_weight={0: 0.007272727272727274, 1: 1};, score=(train=0.877, test=0.864) total time=  10.0s\n",
      "[CV 4/10; 77/100] START class_weight={0: 0.00790909090909091, 1: 1}.............\n",
      "[CV 4/10; 77/100] END class_weight={0: 0.00790909090909091, 1: 1};, score=(train=0.877, test=0.837) total time=  10.5s\n",
      "[CV 1/10; 85/100] START class_weight={0: 0.008636363636363636, 1: 1}............\n",
      "[CV 1/10; 85/100] END class_weight={0: 0.008636363636363636, 1: 1};, score=(train=0.877, test=0.842) total time=  10.6s\n",
      "[CV 5/10; 92/100] START class_weight={0: 0.009272727272727273, 1: 1}............\n",
      "[CV 5/10; 92/100] END class_weight={0: 0.009272727272727273, 1: 1};, score=(train=0.879, test=0.836) total time=  10.5s\n",
      "[CV 5/10; 99/100] START class_weight={0: 0.009909090909090909, 1: 1}............\n",
      "[CV 5/10; 99/100] END class_weight={0: 0.009909090909090909, 1: 1};, score=(train=0.877, test=0.839) total time=   7.5s\n",
      "[CV 1/10; 6/100] START class_weight={0: 0.010505050505050505, 1: 1}.............\n",
      "[CV 1/10; 6/100] END class_weight={0: 0.010505050505050505, 1: 1};, score=(train=0.878, test=0.855) total time=   8.3s\n",
      "[CV 4/10; 9/100] START class_weight={0: 0.010808080808080808, 1: 1}.............\n",
      "[CV 4/10; 9/100] END class_weight={0: 0.010808080808080808, 1: 1};, score=(train=0.876, test=0.838) total time=   8.9s\n",
      "[CV 5/10; 15/100] START class_weight={0: 0.011414141414141415, 1: 1}............\n",
      "[CV 5/10; 15/100] END class_weight={0: 0.011414141414141415, 1: 1};, score=(train=0.877, test=0.839) total time=  11.6s\n",
      "[CV 1/10; 24/100] START class_weight={0: 0.012323232323232323, 1: 1}............\n",
      "[CV 1/10; 24/100] END class_weight={0: 0.012323232323232323, 1: 1};, score=(train=0.878, test=0.867) total time=   9.5s\n",
      "[CV 7/10; 30/100] START class_weight={0: 0.01292929292929293, 1: 1}.............\n",
      "[CV 7/10; 30/100] END class_weight={0: 0.01292929292929293, 1: 1};, score=(train=0.880, test=0.867) total time=  11.8s\n",
      "[CV 10/10; 37/100] START class_weight={0: 0.013636363636363637, 1: 1}...........\n",
      "[CV 10/10; 37/100] END class_weight={0: 0.013636363636363637, 1: 1};, score=(train=0.878, test=0.861) total time=   8.2s\n",
      "[CV 4/10; 43/100] START class_weight={0: 0.014242424242424242, 1: 1}............\n",
      "[CV 4/10; 43/100] END class_weight={0: 0.014242424242424242, 1: 1};, score=(train=0.878, test=0.835) total time=   9.3s\n",
      "[CV 5/10; 49/100] START class_weight={0: 0.014848484848484849, 1: 1}............\n",
      "[CV 5/10; 49/100] END class_weight={0: 0.014848484848484849, 1: 1};, score=(train=0.879, test=0.824) total time=   8.9s\n",
      "[CV 8/10; 54/100] START class_weight={0: 0.015353535353535354, 1: 1}............\n",
      "[CV 8/10; 54/100] END class_weight={0: 0.015353535353535354, 1: 1};, score=(train=0.880, test=0.883) total time=   8.4s\n",
      "[CV 1/10; 60/100] START class_weight={0: 0.01595959595959596, 1: 1}.............\n",
      "[CV 1/10; 60/100] END class_weight={0: 0.01595959595959596, 1: 1};, score=(train=0.880, test=0.861) total time=   9.7s\n",
      "[CV 6/10; 66/100] START class_weight={0: 0.016565656565656565, 1: 1}............\n",
      "[CV 6/10; 66/100] END class_weight={0: 0.016565656565656565, 1: 1};, score=(train=0.881, test=0.826) total time=  11.5s\n",
      "[CV 10/10; 73/100] START class_weight={0: 0.017272727272727273, 1: 1}...........\n",
      "[CV 10/10; 73/100] END class_weight={0: 0.017272727272727273, 1: 1};, score=(train=0.879, test=0.869) total time=  10.8s\n",
      "[CV 10/10; 80/100] START class_weight={0: 0.017979797979797978, 1: 1}...........\n",
      "[CV 10/10; 80/100] END class_weight={0: 0.017979797979797978, 1: 1};, score=(train=0.881, test=0.865) total time=  10.8s\n",
      "[CV 1/10; 88/100] START class_weight={0: 0.018787878787878787, 1: 1}............\n",
      "[CV 1/10; 88/100] END class_weight={0: 0.018787878787878787, 1: 1};, score=(train=0.881, test=0.858) total time=   9.1s\n",
      "[CV 8/10; 93/100] START class_weight={0: 0.019292929292929292, 1: 1}............\n",
      "[CV 8/10; 93/100] END class_weight={0: 0.019292929292929292, 1: 1};, score=(train=0.875, test=0.875) total time=   8.8s\n",
      "[CV 3/10; 99/100] START class_weight={0: 0.0198989898989899, 1: 1}..............\n",
      "[CV 3/10; 99/100] END class_weight={0: 0.0198989898989899, 1: 1};, score=(train=0.882, test=0.829) total time=   7.6s\n",
      "[CV 10/10; 5/10] START class_weight={0: 0.002777777777777778, 1: 1}.............\n",
      "[CV 10/10; 5/10] END class_weight={0: 0.002777777777777778, 1: 1};, score=(train=0.875, test=0.846) total time=   8.1s\n",
      "[CV 3/10; 1/100] START class_weight={0: 0.001, 1: 1}............................\n",
      "[CV 3/10; 1/100] END class_weight={0: 0.001, 1: 1};, score=(train=0.879, test=0.837) total time=   8.9s\n",
      "[CV 4/10; 12/100] START class_weight={0: 0.002, 1: 1}...........................\n",
      "[CV 4/10; 12/100] END class_weight={0: 0.002, 1: 1};, score=(train=0.878, test=0.831) total time=  10.4s\n",
      "[CV 7/10; 19/100] START class_weight={0: 0.0026363636363636363, 1: 1}...........\n",
      "[CV 7/10; 19/100] END class_weight={0: 0.0026363636363636363, 1: 1};, score=(train=0.877, test=0.853) total time=   9.8s\n",
      "[CV 8/10; 26/100] START class_weight={0: 0.003272727272727273, 1: 1}............\n",
      "[CV 8/10; 26/100] END class_weight={0: 0.003272727272727273, 1: 1};, score=(train=0.877, test=0.864) total time=   8.4s\n",
      "[CV 5/10; 33/100] START class_weight={0: 0.003909090909090909, 1: 1}............\n",
      "[CV 5/10; 33/100] END class_weight={0: 0.003909090909090909, 1: 1};, score=(train=0.880, test=0.836) total time=   7.9s\n",
      "[CV 10/10; 38/100] START class_weight={0: 0.004363636363636364, 1: 1}...........\n",
      "[CV 10/10; 38/100] END class_weight={0: 0.004363636363636364, 1: 1};, score=(train=0.879, test=0.857) total time=   7.3s\n",
      "[CV 2/10; 44/100] START class_weight={0: 0.00490909090909091, 1: 1}.............\n",
      "[CV 2/10; 44/100] END class_weight={0: 0.00490909090909091, 1: 1};, score=(train=0.879, test=0.830) total time=   7.8s\n",
      "[CV 9/10; 49/100] START class_weight={0: 0.005363636363636364, 1: 1}............\n",
      "[CV 9/10; 49/100] END class_weight={0: 0.005363636363636364, 1: 1};, score=(train=0.880, test=0.846) total time=  11.0s\n",
      "[CV 9/10; 57/100] START class_weight={0: 0.006090909090909091, 1: 1}............\n",
      "[CV 9/10; 57/100] END class_weight={0: 0.006090909090909091, 1: 1};, score=(train=0.881, test=0.842) total time=   9.4s\n",
      "[CV 8/10; 64/100] START class_weight={0: 0.006727272727272728, 1: 1}............\n",
      "[CV 8/10; 64/100] END class_weight={0: 0.006727272727272728, 1: 1};, score=(train=0.878, test=0.865) total time=   8.1s\n",
      "[CV 6/10; 70/100] START class_weight={0: 0.007272727272727274, 1: 1}............\n",
      "[CV 6/10; 70/100] END class_weight={0: 0.007272727272727274, 1: 1};, score=(train=0.879, test=0.837) total time=  10.3s\n",
      "[CV 5/10; 77/100] START class_weight={0: 0.00790909090909091, 1: 1}.............\n",
      "[CV 5/10; 77/100] END class_weight={0: 0.00790909090909091, 1: 1};, score=(train=0.880, test=0.831) total time=   7.1s\n",
      "[CV 10/10; 82/100] START class_weight={0: 0.008363636363636365, 1: 1}...........\n",
      "[CV 10/10; 82/100] END class_weight={0: 0.008363636363636365, 1: 1};, score=(train=0.876, test=0.849) total time=   9.4s\n",
      "[CV 1/10; 89/100] START class_weight={0: 0.009000000000000001, 1: 1}............\n",
      "[CV 1/10; 89/100] END class_weight={0: 0.009000000000000001, 1: 1};, score=(train=0.877, test=0.844) total time=   8.1s\n",
      "[CV 10/10; 94/100] START class_weight={0: 0.009454545454545455, 1: 1}...........\n",
      "[CV 10/10; 94/100] END class_weight={0: 0.009454545454545455, 1: 1};, score=(train=0.878, test=0.865) total time=  10.5s\n",
      "[CV 8/10; 1/100] START class_weight={0: 0.01, 1: 1}.............................\n",
      "[CV 8/10; 1/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.878, test=0.860) total time=  10.3s\n",
      "[CV 1/10; 11/100] START class_weight={0: 0.01101010101010101, 1: 1}.............\n",
      "[CV 1/10; 11/100] END class_weight={0: 0.01101010101010101, 1: 1};, score=(train=0.877, test=0.860) total time=   9.2s\n",
      "[CV 1/10; 17/100] START class_weight={0: 0.011616161616161616, 1: 1}............\n",
      "[CV 1/10; 17/100] END class_weight={0: 0.011616161616161616, 1: 1};, score=(train=0.877, test=0.860) total time=  11.0s\n",
      "[CV 7/10; 24/100] START class_weight={0: 0.012323232323232323, 1: 1}............\n",
      "[CV 7/10; 24/100] END class_weight={0: 0.012323232323232323, 1: 1};, score=(train=0.880, test=0.867) total time=   8.8s\n",
      "[CV 6/10; 29/100] START class_weight={0: 0.012828282828282828, 1: 1}............\n",
      "[CV 6/10; 29/100] END class_weight={0: 0.012828282828282828, 1: 1};, score=(train=0.880, test=0.832) total time=   7.4s\n",
      "[CV 5/10; 34/100] START class_weight={0: 0.013333333333333332, 1: 1}............\n",
      "[CV 5/10; 34/100] END class_weight={0: 0.013333333333333332, 1: 1};, score=(train=0.879, test=0.824) total time=   9.0s\n",
      "[CV 5/10; 40/100] START class_weight={0: 0.013939393939393939, 1: 1}............\n",
      "[CV 5/10; 40/100] END class_weight={0: 0.013939393939393939, 1: 1};, score=(train=0.879, test=0.824) total time=   6.9s\n",
      "[CV 5/10; 45/100] START class_weight={0: 0.014444444444444444, 1: 1}............\n",
      "[CV 5/10; 45/100] END class_weight={0: 0.014444444444444444, 1: 1};, score=(train=0.882, test=0.839) total time=   8.4s\n",
      "[CV 3/10; 51/100] START class_weight={0: 0.01505050505050505, 1: 1}.............\n",
      "[CV 3/10; 51/100] END class_weight={0: 0.01505050505050505, 1: 1};, score=(train=0.879, test=0.834) total time=   7.4s\n",
      "[CV 1/10; 56/100] START class_weight={0: 0.015555555555555555, 1: 1}............\n",
      "[CV 1/10; 56/100] END class_weight={0: 0.015555555555555555, 1: 1};, score=(train=0.881, test=0.859) total time=   9.9s\n",
      "[CV 4/10; 62/100] START class_weight={0: 0.01616161616161616, 1: 1}.............\n",
      "[CV 4/10; 62/100] END class_weight={0: 0.01616161616161616, 1: 1};, score=(train=0.884, test=0.844) total time=   9.9s\n",
      "[CV 4/10; 68/100] START class_weight={0: 0.016767676767676768, 1: 1}............\n",
      "[CV 4/10; 68/100] END class_weight={0: 0.016767676767676768, 1: 1};, score=(train=0.884, test=0.844) total time=   9.4s\n",
      "[CV 8/10; 74/100] START class_weight={0: 0.017373737373737375, 1: 1}............\n",
      "[CV 8/10; 74/100] END class_weight={0: 0.017373737373737375, 1: 1};, score=(train=0.880, test=0.872) total time=  10.8s\n",
      "[CV 4/10; 81/100] START class_weight={0: 0.01808080808080808, 1: 1}.............\n",
      "[CV 4/10; 81/100] END class_weight={0: 0.01808080808080808, 1: 1};, score=(train=0.884, test=0.844) total time=  10.2s\n",
      "[CV 2/10; 88/100] START class_weight={0: 0.018787878787878787, 1: 1}............\n",
      "[CV 2/10; 88/100] END class_weight={0: 0.018787878787878787, 1: 1};, score=(train=0.885, test=0.847) total time=   9.5s\n",
      "[CV 10/10; 93/100] START class_weight={0: 0.019292929292929292, 1: 1}...........\n",
      "[CV 10/10; 93/100] END class_weight={0: 0.019292929292929292, 1: 1};, score=(train=0.879, test=0.869) total time=   8.7s\n",
      "[CV 8/10; 99/100] START class_weight={0: 0.0198989898989899, 1: 1}..............\n",
      "[CV 8/10; 99/100] END class_weight={0: 0.0198989898989899, 1: 1};, score=(train=0.875, test=0.875) total time=   7.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10; 2/10] START class_weight={0: 0.0014444444444444444, 1: 1}............\n",
      "[CV 10/10; 2/10] END class_weight={0: 0.0014444444444444444, 1: 1};, score=(train=0.877, test=0.856) total time=   8.6s\n",
      "[CV 1/10; 1/100] START class_weight={0: 0.001, 1: 1}............................\n",
      "[CV 1/10; 1/100] END class_weight={0: 0.001, 1: 1};, score=(train=0.875, test=0.845) total time=   7.8s\n",
      "[CV 5/10; 9/100] START class_weight={0: 0.0017272727272727275, 1: 1}............\n",
      "[CV 5/10; 9/100] END class_weight={0: 0.0017272727272727275, 1: 1};, score=(train=0.882, test=0.822) total time=   7.0s\n",
      "[CV 1/10; 15/100] START class_weight={0: 0.0022727272727272726, 1: 1}...........\n",
      "[CV 1/10; 15/100] END class_weight={0: 0.0022727272727272726, 1: 1};, score=(train=0.883, test=0.843) total time=   8.1s\n",
      "[CV 4/10; 21/100] START class_weight={0: 0.0028181818181818186, 1: 1}...........\n",
      "[CV 4/10; 21/100] END class_weight={0: 0.0028181818181818186, 1: 1};, score=(train=0.877, test=0.848) total time=   7.3s\n",
      "[CV 6/10; 27/100] START class_weight={0: 0.003363636363636364, 1: 1}............\n",
      "[CV 6/10; 27/100] END class_weight={0: 0.003363636363636364, 1: 1};, score=(train=0.878, test=0.836) total time=   6.7s\n",
      "[CV 9/10; 32/100] START class_weight={0: 0.0038181818181818187, 1: 1}...........\n",
      "[CV 9/10; 32/100] END class_weight={0: 0.0038181818181818187, 1: 1};, score=(train=0.881, test=0.835) total time=   8.9s\n",
      "[CV 6/10; 39/100] START class_weight={0: 0.004454545454545455, 1: 1}............\n",
      "[CV 6/10; 39/100] END class_weight={0: 0.004454545454545455, 1: 1};, score=(train=0.880, test=0.833) total time=   8.8s\n",
      "[CV 8/10; 45/100] START class_weight={0: 0.005, 1: 1}...........................\n",
      "[CV 8/10; 45/100] END class_weight={0: 0.005, 1: 1};, score=(train=0.877, test=0.862) total time=   7.4s\n",
      "[CV 10/10; 50/100] START class_weight={0: 0.005454545454545455, 1: 1}...........\n",
      "[CV 10/10; 50/100] END class_weight={0: 0.005454545454545455, 1: 1};, score=(train=0.879, test=0.858) total time=  11.1s\n",
      "[CV 1/10; 59/100] START class_weight={0: 0.006272727272727274, 1: 1}............\n",
      "[CV 1/10; 59/100] END class_weight={0: 0.006272727272727274, 1: 1};, score=(train=0.878, test=0.839) total time=  11.7s\n",
      "[CV 1/10; 68/100] START class_weight={0: 0.007090909090909091, 1: 1}............\n",
      "[CV 1/10; 68/100] END class_weight={0: 0.007090909090909091, 1: 1};, score=(train=0.877, test=0.839) total time=  10.2s\n",
      "[CV 3/10; 75/100] START class_weight={0: 0.007727272727272728, 1: 1}............\n",
      "[CV 3/10; 75/100] END class_weight={0: 0.007727272727272728, 1: 1};, score=(train=0.880, test=0.844) total time=   9.7s\n",
      "[CV 8/10; 81/100] START class_weight={0: 0.008272727272727274, 1: 1}............\n",
      "[CV 8/10; 81/100] END class_weight={0: 0.008272727272727274, 1: 1};, score=(train=0.874, test=0.866) total time=   9.0s\n",
      "[CV 1/10; 88/100] START class_weight={0: 0.008909090909090908, 1: 1}............\n",
      "[CV 1/10; 88/100] END class_weight={0: 0.008909090909090908, 1: 1};, score=(train=0.877, test=0.842) total time=   9.8s\n",
      "[CV 8/10; 94/100] START class_weight={0: 0.009454545454545455, 1: 1}............\n",
      "[CV 8/10; 94/100] END class_weight={0: 0.009454545454545455, 1: 1};, score=(train=0.877, test=0.863) total time=   9.1s\n",
      "[CV 7/10; 100/100] START class_weight={0: 0.01, 1: 1}...........................\n",
      "[CV 7/10; 100/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.876, test=0.864) total time=   6.3s\n",
      "[CV 2/10; 7/100] START class_weight={0: 0.010606060606060607, 1: 1}.............\n",
      "[CV 2/10; 7/100] END class_weight={0: 0.010606060606060607, 1: 1};, score=(train=0.880, test=0.846) total time=  10.7s\n",
      "[CV 9/10; 12/100] START class_weight={0: 0.011111111111111112, 1: 1}............\n",
      "[CV 9/10; 12/100] END class_weight={0: 0.011111111111111112, 1: 1};, score=(train=0.880, test=0.850) total time=   7.9s\n",
      "[CV 6/10; 16/100] START class_weight={0: 0.011515151515151515, 1: 1}............\n",
      "[CV 6/10; 16/100] END class_weight={0: 0.011515151515151515, 1: 1};, score=(train=0.881, test=0.832) total time=   9.4s\n",
      "[CV 7/10; 22/100] START class_weight={0: 0.012121212121212121, 1: 1}............\n",
      "[CV 7/10; 22/100] END class_weight={0: 0.012121212121212121, 1: 1};, score=(train=0.879, test=0.866) total time=   7.5s\n",
      "[CV 5/10; 27/100] START class_weight={0: 0.012626262626262626, 1: 1}............\n",
      "[CV 5/10; 27/100] END class_weight={0: 0.012626262626262626, 1: 1};, score=(train=0.880, test=0.834) total time=   8.8s\n",
      "[CV 5/10; 33/100] START class_weight={0: 0.013232323232323233, 1: 1}............\n",
      "[CV 5/10; 33/100] END class_weight={0: 0.013232323232323233, 1: 1};, score=(train=0.882, test=0.839) total time=   8.1s\n",
      "[CV 3/10; 39/100] START class_weight={0: 0.013838383838383839, 1: 1}............\n",
      "[CV 3/10; 39/100] END class_weight={0: 0.013838383838383839, 1: 1};, score=(train=0.879, test=0.830) total time=   9.4s\n",
      "[CV 6/10; 45/100] START class_weight={0: 0.014444444444444444, 1: 1}............\n",
      "[CV 6/10; 45/100] END class_weight={0: 0.014444444444444444, 1: 1};, score=(train=0.881, test=0.826) total time=   8.0s\n",
      "[CV 9/10; 50/100] START class_weight={0: 0.014949494949494949, 1: 1}............\n",
      "[CV 9/10; 50/100] END class_weight={0: 0.014949494949494949, 1: 1};, score=(train=0.880, test=0.837) total time=   9.5s\n",
      "[CV 8/10; 56/100] START class_weight={0: 0.015555555555555555, 1: 1}............\n",
      "[CV 8/10; 56/100] END class_weight={0: 0.015555555555555555, 1: 1};, score=(train=0.880, test=0.878) total time=  12.2s\n",
      "[CV 10/10; 64/100] START class_weight={0: 0.016363636363636365, 1: 1}...........\n",
      "[CV 10/10; 64/100] END class_weight={0: 0.016363636363636365, 1: 1};, score=(train=0.879, test=0.869) total time=  10.3s\n",
      "[CV 6/10; 71/100] START class_weight={0: 0.01707070707070707, 1: 1}.............\n",
      "[CV 6/10; 71/100] END class_weight={0: 0.01707070707070707, 1: 1};, score=(train=0.881, test=0.830) total time=  11.3s\n",
      "[CV 3/10; 78/100] START class_weight={0: 0.017777777777777778, 1: 1}............\n",
      "[CV 3/10; 78/100] END class_weight={0: 0.017777777777777778, 1: 1};, score=(train=0.879, test=0.830) total time=   8.7s\n",
      "[CV 4/10; 84/100] START class_weight={0: 0.018383838383838384, 1: 1}............\n",
      "[CV 4/10; 84/100] END class_weight={0: 0.018383838383838384, 1: 1};, score=(train=0.883, test=0.848) total time=   9.1s\n",
      "[CV 6/10; 90/100] START class_weight={0: 0.01898989898989899, 1: 1}.............\n",
      "[CV 6/10; 90/100] END class_weight={0: 0.01898989898989899, 1: 1};, score=(train=0.881, test=0.826) total time=   8.0s\n",
      "[CV 6/10; 95/100] START class_weight={0: 0.019494949494949496, 1: 1}............\n",
      "[CV 6/10; 95/100] END class_weight={0: 0.019494949494949496, 1: 1};, score=(train=0.881, test=0.830) total time=   7.8s\n",
      "[CV 5/10; 100/100] START class_weight={0: 0.02, 1: 1}...........................\n",
      "[CV 5/10; 100/100] END class_weight={0: 0.02, 1: 1};, score=(train=0.881, test=0.828) total time=   6.4s\n",
      "[CV 2/10; 2/10] START class_weight={0: 0.0014444444444444444, 1: 1}.............\n",
      "[CV 2/10; 2/10] END class_weight={0: 0.0014444444444444444, 1: 1};, score=(train=0.882, test=0.842) total time=   7.6s\n",
      "[CV 8/10; 9/10] START class_weight={0: 0.004555555555555556, 1: 1}..............\n",
      "[CV 8/10; 9/10] END class_weight={0: 0.004555555555555556, 1: 1};, score=(train=0.877, test=0.864) total time=   6.4s\n",
      "[CV 2/10; 6/100] START class_weight={0: 0.0014545454545454547, 1: 1}............\n",
      "[CV 2/10; 6/100] END class_weight={0: 0.0014545454545454547, 1: 1};, score=(train=0.880, test=0.841) total time=   7.8s\n",
      "[CV 7/10; 10/100] START class_weight={0: 0.0018181818181818182, 1: 1}...........\n",
      "[CV 7/10; 10/100] END class_weight={0: 0.0018181818181818182, 1: 1};, score=(train=0.873, test=0.854) total time=   8.5s\n",
      "[CV 5/10; 17/100] START class_weight={0: 0.002454545454545455, 1: 1}............\n",
      "[CV 5/10; 17/100] END class_weight={0: 0.002454545454545455, 1: 1};, score=(train=0.878, test=0.838) total time=   7.8s\n",
      "[CV 1/10; 23/100] START class_weight={0: 0.003, 1: 1}...........................\n",
      "[CV 1/10; 23/100] END class_weight={0: 0.003, 1: 1};, score=(train=0.882, test=0.843) total time=   7.8s\n",
      "[CV 9/10; 28/100] START class_weight={0: 0.003454545454545455, 1: 1}............\n",
      "[CV 9/10; 28/100] END class_weight={0: 0.003454545454545455, 1: 1};, score=(train=0.881, test=0.835) total time=   9.0s\n",
      "[CV 7/10; 35/100] START class_weight={0: 0.004090909090909091, 1: 1}............\n",
      "[CV 7/10; 35/100] END class_weight={0: 0.004090909090909091, 1: 1};, score=(train=0.876, test=0.861) total time=   8.4s\n",
      "[CV 7/10; 41/100] START class_weight={0: 0.004636363636363636, 1: 1}............\n",
      "[CV 7/10; 41/100] END class_weight={0: 0.004636363636363636, 1: 1};, score=(train=0.878, test=0.866) total time=   8.0s\n",
      "[CV 2/10; 48/100] START class_weight={0: 0.0052727272727272735, 1: 1}...........\n",
      "[CV 2/10; 48/100] END class_weight={0: 0.0052727272727272735, 1: 1};, score=(train=0.880, test=0.833) total time=   7.6s\n",
      "[CV 8/10; 53/100] START class_weight={0: 0.0057272727272727275, 1: 1}...........\n",
      "[CV 8/10; 53/100] END class_weight={0: 0.0057272727272727275, 1: 1};, score=(train=0.877, test=0.865) total time=   7.2s\n",
      "[CV 2/10; 59/100] START class_weight={0: 0.006272727272727274, 1: 1}............\n",
      "[CV 2/10; 59/100] END class_weight={0: 0.006272727272727274, 1: 1};, score=(train=0.880, test=0.831) total time=   8.9s\n",
      "[CV 6/10; 65/100] START class_weight={0: 0.006818181818181819, 1: 1}............\n",
      "[CV 6/10; 65/100] END class_weight={0: 0.006818181818181819, 1: 1};, score=(train=0.879, test=0.837) total time=  10.2s\n",
      "[CV 4/10; 73/100] START class_weight={0: 0.007545454545454546, 1: 1}............\n",
      "[CV 4/10; 73/100] END class_weight={0: 0.007545454545454546, 1: 1};, score=(train=0.877, test=0.841) total time=   8.9s\n",
      "[CV 5/10; 79/100] START class_weight={0: 0.008090909090909091, 1: 1}............\n",
      "[CV 5/10; 79/100] END class_weight={0: 0.008090909090909091, 1: 1};, score=(train=0.880, test=0.831) total time=   7.9s\n",
      "[CV 2/10; 85/100] START class_weight={0: 0.008636363636363636, 1: 1}............\n",
      "[CV 2/10; 85/100] END class_weight={0: 0.008636363636363636, 1: 1};, score=(train=0.879, test=0.858) total time=  11.2s\n",
      "[CV 2/10; 93/100] START class_weight={0: 0.009363636363636366, 1: 1}............\n",
      "[CV 2/10; 93/100] END class_weight={0: 0.009363636363636366, 1: 1};, score=(train=0.879, test=0.857) total time=  11.4s\n",
      "[CV 5/10; 100/100] START class_weight={0: 0.01, 1: 1}...........................\n",
      "[CV 5/10; 100/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.879, test=0.836) total time=   6.5s\n",
      "[CV 1/10; 7/100] START class_weight={0: 0.010606060606060607, 1: 1}.............\n",
      "[CV 1/10; 7/100] END class_weight={0: 0.010606060606060607, 1: 1};, score=(train=0.879, test=0.844) total time=  12.1s\n",
      "[CV 6/10; 13/100] START class_weight={0: 0.011212121212121211, 1: 1}............\n",
      "[CV 6/10; 13/100] END class_weight={0: 0.011212121212121211, 1: 1};, score=(train=0.876, test=0.833) total time=   8.8s\n",
      "[CV 3/10; 19/100] START class_weight={0: 0.011818181818181818, 1: 1}............\n",
      "[CV 3/10; 19/100] END class_weight={0: 0.011818181818181818, 1: 1};, score=(train=0.879, test=0.831) total time=   8.3s\n",
      "[CV 10/10; 23/100] START class_weight={0: 0.012222222222222223, 1: 1}...........\n",
      "[CV 10/10; 23/100] END class_weight={0: 0.012222222222222223, 1: 1};, score=(train=0.880, test=0.866) total time=   8.0s\n",
      "[CV 8/10; 28/100] START class_weight={0: 0.012727272727272728, 1: 1}............\n",
      "[CV 8/10; 28/100] END class_weight={0: 0.012727272727272728, 1: 1};, score=(train=0.880, test=0.883) total time=   7.7s\n",
      "[CV 7/10; 33/100] START class_weight={0: 0.013232323232323233, 1: 1}............\n",
      "[CV 7/10; 33/100] END class_weight={0: 0.013232323232323233, 1: 1};, score=(train=0.878, test=0.862) total time=   9.2s\n",
      "[CV 10/10; 39/100] START class_weight={0: 0.013838383838383839, 1: 1}...........\n",
      "[CV 10/10; 39/100] END class_weight={0: 0.013838383838383839, 1: 1};, score=(train=0.878, test=0.861) total time=   7.4s\n",
      "[CV 1/10; 45/100] START class_weight={0: 0.014444444444444444, 1: 1}............\n",
      "[CV 1/10; 45/100] END class_weight={0: 0.014444444444444444, 1: 1};, score=(train=0.879, test=0.871) total time=  11.7s\n",
      "[CV 6/10; 52/100] START class_weight={0: 0.015151515151515152, 1: 1}............\n",
      "[CV 6/10; 52/100] END class_weight={0: 0.015151515151515152, 1: 1};, score=(train=0.881, test=0.826) total time=  10.1s\n",
      "[CV 2/10; 59/100] START class_weight={0: 0.015858585858585857, 1: 1}............\n",
      "[CV 2/10; 59/100] END class_weight={0: 0.015858585858585857, 1: 1};, score=(train=0.883, test=0.847) total time=  10.1s\n",
      "[CV 8/10; 65/100] START class_weight={0: 0.016464646464646467, 1: 1}............\n",
      "[CV 8/10; 65/100] END class_weight={0: 0.016464646464646467, 1: 1};, score=(train=0.877, test=0.872) total time=   9.4s\n",
      "[CV 4/10; 72/100] START class_weight={0: 0.01717171717171717, 1: 1}.............\n",
      "[CV 4/10; 72/100] END class_weight={0: 0.01717171717171717, 1: 1};, score=(train=0.883, test=0.848) total time=  10.1s\n",
      "[CV 4/10; 78/100] START class_weight={0: 0.017777777777777778, 1: 1}............\n",
      "[CV 4/10; 78/100] END class_weight={0: 0.017777777777777778, 1: 1};, score=(train=0.883, test=0.848) total time=  11.9s\n",
      "[CV 8/10; 85/100] START class_weight={0: 0.018484848484848486, 1: 1}............\n",
      "[CV 8/10; 85/100] END class_weight={0: 0.018484848484848486, 1: 1};, score=(train=0.879, test=0.884) total time=  10.0s\n",
      "[CV 7/10; 92/100] START class_weight={0: 0.01919191919191919, 1: 1}.............\n",
      "[CV 7/10; 92/100] END class_weight={0: 0.01919191919191919, 1: 1};, score=(train=0.880, test=0.852) total time=  10.9s\n",
      "[CV 6/10; 99/100] START class_weight={0: 0.0198989898989899, 1: 1}..............\n",
      "[CV 6/10; 99/100] END class_weight={0: 0.0198989898989899, 1: 1};, score=(train=0.881, test=0.826) total time=   7.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10; 3/10] START class_weight={0: 0.001888888888888889, 1: 1}..............\n",
      "[CV 1/10; 3/10] END class_weight={0: 0.001888888888888889, 1: 1};, score=(train=0.883, test=0.845) total time=   7.3s\n",
      "[CV 5/10; 9/10] START class_weight={0: 0.004555555555555556, 1: 1}..............\n",
      "[CV 5/10; 9/10] END class_weight={0: 0.004555555555555556, 1: 1};, score=(train=0.880, test=0.844) total time=   6.1s\n",
      "[CV 6/10; 5/100] START class_weight={0: 0.0013636363636363637, 1: 1}............\n",
      "[CV 6/10; 5/100] END class_weight={0: 0.0013636363636363637, 1: 1};, score=(train=0.882, test=0.835) total time=   7.7s\n",
      "[CV 10/10; 10/100] START class_weight={0: 0.0018181818181818182, 1: 1}..........\n",
      "[CV 10/10; 10/100] END class_weight={0: 0.0018181818181818182, 1: 1};, score=(train=0.877, test=0.848) total time=   7.6s\n",
      "[CV 3/10; 16/100] START class_weight={0: 0.0023636363636363638, 1: 1}...........\n",
      "[CV 3/10; 16/100] END class_weight={0: 0.0023636363636363638, 1: 1};, score=(train=0.879, test=0.839) total time=   7.0s\n",
      "[CV 6/10; 21/100] START class_weight={0: 0.0028181818181818186, 1: 1}...........\n",
      "[CV 6/10; 21/100] END class_weight={0: 0.0028181818181818186, 1: 1};, score=(train=0.880, test=0.832) total time=  10.5s\n",
      "[CV 1/10; 30/100] START class_weight={0: 0.003636363636363637, 1: 1}............\n",
      "[CV 1/10; 30/100] END class_weight={0: 0.003636363636363637, 1: 1};, score=(train=0.879, test=0.838) total time=   7.0s\n",
      "[CV 1/10; 35/100] START class_weight={0: 0.004090909090909091, 1: 1}............\n",
      "[CV 1/10; 35/100] END class_weight={0: 0.004090909090909091, 1: 1};, score=(train=0.881, test=0.839) total time=   8.5s\n",
      "[CV 4/10; 41/100] START class_weight={0: 0.004636363636363636, 1: 1}............\n",
      "[CV 4/10; 41/100] END class_weight={0: 0.004636363636363636, 1: 1};, score=(train=0.879, test=0.849) total time=   6.8s\n",
      "[CV 3/10; 47/100] START class_weight={0: 0.005181818181818182, 1: 1}............\n",
      "[CV 3/10; 47/100] END class_weight={0: 0.005181818181818182, 1: 1};, score=(train=0.879, test=0.846) total time=   6.9s\n",
      "[CV 10/10; 51/100] START class_weight={0: 0.005545454545454546, 1: 1}...........\n",
      "[CV 10/10; 51/100] END class_weight={0: 0.005545454545454546, 1: 1};, score=(train=0.879, test=0.858) total time=   9.3s\n",
      "[CV 9/10; 58/100] START class_weight={0: 0.006181818181818182, 1: 1}............\n",
      "[CV 9/10; 58/100] END class_weight={0: 0.006181818181818182, 1: 1};, score=(train=0.880, test=0.848) total time=  10.1s\n",
      "[CV 10/10; 65/100] START class_weight={0: 0.006818181818181819, 1: 1}...........\n",
      "[CV 10/10; 65/100] END class_weight={0: 0.006818181818181819, 1: 1};, score=(train=0.879, test=0.858) total time=   8.7s\n",
      "[CV 3/10; 72/100] START class_weight={0: 0.007454545454545455, 1: 1}............\n",
      "[CV 3/10; 72/100] END class_weight={0: 0.007454545454545455, 1: 1};, score=(train=0.881, test=0.843) total time=   9.7s\n",
      "[CV 10/10; 78/100] START class_weight={0: 0.008, 1: 1}..........................\n",
      "[CV 10/10; 78/100] END class_weight={0: 0.008, 1: 1};, score=(train=0.877, test=0.850) total time=   9.4s\n",
      "[CV 1/10; 86/100] START class_weight={0: 0.008727272727272728, 1: 1}............\n",
      "[CV 1/10; 86/100] END class_weight={0: 0.008727272727272728, 1: 1};, score=(train=0.877, test=0.844) total time=  11.9s\n",
      "[CV 2/10; 94/100] START class_weight={0: 0.009454545454545455, 1: 1}............\n",
      "[CV 2/10; 94/100] END class_weight={0: 0.009454545454545455, 1: 1};, score=(train=0.879, test=0.834) total time=   9.1s\n",
      "[CV 3/10; 100/100] START class_weight={0: 0.01, 1: 1}...........................\n",
      "[CV 3/10; 100/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.879, test=0.835) total time=   6.7s\n",
      "[CV 4/10; 6/100] START class_weight={0: 0.010505050505050505, 1: 1}.............\n",
      "[CV 4/10; 6/100] END class_weight={0: 0.010505050505050505, 1: 1};, score=(train=0.876, test=0.838) total time=  12.6s\n",
      "[CV 7/10; 13/100] START class_weight={0: 0.011212121212121211, 1: 1}............\n",
      "[CV 7/10; 13/100] END class_weight={0: 0.011212121212121211, 1: 1};, score=(train=0.878, test=0.862) total time=  12.5s\n",
      "[CV 5/10; 20/100] START class_weight={0: 0.01191919191919192, 1: 1}.............\n",
      "[CV 5/10; 20/100] END class_weight={0: 0.01191919191919192, 1: 1};, score=(train=0.878, test=0.841) total time=   9.0s\n",
      "[CV 6/10; 26/100] START class_weight={0: 0.012525252525252526, 1: 1}............\n",
      "[CV 6/10; 26/100] END class_weight={0: 0.012525252525252526, 1: 1};, score=(train=0.880, test=0.832) total time=  11.6s\n",
      "[CV 9/10; 33/100] START class_weight={0: 0.013232323232323233, 1: 1}............\n",
      "[CV 9/10; 33/100] END class_weight={0: 0.013232323232323233, 1: 1};, score=(train=0.880, test=0.837) total time=   9.4s\n",
      "[CV 4/10; 40/100] START class_weight={0: 0.013939393939393939, 1: 1}............\n",
      "[CV 4/10; 40/100] END class_weight={0: 0.013939393939393939, 1: 1};, score=(train=0.878, test=0.835) total time=  10.4s\n",
      "[CV 10/10; 46/100] START class_weight={0: 0.014545454545454545, 1: 1}...........\n",
      "[CV 10/10; 46/100] END class_weight={0: 0.014545454545454545, 1: 1};, score=(train=0.878, test=0.861) total time=  11.5s\n",
      "[CV 6/10; 54/100] START class_weight={0: 0.015353535353535354, 1: 1}............\n",
      "[CV 6/10; 54/100] END class_weight={0: 0.015353535353535354, 1: 1};, score=(train=0.881, test=0.826) total time=   8.4s\n",
      "[CV 2/10; 60/100] START class_weight={0: 0.01595959595959596, 1: 1}.............\n",
      "[CV 2/10; 60/100] END class_weight={0: 0.01595959595959596, 1: 1};, score=(train=0.878, test=0.843) total time=  13.9s\n",
      "[CV 7/10; 69/100] START class_weight={0: 0.01686868686868687, 1: 1}.............\n",
      "[CV 7/10; 69/100] END class_weight={0: 0.01686868686868687, 1: 1};, score=(train=0.881, test=0.852) total time=   9.5s\n",
      "[CV 8/10; 75/100] START class_weight={0: 0.017474747474747476, 1: 1}............\n",
      "[CV 8/10; 75/100] END class_weight={0: 0.017474747474747476, 1: 1};, score=(train=0.880, test=0.873) total time=   9.3s\n",
      "[CV 6/10; 81/100] START class_weight={0: 0.01808080808080808, 1: 1}.............\n",
      "[CV 6/10; 81/100] END class_weight={0: 0.01808080808080808, 1: 1};, score=(train=0.881, test=0.826) total time=   8.4s\n",
      "[CV 10/10; 86/100] START class_weight={0: 0.018585858585858588, 1: 1}...........\n",
      "[CV 10/10; 86/100] END class_weight={0: 0.018585858585858588, 1: 1};, score=(train=0.881, test=0.865) total time=   9.9s\n",
      "[CV 3/10; 93/100] START class_weight={0: 0.019292929292929292, 1: 1}............\n",
      "[CV 3/10; 93/100] END class_weight={0: 0.019292929292929292, 1: 1};, score=(train=0.882, test=0.829) total time=   8.0s\n",
      "[CV 10/10; 98/100] START class_weight={0: 0.0197979797979798, 1: 1}.............\n",
      "[CV 10/10; 98/100] END class_weight={0: 0.0197979797979798, 1: 1};, score=(train=0.881, test=0.865) total time=   8.8s\n",
      "[CV 1/10; 7/10] START class_weight={0: 0.003666666666666667, 1: 1}..............\n",
      "[CV 1/10; 7/10] END class_weight={0: 0.003666666666666667, 1: 1};, score=(train=0.881, test=0.841) total time=   9.4s\n",
      "[CV 3/10; 3/100] START class_weight={0: 0.0011818181818181819, 1: 1}............\n",
      "[CV 3/10; 3/100] END class_weight={0: 0.0011818181818181819, 1: 1};, score=(train=0.879, test=0.837) total time=   7.4s\n",
      "[CV 9/10; 8/100] START class_weight={0: 0.0016363636363636363, 1: 1}............\n",
      "[CV 9/10; 8/100] END class_weight={0: 0.0016363636363636363, 1: 1};, score=(train=0.877, test=0.833) total time=   9.2s\n",
      "[CV 3/10; 17/100] START class_weight={0: 0.002454545454545455, 1: 1}............\n",
      "[CV 3/10; 17/100] END class_weight={0: 0.002454545454545455, 1: 1};, score=(train=0.879, test=0.839) total time=   9.0s\n",
      "[CV 1/10; 24/100] START class_weight={0: 0.003090909090909091, 1: 1}............\n",
      "[CV 1/10; 24/100] END class_weight={0: 0.003090909090909091, 1: 1};, score=(train=0.880, test=0.837) total time=   8.6s\n",
      "[CV 2/10; 30/100] START class_weight={0: 0.003636363636363637, 1: 1}............\n",
      "[CV 2/10; 30/100] END class_weight={0: 0.003636363636363637, 1: 1};, score=(train=0.881, test=0.829) total time=   7.3s\n",
      "[CV 6/10; 35/100] START class_weight={0: 0.004090909090909091, 1: 1}............\n",
      "[CV 6/10; 35/100] END class_weight={0: 0.004090909090909091, 1: 1};, score=(train=0.880, test=0.832) total time=   8.4s\n",
      "[CV 6/10; 41/100] START class_weight={0: 0.004636363636363636, 1: 1}............\n",
      "[CV 6/10; 41/100] END class_weight={0: 0.004636363636363636, 1: 1};, score=(train=0.880, test=0.836) total time=   8.6s\n",
      "[CV 3/10; 48/100] START class_weight={0: 0.0052727272727272735, 1: 1}...........\n",
      "[CV 3/10; 48/100] END class_weight={0: 0.0052727272727272735, 1: 1};, score=(train=0.880, test=0.846) total time=   8.6s\n",
      "[CV 10/10; 54/100] START class_weight={0: 0.005818181818181819, 1: 1}...........\n",
      "[CV 10/10; 54/100] END class_weight={0: 0.005818181818181819, 1: 1};, score=(train=0.878, test=0.860) total time=   8.1s\n",
      "[CV 3/10; 60/100] START class_weight={0: 0.006363636363636364, 1: 1}............\n",
      "[CV 3/10; 60/100] END class_weight={0: 0.006363636363636364, 1: 1};, score=(train=0.881, test=0.843) total time=   9.3s\n",
      "[CV 1/10; 67/100] START class_weight={0: 0.007, 1: 1}...........................\n",
      "[CV 1/10; 67/100] END class_weight={0: 0.007, 1: 1};, score=(train=0.877, test=0.846) total time=  10.3s\n",
      "[CV 10/10; 74/100] START class_weight={0: 0.007636363636363637, 1: 1}...........\n",
      "[CV 10/10; 74/100] END class_weight={0: 0.007636363636363637, 1: 1};, score=(train=0.877, test=0.851) total time=   8.4s\n",
      "[CV 8/10; 80/100] START class_weight={0: 0.008181818181818182, 1: 1}............\n",
      "[CV 8/10; 80/100] END class_weight={0: 0.008181818181818182, 1: 1};, score=(train=0.874, test=0.866) total time=   7.5s\n",
      "[CV 6/10; 85/100] START class_weight={0: 0.008636363636363636, 1: 1}............\n",
      "[CV 6/10; 85/100] END class_weight={0: 0.008636363636363636, 1: 1};, score=(train=0.879, test=0.836) total time=  10.0s\n",
      "[CV 8/10; 92/100] START class_weight={0: 0.009272727272727273, 1: 1}............\n",
      "[CV 8/10; 92/100] END class_weight={0: 0.009272727272727273, 1: 1};, score=(train=0.877, test=0.856) total time=   8.8s\n",
      "[CV 7/10; 98/100] START class_weight={0: 0.00981818181818182, 1: 1}.............\n",
      "[CV 7/10; 98/100] END class_weight={0: 0.00981818181818182, 1: 1};, score=(train=0.878, test=0.857) total time=   7.9s\n",
      "[CV 5/10; 4/100] START class_weight={0: 0.010303030303030303, 1: 1}.............\n",
      "[CV 5/10; 4/100] END class_weight={0: 0.010303030303030303, 1: 1};, score=(train=0.879, test=0.836) total time=   8.7s\n",
      "[CV 7/10; 8/100] START class_weight={0: 0.010707070707070707, 1: 1}.............\n",
      "[CV 7/10; 8/100] END class_weight={0: 0.010707070707070707, 1: 1};, score=(train=0.880, test=0.868) total time=  10.4s\n",
      "[CV 5/10; 16/100] START class_weight={0: 0.011515151515151515, 1: 1}............\n",
      "[CV 5/10; 16/100] END class_weight={0: 0.011515151515151515, 1: 1};, score=(train=0.876, test=0.841) total time=   9.6s\n",
      "[CV 8/10; 22/100] START class_weight={0: 0.012121212121212121, 1: 1}............\n",
      "[CV 8/10; 22/100] END class_weight={0: 0.012121212121212121, 1: 1};, score=(train=0.880, test=0.882) total time=  12.0s\n",
      "[CV 3/10; 31/100] START class_weight={0: 0.013030303030303031, 1: 1}............\n",
      "[CV 3/10; 31/100] END class_weight={0: 0.013030303030303031, 1: 1};, score=(train=0.876, test=0.838) total time=   9.4s\n",
      "[CV 1/10; 37/100] START class_weight={0: 0.013636363636363637, 1: 1}............\n",
      "[CV 1/10; 37/100] END class_weight={0: 0.013636363636363637, 1: 1};, score=(train=0.877, test=0.864) total time=   8.0s\n",
      "[CV 2/10; 42/100] START class_weight={0: 0.014141414141414142, 1: 1}............\n",
      "[CV 2/10; 42/100] END class_weight={0: 0.014141414141414142, 1: 1};, score=(train=0.878, test=0.843) total time=   9.8s\n",
      "[CV 9/10; 48/100] START class_weight={0: 0.014747474747474749, 1: 1}............\n",
      "[CV 9/10; 48/100] END class_weight={0: 0.014747474747474749, 1: 1};, score=(train=0.880, test=0.837) total time=  11.5s\n",
      "[CV 6/10; 56/100] START class_weight={0: 0.015555555555555555, 1: 1}............\n",
      "[CV 6/10; 56/100] END class_weight={0: 0.015555555555555555, 1: 1};, score=(train=0.881, test=0.832) total time=  10.9s\n",
      "[CV 7/10; 63/100] START class_weight={0: 0.016262626262626263, 1: 1}............\n",
      "[CV 7/10; 63/100] END class_weight={0: 0.016262626262626263, 1: 1};, score=(train=0.881, test=0.852) total time=   9.2s\n",
      "[CV 6/10; 69/100] START class_weight={0: 0.01686868686868687, 1: 1}.............\n",
      "[CV 6/10; 69/100] END class_weight={0: 0.01686868686868687, 1: 1};, score=(train=0.881, test=0.826) total time=   8.7s\n",
      "[CV 2/10; 75/100] START class_weight={0: 0.017474747474747476, 1: 1}............\n",
      "[CV 2/10; 75/100] END class_weight={0: 0.017474747474747476, 1: 1};, score=(train=0.882, test=0.845) total time=  10.5s\n",
      "[CV 5/10; 81/100] START class_weight={0: 0.01808080808080808, 1: 1}.............\n",
      "[CV 5/10; 81/100] END class_weight={0: 0.01808080808080808, 1: 1};, score=(train=0.883, test=0.836) total time=  10.3s\n",
      "[CV 8/10; 88/100] START class_weight={0: 0.018787878787878787, 1: 1}............\n",
      "[CV 8/10; 88/100] END class_weight={0: 0.018787878787878787, 1: 1};, score=(train=0.879, test=0.884) total time=   9.2s\n",
      "[CV 7/10; 94/100] START class_weight={0: 0.019393939393939394, 1: 1}............\n",
      "[CV 7/10; 94/100] END class_weight={0: 0.019393939393939394, 1: 1};, score=(train=0.878, test=0.851) total time=   8.2s\n",
      "[CV 7/10; 99/100] START class_weight={0: 0.0198989898989899, 1: 1}..............\n",
      "[CV 7/10; 99/100] END class_weight={0: 0.0198989898989899, 1: 1};, score=(train=0.879, test=0.851) total time=   7.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10; 3/10] START class_weight={0: 0.001888888888888889, 1: 1}..............\n",
      "[CV 3/10; 3/10] END class_weight={0: 0.001888888888888889, 1: 1};, score=(train=0.880, test=0.838) total time=   7.2s\n",
      "[CV 7/10; 8/10] START class_weight={0: 0.004111111111111111, 1: 1}..............\n",
      "[CV 7/10; 8/10] END class_weight={0: 0.004111111111111111, 1: 1};, score=(train=0.878, test=0.866) total time=   6.0s\n",
      "[CV 3/10; 4/100] START class_weight={0: 0.0012727272727272728, 1: 1}............\n",
      "[CV 3/10; 4/100] END class_weight={0: 0.0012727272727272728, 1: 1};, score=(train=0.879, test=0.837) total time=   6.1s\n",
      "[CV 6/10; 7/100] START class_weight={0: 0.0015454545454545456, 1: 1}............\n",
      "[CV 6/10; 7/100] END class_weight={0: 0.0015454545454545456, 1: 1};, score=(train=0.881, test=0.821) total time=   7.0s\n",
      "[CV 3/10; 14/100] START class_weight={0: 0.002181818181818182, 1: 1}............\n",
      "[CV 3/10; 14/100] END class_weight={0: 0.002181818181818182, 1: 1};, score=(train=0.880, test=0.836) total time=   7.2s\n",
      "[CV 6/10; 20/100] START class_weight={0: 0.0027272727272727275, 1: 1}...........\n",
      "[CV 6/10; 20/100] END class_weight={0: 0.0027272727272727275, 1: 1};, score=(train=0.879, test=0.831) total time=   8.0s\n",
      "[CV 7/10; 26/100] START class_weight={0: 0.003272727272727273, 1: 1}............\n",
      "[CV 7/10; 26/100] END class_weight={0: 0.003272727272727273, 1: 1};, score=(train=0.875, test=0.856) total time=   7.8s\n",
      "[CV 5/10; 32/100] START class_weight={0: 0.0038181818181818187, 1: 1}...........\n",
      "[CV 5/10; 32/100] END class_weight={0: 0.0038181818181818187, 1: 1};, score=(train=0.880, test=0.836) total time=   8.2s\n",
      "[CV 9/10; 38/100] START class_weight={0: 0.004363636363636364, 1: 1}............\n",
      "[CV 9/10; 38/100] END class_weight={0: 0.004363636363636364, 1: 1};, score=(train=0.882, test=0.841) total time=   8.1s\n",
      "[CV 9/10; 44/100] START class_weight={0: 0.00490909090909091, 1: 1}.............\n",
      "[CV 9/10; 44/100] END class_weight={0: 0.00490909090909091, 1: 1};, score=(train=0.882, test=0.845) total time=   9.9s\n",
      "[CV 3/10; 52/100] START class_weight={0: 0.005636363636363636, 1: 1}............\n",
      "[CV 3/10; 52/100] END class_weight={0: 0.005636363636363636, 1: 1};, score=(train=0.881, test=0.843) total time=  10.6s\n",
      "[CV 5/10; 59/100] START class_weight={0: 0.006272727272727274, 1: 1}............\n",
      "[CV 5/10; 59/100] END class_weight={0: 0.006272727272727274, 1: 1};, score=(train=0.879, test=0.832) total time=   8.1s\n",
      "[CV 5/10; 65/100] START class_weight={0: 0.006818181818181819, 1: 1}............\n",
      "[CV 5/10; 65/100] END class_weight={0: 0.006818181818181819, 1: 1};, score=(train=0.880, test=0.833) total time=   8.6s\n",
      "[CV 9/10; 71/100] START class_weight={0: 0.007363636363636364, 1: 1}............\n",
      "[CV 9/10; 71/100] END class_weight={0: 0.007363636363636364, 1: 1};, score=(train=0.881, test=0.842) total time=   9.2s\n",
      "[CV 4/10; 78/100] START class_weight={0: 0.008, 1: 1}...........................\n",
      "[CV 4/10; 78/100] END class_weight={0: 0.008, 1: 1};, score=(train=0.877, test=0.841) total time=   7.8s\n",
      "[CV 10/10; 83/100] START class_weight={0: 0.008454545454545454, 1: 1}...........\n",
      "[CV 10/10; 83/100] END class_weight={0: 0.008454545454545454, 1: 1};, score=(train=0.876, test=0.850) total time=   8.7s\n",
      "[CV 9/10; 89/100] START class_weight={0: 0.009000000000000001, 1: 1}............\n",
      "[CV 9/10; 89/100] END class_weight={0: 0.009000000000000001, 1: 1};, score=(train=0.881, test=0.843) total time=   8.6s\n",
      "[CV 10/10; 95/100] START class_weight={0: 0.009545454545454548, 1: 1}...........\n",
      "[CV 10/10; 95/100] END class_weight={0: 0.009545454545454548, 1: 1};, score=(train=0.876, test=0.864) total time=   9.0s\n",
      "[CV 1/10; 2/100] START class_weight={0: 0.010101010101010102, 1: 1}.............\n",
      "[CV 1/10; 2/100] END class_weight={0: 0.010101010101010102, 1: 1};, score=(train=0.878, test=0.855) total time=  11.1s\n",
      "[CV 1/10; 13/100] START class_weight={0: 0.011212121212121211, 1: 1}............\n",
      "[CV 1/10; 13/100] END class_weight={0: 0.011212121212121211, 1: 1};, score=(train=0.879, test=0.860) total time=   9.9s\n",
      "[CV 8/10; 18/100] START class_weight={0: 0.011717171717171718, 1: 1}............\n",
      "[CV 8/10; 18/100] END class_weight={0: 0.011717171717171718, 1: 1};, score=(train=0.878, test=0.863) total time=  10.9s\n",
      "[CV 5/10; 25/100] START class_weight={0: 0.012424242424242424, 1: 1}............\n",
      "[CV 5/10; 25/100] END class_weight={0: 0.012424242424242424, 1: 1};, score=(train=0.876, test=0.841) total time=  11.2s\n",
      "[CV 7/10; 32/100] START class_weight={0: 0.013131313131313133, 1: 1}............\n",
      "[CV 7/10; 32/100] END class_weight={0: 0.013131313131313133, 1: 1};, score=(train=0.877, test=0.862) total time=  11.1s\n",
      "[CV 8/10; 39/100] START class_weight={0: 0.013838383838383839, 1: 1}............\n",
      "[CV 8/10; 39/100] END class_weight={0: 0.013838383838383839, 1: 1};, score=(train=0.880, test=0.883) total time=   7.7s\n",
      "[CV 2/10; 45/100] START class_weight={0: 0.014444444444444444, 1: 1}............\n",
      "[CV 2/10; 45/100] END class_weight={0: 0.014444444444444444, 1: 1};, score=(train=0.884, test=0.843) total time=  11.8s\n",
      "[CV 5/10; 52/100] START class_weight={0: 0.015151515151515152, 1: 1}............\n",
      "[CV 5/10; 52/100] END class_weight={0: 0.015151515151515152, 1: 1};, score=(train=0.879, test=0.824) total time=   8.3s\n",
      "[CV 5/10; 58/100] START class_weight={0: 0.01575757575757576, 1: 1}.............\n",
      "[CV 5/10; 58/100] END class_weight={0: 0.01575757575757576, 1: 1};, score=(train=0.879, test=0.824) total time=   9.2s\n",
      "[CV 3/10; 64/100] START class_weight={0: 0.016363636363636365, 1: 1}............\n",
      "[CV 3/10; 64/100] END class_weight={0: 0.016363636363636365, 1: 1};, score=(train=0.876, test=0.838) total time=   8.0s\n",
      "[CV 8/10; 69/100] START class_weight={0: 0.01686868686868687, 1: 1}.............\n",
      "[CV 8/10; 69/100] END class_weight={0: 0.01686868686868687, 1: 1};, score=(train=0.880, test=0.872) total time=  10.8s\n",
      "[CV 3/10; 76/100] START class_weight={0: 0.017575757575757578, 1: 1}............\n",
      "[CV 3/10; 76/100] END class_weight={0: 0.017575757575757578, 1: 1};, score=(train=0.876, test=0.838) total time=   9.0s\n",
      "[CV 7/10; 82/100] START class_weight={0: 0.01818181818181818, 1: 1}.............\n",
      "[CV 7/10; 82/100] END class_weight={0: 0.01818181818181818, 1: 1};, score=(train=0.879, test=0.863) total time=  11.4s\n",
      "[CV 6/10; 89/100] START class_weight={0: 0.01888888888888889, 1: 1}.............\n",
      "[CV 6/10; 89/100] END class_weight={0: 0.01888888888888889, 1: 1};, score=(train=0.881, test=0.830) total time=   8.6s\n",
      "[CV 3/10; 95/100] START class_weight={0: 0.019494949494949496, 1: 1}............\n",
      "[CV 3/10; 95/100] END class_weight={0: 0.019494949494949496, 1: 1};, score=(train=0.882, test=0.835) total time=   8.0s\n",
      "[CV 6/10; 100/100] START class_weight={0: 0.02, 1: 1}...........................\n",
      "[CV 6/10; 100/100] END class_weight={0: 0.02, 1: 1};, score=(train=0.881, test=0.832) total time=   6.4s\n",
      "[CV 1/10; 2/10] START class_weight={0: 0.0014444444444444444, 1: 1}.............\n",
      "[CV 1/10; 2/10] END class_weight={0: 0.0014444444444444444, 1: 1};, score=(train=0.878, test=0.836) total time=   6.3s\n",
      "[CV 9/10; 7/10] START class_weight={0: 0.003666666666666667, 1: 1}..............\n",
      "[CV 9/10; 7/10] END class_weight={0: 0.003666666666666667, 1: 1};, score=(train=0.878, test=0.840) total time=   6.6s\n",
      "[CV 2/10; 4/100] START class_weight={0: 0.0012727272727272728, 1: 1}............\n",
      "[CV 2/10; 4/100] END class_weight={0: 0.0012727272727272728, 1: 1};, score=(train=0.879, test=0.839) total time=   7.7s\n",
      "[CV 2/10; 10/100] START class_weight={0: 0.0018181818181818182, 1: 1}...........\n",
      "[CV 2/10; 10/100] END class_weight={0: 0.0018181818181818182, 1: 1};, score=(train=0.882, test=0.840) total time=  10.6s\n",
      "[CV 2/10; 19/100] START class_weight={0: 0.0026363636363636363, 1: 1}...........\n",
      "[CV 2/10; 19/100] END class_weight={0: 0.0026363636363636363, 1: 1};, score=(train=0.883, test=0.847) total time=   9.2s\n",
      "[CV 1/10; 26/100] START class_weight={0: 0.003272727272727273, 1: 1}............\n",
      "[CV 1/10; 26/100] END class_weight={0: 0.003272727272727273, 1: 1};, score=(train=0.882, test=0.843) total time=   8.0s\n",
      "[CV 2/10; 32/100] START class_weight={0: 0.0038181818181818187, 1: 1}...........\n",
      "[CV 2/10; 32/100] END class_weight={0: 0.0038181818181818187, 1: 1};, score=(train=0.880, test=0.837) total time=   6.8s\n",
      "[CV 9/10; 36/100] START class_weight={0: 0.004181818181818182, 1: 1}............\n",
      "[CV 9/10; 36/100] END class_weight={0: 0.004181818181818182, 1: 1};, score=(train=0.881, test=0.848) total time=   9.9s\n",
      "[CV 9/10; 43/100] START class_weight={0: 0.004818181818181819, 1: 1}............\n",
      "[CV 9/10; 43/100] END class_weight={0: 0.004818181818181819, 1: 1};, score=(train=0.882, test=0.839) total time=   8.4s\n",
      "[CV 2/10; 50/100] START class_weight={0: 0.005454545454545455, 1: 1}............\n",
      "[CV 2/10; 50/100] END class_weight={0: 0.005454545454545455, 1: 1};, score=(train=0.879, test=0.830) total time=   7.6s\n",
      "[CV 9/10; 55/100] START class_weight={0: 0.00590909090909091, 1: 1}.............\n",
      "[CV 9/10; 55/100] END class_weight={0: 0.00590909090909091, 1: 1};, score=(train=0.880, test=0.846) total time=   9.8s\n",
      "[CV 2/10; 63/100] START class_weight={0: 0.006636363636363637, 1: 1}............\n",
      "[CV 2/10; 63/100] END class_weight={0: 0.006636363636363637, 1: 1};, score=(train=0.881, test=0.825) total time=   8.4s\n",
      "[CV 3/10; 69/100] START class_weight={0: 0.0071818181818181824, 1: 1}...........\n",
      "[CV 3/10; 69/100] END class_weight={0: 0.0071818181818181824, 1: 1};, score=(train=0.881, test=0.843) total time=  10.0s\n",
      "[CV 1/10; 76/100] START class_weight={0: 0.007818181818181818, 1: 1}............\n",
      "[CV 1/10; 76/100] END class_weight={0: 0.007818181818181818, 1: 1};, score=(train=0.877, test=0.846) total time=  10.6s\n",
      "[CV 4/10; 83/100] START class_weight={0: 0.008454545454545454, 1: 1}............\n",
      "[CV 4/10; 83/100] END class_weight={0: 0.008454545454545454, 1: 1};, score=(train=0.877, test=0.841) total time=   8.9s\n",
      "[CV 7/10; 89/100] START class_weight={0: 0.009000000000000001, 1: 1}............\n",
      "[CV 7/10; 89/100] END class_weight={0: 0.009000000000000001, 1: 1};, score=(train=0.877, test=0.862) total time=   8.1s\n",
      "[CV 9/10; 95/100] START class_weight={0: 0.009545454545454548, 1: 1}............\n",
      "[CV 9/10; 95/100] END class_weight={0: 0.009545454545454548, 1: 1};, score=(train=0.881, test=0.842) total time=  10.3s\n",
      "[CV 4/10; 2/100] START class_weight={0: 0.010101010101010102, 1: 1}.............\n",
      "[CV 4/10; 2/100] END class_weight={0: 0.010101010101010102, 1: 1};, score=(train=0.876, test=0.840) total time=   9.3s\n",
      "[CV 10/10; 9/100] START class_weight={0: 0.010808080808080808, 1: 1}............\n",
      "[CV 10/10; 9/100] END class_weight={0: 0.010808080808080808, 1: 1};, score=(train=0.878, test=0.865) total time=   8.4s\n",
      "[CV 2/10; 15/100] START class_weight={0: 0.011414141414141415, 1: 1}............\n",
      "[CV 2/10; 15/100] END class_weight={0: 0.011414141414141415, 1: 1};, score=(train=0.877, test=0.849) total time=   9.6s\n",
      "[CV 7/10; 21/100] START class_weight={0: 0.012020202020202021, 1: 1}............\n",
      "[CV 7/10; 21/100] END class_weight={0: 0.012020202020202021, 1: 1};, score=(train=0.877, test=0.862) total time=   8.5s\n",
      "[CV 4/10; 27/100] START class_weight={0: 0.012626262626262626, 1: 1}............\n",
      "[CV 4/10; 27/100] END class_weight={0: 0.012626262626262626, 1: 1};, score=(train=0.878, test=0.835) total time=  11.0s\n",
      "[CV 6/10; 34/100] START class_weight={0: 0.013333333333333332, 1: 1}............\n",
      "[CV 6/10; 34/100] END class_weight={0: 0.013333333333333332, 1: 1};, score=(train=0.880, test=0.832) total time=   8.1s\n",
      "[CV 3/10; 40/100] START class_weight={0: 0.013939393939393939, 1: 1}............\n",
      "[CV 3/10; 40/100] END class_weight={0: 0.013939393939393939, 1: 1};, score=(train=0.876, test=0.838) total time=   8.5s\n",
      "[CV 8/10; 45/100] START class_weight={0: 0.014444444444444444, 1: 1}............\n",
      "[CV 8/10; 45/100] END class_weight={0: 0.014444444444444444, 1: 1};, score=(train=0.880, test=0.883) total time=   9.7s\n",
      "[CV 10/10; 51/100] START class_weight={0: 0.01505050505050505, 1: 1}............\n",
      "[CV 10/10; 51/100] END class_weight={0: 0.01505050505050505, 1: 1};, score=(train=0.878, test=0.861) total time=   8.8s\n",
      "[CV 1/10; 58/100] START class_weight={0: 0.01575757575757576, 1: 1}.............\n",
      "[CV 1/10; 58/100] END class_weight={0: 0.01575757575757576, 1: 1};, score=(train=0.878, test=0.851) total time=   7.7s\n",
      "[CV 2/10; 63/100] START class_weight={0: 0.016262626262626263, 1: 1}............\n",
      "[CV 2/10; 63/100] END class_weight={0: 0.016262626262626263, 1: 1};, score=(train=0.884, test=0.843) total time=   9.6s\n",
      "[CV 4/10; 69/100] START class_weight={0: 0.01686868686868687, 1: 1}.............\n",
      "[CV 4/10; 69/100] END class_weight={0: 0.01686868686868687, 1: 1};, score=(train=0.884, test=0.844) total time=   8.2s\n",
      "[CV 3/10; 74/100] START class_weight={0: 0.017373737373737375, 1: 1}............\n",
      "[CV 3/10; 74/100] END class_weight={0: 0.017373737373737375, 1: 1};, score=(train=0.879, test=0.830) total time=   8.3s\n",
      "[CV 7/10; 79/100] START class_weight={0: 0.01787878787878788, 1: 1}.............\n",
      "[CV 7/10; 79/100] END class_weight={0: 0.01787878787878788, 1: 1};, score=(train=0.881, test=0.853) total time=  10.0s\n",
      "[CV 2/10; 86/100] START class_weight={0: 0.018585858585858588, 1: 1}............\n",
      "[CV 2/10; 86/100] END class_weight={0: 0.018585858585858588, 1: 1};, score=(train=0.885, test=0.846) total time=  10.7s\n",
      "[CV 9/10; 92/100] START class_weight={0: 0.01919191919191919, 1: 1}.............\n",
      "[CV 9/10; 92/100] END class_weight={0: 0.01919191919191919, 1: 1};, score=(train=0.883, test=0.842) total time=   8.8s\n",
      "[CV 2/10; 99/100] START class_weight={0: 0.0198989898989899, 1: 1}..............\n",
      "[CV 2/10; 99/100] END class_weight={0: 0.0198989898989899, 1: 1};, score=(train=0.885, test=0.847) total time=   8.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10; 1/10] START class_weight={0: 0.001, 1: 1}.............................\n",
      "[CV 3/10; 1/10] END class_weight={0: 0.001, 1: 1};, score=(train=0.879, test=0.837) total time=   5.9s\n",
      "[CV 6/10; 7/10] START class_weight={0: 0.003666666666666667, 1: 1}..............\n",
      "[CV 6/10; 7/10] END class_weight={0: 0.003666666666666667, 1: 1};, score=(train=0.880, test=0.832) total time=   6.8s\n",
      "[CV 1/10; 4/100] START class_weight={0: 0.0012727272727272728, 1: 1}............\n",
      "[CV 1/10; 4/100] END class_weight={0: 0.0012727272727272728, 1: 1};, score=(train=0.877, test=0.840) total time=   7.7s\n",
      "[CV 6/10; 9/100] START class_weight={0: 0.0017272727272727275, 1: 1}............\n",
      "[CV 6/10; 9/100] END class_weight={0: 0.0017272727272727275, 1: 1};, score=(train=0.881, test=0.823) total time=   8.2s\n",
      "[CV 10/10; 16/100] START class_weight={0: 0.0023636363636363638, 1: 1}..........\n",
      "[CV 10/10; 16/100] END class_weight={0: 0.0023636363636363638, 1: 1};, score=(train=0.876, test=0.854) total time=   8.4s\n",
      "[CV 4/10; 23/100] START class_weight={0: 0.003, 1: 1}...........................\n",
      "[CV 4/10; 23/100] END class_weight={0: 0.003, 1: 1};, score=(train=0.878, test=0.842) total time=   7.6s\n",
      "[CV 10/10; 28/100] START class_weight={0: 0.003454545454545455, 1: 1}...........\n",
      "[CV 10/10; 28/100] END class_weight={0: 0.003454545454545455, 1: 1};, score=(train=0.878, test=0.855) total time=   7.3s\n",
      "[CV 3/10; 34/100] START class_weight={0: 0.004, 1: 1}...........................\n",
      "[CV 3/10; 34/100] END class_weight={0: 0.004, 1: 1};, score=(train=0.878, test=0.843) total time=   7.3s\n",
      "[CV 2/10; 40/100] START class_weight={0: 0.004545454545454545, 1: 1}............\n",
      "[CV 2/10; 40/100] END class_weight={0: 0.004545454545454545, 1: 1};, score=(train=0.879, test=0.830) total time=   8.1s\n",
      "[CV 5/10; 46/100] START class_weight={0: 0.005090909090909091, 1: 1}............\n",
      "[CV 5/10; 46/100] END class_weight={0: 0.005090909090909091, 1: 1};, score=(train=0.879, test=0.840) total time=   8.6s\n",
      "[CV 8/10; 52/100] START class_weight={0: 0.005636363636363636, 1: 1}............\n",
      "[CV 8/10; 52/100] END class_weight={0: 0.005636363636363636, 1: 1};, score=(train=0.877, test=0.865) total time=   8.1s\n",
      "[CV 6/10; 58/100] START class_weight={0: 0.006181818181818182, 1: 1}............\n",
      "[CV 6/10; 58/100] END class_weight={0: 0.006181818181818182, 1: 1};, score=(train=0.880, test=0.837) total time=   9.2s\n",
      "[CV 1/10; 65/100] START class_weight={0: 0.006818181818181819, 1: 1}............\n",
      "[CV 1/10; 65/100] END class_weight={0: 0.006818181818181819, 1: 1};, score=(train=0.877, test=0.846) total time=   8.5s\n",
      "[CV 2/10; 71/100] START class_weight={0: 0.007363636363636364, 1: 1}............\n",
      "[CV 2/10; 71/100] END class_weight={0: 0.007363636363636364, 1: 1};, score=(train=0.879, test=0.834) total time=   9.8s\n",
      "[CV 9/10; 77/100] START class_weight={0: 0.00790909090909091, 1: 1}.............\n",
      "[CV 9/10; 77/100] END class_weight={0: 0.00790909090909091, 1: 1};, score=(train=0.881, test=0.842) total time=   8.6s\n",
      "[CV 3/10; 84/100] START class_weight={0: 0.008545454545454547, 1: 1}............\n",
      "[CV 3/10; 84/100] END class_weight={0: 0.008545454545454547, 1: 1};, score=(train=0.881, test=0.843) total time=   8.6s\n",
      "[CV 5/10; 90/100] START class_weight={0: 0.00909090909090909, 1: 1}.............\n",
      "[CV 5/10; 90/100] END class_weight={0: 0.00909090909090909, 1: 1};, score=(train=0.879, test=0.836) total time=   9.5s\n",
      "[CV 4/10; 97/100] START class_weight={0: 0.009727272727272727, 1: 1}............\n",
      "[CV 4/10; 97/100] END class_weight={0: 0.009727272727272727, 1: 1};, score=(train=0.879, test=0.843) total time=   9.6s\n",
      "[CV 9/10; 3/100] START class_weight={0: 0.010202020202020202, 1: 1}.............\n",
      "[CV 9/10; 3/100] END class_weight={0: 0.010202020202020202, 1: 1};, score=(train=0.880, test=0.850) total time=   8.6s\n",
      "[CV 6/10; 8/100] START class_weight={0: 0.010707070707070707, 1: 1}.............\n",
      "[CV 6/10; 8/100] END class_weight={0: 0.010707070707070707, 1: 1};, score=(train=0.877, test=0.836) total time=  11.5s\n",
      "[CV 10/10; 17/100] START class_weight={0: 0.011616161616161616, 1: 1}...........\n",
      "[CV 10/10; 17/100] END class_weight={0: 0.011616161616161616, 1: 1};, score=(train=0.880, test=0.866) total time=  12.2s\n",
      "[CV 9/10; 25/100] START class_weight={0: 0.012424242424242424, 1: 1}............\n",
      "[CV 9/10; 25/100] END class_weight={0: 0.012424242424242424, 1: 1};, score=(train=0.880, test=0.838) total time=   8.8s\n",
      "[CV 6/10; 31/100] START class_weight={0: 0.013030303030303031, 1: 1}............\n",
      "[CV 6/10; 31/100] END class_weight={0: 0.013030303030303031, 1: 1};, score=(train=0.880, test=0.835) total time=   8.4s\n",
      "[CV 8/10; 36/100] START class_weight={0: 0.013535353535353536, 1: 1}............\n",
      "[CV 8/10; 36/100] END class_weight={0: 0.013535353535353536, 1: 1};, score=(train=0.880, test=0.883) total time=   9.5s\n",
      "[CV 2/10; 43/100] START class_weight={0: 0.014242424242424242, 1: 1}............\n",
      "[CV 2/10; 43/100] END class_weight={0: 0.014242424242424242, 1: 1};, score=(train=0.884, test=0.843) total time=   8.0s\n",
      "[CV 2/10; 48/100] START class_weight={0: 0.014747474747474749, 1: 1}............\n",
      "[CV 2/10; 48/100] END class_weight={0: 0.014747474747474749, 1: 1};, score=(train=0.878, test=0.843) total time=  13.0s\n",
      "[CV 9/10; 56/100] START class_weight={0: 0.015555555555555555, 1: 1}............\n",
      "[CV 9/10; 56/100] END class_weight={0: 0.015555555555555555, 1: 1};, score=(train=0.883, test=0.843) total time=  10.0s\n",
      "[CV 5/10; 63/100] START class_weight={0: 0.016262626262626263, 1: 1}............\n",
      "[CV 5/10; 63/100] END class_weight={0: 0.016262626262626263, 1: 1};, score=(train=0.883, test=0.837) total time=   8.8s\n",
      "[CV 8/10; 68/100] START class_weight={0: 0.016767676767676768, 1: 1}............\n",
      "[CV 8/10; 68/100] END class_weight={0: 0.016767676767676768, 1: 1};, score=(train=0.880, test=0.872) total time=   9.1s\n",
      "[CV 7/10; 74/100] START class_weight={0: 0.017373737373737375, 1: 1}............\n",
      "[CV 7/10; 74/100] END class_weight={0: 0.017373737373737375, 1: 1};, score=(train=0.881, test=0.853) total time=  11.2s\n",
      "[CV 1/10; 82/100] START class_weight={0: 0.01818181818181818, 1: 1}.............\n",
      "[CV 1/10; 82/100] END class_weight={0: 0.01818181818181818, 1: 1};, score=(train=0.878, test=0.851) total time=   8.3s\n",
      "[CV 1/10; 87/100] START class_weight={0: 0.01868686868686869, 1: 1}.............\n",
      "[CV 1/10; 87/100] END class_weight={0: 0.01868686868686869, 1: 1};, score=(train=0.877, test=0.856) total time=   8.6s\n",
      "[CV 8/10; 92/100] START class_weight={0: 0.01919191919191919, 1: 1}.............\n",
      "[CV 8/10; 92/100] END class_weight={0: 0.01919191919191919, 1: 1};, score=(train=0.879, test=0.884) total time=  11.8s\n",
      "[CV 4/10; 100/100] START class_weight={0: 0.02, 1: 1}...........................\n",
      "[CV 4/10; 100/100] END class_weight={0: 0.02, 1: 1};, score=(train=0.882, test=0.838) total time=   6.8s\n",
      "[CV 2/10; 3/10] START class_weight={0: 0.001888888888888889, 1: 1}..............\n",
      "[CV 2/10; 3/10] END class_weight={0: 0.001888888888888889, 1: 1};, score=(train=0.882, test=0.844) total time=   6.6s\n",
      "[CV 2/10; 8/10] START class_weight={0: 0.004111111111111111, 1: 1}..............\n",
      "[CV 2/10; 8/10] END class_weight={0: 0.004111111111111111, 1: 1};, score=(train=0.880, test=0.831) total time=   6.9s\n",
      "[CV 5/10; 5/100] START class_weight={0: 0.0013636363636363637, 1: 1}............\n",
      "[CV 5/10; 5/100] END class_weight={0: 0.0013636363636363637, 1: 1};, score=(train=0.879, test=0.829) total time=   5.6s\n",
      "[CV 5/10; 7/100] START class_weight={0: 0.0015454545454545456, 1: 1}............\n",
      "[CV 5/10; 7/100] END class_weight={0: 0.0015454545454545456, 1: 1};, score=(train=0.883, test=0.828) total time=   8.0s\n",
      "[CV 4/10; 14/100] START class_weight={0: 0.002181818181818182, 1: 1}............\n",
      "[CV 4/10; 14/100] END class_weight={0: 0.002181818181818182, 1: 1};, score=(train=0.877, test=0.840) total time=   6.7s\n",
      "[CV 8/10; 20/100] START class_weight={0: 0.0027272727272727275, 1: 1}...........\n",
      "[CV 8/10; 20/100] END class_weight={0: 0.0027272727272727275, 1: 1};, score=(train=0.877, test=0.864) total time=   7.2s\n",
      "[CV 5/10; 26/100] START class_weight={0: 0.003272727272727273, 1: 1}............\n",
      "[CV 5/10; 26/100] END class_weight={0: 0.003272727272727273, 1: 1};, score=(train=0.880, test=0.837) total time=   7.0s\n",
      "[CV 4/10; 31/100] START class_weight={0: 0.0037272727272727275, 1: 1}...........\n",
      "[CV 4/10; 31/100] END class_weight={0: 0.0037272727272727275, 1: 1};, score=(train=0.880, test=0.849) total time=   7.6s\n",
      "[CV 7/10; 36/100] START class_weight={0: 0.004181818181818182, 1: 1}............\n",
      "[CV 7/10; 36/100] END class_weight={0: 0.004181818181818182, 1: 1};, score=(train=0.878, test=0.866) total time=   6.9s\n",
      "[CV 5/10; 41/100] START class_weight={0: 0.004636363636363636, 1: 1}............\n",
      "[CV 5/10; 41/100] END class_weight={0: 0.004636363636363636, 1: 1};, score=(train=0.881, test=0.839) total time=   7.4s\n",
      "[CV 8/10; 47/100] START class_weight={0: 0.005181818181818182, 1: 1}............\n",
      "[CV 8/10; 47/100] END class_weight={0: 0.005181818181818182, 1: 1};, score=(train=0.877, test=0.865) total time=  10.9s\n",
      "[CV 7/10; 55/100] START class_weight={0: 0.00590909090909091, 1: 1}.............\n",
      "[CV 7/10; 55/100] END class_weight={0: 0.00590909090909091, 1: 1};, score=(train=0.877, test=0.862) total time=   8.3s\n",
      "[CV 9/10; 61/100] START class_weight={0: 0.006454545454545455, 1: 1}............\n",
      "[CV 9/10; 61/100] END class_weight={0: 0.006454545454545455, 1: 1};, score=(train=0.880, test=0.846) total time=   8.4s\n",
      "[CV 10/10; 67/100] START class_weight={0: 0.007, 1: 1}..........................\n",
      "[CV 10/10; 67/100] END class_weight={0: 0.007, 1: 1};, score=(train=0.874, test=0.848) total time=   9.2s\n",
      "[CV 9/10; 74/100] START class_weight={0: 0.007636363636363637, 1: 1}............\n",
      "[CV 9/10; 74/100] END class_weight={0: 0.007636363636363637, 1: 1};, score=(train=0.881, test=0.842) total time=   9.5s\n",
      "[CV 1/10; 81/100] START class_weight={0: 0.008272727272727274, 1: 1}............\n",
      "[CV 1/10; 81/100] END class_weight={0: 0.008272727272727274, 1: 1};, score=(train=0.878, test=0.847) total time=   7.9s\n",
      "[CV 2/10; 87/100] START class_weight={0: 0.008818181818181819, 1: 1}............\n",
      "[CV 2/10; 87/100] END class_weight={0: 0.008818181818181819, 1: 1};, score=(train=0.879, test=0.858) total time=   9.5s\n",
      "[CV 5/10; 93/100] START class_weight={0: 0.009363636363636366, 1: 1}............\n",
      "[CV 5/10; 93/100] END class_weight={0: 0.009363636363636366, 1: 1};, score=(train=0.879, test=0.836) total time=  10.6s\n",
      "[CV 2/10; 100/100] START class_weight={0: 0.01, 1: 1}...........................\n",
      "[CV 2/10; 100/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.880, test=0.846) total time=   6.9s\n",
      "[CV 5/10; 6/100] START class_weight={0: 0.010505050505050505, 1: 1}.............\n",
      "[CV 5/10; 6/100] END class_weight={0: 0.010505050505050505, 1: 1};, score=(train=0.877, test=0.839) total time=   8.9s\n",
      "[CV 9/10; 9/100] START class_weight={0: 0.010808080808080808, 1: 1}.............\n",
      "[CV 9/10; 9/100] END class_weight={0: 0.010808080808080808, 1: 1};, score=(train=0.880, test=0.850) total time=   7.6s\n",
      "[CV 5/10; 14/100] START class_weight={0: 0.011313131313131313, 1: 1}............\n",
      "[CV 5/10; 14/100] END class_weight={0: 0.011313131313131313, 1: 1};, score=(train=0.877, test=0.839) total time=   8.4s\n",
      "[CV 7/10; 20/100] START class_weight={0: 0.01191919191919192, 1: 1}.............\n",
      "[CV 7/10; 20/100] END class_weight={0: 0.01191919191919192, 1: 1};, score=(train=0.877, test=0.862) total time=  11.0s\n",
      "[CV 7/10; 27/100] START class_weight={0: 0.012626262626262626, 1: 1}............\n",
      "[CV 7/10; 27/100] END class_weight={0: 0.012626262626262626, 1: 1};, score=(train=0.878, test=0.862) total time=   9.4s\n",
      "[CV 8/10; 33/100] START class_weight={0: 0.013232323232323233, 1: 1}............\n",
      "[CV 8/10; 33/100] END class_weight={0: 0.013232323232323233, 1: 1};, score=(train=0.880, test=0.883) total time=   9.5s\n",
      "[CV 8/10; 40/100] START class_weight={0: 0.013939393939393939, 1: 1}............\n",
      "[CV 8/10; 40/100] END class_weight={0: 0.013939393939393939, 1: 1};, score=(train=0.880, test=0.883) total time=   9.8s\n",
      "[CV 7/10; 46/100] START class_weight={0: 0.014545454545454545, 1: 1}............\n",
      "[CV 7/10; 46/100] END class_weight={0: 0.014545454545454545, 1: 1};, score=(train=0.879, test=0.866) total time=  10.7s\n",
      "[CV 8/10; 53/100] START class_weight={0: 0.015252525252525254, 1: 1}............\n",
      "[CV 8/10; 53/100] END class_weight={0: 0.015252525252525254, 1: 1};, score=(train=0.880, test=0.884) total time=  11.2s\n",
      "[CV 3/10; 61/100] START class_weight={0: 0.01606060606060606, 1: 1}.............\n",
      "[CV 3/10; 61/100] END class_weight={0: 0.01606060606060606, 1: 1};, score=(train=0.876, test=0.838) total time=   7.6s\n",
      "[CV 1/10; 66/100] START class_weight={0: 0.016565656565656565, 1: 1}............\n",
      "[CV 1/10; 66/100] END class_weight={0: 0.016565656565656565, 1: 1};, score=(train=0.880, test=0.861) total time=   8.8s\n",
      "[CV 10/10; 71/100] START class_weight={0: 0.01707070707070707, 1: 1}............\n",
      "[CV 10/10; 71/100] END class_weight={0: 0.01707070707070707, 1: 1};, score=(train=0.881, test=0.867) total time=  10.9s\n",
      "[CV 10/10; 78/100] START class_weight={0: 0.017777777777777778, 1: 1}...........\n",
      "[CV 10/10; 78/100] END class_weight={0: 0.017777777777777778, 1: 1};, score=(train=0.879, test=0.869) total time=   9.3s\n",
      "[CV 4/10; 85/100] START class_weight={0: 0.018484848484848486, 1: 1}............\n",
      "[CV 4/10; 85/100] END class_weight={0: 0.018484848484848486, 1: 1};, score=(train=0.881, test=0.842) total time=  11.2s\n",
      "[CV 2/10; 92/100] START class_weight={0: 0.01919191919191919, 1: 1}.............\n",
      "[CV 2/10; 92/100] END class_weight={0: 0.01919191919191919, 1: 1};, score=(train=0.885, test=0.846) total time=  12.4s\n",
      "[CV 10/10; 99/100] START class_weight={0: 0.0198989898989899, 1: 1}.............\n",
      "[CV 10/10; 99/100] END class_weight={0: 0.0198989898989899, 1: 1};, score=(train=0.879, test=0.869) total time=   7.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10; 6/10] START class_weight={0: 0.0032222222222222222, 1: 1}............\n",
      "[CV 10/10; 6/10] END class_weight={0: 0.0032222222222222222, 1: 1};, score=(train=0.878, test=0.855) total time=   9.2s\n",
      "[CV 4/10; 3/100] START class_weight={0: 0.0011818181818181819, 1: 1}............\n",
      "[CV 4/10; 3/100] END class_weight={0: 0.0011818181818181819, 1: 1};, score=(train=0.877, test=0.834) total time=   8.1s\n",
      "[CV 3/10; 11/100] START class_weight={0: 0.0019090909090909093, 1: 1}...........\n",
      "[CV 3/10; 11/100] END class_weight={0: 0.0019090909090909093, 1: 1};, score=(train=0.880, test=0.837) total time=   7.0s\n",
      "[CV 9/10; 15/100] START class_weight={0: 0.0022727272727272726, 1: 1}...........\n",
      "[CV 9/10; 15/100] END class_weight={0: 0.0022727272727272726, 1: 1};, score=(train=0.881, test=0.839) total time=   9.4s\n",
      "[CV 6/10; 23/100] START class_weight={0: 0.003, 1: 1}...........................\n",
      "[CV 6/10; 23/100] END class_weight={0: 0.003, 1: 1};, score=(train=0.880, test=0.832) total time=   8.9s\n",
      "[CV 5/10; 30/100] START class_weight={0: 0.003636363636363637, 1: 1}............\n",
      "[CV 5/10; 30/100] END class_weight={0: 0.003636363636363637, 1: 1};, score=(train=0.880, test=0.837) total time=  10.3s\n",
      "[CV 8/10; 37/100] START class_weight={0: 0.0042727272727272735, 1: 1}...........\n",
      "[CV 8/10; 37/100] END class_weight={0: 0.0042727272727272735, 1: 1};, score=(train=0.878, test=0.869) total time=  11.4s\n",
      "[CV 7/10; 46/100] START class_weight={0: 0.005090909090909091, 1: 1}............\n",
      "[CV 7/10; 46/100] END class_weight={0: 0.005090909090909091, 1: 1};, score=(train=0.878, test=0.865) total time=   7.1s\n",
      "[CV 7/10; 51/100] START class_weight={0: 0.005545454545454546, 1: 1}............\n",
      "[CV 7/10; 51/100] END class_weight={0: 0.005545454545454546, 1: 1};, score=(train=0.878, test=0.865) total time=   9.3s\n",
      "[CV 7/10; 58/100] START class_weight={0: 0.006181818181818182, 1: 1}............\n",
      "[CV 7/10; 58/100] END class_weight={0: 0.006181818181818182, 1: 1};, score=(train=0.877, test=0.864) total time=  10.4s\n",
      "[CV 8/10; 65/100] START class_weight={0: 0.006818181818181819, 1: 1}............\n",
      "[CV 8/10; 65/100] END class_weight={0: 0.006818181818181819, 1: 1};, score=(train=0.878, test=0.865) total time=   8.1s\n",
      "[CV 4/10; 71/100] START class_weight={0: 0.007363636363636364, 1: 1}............\n",
      "[CV 4/10; 71/100] END class_weight={0: 0.007363636363636364, 1: 1};, score=(train=0.877, test=0.841) total time=   9.7s\n",
      "[CV 2/10; 78/100] START class_weight={0: 0.008, 1: 1}...........................\n",
      "[CV 2/10; 78/100] END class_weight={0: 0.008, 1: 1};, score=(train=0.879, test=0.857) total time=   7.5s\n",
      "[CV 6/10; 83/100] START class_weight={0: 0.008454545454545454, 1: 1}............\n",
      "[CV 6/10; 83/100] END class_weight={0: 0.008454545454545454, 1: 1};, score=(train=0.879, test=0.836) total time=   8.1s\n",
      "[CV 2/10; 89/100] START class_weight={0: 0.009000000000000001, 1: 1}............\n",
      "[CV 2/10; 89/100] END class_weight={0: 0.009000000000000001, 1: 1};, score=(train=0.880, test=0.836) total time=   7.6s\n",
      "[CV 6/10; 94/100] START class_weight={0: 0.009454545454545455, 1: 1}............\n",
      "[CV 6/10; 94/100] END class_weight={0: 0.009454545454545455, 1: 1};, score=(train=0.878, test=0.839) total time=   9.2s\n",
      "[CV 6/10; 100/100] START class_weight={0: 0.01, 1: 1}...........................\n",
      "[CV 6/10; 100/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.879, test=0.839) total time=   6.3s\n",
      "[CV 10/10; 6/100] START class_weight={0: 0.010505050505050505, 1: 1}............\n",
      "[CV 10/10; 6/100] END class_weight={0: 0.010505050505050505, 1: 1};, score=(train=0.878, test=0.865) total time=  11.2s\n",
      "[CV 3/10; 13/100] START class_weight={0: 0.011212121212121211, 1: 1}............\n",
      "[CV 3/10; 13/100] END class_weight={0: 0.011212121212121211, 1: 1};, score=(train=0.879, test=0.831) total time=  10.8s\n",
      "[CV 8/10; 19/100] START class_weight={0: 0.011818181818181818, 1: 1}............\n",
      "[CV 8/10; 19/100] END class_weight={0: 0.011818181818181818, 1: 1};, score=(train=0.880, test=0.882) total time=  10.7s\n",
      "[CV 2/10; 26/100] START class_weight={0: 0.012525252525252526, 1: 1}............\n",
      "[CV 2/10; 26/100] END class_weight={0: 0.012525252525252526, 1: 1};, score=(train=0.878, test=0.850) total time=   8.0s\n",
      "[CV 4/10; 31/100] START class_weight={0: 0.013030303030303031, 1: 1}............\n",
      "[CV 4/10; 31/100] END class_weight={0: 0.013030303030303031, 1: 1};, score=(train=0.878, test=0.835) total time=   9.1s\n",
      "[CV 4/10; 37/100] START class_weight={0: 0.013636363636363637, 1: 1}............\n",
      "[CV 4/10; 37/100] END class_weight={0: 0.013636363636363637, 1: 1};, score=(train=0.878, test=0.835) total time=   9.0s\n",
      "[CV 3/10; 43/100] START class_weight={0: 0.014242424242424242, 1: 1}............\n",
      "[CV 3/10; 43/100] END class_weight={0: 0.014242424242424242, 1: 1};, score=(train=0.876, test=0.838) total time=   6.9s\n",
      "[CV 8/10; 47/100] START class_weight={0: 0.014646464646464647, 1: 1}............\n",
      "[CV 8/10; 47/100] END class_weight={0: 0.014646464646464647, 1: 1};, score=(train=0.880, test=0.884) total time=   8.9s\n",
      "[CV 6/10; 53/100] START class_weight={0: 0.015252525252525254, 1: 1}............\n",
      "[CV 6/10; 53/100] END class_weight={0: 0.015252525252525254, 1: 1};, score=(train=0.881, test=0.830) total time=   9.9s\n",
      "[CV 9/10; 59/100] START class_weight={0: 0.015858585858585857, 1: 1}............\n",
      "[CV 9/10; 59/100] END class_weight={0: 0.015858585858585857, 1: 1};, score=(train=0.881, test=0.854) total time=  10.7s\n",
      "[CV 9/10; 66/100] START class_weight={0: 0.016565656565656565, 1: 1}............\n",
      "[CV 9/10; 66/100] END class_weight={0: 0.016565656565656565, 1: 1};, score=(train=0.881, test=0.854) total time=  11.1s\n",
      "[CV 8/10; 73/100] START class_weight={0: 0.017272727272727273, 1: 1}............\n",
      "[CV 8/10; 73/100] END class_weight={0: 0.017272727272727273, 1: 1};, score=(train=0.880, test=0.872) total time=   9.2s\n",
      "[CV 10/10; 79/100] START class_weight={0: 0.01787878787878788, 1: 1}............\n",
      "[CV 10/10; 79/100] END class_weight={0: 0.01787878787878788, 1: 1};, score=(train=0.879, test=0.869) total time=   9.0s\n",
      "[CV 7/10; 85/100] START class_weight={0: 0.018484848484848486, 1: 1}............\n",
      "[CV 7/10; 85/100] END class_weight={0: 0.018484848484848486, 1: 1};, score=(train=0.877, test=0.860) total time=  11.7s\n",
      "[CV 6/10; 93/100] START class_weight={0: 0.019292929292929292, 1: 1}............\n",
      "[CV 6/10; 93/100] END class_weight={0: 0.019292929292929292, 1: 1};, score=(train=0.881, test=0.826) total time=   9.9s\n",
      "[CV 1/10; 100/100] START class_weight={0: 0.02, 1: 1}...........................\n",
      "[CV 1/10; 100/100] END class_weight={0: 0.02, 1: 1};, score=(train=0.881, test=0.858) total time=   7.3s\n",
      "[CV 8/10; 4/10] START class_weight={0: 0.0023333333333333335, 1: 1}.............\n",
      "[CV 8/10; 4/10] END class_weight={0: 0.0023333333333333335, 1: 1};, score=(train=0.878, test=0.865) total time=   6.9s\n",
      "[CV 4/10; 8/10] START class_weight={0: 0.004111111111111111, 1: 1}..............\n",
      "[CV 4/10; 8/10] END class_weight={0: 0.004111111111111111, 1: 1};, score=(train=0.879, test=0.850) total time=   6.2s\n",
      "[CV 4/10; 4/100] START class_weight={0: 0.0012727272727272728, 1: 1}............\n",
      "[CV 4/10; 4/100] END class_weight={0: 0.0012727272727272728, 1: 1};, score=(train=0.874, test=0.831) total time=   7.5s\n",
      "[CV 8/10; 9/100] START class_weight={0: 0.0017272727272727275, 1: 1}............\n",
      "[CV 8/10; 9/100] END class_weight={0: 0.0017272727272727275, 1: 1};, score=(train=0.874, test=0.853) total time=   7.8s\n",
      "[CV 7/10; 15/100] START class_weight={0: 0.0022727272727272726, 1: 1}...........\n",
      "[CV 7/10; 15/100] END class_weight={0: 0.0022727272727272726, 1: 1};, score=(train=0.877, test=0.836) total time=   8.0s\n",
      "[CV 3/10; 22/100] START class_weight={0: 0.0029090909090909093, 1: 1}...........\n",
      "[CV 3/10; 22/100] END class_weight={0: 0.0029090909090909093, 1: 1};, score=(train=0.879, test=0.840) total time=   7.8s\n",
      "[CV 4/10; 28/100] START class_weight={0: 0.003454545454545455, 1: 1}............\n",
      "[CV 4/10; 28/100] END class_weight={0: 0.003454545454545455, 1: 1};, score=(train=0.880, test=0.849) total time=   8.1s\n",
      "[CV 4/10; 34/100] START class_weight={0: 0.004, 1: 1}...........................\n",
      "[CV 4/10; 34/100] END class_weight={0: 0.004, 1: 1};, score=(train=0.878, test=0.853) total time=   8.4s\n",
      "[CV 2/10; 41/100] START class_weight={0: 0.004636363636363636, 1: 1}............\n",
      "[CV 2/10; 41/100] END class_weight={0: 0.004636363636363636, 1: 1};, score=(train=0.879, test=0.830) total time=   8.6s\n",
      "[CV 7/10; 47/100] START class_weight={0: 0.005181818181818182, 1: 1}............\n",
      "[CV 7/10; 47/100] END class_weight={0: 0.005181818181818182, 1: 1};, score=(train=0.878, test=0.865) total time=   7.8s\n",
      "[CV 5/10; 53/100] START class_weight={0: 0.0057272727272727275, 1: 1}...........\n",
      "[CV 5/10; 53/100] END class_weight={0: 0.0057272727272727275, 1: 1};, score=(train=0.879, test=0.832) total time=   7.4s\n",
      "[CV 10/10; 58/100] START class_weight={0: 0.006181818181818182, 1: 1}...........\n",
      "[CV 10/10; 58/100] END class_weight={0: 0.006181818181818182, 1: 1};, score=(train=0.881, test=0.860) total time=  10.1s\n",
      "[CV 2/10; 66/100] START class_weight={0: 0.00690909090909091, 1: 1}.............\n",
      "[CV 2/10; 66/100] END class_weight={0: 0.00690909090909091, 1: 1};, score=(train=0.880, test=0.831) total time=   9.3s\n",
      "[CV 9/10; 72/100] START class_weight={0: 0.007454545454545455, 1: 1}............\n",
      "[CV 9/10; 72/100] END class_weight={0: 0.007454545454545455, 1: 1};, score=(train=0.881, test=0.842) total time=  12.3s\n",
      "[CV 2/10; 82/100] START class_weight={0: 0.008363636363636365, 1: 1}............\n",
      "[CV 2/10; 82/100] END class_weight={0: 0.008363636363636365, 1: 1};, score=(train=0.879, test=0.834) total time=  10.0s\n",
      "[CV 8/10; 88/100] START class_weight={0: 0.008909090909090908, 1: 1}............\n",
      "[CV 8/10; 88/100] END class_weight={0: 0.008909090909090908, 1: 1};, score=(train=0.877, test=0.868) total time=   9.4s\n",
      "[CV 2/10; 95/100] START class_weight={0: 0.009545454545454548, 1: 1}............\n",
      "[CV 2/10; 95/100] END class_weight={0: 0.009545454545454548, 1: 1};, score=(train=0.880, test=0.840) total time=   9.5s\n",
      "[CV 7/10; 1/100] START class_weight={0: 0.01, 1: 1}.............................\n",
      "[CV 7/10; 1/100] END class_weight={0: 0.01, 1: 1};, score=(train=0.876, test=0.864) total time=  10.0s\n",
      "[CV 5/10; 11/100] START class_weight={0: 0.01101010101010101, 1: 1}.............\n",
      "[CV 5/10; 11/100] END class_weight={0: 0.01101010101010101, 1: 1};, score=(train=0.877, test=0.839) total time=  12.2s\n",
      "[CV 7/10; 19/100] START class_weight={0: 0.011818181818181818, 1: 1}............\n",
      "[CV 7/10; 19/100] END class_weight={0: 0.011818181818181818, 1: 1};, score=(train=0.878, test=0.862) total time=  12.2s\n",
      "[CV 7/10; 26/100] START class_weight={0: 0.012525252525252526, 1: 1}............\n",
      "[CV 7/10; 26/100] END class_weight={0: 0.012525252525252526, 1: 1};, score=(train=0.877, test=0.862) total time=   9.4s\n",
      "[CV 9/10; 32/100] START class_weight={0: 0.013131313131313133, 1: 1}............\n",
      "[CV 9/10; 32/100] END class_weight={0: 0.013131313131313133, 1: 1};, score=(train=0.880, test=0.842) total time=   9.5s\n",
      "[CV 2/10; 39/100] START class_weight={0: 0.013838383838383839, 1: 1}............\n",
      "[CV 2/10; 39/100] END class_weight={0: 0.013838383838383839, 1: 1};, score=(train=0.884, test=0.843) total time=   9.3s\n",
      "[CV 4/10; 45/100] START class_weight={0: 0.014444444444444444, 1: 1}............\n",
      "[CV 4/10; 45/100] END class_weight={0: 0.014444444444444444, 1: 1};, score=(train=0.884, test=0.844) total time=  10.6s\n",
      "[CV 9/10; 51/100] START class_weight={0: 0.01505050505050505, 1: 1}.............\n",
      "[CV 9/10; 51/100] END class_weight={0: 0.01505050505050505, 1: 1};, score=(train=0.880, test=0.837) total time=   9.5s\n",
      "[CV 4/10; 58/100] START class_weight={0: 0.01575757575757576, 1: 1}.............\n",
      "[CV 4/10; 58/100] END class_weight={0: 0.01575757575757576, 1: 1};, score=(train=0.882, test=0.837) total time=   9.3s\n",
      "[CV 4/10; 64/100] START class_weight={0: 0.016363636363636365, 1: 1}............\n",
      "[CV 4/10; 64/100] END class_weight={0: 0.016363636363636365, 1: 1};, score=(train=0.882, test=0.837) total time=  11.9s\n",
      "[CV 9/10; 71/100] START class_weight={0: 0.01707070707070707, 1: 1}.............\n",
      "[CV 9/10; 71/100] END class_weight={0: 0.01707070707070707, 1: 1};, score=(train=0.881, test=0.854) total time=  11.9s\n",
      "[CV 4/10; 79/100] START class_weight={0: 0.01787878787878788, 1: 1}.............\n",
      "[CV 4/10; 79/100] END class_weight={0: 0.01787878787878788, 1: 1};, score=(train=0.881, test=0.842) total time=  10.7s\n",
      "[CV 10/10; 85/100] START class_weight={0: 0.018484848484848486, 1: 1}...........\n",
      "[CV 10/10; 85/100] END class_weight={0: 0.018484848484848486, 1: 1};, score=(train=0.879, test=0.869) total time=  11.2s\n",
      "[CV 2/10; 93/100] START class_weight={0: 0.019292929292929292, 1: 1}............\n",
      "[CV 2/10; 93/100] END class_weight={0: 0.019292929292929292, 1: 1};, score=(train=0.885, test=0.846) total time=   9.4s\n",
      "[CV 4/10; 99/100] START class_weight={0: 0.0198989898989899, 1: 1}..............\n",
      "[CV 4/10; 99/100] END class_weight={0: 0.0198989898989899, 1: 1};, score=(train=0.881, test=0.842) total time=   8.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 1/10] START class_weight={0: 0.001, 1: 1}.............................\n",
      "[CV 7/10; 1/10] END class_weight={0: 0.001, 1: 1};, score=(train=0.873, test=0.846) total time=   7.1s\n",
      "[CV 9/10; 8/10] START class_weight={0: 0.004111111111111111, 1: 1}..............\n",
      "[CV 9/10; 8/10] END class_weight={0: 0.004111111111111111, 1: 1};, score=(train=0.881, test=0.835) total time=   6.6s\n",
      "[CV 10/10; 5/100] START class_weight={0: 0.0013636363636363637, 1: 1}...........\n",
      "[CV 10/10; 5/100] END class_weight={0: 0.0013636363636363637, 1: 1};, score=(train=0.876, test=0.847) total time=   6.4s\n",
      "[CV 8/10; 7/100] START class_weight={0: 0.0015454545454545456, 1: 1}............\n",
      "[CV 8/10; 7/100] END class_weight={0: 0.0015454545454545456, 1: 1};, score=(train=0.877, test=0.873) total time=   6.3s\n",
      "[CV 10/10; 13/100] START class_weight={0: 0.002090909090909091, 1: 1}...........\n",
      "[CV 10/10; 13/100] END class_weight={0: 0.002090909090909091, 1: 1};, score=(train=0.880, test=0.847) total time=   7.9s\n",
      "[CV 9/10; 20/100] START class_weight={0: 0.0027272727272727275, 1: 1}...........\n",
      "[CV 9/10; 20/100] END class_weight={0: 0.0027272727272727275, 1: 1};, score=(train=0.881, test=0.833) total time=   6.5s\n",
      "[CV 8/10; 25/100] START class_weight={0: 0.003181818181818182, 1: 1}............\n",
      "[CV 8/10; 25/100] END class_weight={0: 0.003181818181818182, 1: 1};, score=(train=0.878, test=0.870) total time=   8.4s\n",
      "[CV 3/10; 32/100] START class_weight={0: 0.0038181818181818187, 1: 1}...........\n",
      "[CV 3/10; 32/100] END class_weight={0: 0.0038181818181818187, 1: 1};, score=(train=0.879, test=0.842) total time=   7.3s\n",
      "[CV 1/10; 37/100] START class_weight={0: 0.0042727272727272735, 1: 1}...........\n",
      "[CV 1/10; 37/100] END class_weight={0: 0.0042727272727272735, 1: 1};, score=(train=0.881, test=0.840) total time=   7.9s\n",
      "[CV 3/10; 43/100] START class_weight={0: 0.004818181818181819, 1: 1}............\n",
      "[CV 3/10; 43/100] END class_weight={0: 0.004818181818181819, 1: 1};, score=(train=0.880, test=0.842) total time=  10.8s\n",
      "[CV 1/10; 51/100] START class_weight={0: 0.005545454545454546, 1: 1}............\n",
      "[CV 1/10; 51/100] END class_weight={0: 0.005545454545454546, 1: 1};, score=(train=0.879, test=0.842) total time=   9.1s\n",
      "[CV 8/10; 57/100] START class_weight={0: 0.006090909090909091, 1: 1}............\n",
      "[CV 8/10; 57/100] END class_weight={0: 0.006090909090909091, 1: 1};, score=(train=0.877, test=0.863) total time=   8.5s\n",
      "[CV 2/10; 64/100] START class_weight={0: 0.006727272727272728, 1: 1}............\n",
      "[CV 2/10; 64/100] END class_weight={0: 0.006727272727272728, 1: 1};, score=(train=0.880, test=0.831) total time=  10.7s\n",
      "[CV 5/10; 71/100] START class_weight={0: 0.007363636363636364, 1: 1}............\n",
      "[CV 5/10; 71/100] END class_weight={0: 0.007363636363636364, 1: 1};, score=(train=0.880, test=0.831) total time=   8.9s\n",
      "[CV 6/10; 77/100] START class_weight={0: 0.00790909090909091, 1: 1}.............\n",
      "[CV 6/10; 77/100] END class_weight={0: 0.00790909090909091, 1: 1};, score=(train=0.879, test=0.838) total time=   9.2s\n",
      "[CV 5/10; 84/100] START class_weight={0: 0.008545454545454547, 1: 1}............\n",
      "[CV 5/10; 84/100] END class_weight={0: 0.008545454545454547, 1: 1};, score=(train=0.880, test=0.831) total time=   9.4s\n",
      "[CV 1/10; 91/100] START class_weight={0: 0.009181818181818183, 1: 1}............\n",
      "[CV 1/10; 91/100] END class_weight={0: 0.009181818181818183, 1: 1};, score=(train=0.878, test=0.847) total time=  10.2s\n",
      "[CV 3/10; 98/100] START class_weight={0: 0.00981818181818182, 1: 1}.............\n",
      "[CV 3/10; 98/100] END class_weight={0: 0.00981818181818182, 1: 1};, score=(train=0.879, test=0.828) total time=   8.5s\n",
      "[CV 6/10; 4/100] START class_weight={0: 0.010303030303030303, 1: 1}.............\n",
      "[CV 6/10; 4/100] END class_weight={0: 0.010303030303030303, 1: 1};, score=(train=0.879, test=0.839) total time=  10.4s\n",
      "[CV 7/10; 12/100] START class_weight={0: 0.011111111111111112, 1: 1}............\n",
      "[CV 7/10; 12/100] END class_weight={0: 0.011111111111111112, 1: 1};, score=(train=0.880, test=0.867) total time=  10.5s\n",
      "[CV 6/10; 18/100] START class_weight={0: 0.011717171717171718, 1: 1}............\n",
      "[CV 6/10; 18/100] END class_weight={0: 0.011717171717171718, 1: 1};, score=(train=0.881, test=0.830) total time=   8.4s\n",
      "[CV 6/10; 23/100] START class_weight={0: 0.012222222222222223, 1: 1}............\n",
      "[CV 6/10; 23/100] END class_weight={0: 0.012222222222222223, 1: 1};, score=(train=0.880, test=0.832) total time=   9.4s\n",
      "[CV 7/10; 29/100] START class_weight={0: 0.012828282828282828, 1: 1}............\n",
      "[CV 7/10; 29/100] END class_weight={0: 0.012828282828282828, 1: 1};, score=(train=0.878, test=0.862) total time=   8.3s\n",
      "[CV 10/10; 34/100] START class_weight={0: 0.013333333333333332, 1: 1}...........\n",
      "[CV 10/10; 34/100] END class_weight={0: 0.013333333333333332, 1: 1};, score=(train=0.877, test=0.861) total time=   7.8s\n",
      "[CV 6/10; 40/100] START class_weight={0: 0.013939393939393939, 1: 1}............\n",
      "[CV 6/10; 40/100] END class_weight={0: 0.013939393939393939, 1: 1};, score=(train=0.881, test=0.826) total time=   8.9s\n",
      "[CV 2/10; 46/100] START class_weight={0: 0.014545454545454545, 1: 1}............\n",
      "[CV 2/10; 46/100] END class_weight={0: 0.014545454545454545, 1: 1};, score=(train=0.884, test=0.844) total time=   9.7s\n",
      "[CV 4/10; 52/100] START class_weight={0: 0.015151515151515152, 1: 1}............\n",
      "[CV 4/10; 52/100] END class_weight={0: 0.015151515151515152, 1: 1};, score=(train=0.882, test=0.837) total time=   8.8s\n",
      "[CV 7/10; 58/100] START class_weight={0: 0.01575757575757576, 1: 1}.............\n",
      "[CV 7/10; 58/100] END class_weight={0: 0.01575757575757576, 1: 1};, score=(train=0.881, test=0.853) total time=   6.8s\n",
      "[CV 10/10; 62/100] START class_weight={0: 0.01616161616161616, 1: 1}............\n",
      "[CV 10/10; 62/100] END class_weight={0: 0.01616161616161616, 1: 1};, score=(train=0.881, test=0.865) total time=   9.0s\n",
      "[CV 3/10; 68/100] START class_weight={0: 0.016767676767676768, 1: 1}............\n",
      "[CV 3/10; 68/100] END class_weight={0: 0.016767676767676768, 1: 1};, score=(train=0.879, test=0.830) total time=   9.1s\n",
      "[CV 9/10; 74/100] START class_weight={0: 0.017373737373737375, 1: 1}............\n",
      "[CV 9/10; 74/100] END class_weight={0: 0.017373737373737375, 1: 1};, score=(train=0.883, test=0.842) total time=   9.3s\n",
      "[CV 5/10; 80/100] START class_weight={0: 0.017979797979797978, 1: 1}............\n",
      "[CV 5/10; 80/100] END class_weight={0: 0.017979797979797978, 1: 1};, score=(train=0.880, test=0.829) total time=   9.1s\n",
      "[CV 5/10; 86/100] START class_weight={0: 0.018585858585858588, 1: 1}............\n",
      "[CV 5/10; 86/100] END class_weight={0: 0.018585858585858588, 1: 1};, score=(train=0.880, test=0.829) total time=  11.4s\n",
      "[CV 9/10; 93/100] START class_weight={0: 0.019292929292929292, 1: 1}............\n",
      "[CV 9/10; 93/100] END class_weight={0: 0.019292929292929292, 1: 1};, score=(train=0.880, test=0.853) total time=   9.5s\n",
      "[CV 3/10; 100/100] START class_weight={0: 0.02, 1: 1}...........................\n",
      "[CV 3/10; 100/100] END class_weight={0: 0.02, 1: 1};, score=(train=0.882, test=0.833) total time=   7.1s\n",
      "[CV 6/10; 5/10] START class_weight={0: 0.002777777777777778, 1: 1}..............\n",
      "[CV 6/10; 5/10] END class_weight={0: 0.002777777777777778, 1: 1};, score=(train=0.879, test=0.831) total time=   7.3s\n",
      "[CV 9/10; 9/10] START class_weight={0: 0.004555555555555556, 1: 1}..............\n",
      "[CV 9/10; 9/10] END class_weight={0: 0.004555555555555556, 1: 1};, score=(train=0.881, test=0.848) total time=   6.2s\n",
      "[CV 9/10; 5/100] START class_weight={0: 0.0013636363636363637, 1: 1}............\n",
      "[CV 9/10; 5/100] END class_weight={0: 0.0013636363636363637, 1: 1};, score=(train=0.880, test=0.843) total time=   7.5s\n",
      "[CV 7/10; 9/100] START class_weight={0: 0.0017272727272727275, 1: 1}............\n",
      "[CV 7/10; 9/100] END class_weight={0: 0.0017272727272727275, 1: 1};, score=(train=0.872, test=0.850) total time=   6.7s\n",
      "[CV 8/10; 14/100] START class_weight={0: 0.002181818181818182, 1: 1}............\n",
      "[CV 8/10; 14/100] END class_weight={0: 0.002181818181818182, 1: 1};, score=(train=0.876, test=0.863) total time=   8.1s\n",
      "[CV 5/10; 21/100] START class_weight={0: 0.0028181818181818186, 1: 1}...........\n",
      "[CV 5/10; 21/100] END class_weight={0: 0.0028181818181818186, 1: 1};, score=(train=0.877, test=0.833) total time=  11.4s\n",
      "[CV 9/10; 30/100] START class_weight={0: 0.003636363636363637, 1: 1}............\n",
      "[CV 9/10; 30/100] END class_weight={0: 0.003636363636363637, 1: 1};, score=(train=0.881, test=0.845) total time=   6.7s\n",
      "[CV 8/10; 35/100] START class_weight={0: 0.004090909090909091, 1: 1}............\n",
      "[CV 8/10; 35/100] END class_weight={0: 0.004090909090909091, 1: 1};, score=(train=0.877, test=0.864) total time=   7.2s\n",
      "[CV 3/10; 41/100] START class_weight={0: 0.004636363636363636, 1: 1}............\n",
      "[CV 3/10; 41/100] END class_weight={0: 0.004636363636363636, 1: 1};, score=(train=0.879, test=0.842) total time=   7.5s\n",
      "[CV 2/10; 47/100] START class_weight={0: 0.005181818181818182, 1: 1}............\n",
      "[CV 2/10; 47/100] END class_weight={0: 0.005181818181818182, 1: 1};, score=(train=0.880, test=0.825) total time=   8.1s\n",
      "[CV 1/10; 53/100] START class_weight={0: 0.0057272727272727275, 1: 1}...........\n",
      "[CV 1/10; 53/100] END class_weight={0: 0.0057272727272727275, 1: 1};, score=(train=0.879, test=0.847) total time=   8.2s\n",
      "[CV 8/10; 58/100] START class_weight={0: 0.006181818181818182, 1: 1}............\n",
      "[CV 8/10; 58/100] END class_weight={0: 0.006181818181818182, 1: 1};, score=(train=0.877, test=0.863) total time=   7.4s\n",
      "[CV 1/10; 64/100] START class_weight={0: 0.006727272727272728, 1: 1}............\n",
      "[CV 1/10; 64/100] END class_weight={0: 0.006727272727272728, 1: 1};, score=(train=0.878, test=0.839) total time=  10.5s\n",
      "[CV 10/10; 70/100] START class_weight={0: 0.007272727272727274, 1: 1}...........\n",
      "[CV 10/10; 70/100] END class_weight={0: 0.007272727272727274, 1: 1};, score=(train=0.876, test=0.849) total time=   7.9s\n",
      "[CV 6/10; 76/100] START class_weight={0: 0.007818181818181818, 1: 1}............\n",
      "[CV 6/10; 76/100] END class_weight={0: 0.007818181818181818, 1: 1};, score=(train=0.879, test=0.837) total time=   9.5s\n",
      "[CV 2/10; 83/100] START class_weight={0: 0.008454545454545454, 1: 1}............\n",
      "[CV 2/10; 83/100] END class_weight={0: 0.008454545454545454, 1: 1};, score=(train=0.879, test=0.857) total time=  10.4s\n",
      "[CV 6/10; 90/100] START class_weight={0: 0.00909090909090909, 1: 1}.............\n",
      "[CV 6/10; 90/100] END class_weight={0: 0.00909090909090909, 1: 1};, score=(train=0.879, test=0.839) total time=   8.2s\n",
      "[CV 4/10; 96/100] START class_weight={0: 0.009636363636363637, 1: 1}............\n",
      "[CV 4/10; 96/100] END class_weight={0: 0.009636363636363637, 1: 1};, score=(train=0.876, test=0.837) total time=   8.7s\n",
      "[CV 3/10; 2/100] START class_weight={0: 0.010101010101010102, 1: 1}.............\n",
      "[CV 3/10; 2/100] END class_weight={0: 0.010101010101010102, 1: 1};, score=(train=0.879, test=0.828) total time=   8.7s\n",
      "[CV 2/10; 9/100] START class_weight={0: 0.010808080808080808, 1: 1}.............\n",
      "[CV 2/10; 9/100] END class_weight={0: 0.010808080808080808, 1: 1};, score=(train=0.880, test=0.840) total time=  10.9s\n",
      "[CV 4/10; 17/100] START class_weight={0: 0.011616161616161616, 1: 1}............\n",
      "[CV 4/10; 17/100] END class_weight={0: 0.011616161616161616, 1: 1};, score=(train=0.876, test=0.836) total time=  11.5s\n",
      "[CV 2/10; 25/100] START class_weight={0: 0.012424242424242424, 1: 1}............\n",
      "[CV 2/10; 25/100] END class_weight={0: 0.012424242424242424, 1: 1};, score=(train=0.878, test=0.850) total time=  10.5s\n",
      "[CV 1/10; 32/100] START class_weight={0: 0.013131313131313133, 1: 1}............\n",
      "[CV 1/10; 32/100] END class_weight={0: 0.013131313131313133, 1: 1};, score=(train=0.877, test=0.864) total time=   8.9s\n",
      "[CV 6/10; 37/100] START class_weight={0: 0.013636363636363637, 1: 1}............\n",
      "[CV 6/10; 37/100] END class_weight={0: 0.013636363636363637, 1: 1};, score=(train=0.881, test=0.826) total time=   8.8s\n",
      "[CV 8/10; 43/100] START class_weight={0: 0.014242424242424242, 1: 1}............\n",
      "[CV 8/10; 43/100] END class_weight={0: 0.014242424242424242, 1: 1};, score=(train=0.880, test=0.883) total time=  10.9s\n",
      "[CV 2/10; 51/100] START class_weight={0: 0.01505050505050505, 1: 1}.............\n",
      "[CV 2/10; 51/100] END class_weight={0: 0.01505050505050505, 1: 1};, score=(train=0.884, test=0.843) total time=  10.9s\n",
      "[CV 10/10; 57/100] START class_weight={0: 0.015656565656565657, 1: 1}...........\n",
      "[CV 10/10; 57/100] END class_weight={0: 0.015656565656565657, 1: 1};, score=(train=0.879, test=0.869) total time=   9.1s\n",
      "[CV 2/10; 64/100] START class_weight={0: 0.016363636363636365, 1: 1}............\n",
      "[CV 2/10; 64/100] END class_weight={0: 0.016363636363636365, 1: 1};, score=(train=0.884, test=0.844) total time=  10.5s\n",
      "[CV 1/10; 71/100] START class_weight={0: 0.01707070707070707, 1: 1}.............\n",
      "[CV 1/10; 71/100] END class_weight={0: 0.01707070707070707, 1: 1};, score=(train=0.881, test=0.859) total time=  11.0s\n",
      "[CV 10/10; 77/100] START class_weight={0: 0.017676767676767676, 1: 1}...........\n",
      "[CV 10/10; 77/100] END class_weight={0: 0.017676767676767676, 1: 1};, score=(train=0.881, test=0.867) total time=   8.7s\n",
      "[CV 8/10; 83/100] START class_weight={0: 0.018282828282828283, 1: 1}............\n",
      "[CV 8/10; 83/100] END class_weight={0: 0.018282828282828283, 1: 1};, score=(train=0.877, test=0.874) total time=   9.2s\n",
      "[CV 3/10; 89/100] START class_weight={0: 0.01888888888888889, 1: 1}.............\n",
      "[CV 3/10; 89/100] END class_weight={0: 0.01888888888888889, 1: 1};, score=(train=0.880, test=0.831) total time=   8.4s\n",
      "[CV 9/10; 94/100] START class_weight={0: 0.019393939393939394, 1: 1}............\n",
      "[CV 9/10; 94/100] END class_weight={0: 0.019393939393939394, 1: 1};, score=(train=0.880, test=0.853) total time=   9.8s\n",
      "[CV 10/10; 100/100] START class_weight={0: 0.02, 1: 1}..........................\n",
      "[CV 10/10; 100/100] END class_weight={0: 0.02, 1: 1};, score=(train=0.879, test=0.869) total time=   6.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10; 1/10] START class_weight={0: 0.001, 1: 1}............................\n",
      "[CV 10/10; 1/10] END class_weight={0: 0.001, 1: 1};, score=(train=0.879, test=0.847) total time=   8.8s\n",
      "[CV 8/10; 1/100] START class_weight={0: 0.001, 1: 1}............................\n",
      "[CV 8/10; 1/100] END class_weight={0: 0.001, 1: 1};, score=(train=0.874, test=0.865) total time=   7.2s\n",
      "[CV 5/10; 8/100] START class_weight={0: 0.0016363636363636363, 1: 1}............\n",
      "[CV 5/10; 8/100] END class_weight={0: 0.0016363636363636363, 1: 1};, score=(train=0.882, test=0.827) total time=   9.0s\n",
      "[CV 1/10; 17/100] START class_weight={0: 0.002454545454545455, 1: 1}............\n",
      "[CV 1/10; 17/100] END class_weight={0: 0.002454545454545455, 1: 1};, score=(train=0.882, test=0.844) total time=   8.6s\n",
      "[CV 9/10; 23/100] START class_weight={0: 0.003, 1: 1}...........................\n",
      "[CV 9/10; 23/100] END class_weight={0: 0.003, 1: 1};, score=(train=0.880, test=0.851) total time=   8.1s\n",
      "[CV 5/10; 29/100] START class_weight={0: 0.0035454545454545456, 1: 1}...........\n",
      "[CV 5/10; 29/100] END class_weight={0: 0.0035454545454545456, 1: 1};, score=(train=0.880, test=0.837) total time=   7.9s\n",
      "[CV 9/10; 35/100] START class_weight={0: 0.004090909090909091, 1: 1}............\n",
      "[CV 9/10; 35/100] END class_weight={0: 0.004090909090909091, 1: 1};, score=(train=0.881, test=0.835) total time=   8.8s\n",
      "[CV 7/10; 42/100] START class_weight={0: 0.0047272727272727275, 1: 1}...........\n",
      "[CV 7/10; 42/100] END class_weight={0: 0.0047272727272727275, 1: 1};, score=(train=0.878, test=0.866) total time=   8.5s\n",
      "[CV 3/10; 49/100] START class_weight={0: 0.005363636363636364, 1: 1}............\n",
      "[CV 3/10; 49/100] END class_weight={0: 0.005363636363636364, 1: 1};, score=(train=0.880, test=0.844) total time=   9.0s\n",
      "[CV 6/10; 55/100] START class_weight={0: 0.00590909090909091, 1: 1}.............\n",
      "[CV 6/10; 55/100] END class_weight={0: 0.00590909090909091, 1: 1};, score=(train=0.880, test=0.840) total time=   8.5s\n",
      "[CV 10/10; 61/100] START class_weight={0: 0.006454545454545455, 1: 1}...........\n",
      "[CV 10/10; 61/100] END class_weight={0: 0.006454545454545455, 1: 1};, score=(train=0.878, test=0.860) total time=   9.3s\n",
      "[CV 10/10; 68/100] START class_weight={0: 0.007090909090909091, 1: 1}...........\n",
      "[CV 10/10; 68/100] END class_weight={0: 0.007090909090909091, 1: 1};, score=(train=0.877, test=0.850) total time=   8.6s\n",
      "[CV 1/10; 75/100] START class_weight={0: 0.007727272727272728, 1: 1}............\n",
      "[CV 1/10; 75/100] END class_weight={0: 0.007727272727272728, 1: 1};, score=(train=0.877, test=0.846) total time=   9.2s\n",
      "[CV 5/10; 81/100] START class_weight={0: 0.008272727272727274, 1: 1}............\n",
      "[CV 5/10; 81/100] END class_weight={0: 0.008272727272727274, 1: 1};, score=(train=0.880, test=0.831) total time=   8.1s\n",
      "[CV 3/10; 87/100] START class_weight={0: 0.008818181818181819, 1: 1}............\n",
      "[CV 3/10; 87/100] END class_weight={0: 0.008818181818181819, 1: 1};, score=(train=0.880, test=0.844) total time=   8.6s\n",
      "[CV 3/10; 93/100] START class_weight={0: 0.009363636363636366, 1: 1}............\n",
      "[CV 3/10; 93/100] END class_weight={0: 0.009363636363636366, 1: 1};, score=(train=0.880, test=0.845) total time=   9.1s\n",
      "[CV 3/10; 99/100] START class_weight={0: 0.009909090909090909, 1: 1}............\n",
      "[CV 3/10; 99/100] END class_weight={0: 0.009909090909090909, 1: 1};, score=(train=0.879, test=0.835) total time=   7.2s\n",
      "[CV 8/10; 4/100] START class_weight={0: 0.010303030303030303, 1: 1}.............\n",
      "[CV 8/10; 4/100] END class_weight={0: 0.010303030303030303, 1: 1};, score=(train=0.878, test=0.860) total time=  10.6s\n",
      "[CV 5/10; 12/100] START class_weight={0: 0.011111111111111112, 1: 1}............\n",
      "[CV 5/10; 12/100] END class_weight={0: 0.011111111111111112, 1: 1};, score=(train=0.877, test=0.839) total time=   8.8s\n",
      "[CV 2/10; 17/100] START class_weight={0: 0.011616161616161616, 1: 1}............\n",
      "[CV 2/10; 17/100] END class_weight={0: 0.011616161616161616, 1: 1};, score=(train=0.878, test=0.850) total time=   9.3s\n",
      "[CV 10/10; 22/100] START class_weight={0: 0.012121212121212121, 1: 1}...........\n",
      "[CV 10/10; 22/100] END class_weight={0: 0.012121212121212121, 1: 1};, score=(train=0.874, test=0.856) total time=   9.9s\n",
      "[CV 3/10; 29/100] START class_weight={0: 0.012828282828282828, 1: 1}............\n",
      "[CV 3/10; 29/100] END class_weight={0: 0.012828282828282828, 1: 1};, score=(train=0.876, test=0.838) total time=   6.8s\n",
      "[CV 6/10; 33/100] START class_weight={0: 0.013232323232323233, 1: 1}............\n",
      "[CV 6/10; 33/100] END class_weight={0: 0.013232323232323233, 1: 1};, score=(train=0.880, test=0.834) total time=  10.0s\n",
      "[CV 7/10; 40/100] START class_weight={0: 0.013939393939393939, 1: 1}............\n",
      "[CV 7/10; 40/100] END class_weight={0: 0.013939393939393939, 1: 1};, score=(train=0.879, test=0.866) total time=  12.7s\n",
      "[CV 2/10; 49/100] START class_weight={0: 0.014848484848484849, 1: 1}............\n",
      "[CV 2/10; 49/100] END class_weight={0: 0.014848484848484849, 1: 1};, score=(train=0.884, test=0.843) total time=  12.6s\n",
      "[CV 1/10; 57/100] START class_weight={0: 0.015656565656565657, 1: 1}............\n",
      "[CV 1/10; 57/100] END class_weight={0: 0.015656565656565657, 1: 1};, score=(train=0.880, test=0.861) total time=  11.3s\n",
      "[CV 8/10; 64/100] START class_weight={0: 0.016363636363636365, 1: 1}............\n",
      "[CV 8/10; 64/100] END class_weight={0: 0.016363636363636365, 1: 1};, score=(train=0.879, test=0.880) total time=  11.8s\n",
      "[CV 2/10; 72/100] START class_weight={0: 0.01717171717171717, 1: 1}.............\n",
      "[CV 2/10; 72/100] END class_weight={0: 0.01717171717171717, 1: 1};, score=(train=0.878, test=0.843) total time=  10.5s\n",
      "[CV 8/10; 78/100] START class_weight={0: 0.017777777777777778, 1: 1}............\n",
      "[CV 8/10; 78/100] END class_weight={0: 0.017777777777777778, 1: 1};, score=(train=0.879, test=0.880) total time=   8.6s\n",
      "[CV 1/10; 85/100] START class_weight={0: 0.018484848484848486, 1: 1}............\n",
      "[CV 1/10; 85/100] END class_weight={0: 0.018484848484848486, 1: 1};, score=(train=0.879, test=0.859) total time=   8.4s\n",
      "[CV 3/10; 90/100] START class_weight={0: 0.01898989898989899, 1: 1}.............\n",
      "[CV 3/10; 90/100] END class_weight={0: 0.01898989898989899, 1: 1};, score=(train=0.880, test=0.824) total time=   7.9s\n",
      "[CV 2/10; 95/100] START class_weight={0: 0.019494949494949496, 1: 1}............\n",
      "[CV 2/10; 95/100] END class_weight={0: 0.019494949494949496, 1: 1};, score=(train=0.883, test=0.842) total time=   8.9s\n",
      "[CV 8/10; 100/100] START class_weight={0: 0.02, 1: 1}...........................\n",
      "[CV 8/10; 100/100] END class_weight={0: 0.02, 1: 1};, score=(train=0.879, test=0.885) total time=   6.3s\n",
      "[CV 6/10; 2/10] START class_weight={0: 0.0014444444444444444, 1: 1}.............\n",
      "[CV 6/10; 2/10] END class_weight={0: 0.0014444444444444444, 1: 1};, score=(train=0.881, test=0.823) total time=   9.3s\n",
      "[CV 1/10; 2/100] START class_weight={0: 0.001090909090909091, 1: 1}.............\n",
      "[CV 1/10; 2/100] END class_weight={0: 0.001090909090909091, 1: 1};, score=(train=0.878, test=0.835) total time=   7.4s\n",
      "[CV 8/10; 8/100] START class_weight={0: 0.0016363636363636363, 1: 1}............\n",
      "[CV 8/10; 8/100] END class_weight={0: 0.0016363636363636363, 1: 1};, score=(train=0.878, test=0.851) total time=   7.0s\n",
      "[CV 2/10; 15/100] START class_weight={0: 0.0022727272727272726, 1: 1}...........\n",
      "[CV 2/10; 15/100] END class_weight={0: 0.0022727272727272726, 1: 1};, score=(train=0.882, test=0.840) total time=   9.8s\n",
      "[CV 3/10; 23/100] START class_weight={0: 0.003, 1: 1}...........................\n",
      "[CV 3/10; 23/100] END class_weight={0: 0.003, 1: 1};, score=(train=0.878, test=0.839) total time=   9.0s\n",
      "[CV 8/10; 29/100] START class_weight={0: 0.0035454545454545456, 1: 1}...........\n",
      "[CV 8/10; 29/100] END class_weight={0: 0.0035454545454545456, 1: 1};, score=(train=0.878, test=0.868) total time=   9.5s\n",
      "[CV 2/10; 37/100] START class_weight={0: 0.0042727272727272735, 1: 1}...........\n",
      "[CV 2/10; 37/100] END class_weight={0: 0.0042727272727272735, 1: 1};, score=(train=0.880, test=0.837) total time=   9.0s\n",
      "[CV 6/10; 43/100] START class_weight={0: 0.004818181818181819, 1: 1}............\n",
      "[CV 6/10; 43/100] END class_weight={0: 0.004818181818181819, 1: 1};, score=(train=0.880, test=0.835) total time=   7.9s\n",
      "[CV 7/10; 49/100] START class_weight={0: 0.005363636363636364, 1: 1}............\n",
      "[CV 7/10; 49/100] END class_weight={0: 0.005363636363636364, 1: 1};, score=(train=0.876, test=0.865) total time=   9.4s\n",
      "[CV 5/10; 56/100] START class_weight={0: 0.006, 1: 1}...........................\n",
      "[CV 5/10; 56/100] END class_weight={0: 0.006, 1: 1};, score=(train=0.880, test=0.834) total time=   8.1s\n",
      "[CV 7/10; 62/100] START class_weight={0: 0.006545454545454546, 1: 1}............\n",
      "[CV 7/10; 62/100] END class_weight={0: 0.006545454545454546, 1: 1};, score=(train=0.877, test=0.864) total time=  10.5s\n",
      "[CV 2/10; 70/100] START class_weight={0: 0.007272727272727274, 1: 1}............\n",
      "[CV 2/10; 70/100] END class_weight={0: 0.007272727272727274, 1: 1};, score=(train=0.879, test=0.858) total time=   9.7s\n",
      "[CV 4/10; 76/100] START class_weight={0: 0.007818181818181818, 1: 1}............\n",
      "[CV 4/10; 76/100] END class_weight={0: 0.007818181818181818, 1: 1};, score=(train=0.876, test=0.837) total time=   7.5s\n",
      "[CV 3/10; 82/100] START class_weight={0: 0.008363636363636365, 1: 1}............\n",
      "[CV 3/10; 82/100] END class_weight={0: 0.008363636363636365, 1: 1};, score=(train=0.879, test=0.846) total time=   6.6s\n",
      "[CV 1/10; 87/100] START class_weight={0: 0.008818181818181819, 1: 1}............\n",
      "[CV 1/10; 87/100] END class_weight={0: 0.008818181818181819, 1: 1};, score=(train=0.877, test=0.842) total time=   7.7s\n",
      "[CV 6/10; 91/100] START class_weight={0: 0.009181818181818183, 1: 1}............\n",
      "[CV 6/10; 91/100] END class_weight={0: 0.009181818181818183, 1: 1};, score=(train=0.879, test=0.839) total time=   9.3s\n",
      "[CV 4/10; 98/100] START class_weight={0: 0.00981818181818182, 1: 1}.............\n",
      "[CV 4/10; 98/100] END class_weight={0: 0.00981818181818182, 1: 1};, score=(train=0.876, test=0.840) total time=   8.8s\n",
      "[CV 2/10; 5/100] START class_weight={0: 0.010404040404040405, 1: 1}.............\n",
      "[CV 2/10; 5/100] END class_weight={0: 0.010404040404040405, 1: 1};, score=(train=0.880, test=0.841) total time=  10.1s\n",
      "[CV 10/10; 11/100] START class_weight={0: 0.01101010101010101, 1: 1}............\n",
      "[CV 10/10; 11/100] END class_weight={0: 0.01101010101010101, 1: 1};, score=(train=0.879, test=0.868) total time=   9.5s\n",
      "[CV 8/10; 17/100] START class_weight={0: 0.011616161616161616, 1: 1}............\n",
      "[CV 8/10; 17/100] END class_weight={0: 0.011616161616161616, 1: 1};, score=(train=0.878, test=0.863) total time=  10.0s\n",
      "[CV 8/10; 24/100] START class_weight={0: 0.012323232323232323, 1: 1}............\n",
      "[CV 8/10; 24/100] END class_weight={0: 0.012323232323232323, 1: 1};, score=(train=0.880, test=0.883) total time=   9.9s\n",
      "[CV 10/10; 30/100] START class_weight={0: 0.01292929292929293, 1: 1}............\n",
      "[CV 10/10; 30/100] END class_weight={0: 0.01292929292929293, 1: 1};, score=(train=0.878, test=0.865) total time=  10.7s\n",
      "[CV 1/10; 38/100] START class_weight={0: 0.013737373737373737, 1: 1}............\n",
      "[CV 1/10; 38/100] END class_weight={0: 0.013737373737373737, 1: 1};, score=(train=0.878, test=0.859) total time=  11.4s\n",
      "[CV 3/10; 45/100] START class_weight={0: 0.014444444444444444, 1: 1}............\n",
      "[CV 3/10; 45/100] END class_weight={0: 0.014444444444444444, 1: 1};, score=(train=0.879, test=0.834) total time=   8.0s\n",
      "[CV 6/10; 50/100] START class_weight={0: 0.014949494949494949, 1: 1}............\n",
      "[CV 6/10; 50/100] END class_weight={0: 0.014949494949494949, 1: 1};, score=(train=0.881, test=0.832) total time=   8.3s\n",
      "[CV 2/10; 56/100] START class_weight={0: 0.015555555555555555, 1: 1}............\n",
      "[CV 2/10; 56/100] END class_weight={0: 0.015555555555555555, 1: 1};, score=(train=0.884, test=0.842) total time=   9.4s\n",
      "[CV 2/10; 62/100] START class_weight={0: 0.01616161616161616, 1: 1}.............\n",
      "[CV 2/10; 62/100] END class_weight={0: 0.01616161616161616, 1: 1};, score=(train=0.884, test=0.842) total time=   9.5s\n",
      "[CV 10/10; 67/100] START class_weight={0: 0.016666666666666666, 1: 1}...........\n",
      "[CV 10/10; 67/100] END class_weight={0: 0.016666666666666666, 1: 1};, score=(train=0.879, test=0.869) total time=  10.4s\n",
      "[CV 10/10; 74/100] START class_weight={0: 0.017373737373737375, 1: 1}...........\n",
      "[CV 10/10; 74/100] END class_weight={0: 0.017373737373737375, 1: 1};, score=(train=0.881, test=0.865) total time=  11.2s\n",
      "[CV 7/10; 81/100] START class_weight={0: 0.01808080808080808, 1: 1}.............\n",
      "[CV 7/10; 81/100] END class_weight={0: 0.01808080808080808, 1: 1};, score=(train=0.878, test=0.862) total time=   8.4s\n",
      "[CV 3/10; 87/100] START class_weight={0: 0.01868686868686869, 1: 1}.............\n",
      "[CV 3/10; 87/100] END class_weight={0: 0.01868686868686869, 1: 1};, score=(train=0.880, test=0.824) total time=  10.2s\n",
      "[CV 2/10; 94/100] START class_weight={0: 0.019393939393939394, 1: 1}............\n",
      "[CV 2/10; 94/100] END class_weight={0: 0.019393939393939394, 1: 1};, score=(train=0.885, test=0.847) total time=  10.4s\n",
      "[CV 9/10; 100/100] START class_weight={0: 0.02, 1: 1}...........................\n",
      "[CV 9/10; 100/100] END class_weight={0: 0.02, 1: 1};, score=(train=0.880, test=0.853) total time=   6.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 5/10] START class_weight={0: 0.002777777777777778, 1: 1}..............\n",
      "[CV 7/10; 5/10] END class_weight={0: 0.002777777777777778, 1: 1};, score=(train=0.876, test=0.859) total time=   9.1s\n",
      "[CV 9/10; 1/100] START class_weight={0: 0.001, 1: 1}............................\n",
      "[CV 9/10; 1/100] END class_weight={0: 0.001, 1: 1};, score=(train=0.878, test=0.833) total time=  10.1s\n",
      "[CV 5/10; 13/100] START class_weight={0: 0.002090909090909091, 1: 1}............\n",
      "[CV 5/10; 13/100] END class_weight={0: 0.002090909090909091, 1: 1};, score=(train=0.878, test=0.836) total time=   8.2s\n",
      "[CV 4/10; 19/100] START class_weight={0: 0.0026363636363636363, 1: 1}...........\n",
      "[CV 4/10; 19/100] END class_weight={0: 0.0026363636363636363, 1: 1};, score=(train=0.878, test=0.839) total time=   9.1s\n",
      "[CV 9/10; 25/100] START class_weight={0: 0.003181818181818182, 1: 1}............\n",
      "[CV 9/10; 25/100] END class_weight={0: 0.003181818181818182, 1: 1};, score=(train=0.881, test=0.833) total time=   8.0s\n",
      "[CV 9/10; 31/100] START class_weight={0: 0.0037272727272727275, 1: 1}...........\n",
      "[CV 9/10; 31/100] END class_weight={0: 0.0037272727272727275, 1: 1};, score=(train=0.878, test=0.840) total time=   6.9s\n",
      "[CV 6/10; 36/100] START class_weight={0: 0.004181818181818182, 1: 1}............\n",
      "[CV 6/10; 36/100] END class_weight={0: 0.004181818181818182, 1: 1};, score=(train=0.880, test=0.834) total time=  10.5s\n",
      "[CV 7/10; 44/100] START class_weight={0: 0.00490909090909091, 1: 1}.............\n",
      "[CV 7/10; 44/100] END class_weight={0: 0.00490909090909091, 1: 1};, score=(train=0.877, test=0.867) total time=  10.3s\n",
      "[CV 5/10; 52/100] START class_weight={0: 0.005636363636363636, 1: 1}............\n",
      "[CV 5/10; 52/100] END class_weight={0: 0.005636363636363636, 1: 1};, score=(train=0.880, test=0.835) total time=  10.6s\n",
      "[CV 8/10; 59/100] START class_weight={0: 0.006272727272727274, 1: 1}............\n",
      "[CV 8/10; 59/100] END class_weight={0: 0.006272727272727274, 1: 1};, score=(train=0.876, test=0.860) total time=   9.9s\n",
      "[CV 6/10; 66/100] START class_weight={0: 0.00690909090909091, 1: 1}.............\n",
      "[CV 6/10; 66/100] END class_weight={0: 0.00690909090909091, 1: 1};, score=(train=0.879, test=0.837) total time=   9.3s\n",
      "[CV 9/10; 73/100] START class_weight={0: 0.007545454545454546, 1: 1}............\n",
      "[CV 9/10; 73/100] END class_weight={0: 0.007545454545454546, 1: 1};, score=(train=0.882, test=0.843) total time=   9.8s\n",
      "[CV 10/10; 80/100] START class_weight={0: 0.008181818181818182, 1: 1}...........\n",
      "[CV 10/10; 80/100] END class_weight={0: 0.008181818181818182, 1: 1};, score=(train=0.874, test=0.848) total time=   8.1s\n",
      "[CV 9/10; 86/100] START class_weight={0: 0.008727272727272728, 1: 1}............\n",
      "[CV 9/10; 86/100] END class_weight={0: 0.008727272727272728, 1: 1};, score=(train=0.880, test=0.850) total time=   9.3s\n",
      "[CV 9/10; 92/100] START class_weight={0: 0.009272727272727273, 1: 1}............\n",
      "[CV 9/10; 92/100] END class_weight={0: 0.009272727272727273, 1: 1};, score=(train=0.881, test=0.845) total time=   8.3s\n",
      "[CV 2/10; 98/100] START class_weight={0: 0.00981818181818182, 1: 1}.............\n",
      "[CV 2/10; 98/100] END class_weight={0: 0.00981818181818182, 1: 1};, score=(train=0.880, test=0.841) total time=   8.3s\n",
      "[CV 4/10; 4/100] START class_weight={0: 0.010303030303030303, 1: 1}.............\n",
      "[CV 4/10; 4/100] END class_weight={0: 0.010303030303030303, 1: 1};, score=(train=0.876, test=0.840) total time=  10.2s\n",
      "[CV 4/10; 12/100] START class_weight={0: 0.011111111111111112, 1: 1}............\n",
      "[CV 4/10; 12/100] END class_weight={0: 0.011111111111111112, 1: 1};, score=(train=0.876, test=0.838) total time=   8.8s\n",
      "[CV 3/10; 17/100] START class_weight={0: 0.011616161616161616, 1: 1}............\n",
      "[CV 3/10; 17/100] END class_weight={0: 0.011616161616161616, 1: 1};, score=(train=0.879, test=0.828) total time=   8.3s\n",
      "[CV 2/10; 22/100] START class_weight={0: 0.012121212121212121, 1: 1}............\n",
      "[CV 2/10; 22/100] END class_weight={0: 0.012121212121212121, 1: 1};, score=(train=0.878, test=0.850) total time=  10.2s\n",
      "[CV 9/10; 28/100] START class_weight={0: 0.012727272727272728, 1: 1}............\n",
      "[CV 9/10; 28/100] END class_weight={0: 0.012727272727272728, 1: 1};, score=(train=0.880, test=0.838) total time=   8.7s\n",
      "[CV 4/10; 34/100] START class_weight={0: 0.013333333333333332, 1: 1}............\n",
      "[CV 4/10; 34/100] END class_weight={0: 0.013333333333333332, 1: 1};, score=(train=0.878, test=0.835) total time=  12.0s\n",
      "[CV 1/10; 42/100] START class_weight={0: 0.014141414141414142, 1: 1}............\n",
      "[CV 1/10; 42/100] END class_weight={0: 0.014141414141414142, 1: 1};, score=(train=0.879, test=0.869) total time=   9.8s\n",
      "[CV 1/10; 49/100] START class_weight={0: 0.014848484848484849, 1: 1}............\n",
      "[CV 1/10; 49/100] END class_weight={0: 0.014848484848484849, 1: 1};, score=(train=0.878, test=0.851) total time=  10.8s\n",
      "[CV 9/10; 55/100] START class_weight={0: 0.015454545454545455, 1: 1}............\n",
      "[CV 9/10; 55/100] END class_weight={0: 0.015454545454545455, 1: 1};, score=(train=0.880, test=0.837) total time=   8.0s\n",
      "[CV 8/10; 60/100] START class_weight={0: 0.01595959595959596, 1: 1}.............\n",
      "[CV 8/10; 60/100] END class_weight={0: 0.01595959595959596, 1: 1};, score=(train=0.880, test=0.883) total time=   9.0s\n",
      "[CV 7/10; 66/100] START class_weight={0: 0.016565656565656565, 1: 1}............\n",
      "[CV 7/10; 66/100] END class_weight={0: 0.016565656565656565, 1: 1};, score=(train=0.878, test=0.862) total time=  10.0s\n",
      "[CV 2/10; 73/100] START class_weight={0: 0.017272727272727273, 1: 1}............\n",
      "[CV 2/10; 73/100] END class_weight={0: 0.017272727272727273, 1: 1};, score=(train=0.882, test=0.845) total time=  12.3s\n",
      "[CV 1/10; 81/100] START class_weight={0: 0.01808080808080808, 1: 1}.............\n",
      "[CV 1/10; 81/100] END class_weight={0: 0.01808080808080808, 1: 1};, score=(train=0.880, test=0.861) total time=  10.4s\n",
      "[CV 7/10; 87/100] START class_weight={0: 0.01868686868686869, 1: 1}.............\n",
      "[CV 7/10; 87/100] END class_weight={0: 0.01868686868686869, 1: 1};, score=(train=0.877, test=0.859) total time=   8.5s\n",
      "[CV 1/10; 93/100] START class_weight={0: 0.019292929292929292, 1: 1}............\n",
      "[CV 1/10; 93/100] END class_weight={0: 0.019292929292929292, 1: 1};, score=(train=0.877, test=0.856) total time=  10.5s\n",
      "[CV 2/10; 100/100] START class_weight={0: 0.02, 1: 1}...........................\n",
      "[CV 2/10; 100/100] END class_weight={0: 0.02, 1: 1};, score=(train=0.885, test=0.847) total time=   7.7s\n",
      "[CV 3/10; 6/10] START class_weight={0: 0.0032222222222222222, 1: 1}.............\n",
      "[CV 3/10; 6/10] END class_weight={0: 0.0032222222222222222, 1: 1};, score=(train=0.880, test=0.844) total time=   7.2s\n",
      "[CV 1/10; 10/10] START class_weight={0: 0.005, 1: 1}............................\n",
      "[CV 1/10; 10/10] END class_weight={0: 0.005, 1: 1};, score=(train=0.879, test=0.842) total time=   6.2s\n",
      "[CV 5/10; 6/100] START class_weight={0: 0.0014545454545454547, 1: 1}............\n",
      "[CV 5/10; 6/100] END class_weight={0: 0.0014545454545454547, 1: 1};, score=(train=0.880, test=0.831) total time=   7.4s\n",
      "[CV 3/10; 10/100] START class_weight={0: 0.0018181818181818182, 1: 1}...........\n",
      "[CV 3/10; 10/100] END class_weight={0: 0.0018181818181818182, 1: 1};, score=(train=0.878, test=0.836) total time=   8.7s\n",
      "[CV 4/10; 17/100] START class_weight={0: 0.002454545454545455, 1: 1}............\n",
      "[CV 4/10; 17/100] END class_weight={0: 0.002454545454545455, 1: 1};, score=(train=0.877, test=0.840) total time=   7.8s\n",
      "[CV 10/10; 22/100] START class_weight={0: 0.0029090909090909093, 1: 1}..........\n",
      "[CV 10/10; 22/100] END class_weight={0: 0.0029090909090909093, 1: 1};, score=(train=0.879, test=0.856) total time=   7.6s\n",
      "[CV 6/10; 28/100] START class_weight={0: 0.003454545454545455, 1: 1}............\n",
      "[CV 6/10; 28/100] END class_weight={0: 0.003454545454545455, 1: 1};, score=(train=0.876, test=0.834) total time=   8.9s\n",
      "[CV 10/10; 34/100] START class_weight={0: 0.004, 1: 1}..........................\n",
      "[CV 10/10; 34/100] END class_weight={0: 0.004, 1: 1};, score=(train=0.878, test=0.855) total time=   7.4s\n",
      "[CV 9/10; 40/100] START class_weight={0: 0.004545454545454545, 1: 1}............\n",
      "[CV 9/10; 40/100] END class_weight={0: 0.004545454545454545, 1: 1};, score=(train=0.881, test=0.848) total time=   6.2s\n",
      "[CV 2/10; 45/100] START class_weight={0: 0.005, 1: 1}...........................\n",
      "[CV 2/10; 45/100] END class_weight={0: 0.005, 1: 1};, score=(train=0.879, test=0.830) total time=   8.3s\n",
      "[CV 4/10; 51/100] START class_weight={0: 0.005545454545454546, 1: 1}............\n",
      "[CV 4/10; 51/100] END class_weight={0: 0.005545454545454546, 1: 1};, score=(train=0.879, test=0.843) total time=  11.4s\n",
      "[CV 4/10; 59/100] START class_weight={0: 0.006272727272727274, 1: 1}............\n",
      "[CV 4/10; 59/100] END class_weight={0: 0.006272727272727274, 1: 1};, score=(train=0.879, test=0.847) total time=   6.8s\n",
      "[CV 4/10; 64/100] START class_weight={0: 0.006727272727272728, 1: 1}............\n",
      "[CV 4/10; 64/100] END class_weight={0: 0.006727272727272728, 1: 1};, score=(train=0.879, test=0.836) total time=   7.2s\n",
      "[CV 9/10; 69/100] START class_weight={0: 0.0071818181818181824, 1: 1}...........\n",
      "[CV 9/10; 69/100] END class_weight={0: 0.0071818181818181824, 1: 1};, score=(train=0.881, test=0.842) total time=   9.6s\n",
      "[CV 2/10; 76/100] START class_weight={0: 0.007818181818181818, 1: 1}............\n",
      "[CV 2/10; 76/100] END class_weight={0: 0.007818181818181818, 1: 1};, score=(train=0.879, test=0.858) total time=   7.3s\n",
      "[CV 10/10; 81/100] START class_weight={0: 0.008272727272727274, 1: 1}...........\n",
      "[CV 10/10; 81/100] END class_weight={0: 0.008272727272727274, 1: 1};, score=(train=0.876, test=0.849) total time=   9.1s\n",
      "[CV 2/10; 88/100] START class_weight={0: 0.008909090909090908, 1: 1}............\n",
      "[CV 2/10; 88/100] END class_weight={0: 0.008909090909090908, 1: 1};, score=(train=0.879, test=0.857) total time=   8.0s\n",
      "[CV 9/10; 93/100] START class_weight={0: 0.009363636363636366, 1: 1}............\n",
      "[CV 9/10; 93/100] END class_weight={0: 0.009363636363636366, 1: 1};, score=(train=0.880, test=0.848) total time=   9.5s\n",
      "[CV 8/10; 99/100] START class_weight={0: 0.009909090909090909, 1: 1}............\n",
      "[CV 8/10; 99/100] END class_weight={0: 0.009909090909090909, 1: 1};, score=(train=0.876, test=0.873) total time=   7.3s\n",
      "[CV 3/10; 6/100] START class_weight={0: 0.010505050505050505, 1: 1}.............\n",
      "[CV 3/10; 6/100] END class_weight={0: 0.010505050505050505, 1: 1};, score=(train=0.879, test=0.827) total time=   9.8s\n",
      "[CV 1/10; 12/100] START class_weight={0: 0.011111111111111112, 1: 1}............\n",
      "[CV 1/10; 12/100] END class_weight={0: 0.011111111111111112, 1: 1};, score=(train=0.878, test=0.864) total time=  11.2s\n",
      "[CV 2/10; 19/100] START class_weight={0: 0.011818181818181818, 1: 1}............\n",
      "[CV 2/10; 19/100] END class_weight={0: 0.011818181818181818, 1: 1};, score=(train=0.878, test=0.850) total time=  10.8s\n",
      "[CV 7/10; 25/100] START class_weight={0: 0.012424242424242424, 1: 1}............\n",
      "[CV 7/10; 25/100] END class_weight={0: 0.012424242424242424, 1: 1};, score=(train=0.878, test=0.862) total time=   9.3s\n",
      "[CV 9/10; 31/100] START class_weight={0: 0.013030303030303031, 1: 1}............\n",
      "[CV 9/10; 31/100] END class_weight={0: 0.013030303030303031, 1: 1};, score=(train=0.880, test=0.842) total time=  10.8s\n",
      "[CV 8/10; 38/100] START class_weight={0: 0.013737373737373737, 1: 1}............\n",
      "[CV 8/10; 38/100] END class_weight={0: 0.013737373737373737, 1: 1};, score=(train=0.880, test=0.884) total time=   8.9s\n",
      "[CV 7/10; 44/100] START class_weight={0: 0.014343434343434344, 1: 1}............\n",
      "[CV 7/10; 44/100] END class_weight={0: 0.014343434343434344, 1: 1};, score=(train=0.877, test=0.862) total time=  10.2s\n",
      "[CV 5/10; 51/100] START class_weight={0: 0.01505050505050505, 1: 1}.............\n",
      "[CV 5/10; 51/100] END class_weight={0: 0.01505050505050505, 1: 1};, score=(train=0.882, test=0.839) total time=   9.2s\n",
      "[CV 2/10; 57/100] START class_weight={0: 0.015656565656565657, 1: 1}............\n",
      "[CV 2/10; 57/100] END class_weight={0: 0.015656565656565657, 1: 1};, score=(train=0.884, test=0.843) total time=  11.4s\n",
      "[CV 7/10; 64/100] START class_weight={0: 0.016363636363636365, 1: 1}............\n",
      "[CV 7/10; 64/100] END class_weight={0: 0.016363636363636365, 1: 1};, score=(train=0.881, test=0.853) total time=   7.0s\n",
      "[CV 9/10; 68/100] START class_weight={0: 0.016767676767676768, 1: 1}............\n",
      "[CV 9/10; 68/100] END class_weight={0: 0.016767676767676768, 1: 1};, score=(train=0.883, test=0.842) total time=  10.4s\n",
      "[CV 9/10; 75/100] START class_weight={0: 0.017474747474747476, 1: 1}............\n",
      "[CV 9/10; 75/100] END class_weight={0: 0.017474747474747476, 1: 1};, score=(train=0.880, test=0.853) total time=   9.4s\n",
      "[CV 10/10; 81/100] START class_weight={0: 0.01808080808080808, 1: 1}............\n",
      "[CV 10/10; 81/100] END class_weight={0: 0.01808080808080808, 1: 1};, score=(train=0.879, test=0.869) total time=   9.3s\n",
      "[CV 5/10; 88/100] START class_weight={0: 0.018787878787878787, 1: 1}............\n",
      "[CV 5/10; 88/100] END class_weight={0: 0.018787878787878787, 1: 1};, score=(train=0.881, test=0.828) total time=   8.0s\n",
      "[CV 10/10; 92/100] START class_weight={0: 0.01919191919191919, 1: 1}............\n",
      "[CV 10/10; 92/100] END class_weight={0: 0.01919191919191919, 1: 1};, score=(train=0.881, test=0.865) total time=  11.3s\n",
      "[CV 7/10; 100/100] START class_weight={0: 0.02, 1: 1}...........................\n",
      "[CV 7/10; 100/100] END class_weight={0: 0.02, 1: 1};, score=(train=0.878, test=0.851) total time=   6.7s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = {\n",
    "                'class_weight': [{\n",
    "                    0:i,\n",
    "                    1: 1\n",
    "                } for i in np.linspace(0.01, 0.01, 100)]\n",
    "}\n",
    "decision_tree = get_best_estimator(DecisionTreeClassifier(random_state=42, max_features=6, min_samples_leaf=0.005,\n",
    "                       min_samples_split=0.03), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0369e02b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m      4\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m      5\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      6\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      7\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mRandomForestClassifier(max_leaf_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m79\u001b[39m,\n\u001b[1;32m      8\u001b[0m                        min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m,\n\u001b[1;32m      9\u001b[0m                        min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0055000000000000005\u001b[39m,\n\u001b[1;32m     10\u001b[0m                        n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m495\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[1;32m     11\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m     refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauroc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     15\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: [{\n\u001b[1;32m     16\u001b[0m                     \u001b[38;5;241m0\u001b[39m:i,\n\u001b[1;32m     17\u001b[0m                     \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 18\u001b[0m                 } \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.0024\u001b[39m, \u001b[38;5;241m0.0026\u001b[39m, \u001b[38;5;241m4\u001b[39m)],\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m495\u001b[39m, \u001b[38;5;241m595\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     20\u001b[0m     },\n\u001b[1;32m     21\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid\u001b[38;5;241m.\u001b[39mbest_estimator_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid={\n",
    "                'class_weight': [{\n",
    "                    0:i,\n",
    "                    1: 1\n",
    "                } for i in np.linspace(0.0024, 0.0026, 4)],\n",
    "        'n_estimators': range(495, 595, 10)\n",
    "    }\n",
    "random_forest = get_best_estimator(RandomForestClassifier(max_leaf_nodes=79,\n",
    "                           min_samples_leaf=0.0001,\n",
    "                           min_samples_split=0.0055,\n",
    "                           n_estimators=500, random_state=42), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57871d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
      "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=6,\n",
      "              max_depth=2, max_leaves=0, min_child_weight=7, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=440, n_jobs=0,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=42, ...)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1-Micro</th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Binary</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leipzig</td>\n",
       "      <td>0.053492</td>\n",
       "      <td>0.801209</td>\n",
       "      <td>0.449972</td>\n",
       "      <td>0.010437</td>\n",
       "      <td>0.874004</td>\n",
       "      <td>0.016250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greifswald</td>\n",
       "      <td>0.033112</td>\n",
       "      <td>0.710985</td>\n",
       "      <td>0.418136</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>0.813196</td>\n",
       "      <td>0.006628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NAME       MCC  F1-Micro  F1-Macro  F1-Binary     AUROC     AUPRC\n",
       "0     Leipzig  0.053492  0.801209  0.449972   0.010437  0.874004  0.016250\n",
       "1  Greifswald  0.033112  0.710985  0.418136   0.005342  0.813196  0.006628"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "param_grid = {\n",
    "    'max_depth': [2],\n",
    "    'learning_rate': [0.1],\n",
    "    'gamma': [0],\n",
    "    'reg_lambda': [10],\n",
    "    'scale_pos_weight': [663],\n",
    "    \"min_child_weight\": [7],\n",
    "    \"max_delta_step\": [6],\n",
    "    'n_estimators': [440, 445, 450]\n",
    "}\n",
    "xgb_classifier = get_best_estimator(XGBClassifier(tree_method='gpu_hist', gpu_id = 1,\n",
    "                                                        seed = 42), param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169978dc",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b767875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83178353])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_log = logistic_regression.predict(X_test)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "##How much does the predictions match \n",
    "(y_pred_rf == y_pred_log).sum() / (corrected_predicted_rf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ba5fbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1-Micro</th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Binary</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leipzig</td>\n",
       "      <td>0.056064</td>\n",
       "      <td>0.842737</td>\n",
       "      <td>0.463305</td>\n",
       "      <td>0.012040</td>\n",
       "      <td>0.876362</td>\n",
       "      <td>0.015233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greifswald</td>\n",
       "      <td>0.036419</td>\n",
       "      <td>0.771250</td>\n",
       "      <td>0.438518</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.006305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NAME       MCC  F1-Micro  F1-Macro  F1-Binary     AUROC     AUPRC\n",
       "0     Leipzig  0.056064  0.842737  0.463305   0.012040  0.876362  0.015233\n",
       "1  Greifswald  0.036419  0.771250  0.438518   0.006287  0.816501  0.006305"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier as VC\n",
    "eclf2 = VC(estimators=[ ('rf', random_forest), ('xgb', xgb_classifier), ('dt', decision_tree), (\"lr\", logistic_regression)],\n",
    "        voting='soft',weights=[100, 100, 1, 1])\n",
    "eclf2 = eclf2.fit(X_train, y_train)\n",
    "get_df_metrics(eclf2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
