{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a913ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f67ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/graph_learning/../dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Assessable data are 528101 cases and 1015074 CBCs\n",
      "Control data are 527038 cases and 1013548 CBCs\n",
      "Sepsis data are 1488 cases and 1526 CBCs\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "Testing: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/graph_learning/../dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 365794, Sepsis: 490\n",
      "Assessable data are 180494 cases and 366284 CBCs\n",
      "Control data are 180157 cases and 365794 CBCs\n",
      "Sepsis data are 472 cases and 490 CBCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/graph_learning/../dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 437629, Sepsis: 448\n",
      "Assessable data are 157922 cases and 438077 CBCs\n",
      "Control data are 180157 cases and 437629 CBCs\n",
      "Sepsis data are 438 cases and 448 CBCs\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import torch\n",
    "\n",
    "data = pd.read_csv(r\"../extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0f6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((data_analysis.get_training_data(), data_analysis.get_testing_data()))\n",
    "max_Id = data[\"Id\"].unique().max()\n",
    "gw_data = data_analysis.get_gw_testing_data().copy(deep=True)\n",
    "gw_data = gw_data.assign(Id=lambda x: x.Id + max_Id)\n",
    "data = pd.concat((data, gw_data))\n",
    "data = data.sort_values(\"Id\")\n",
    "unique_ids = data[\"Id\"].unique()\n",
    "data = data.reset_index(drop=True)\n",
    "data.pop(\"index\")\n",
    "data = data.sort_values([\"Id\", \"Time\"])\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1ac4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Constants import SEX_CATEGORY_COLUMN_NAME, SEX_COLUMN_NAME, FEATURES\n",
    "data[SEX_CATEGORY_COLUMN_NAME] = data.loc[:, SEX_COLUMN_NAME] ==\"W\"\n",
    "data[SEX_CATEGORY_COLUMN_NAME] = data[SEX_CATEGORY_COLUMN_NAME].astype(\"int8\")\n",
    "data[\"Label\"] = data[\"Label\"] == \"Sepsis\"\n",
    "data[\"Label\"] = data[\"Label\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77ca8041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 6 5 2]\n"
     ]
    }
   ],
   "source": [
    "## ADD counter column for relative position of each measurement\n",
    "import numpy as np\n",
    "uniques, counts = np.unique(data[\"Id\"].values, return_counts=True)\n",
    "\n",
    "counter = []\n",
    "print(counts)\n",
    "for count in counts:\n",
    "    if count != 1:\n",
    "        counter.extend((np.arange(count) / (count-1)))\n",
    "    if count == 1:\n",
    "        counter.extend([1])\n",
    "data[\"counter\"] = counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43da6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = torch.tensor(data[FEATURES].values).type(torch.float32)\n",
    "y = torch.tensor(data[\"Label\"].values).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a8a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from dataAnalysis.FeatureImportance import normalize\n",
    "\n",
    "X_features = normalize(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "980fbb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "edge_index = torch.tensor(pd.read_csv(\"dir_edge_index_sorted_ids_w_gw_corr.csv\", header=None, skiprows=1).values.transpose(), dtype=torch.long)\n",
    "rev_edge_index = torch.zeros_like(edge_index)\n",
    "index = torch.LongTensor([1,0])\n",
    "rev_edge_index[index] = edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0896f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "def ratio_bool_switch(tensor, ratio = 0.8):\n",
    "    random = np.random.uniform(0, 1 ,tensor.shape[0])\n",
    "    val_ratio_mask = (random >= ratio)\n",
    "    train_ratio_mask = (random < ratio)\n",
    "    val_mask = np.logical_and(tensor.tolist(), val_ratio_mask.tolist())\n",
    "    train_mask = np.logical_and(tensor.tolist(), train_ratio_mask.tolist())\n",
    "    return torch.from_numpy(train_mask).type(torch.bool), torch.from_numpy(val_mask).type(torch.bool)\n",
    "\n",
    "train_mask_ser = data[\"Set\"] != \"Validation\"\n",
    "train_mask, val_mask = ratio_bool_switch(train_mask_ser.values)\n",
    "test_mask = torch.from_numpy(np.logical_and((data[\"Set\"] == \"Validation\").values, (data[\"Center\"] == \"Leipzig\").values)).type(torch.bool)\n",
    "test_gw_mask = torch.from_numpy(np.logical_and((data[\"Set\"] == \"Validation\").values, (data[\"Center\"] == \"Greifswald\").values)).type(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5564ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Data(x=X_features, train_mask = train_mask, test_mask=test_mask, val_mask=val_mask, y= y, edge_index=edge_index,\n",
    "             test_gw_mask = test_gw_mask)\n",
    "graph_rev = Data(x=X_features, train_mask = train_mask, test_mask=test_mask, val_mask=val_mask, y= y, edge_index=rev_edge_index,\n",
    "             test_gw_mask = test_gw_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0244463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7259211])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7315287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected\n",
    "graph = Data(x=X_features, train_mask = train_mask, test_mask=test_mask, val_mask=val_mask, y= y, edge_index=to_undirected(edge_index),\n",
    "             test_gw_mask = test_gw_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4599ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, GCNConv,GATv2Conv, GINConv, global_add_pool\n",
    "from torch.nn import Linear\n",
    "import torch\n",
    "from dataAnalysis.Constants import FEATURES\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "from torch.nn import BatchNorm1d as BatchNorm\n",
    "\n",
    "class GraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim = 128, out_channels = 1):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        input_dim = len(FEATURES)      \n",
    "        \n",
    "        HEADS = 5\n",
    "        \n",
    "        conv_1= GATConv(input_dim, hidden_dim,heads=HEADS, add_self_loops = False)\n",
    "        conv_end = GATConv((-1,-1), out_channels,add_self_loops = False)\n",
    "        \n",
    "        self.conv_1 = conv_1\n",
    "        self.conv_end = conv_end\n",
    "        \n",
    "\n",
    "    def forward(self, graph):\n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = x.type(torch.float)\n",
    "        x, attention_w_1 = self.conv_1(x, edge_index, return_attention_weights = True)\n",
    "        x = F.normalize(x, p=2., dim=-1)\n",
    "        x = torch.relu(x)\n",
    "        x, attention_w_2 = self.conv_end(x, edge_index, return_attention_weights = True)\n",
    "        return x, (attention_w_1, attention_w_2)\n",
    "            \n",
    "    def predict_proba(self, graph, mask):\n",
    "        with torch.inference_mode():\n",
    "            self.eval()\n",
    "            logits = self.forward(graph)\n",
    "            scores = torch.sigmoid(torch.squeeze(logits[0][mask]))\n",
    "            scores = torch.unsqueeze(scores, 0)\n",
    "            proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "            return torch.transpose(proba_predict, 0, 1)\n",
    "            \n",
    "    def predict(self, graph, mask, threshold = 0.5):\n",
    "        return (self.predict_proba(graph, mask)[:, 1] >= threshold).type(torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "346cd314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rev = GraphNeuralNetwork().cpu() #.to(device)\n",
    "model_rev.load_state_dict(torch.load(\"../models/rev_directed_gat_wo_pos.pt\", map_location=torch.device('cpu')))\n",
    "model = GraphNeuralNetwork().cpu() #.to(device)\n",
    "model.load_state_dict(torch.load(\"../models/directed_gat_wo_pos.pt\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4893bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    model.eval()\n",
    "    logits, (attention_w) = model(graph)\n",
    "    scores = torch.sigmoid(torch.squeeze(logits))\n",
    "    scores = torch.unsqueeze(scores, 0)\n",
    "    proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "    pred = torch.round(scores).squeeze()[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa38f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    model_rev.eval()\n",
    "    logits, (attention_w) = model_rev(graph_rev)\n",
    "    scores = torch.sigmoid(torch.squeeze(logits))\n",
    "    scores = torch.unsqueeze(scores, 0)\n",
    "    proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "    pred_rev = torch.round(scores).squeeze()[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4d6be64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45598)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_pred_rev = (pred_rev == graph_rev.y[test_mask])\n",
    "corr_pred = (pred == graph.y[test_mask])\n",
    "\n",
    "rev_corr_pred = np.logical_and(corr_pred_rev == 1, corr_pred == 0)\n",
    "rev_corr_pred.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a17e6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Center</th>\n",
       "      <th>Set</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Time</th>\n",
       "      <th>TargetIcu</th>\n",
       "      <th>...</th>\n",
       "      <th>CRP</th>\n",
       "      <th>HGB</th>\n",
       "      <th>MCV</th>\n",
       "      <th>PCT</th>\n",
       "      <th>PLT</th>\n",
       "      <th>RBC</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Label</th>\n",
       "      <th>SexCategory</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1015074</th>\n",
       "      <td>583815</td>\n",
       "      <td>77</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>AMB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>97.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015114</th>\n",
       "      <td>583848</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>ED</td>\n",
       "      <td>1</td>\n",
       "      <td>900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>186.42</td>\n",
       "      <td>9.3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>434.0</td>\n",
       "      <td>4.62</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015115</th>\n",
       "      <td>583848</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>58080.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>184.32</td>\n",
       "      <td>8.1</td>\n",
       "      <td>89.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015116</th>\n",
       "      <td>583848</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>159720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>203.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>92.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>329.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015117</th>\n",
       "      <td>583848</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>252660.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>142.23</td>\n",
       "      <td>7.9</td>\n",
       "      <td>94.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>291.0</td>\n",
       "      <td>3.98</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381351</th>\n",
       "      <td>778980</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>...</td>\n",
       "      <td>27.81</td>\n",
       "      <td>7.1</td>\n",
       "      <td>98.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.0</td>\n",
       "      <td>3.28</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381352</th>\n",
       "      <td>778980</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>267660.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>...</td>\n",
       "      <td>19.55</td>\n",
       "      <td>6.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381353</th>\n",
       "      <td>778980</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>354780.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>...</td>\n",
       "      <td>20.14</td>\n",
       "      <td>6.8</td>\n",
       "      <td>97.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381354</th>\n",
       "      <td>778980</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>606720.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>...</td>\n",
       "      <td>17.88</td>\n",
       "      <td>6.7</td>\n",
       "      <td>96.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381355</th>\n",
       "      <td>778980</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>870420.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>...</td>\n",
       "      <td>20.46</td>\n",
       "      <td>6.5</td>\n",
       "      <td>93.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45598 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  Age Sex Diagnosis   Center         Set Sender  Episode  \\\n",
       "1015074  583815   77   M   Control  Leipzig  Validation    AMB        1   \n",
       "1015114  583848   56   M   Control  Leipzig  Validation     ED        1   \n",
       "1015115  583848   56   M   Control  Leipzig  Validation    GEN        1   \n",
       "1015116  583848   56   M   Control  Leipzig  Validation    GEN        1   \n",
       "1015117  583848   56   M   Control  Leipzig  Validation    GEN        1   \n",
       "...         ...  ...  ..       ...      ...         ...    ...      ...   \n",
       "1381351  778980   56   M    Sepsis  Leipzig  Validation    GEN        1   \n",
       "1381352  778980   56   M    Sepsis  Leipzig  Validation    GEN        1   \n",
       "1381353  778980   56   M    Sepsis  Leipzig  Validation    GEN        1   \n",
       "1381354  778980   56   M    Sepsis  Leipzig  Validation    GEN        1   \n",
       "1381355  778980   56   M    Sepsis  Leipzig  Validation    GEN        1   \n",
       "\n",
       "             Time TargetIcu  ...     CRP  HGB    MCV  PCT    PLT   RBC   WBC  \\\n",
       "1015074       0.0       NaN  ...     NaN  8.4   97.3  NaN  199.0  4.01   8.8   \n",
       "1015114     900.0       NaN  ...  186.42  9.3   90.0  NaN  434.0  4.62  14.8   \n",
       "1015115   58080.0       NaN  ...  184.32  8.1   89.4  NaN  363.0  4.05  13.9   \n",
       "1015116  159720.0       NaN  ...  203.36  8.0   92.3  NaN  329.0  4.01  10.1   \n",
       "1015117  252660.0       NaN  ...  142.23  7.9   94.7  NaN  291.0  3.98  12.1   \n",
       "...           ...       ...  ...     ...  ...    ...  ...    ...   ...   ...   \n",
       "1381351       0.0      MICU  ...   27.81  7.1   98.2  NaN  158.0  3.28   9.4   \n",
       "1381352  267660.0      MICU  ...   19.55  6.7  100.0  NaN  129.0  3.11   6.0   \n",
       "1381353  354780.0      MICU  ...   20.14  6.8   97.5  NaN  134.0  3.18   7.0   \n",
       "1381354  606720.0      MICU  ...   17.88  6.7   96.6  NaN  121.0  3.20   7.2   \n",
       "1381355  870420.0      MICU  ...   20.46  6.5   93.2  NaN  114.0  3.07   8.3   \n",
       "\n",
       "         Label  SexCategory   counter  \n",
       "1015074      0            0  1.000000  \n",
       "1015114      0            0  0.000000  \n",
       "1015115      0            0  0.200000  \n",
       "1015116      0            0  0.400000  \n",
       "1015117      0            0  0.600000  \n",
       "...        ...          ...       ...  \n",
       "1381351      0            0  0.000000  \n",
       "1381352      0            0  0.166667  \n",
       "1381353      0            0  0.333333  \n",
       "1381354      0            0  0.500000  \n",
       "1381355      0            0  0.666667  \n",
       "\n",
       "[45598 rows x 21 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[test_mask.numpy()][rev_corr_pred.numpy().astype(np.bool_)]#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6da38fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name       MCC  F1-Micro  F1-Macro  F1-Binary     AUROC     AUPRC\n",
      "0     Leipzig  0.105392  0.962586  0.510562   0.040202  0.807568  0.048663\n",
      "1  Greifswald  0.086959  0.970795  0.509065   0.032955  0.783786  0.042402\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "y_dict = Evaluation.create_y_dict(model_rev.predict(graph, test_mask), model_rev.predict_proba(graph, test_mask) ,graph.y[test_mask])\n",
    "y_dict_gw = Evaluation.create_y_dict(model_rev.predict(graph, test_gw_mask), model_rev.predict_proba(graph, test_gw_mask) , graph.y[test_gw_mask])\n",
    "print(Evaluation.get_df_metrics_from_pred(y_dict, y_dict_gw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "edca5e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -5.5509,  -7.3917,   5.3115,   8.5988,  -7.0259,  -0.8020,  -6.6783,\n",
      "           -5.9650,   5.9438,   2.5997,  -8.6165,  -5.2122,  -4.7542,  -7.2708,\n",
      "           -7.5291,   7.0018,   5.1190,   6.5479,  -0.5558,  -0.6842,   2.2853,\n",
      "           -0.6124,  -1.8540,  -6.4124,  -9.2630,  -7.4157,   4.0730,  -1.4049,\n",
      "            5.5289,   5.7126,  -6.4629,  -6.9577,   5.0042,   3.6878,  -5.4086,\n",
      "           -1.5344,   5.4401,  -5.2238,   5.2753,  -9.7615,   5.1172,   5.9925,\n",
      "           -1.7588,   3.6685,   5.5855,   5.1395,  -6.3127,   6.0387,   6.0029,\n",
      "            8.8247,   5.5432,   4.5888,  -8.5960,  -5.0837,   3.8377,  -1.8420,\n",
      "           -5.1039,  -4.9215,   4.2555,  -0.4275,   3.4322,  -4.5593,   3.5347,\n",
      "            5.5869,   5.5903,  -9.7874,  -8.3494,  -0.8473,   5.5489,   3.6597,\n",
      "            3.6747,  -6.6002,   5.5651,  -7.3569,  -6.1538,   6.9242,   0.3783,\n",
      "            5.3847,   5.1020,  -5.7713,   4.3229,  -9.6634,  -1.2521,   4.0553,\n",
      "            3.8016,  -6.2739,  -6.5930,   5.2566,  -5.3878,  -7.4909,   6.2705,\n",
      "            5.3182,   4.1904,   5.3774,   5.4415,  -4.2834,  -8.6089,  -4.8457,\n",
      "            4.4648,  -5.4498,  -6.5629,  -9.1564,  -8.4217,   5.4701,  -8.8500,\n",
      "            5.4131,   5.2715,   4.9115,   3.6831,   3.7886,   5.3071,   3.9157,\n",
      "           -6.3623,   5.9397,   5.0495,   5.1595,  -1.5299,  -6.9975,   6.5284,\n",
      "           -5.3418,  -4.9284,   7.3218,  -6.5797,  -2.5284,  -7.4828,   5.5294,\n",
      "            5.2253,   7.0101],\n",
      "         [  5.3382,  -6.0091,   4.0044,   4.1088,  -3.1450,   4.0740,   4.3765,\n",
      "           -6.2780,   4.1193,   4.2294,   4.5028,   4.2641,   4.0250,   4.1888,\n",
      "            4.3559,   4.4017,   5.1096,  -4.7984,   4.3650,   4.8235,  -6.7836,\n",
      "           -4.8060,   0.0686,   4.0913,   5.3053,  -4.8850,   4.6907,   5.7267,\n",
      "           -4.5623,   4.4132,  -6.1413,   5.2318,  -4.3994,  -4.5167,   5.1110,\n",
      "           -4.8226,  -0.1689,   7.1129,  -3.3011,   4.6928,   3.7920,  -6.2540,\n",
      "           -5.9839,  -0.4172,   1.8013,  -6.9762,   5.8855,   6.2227,   3.9419,\n",
      "           -4.2285,   5.1825,  -4.9024,  -3.8869,   0.9042,  -7.0790,  -5.4282,\n",
      "            4.1212,  -3.4848,  -5.1533,   3.7140,  -6.9132,  -5.4601,   4.0939,\n",
      "           -5.8235,  -5.3855,   2.9564,   3.9298,  -6.1760,   4.8697,   4.5281,\n",
      "           -7.1201,   3.4128,  -4.7743,   4.9852,  -4.9183,   4.0641,  -6.8862,\n",
      "            4.2855,   4.5993,   3.9040,  -6.3381,   0.6736,  -7.2218,   5.1118,\n",
      "            3.9357,  -4.8377,  -5.6552,  -1.3518,  -5.6481,   4.1451,  -4.4089,\n",
      "           -0.7487,   4.1630,  -6.0519,   1.2838,  -6.7447,  -5.8678,  -6.2411,\n",
      "            2.0637,  -5.0269,  -6.3289,   0.6792,  -4.9704,  -2.5166,  -6.2614,\n",
      "           -5.7183,  -5.7130,   4.1311,  -4.8174,  -0.5229,   4.5457,  -5.2470,\n",
      "           -0.5915,  -4.8040,  -7.0690,   4.8406,  -7.2013,   4.0570,  -6.2123,\n",
      "           -5.8092,   4.0068,  -6.1427,   3.8696,   4.1673,  -7.4766,  -5.7680,\n",
      "            4.6251,  -6.0094],\n",
      "         [  6.7625,  -2.0461,   4.8849,   1.0456,  -4.8348,   7.7604,  -3.8451,\n",
      "            0.6959,  -3.3581,   8.5331,  -5.3412,   9.5250,  -2.7173,  -3.5450,\n",
      "           -0.3339,  -3.5203,   2.9297,  -5.0686,  -4.7320,  -0.5608,  -2.2097,\n",
      "            4.4029,  -0.5584,  -3.7421,   8.1474,   7.2746,  -3.7386,  -0.1743,\n",
      "           -2.1111,  -2.4647,   0.5351,  12.2301,  -3.7659,  -3.1505,  -1.8713,\n",
      "           13.5277,  -0.5918,  -5.0147,   2.1260,  -4.9314,   6.7398,   4.9897,\n",
      "           -2.1855,   8.5840,  -0.8795,  -2.3108,  -4.0341,   4.1879,   7.1867,\n",
      "           -1.6393,   6.5367,   8.5025,   4.5797,  -3.3607,   8.1755,  -8.1619,\n",
      "            6.9888,  -5.6106,  -1.8070,   7.6839,  -5.5121,  -2.8460,  -9.5744,\n",
      "           -1.5882,  -0.2030,  -3.5595,   7.6924,   7.5252,  -2.5142,  -5.1619,\n",
      "           -3.3965,   4.5135,   4.6419,   4.4195,   5.4343,   9.6522,  -3.0255,\n",
      "           -6.8976,   8.0667,   9.8186,  -0.6424,   8.5863,  -1.3629,   6.8815,\n",
      "            5.7692,   6.9997,   8.1221,   3.6530,  -1.5334,   7.2314,   0.7191,\n",
      "           -0.5437,  -1.5507,   4.8884,  12.5957,   7.8661,  -2.4257,   8.2247,\n",
      "           -3.1122,  -4.7161,   8.8735,   5.7675,  -4.2397,   0.4926,  -1.4304,\n",
      "           -3.3810,   6.5822,   7.7591,  -5.1308,  -4.1978,  -4.8444,  -0.5683,\n",
      "            8.7336,  -5.0830,  12.4564,  11.9924,  -5.0708,  -1.3856,  -2.1939,\n",
      "           -7.7185,  -3.8967,  -4.4226,   7.1798,  -1.3532,  12.8668,  -5.1638,\n",
      "            7.8430,   7.8872],\n",
      "         [  3.5508,  -0.9394,   6.5702,  -6.2739,   6.5291,  -1.0813,  -4.2441,\n",
      "            7.5993,  -4.9916,   6.5682,   8.7387,   2.2796,   6.5939,   7.6877,\n",
      "            2.8846,  -9.2699,   8.5231,   2.4405,  -3.8711,   6.2120,  -0.3376,\n",
      "            1.8544,  -1.7845,  -6.3738,   8.5982,   3.1119,  -4.2827,   1.0487,\n",
      "           -4.7172,   7.7929,   4.3855,  -2.3297,   0.7724,   7.6936,  -3.4681,\n",
      "           -0.5386,   2.7251,   2.9008,   8.2498,  -5.0569, -11.1743,  -7.9694,\n",
      "            6.6624,   4.8591,   0.6998,   8.0435,  -7.1326,   1.1037,  -4.0028,\n",
      "           -4.5045,   0.2504,   7.8582,  -3.7506,  -0.2257,   7.5757,   6.6611,\n",
      "            8.4557,   6.8544, -16.3433,  -2.2512,  -0.8940,   6.7231, -13.8708,\n",
      "           -3.7511,  -5.3694,  -2.9671,  -3.5550,   2.4277,   3.4464, -17.1788,\n",
      "            0.7586,   6.7809,  -6.7782,   7.1275,   3.4837,  -5.2938,  -7.3106,\n",
      "            2.1897,   0.3862,   7.2833,   0.6161,   0.4230,  -3.2236,   8.0574,\n",
      "           -6.1894,   9.7618,  -3.9137,  -1.9567, -10.5640,   0.1558,   5.9987,\n",
      "           -9.4515,   8.3632,   7.9744,   1.2604,   3.7135, -15.6222,  -3.0617,\n",
      "            0.3140,  -4.8958,   1.7353,  -6.0494,  -1.3672,   7.2778,  -3.1107,\n",
      "            6.2882,   3.4508,   2.1118,   0.0513,  -1.5144,   2.5396,   6.5993,\n",
      "            7.6529,  -6.6882, -12.2336,  -7.0033,  -6.2692,  -2.9678,   6.7651,\n",
      "           -2.0383,   4.7720,  -7.3780,   6.7074,   3.1227,   4.8212,  -7.0533,\n",
      "            3.3146,  -3.4666],\n",
      "         [  4.2210,   4.4773,  -4.1498,   2.3102,   3.8960,  -5.4156,   6.8510,\n",
      "           -4.6999,   6.1168,   1.4294,   1.2635,   6.1229,   3.7624,  -4.4547,\n",
      "            6.2396,  -3.9173,   5.9117,  -3.9821,   4.1020,  -8.4245,   5.8270,\n",
      "            5.7617,   6.4644,   1.4910,   3.2922,  -5.3864,   0.7637,  -5.4497,\n",
      "            4.4708,   3.2141,  -5.9764,   5.9889,  -4.2294,   0.2975,   4.5668,\n",
      "           -4.5989,   4.2093,  -5.6124,  -4.7556,  -5.7377,   0.7554,   6.4838,\n",
      "           -4.2090,   1.6495,   6.4378,  -5.5531,   1.0437,   0.3139,   5.0926,\n",
      "            4.3182,   1.0006,  -6.0523,  -4.1174,   3.5804,   5.2469,  -3.7064,\n",
      "            4.3595,  -1.3121,   6.0879,   5.2795,   3.1946,   6.6397,   4.6468,\n",
      "           -5.8312,   4.0942,   1.1809,  -5.4951,   3.8258,   3.7635,  -5.8418,\n",
      "            5.8517,  -4.5214,   1.4780,   5.9174,   6.2181,  -3.8201,   0.3286,\n",
      "           -5.1154,   4.8808,   6.2408,   5.3453,  -5.6981,  -7.6458,   5.6526,\n",
      "            4.4246,   1.6320,  -5.6909,   4.1012,   6.1750,  -4.3345,   1.0782,\n",
      "            5.3929,  -5.2945,  -6.6692,   6.6772,  -4.6408,  -0.0548,   4.1247,\n",
      "            6.7774,   4.6750,  -5.4016,   6.3486,   5.0714,   6.3596,  -4.6872,\n",
      "            5.5060,   4.2084,   6.4803,   0.8085,   4.3103,   4.1840,   3.9532,\n",
      "            0.3926,   0.9288,   6.0918,  -3.6567,  -6.4097,   3.7652,   5.5375,\n",
      "            4.8449,   1.8810,  -4.2051,  -6.0025,   4.3440,   4.0771,   3.5672,\n",
      "           -5.9860,   5.8293]]])\n",
      "conv_1.att_src\n",
      "torch.Size([1, 5, 128])\n",
      "conv_1.att_dst\n",
      "torch.Size([1, 5, 128])\n",
      "conv_1.bias\n",
      "torch.Size([640])\n",
      "conv_1.lin_src.weight\n",
      "torch.Size([640, 7])\n",
      "conv_1.lin_dst.weight\n",
      "torch.Size([640, 7])\n",
      "conv_end.att_src\n",
      "torch.Size([1, 1, 1])\n",
      "conv_end.att_dst\n",
      "torch.Size([1, 1, 1])\n",
      "conv_end.bias\n",
      "torch.Size([1])\n",
      "conv_end.lin_src.weight\n",
      "torch.Size([1, 640])\n",
      "conv_end.lin_dst.weight\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't access the shape of an uninitialized parameter or buffer. This error usually happens in `load_state_dict` when trying to load an uninitialized parameter into an initialized one. Call `forward` to initialize the parameters before accessing their attributes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m model_rev\u001b[38;5;241m.\u001b[39mstate_dict():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(key)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel_rev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/parameter.py:123\u001b[0m, in \u001b[0;36mUninitializedTensorMixin.shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt access the shape of an uninitialized parameter or buffer. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis error usually happens in `load_state_dict` when trying to load \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man uninitialized parameter into an initialized one. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCall `forward` to initialize the parameters before accessing their attributes.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't access the shape of an uninitialized parameter or buffer. This error usually happens in `load_state_dict` when trying to load an uninitialized parameter into an initialized one. Call `forward` to initialize the parameters before accessing their attributes."
     ]
    }
   ],
   "source": [
    "print(model_rev.state_dict()[\"conv_1.att_src\"])\n",
    "for key in model_rev.state_dict():\n",
    "    print(key)\n",
    "    print(model_rev.state_dict()[key].shape)#[\"conv_1.lin_src.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac96cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df = pd.DataFrame(graph.edge_index.t(), columns = [\"source\", \"target\"])\n",
    "edge_df[\"attention_weights\"] = attention_w[1][1]\n",
    "for i in range(5):\n",
    "    edge_df[f\"attention_weights_{i}\"] = attention_w[0][1][:, i]\n",
    "edge_df[f\"attention_weights_mean\"] = torch.mean(attention_w[0][1], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ff876e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>attention_weights</th>\n",
       "      <th>attention_weights_0</th>\n",
       "      <th>attention_weights_1</th>\n",
       "      <th>attention_weights_2</th>\n",
       "      <th>attention_weights_3</th>\n",
       "      <th>attention_weights_4</th>\n",
       "      <th>attention_weights_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.188420e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259206</th>\n",
       "      <td>1819432</td>\n",
       "      <td>1819430</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>5.173853e-11</td>\n",
       "      <td>0.602167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259207</th>\n",
       "      <td>1819432</td>\n",
       "      <td>1819431</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>0.430858</td>\n",
       "      <td>2.381722e-05</td>\n",
       "      <td>0.686176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259208</th>\n",
       "      <td>1819433</td>\n",
       "      <td>1819433</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.886244</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>8.557699e-01</td>\n",
       "      <td>0.998996</td>\n",
       "      <td>6.175879e-09</td>\n",
       "      <td>0.548203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259209</th>\n",
       "      <td>1819434</td>\n",
       "      <td>1819434</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259210</th>\n",
       "      <td>1819434</td>\n",
       "      <td>1819433</td>\n",
       "      <td>7.233350e-38</td>\n",
       "      <td>0.113756</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.442300e-01</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.451797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7259211 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source   target  attention_weights  attention_weights_0  \\\n",
       "0              0        0       1.000000e+00             1.000000   \n",
       "1              1        1       1.000000e+00             1.000000   \n",
       "2              2        2       1.000000e+00             1.000000   \n",
       "3              3        3       1.000000e+00             1.000000   \n",
       "4              4        4       1.000000e+00             0.000000   \n",
       "...          ...      ...                ...                  ...   \n",
       "7259206  1819432  1819430       0.000000e+00             1.000000   \n",
       "7259207  1819432  1819431       0.000000e+00             1.000000   \n",
       "7259208  1819433  1819433       1.000000e+00             0.886244   \n",
       "7259209  1819434  1819434       1.000000e+00             1.000000   \n",
       "7259210  1819434  1819433       7.233350e-38             0.113756   \n",
       "\n",
       "         attention_weights_1  attention_weights_2  attention_weights_3  \\\n",
       "0                   1.000000         1.000000e+00             1.000000   \n",
       "1                   1.000000         1.000000e+00             1.000000   \n",
       "2                   1.000000         1.000000e+00             1.000000   \n",
       "3                   1.000000         1.000000e+00             1.000000   \n",
       "4                   0.000000         2.188420e-08             1.000000   \n",
       "...                      ...                  ...                  ...   \n",
       "7259206             1.000000         9.999998e-01             0.010834   \n",
       "7259207             1.000000         9.999999e-01             0.430858   \n",
       "7259208             0.000005         8.557699e-01             0.998996   \n",
       "7259209             1.000000         1.000000e+00             1.000000   \n",
       "7259210             0.999995         1.442300e-01             0.001004   \n",
       "\n",
       "         attention_weights_4  attention_weights_mean  \n",
       "0               1.000000e+00                1.000000  \n",
       "1               1.000000e+00                1.000000  \n",
       "2               1.000000e+00                1.000000  \n",
       "3               1.000000e+00                1.000000  \n",
       "4               1.000000e+00                0.400000  \n",
       "...                      ...                     ...  \n",
       "7259206         5.173853e-11                0.602167  \n",
       "7259207         2.381722e-05                0.686176  \n",
       "7259208         6.175879e-09                0.548203  \n",
       "7259209         1.000000e+00                1.000000  \n",
       "7259210         1.000000e+00                0.451797  \n",
       "\n",
       "[7259211 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ce6bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df[\"source_label\"] = data[\"Label\"].iloc[edge_df[\"source\"]].reset_index(drop=True)\n",
    "edge_df[\"target_label\"] = data[\"Label\"].iloc[edge_df[\"target\"]].reset_index(drop=True)\n",
    "\n",
    "edge_df[\"source_counter\"] = data[\"counter\"].iloc[edge_df[\"source\"]].reset_index(drop=True)\n",
    "edge_df[\"target_counter\"] = data[\"counter\"].iloc[edge_df[\"target\"]].reset_index(drop=True)\n",
    "\n",
    "edge_df[\"source_pred\"] = torch.index_select(pred.squeeze(), 0, edge_index[0])\n",
    "edge_df[\"target_pred\"] = torch.index_select(pred.squeeze(), 0, edge_index[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d3a4467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>attention_weights</th>\n",
       "      <th>attention_weights_0</th>\n",
       "      <th>attention_weights_1</th>\n",
       "      <th>attention_weights_2</th>\n",
       "      <th>attention_weights_3</th>\n",
       "      <th>attention_weights_4</th>\n",
       "      <th>attention_weights_mean</th>\n",
       "      <th>source_label</th>\n",
       "      <th>target_label</th>\n",
       "      <th>source_counter</th>\n",
       "      <th>target_counter</th>\n",
       "      <th>source_pred</th>\n",
       "      <th>target_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3633999</th>\n",
       "      <td>921597</td>\n",
       "      <td>921589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.057076e-10</td>\n",
       "      <td>3.430381e-07</td>\n",
       "      <td>1.250125e-09</td>\n",
       "      <td>6.515525e-23</td>\n",
       "      <td>1.116182e-07</td>\n",
       "      <td>9.120244e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938803</th>\n",
       "      <td>1006171</td>\n",
       "      <td>1006150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.480298e-43</td>\n",
       "      <td>7.854222e-40</td>\n",
       "      <td>9.993143e-01</td>\n",
       "      <td>3.247005e-25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.998629e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938804</th>\n",
       "      <td>1006171</td>\n",
       "      <td>1006151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.480298e-43</td>\n",
       "      <td>7.854222e-40</td>\n",
       "      <td>9.993143e-01</td>\n",
       "      <td>4.136962e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.998629e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938805</th>\n",
       "      <td>1006171</td>\n",
       "      <td>1006152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.480298e-43</td>\n",
       "      <td>7.854222e-40</td>\n",
       "      <td>9.993143e-01</td>\n",
       "      <td>2.691979e-21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.998629e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938806</th>\n",
       "      <td>1006171</td>\n",
       "      <td>1006153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.480298e-43</td>\n",
       "      <td>7.854222e-40</td>\n",
       "      <td>9.993143e-01</td>\n",
       "      <td>4.877231e-25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.998629e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198517</th>\n",
       "      <td>315568</td>\n",
       "      <td>315568</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.612282e-34</td>\n",
       "      <td>4.746074e-11</td>\n",
       "      <td>8.015552e-04</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.001603e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631892</th>\n",
       "      <td>1166900</td>\n",
       "      <td>1166900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.244817e-06</td>\n",
       "      <td>1.987549e-27</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000002e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631893</th>\n",
       "      <td>1166901</td>\n",
       "      <td>1166901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.390931e-08</td>\n",
       "      <td>8.106259e-21</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631823</th>\n",
       "      <td>1166865</td>\n",
       "      <td>1166865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.645202e-10</td>\n",
       "      <td>4.367634e-20</td>\n",
       "      <td>3.575913e-02</td>\n",
       "      <td>9.992600e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.070038e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.362828e-01</td>\n",
       "      <td>9.841182e-01</td>\n",
       "      <td>5.563017e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.724389e-15</td>\n",
       "      <td>3.640802e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5143510 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source   target  attention_weights  attention_weights_0  \\\n",
       "3633999   921597   921589                0.0         1.057076e-10   \n",
       "3938803  1006171  1006150                0.0         2.480298e-43   \n",
       "3938804  1006171  1006151                0.0         2.480298e-43   \n",
       "3938805  1006171  1006152                0.0         2.480298e-43   \n",
       "3938806  1006171  1006153                0.0         2.480298e-43   \n",
       "...          ...      ...                ...                  ...   \n",
       "1198517   315568   315568                1.0         0.000000e+00   \n",
       "4631892  1166900  1166900                1.0         0.000000e+00   \n",
       "4631893  1166901  1166901                1.0         0.000000e+00   \n",
       "4631823  1166865  1166865                1.0         3.645202e-10   \n",
       "9              8        8                1.0         8.362828e-01   \n",
       "\n",
       "         attention_weights_1  attention_weights_2  attention_weights_3  \\\n",
       "3633999         3.430381e-07         1.250125e-09         6.515525e-23   \n",
       "3938803         7.854222e-40         9.993143e-01         3.247005e-25   \n",
       "3938804         7.854222e-40         9.993143e-01         4.136962e-19   \n",
       "3938805         7.854222e-40         9.993143e-01         2.691979e-21   \n",
       "3938806         7.854222e-40         9.993143e-01         4.877231e-25   \n",
       "...                      ...                  ...                  ...   \n",
       "1198517         4.612282e-34         4.746074e-11         8.015552e-04   \n",
       "4631892         0.000000e+00         1.244817e-06         1.987549e-27   \n",
       "4631893         0.000000e+00         1.390931e-08         8.106259e-21   \n",
       "4631823         4.367634e-20         3.575913e-02         9.992600e-01   \n",
       "9               9.841182e-01         5.563017e-08         0.000000e+00   \n",
       "\n",
       "         attention_weights_4  attention_weights_mean  source_label  \\\n",
       "3633999         1.116182e-07            9.120244e-08             0   \n",
       "3938803         0.000000e+00            1.998629e-01             0   \n",
       "3938804         0.000000e+00            1.998629e-01             0   \n",
       "3938805         0.000000e+00            1.998629e-01             0   \n",
       "3938806         0.000000e+00            1.998629e-01             0   \n",
       "...                      ...                     ...           ...   \n",
       "1198517         9.999999e-01            2.001603e-01             0   \n",
       "4631892         1.000000e+00            2.000002e-01             0   \n",
       "4631893         1.000000e+00            2.000000e-01             0   \n",
       "4631823         0.000000e+00            2.070038e-01             0   \n",
       "9               4.724389e-15            3.640802e-01             0   \n",
       "\n",
       "         target_label  source_counter  target_counter  source_pred  \\\n",
       "3633999             0        0.863636        0.681818          0.0   \n",
       "3938803             0        0.681818        0.363636          0.0   \n",
       "3938804             0        0.681818        0.378788          0.0   \n",
       "3938805             0        0.681818        0.393939          0.0   \n",
       "3938806             0        0.681818        0.409091          0.0   \n",
       "...               ...             ...             ...          ...   \n",
       "1198517             0        0.250000        0.250000          0.0   \n",
       "4631892             0        0.076923        0.076923          0.0   \n",
       "4631893             0        0.096154        0.096154          0.0   \n",
       "4631823             0        0.500000        0.500000          0.0   \n",
       "9                   0        0.200000        0.200000          0.0   \n",
       "\n",
       "         target_pred  \n",
       "3633999          0.0  \n",
       "3938803          0.0  \n",
       "3938804          0.0  \n",
       "3938805          0.0  \n",
       "3938806          0.0  \n",
       "...              ...  \n",
       "1198517          0.0  \n",
       "4631892          0.0  \n",
       "4631893          0.0  \n",
       "4631823          0.0  \n",
       "9                0.0  \n",
       "\n",
       "[5143510 rows x 15 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_edge_df = edge_df[np.logical_and(edge_df[\"target_counter\"] != 1, edge_df[\"target_counter\"] != 0)]\n",
    "middle_edge_df.sort_values(\"attention_weights\")\n",
    "## where are the attention heads low (0) or especeially high (-> 1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bdf7603a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_counter</th>\n",
       "      <th>target_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207494.000000</td>\n",
       "      <td>207494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.514939</td>\n",
       "      <td>0.377583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.210556</td>\n",
       "      <td>0.216055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.003049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.538329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source_counter  target_counter\n",
       "count   207494.000000   207494.000000\n",
       "mean         0.514939        0.377583\n",
       "std          0.210556        0.216055\n",
       "min          0.006098        0.003049\n",
       "25%          0.350000        0.200000\n",
       "50%          0.500000        0.333333\n",
       "75%          0.666667        0.538329\n",
       "max          1.000000        0.993902"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_target_edges = middle_edge_df[middle_edge_df[\"target_label\"] == middle_edge_df[\"target_pred\"]]\n",
    "correct_target_edges_with_importance = correct_target_edges[correct_target_edges[\"attention_weights\"] >= .2]\n",
    "correct_target_edges_with_importance_wo_self_edges = correct_target_edges_with_importance[correct_target_edges_with_importance[\"source\"] != correct_target_edges_with_importance[\"target\"]]\n",
    "correct_target_edges_with_importance_wo_self_edges[[\"source_counter\", \"target_counter\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6a3bcccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.2563953847228662, pvalue=0.0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(correct_target_edges_with_importance_wo_self_edges[\"source_counter\"],\n",
    "         correct_target_edges_with_importance_wo_self_edges[\"attention_weights_mean\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
