{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89657ef6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.insert(0, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e59c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"../../extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "y_train = torch.tensor(data_analysis.get_y_train(), dtype=torch.long)\n",
    "X_train = torch.tensor(data_analysis.get_X_train(), dtype=torch.float)\n",
    "\n",
    "y_test = torch.tensor(data_analysis.get_y_test(), dtype=torch.long)\n",
    "X_test = torch.tensor(data_analysis.get_X_test(), dtype=torch.float)\n",
    "\n",
    "y_gw_test = torch.tensor(data_analysis.get_y_gw(), dtype=torch.long)\n",
    "X_gw_test = torch.tensor(data_analysis.get_X_gw(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f85fa",
   "metadata": {},
   "source": [
    "## Normalize and Concatenate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac500a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tensor):\n",
    "    mean = torch.mean(tensor, dim = 0)\n",
    "    std = torch.std(tensor, dim = 0)\n",
    "    mean_diff = tensor - mean\n",
    "    return mean_diff / std\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "X_gw_test = normalize(X_gw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ed51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = torch.concat((y_train, y_test, y_gw_test))\n",
    "X_all = torch.concat((X_train, X_test, X_gw_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6327f",
   "metadata": {},
   "source": [
    "## Train/Validation/Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_indices_like(tensor):\n",
    "    return torch.ones((tensor.shape[0])).type(torch.bool)\n",
    "\n",
    "def false_indices_like(tensor):\n",
    "    return torch.zeros((tensor.shape[0])).type(torch.bool)\n",
    "\n",
    "def split(train_features):\n",
    "    tensor = true_indices_like(train_features)\n",
    "    max_index = round(tensor.shape[0] * .8)\n",
    "    train = torch.zeros(tensor.shape[0])\n",
    "    train[:max_index] = 1\n",
    "    \n",
    "    val = torch.zeros(tensor.shape[0])\n",
    "    val[max_index:] = 1\n",
    "    return{\n",
    "        \"train\": train.type(torch.bool),\n",
    "        \"val\":val.type(torch.bool)\n",
    "    }\n",
    "train_data = split(X_train)\n",
    "\n",
    "train_mask = torch.concat((train_data[\"train\"], false_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "val_mask = torch.concat((train_data[\"val\"], false_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "test_l_mask = torch.concat((false_indices_like(X_train), true_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "test_gw_mask = torch.concat((false_indices_like(X_train), false_indices_like(X_test), true_indices_like(X_gw_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c99071b",
   "metadata": {},
   "source": [
    "## Construct edges and define graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b68f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = knn_graph(X_all[:, :7],k = 4, loop = True, num_workers = -1)\n",
    "graph = Data(x= X_all,  edge_index = edge_index, y = y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3414af85",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa14d28",
   "metadata": {},
   "source": [
    "## Model in paper GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch\n",
    "from dataAnalysis.Constants import FEATURES\n",
    "\n",
    "class GraphNeuralNetwork(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim = 128, out_channels = 1):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        \n",
    "        input_dim = len(FEATURES)          \n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim, normalize=True, project= True, aggr = \"mean\", root_weight = True, dropout=0.0)\n",
    "        self.conv_end = SAGEConv(hidden_dim, out_channels, aggr = \"mean\", root_weight = True)\n",
    "\n",
    "\n",
    "    def forward(self, graph):\n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv_end(x, edge_index)\n",
    "        return x\n",
    "            \n",
    "    def predict_proba(self, graph, mask):\n",
    "        with torch.inference_mode():\n",
    "            self.eval()\n",
    "            logits = self.forward(graph)\n",
    "            scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "            scores = torch.unsqueeze(scores, 0)\n",
    "            proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "            return torch.transpose(proba_predict, 0, 1)\n",
    "            \n",
    "    def predict(self, graph, mask):\n",
    "        return torch.round(self.predict_proba(graph, mask)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f298433d",
   "metadata": {},
   "source": [
    "## Shift data to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "graph = graph.to(device)\n",
    "WEIGHT = torch.tensor([664])\n",
    "WEIGHT = WEIGHT.to(device)\n",
    "\n",
    "print(\"Data shifted to the device \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effc3e47",
   "metadata": {},
   "source": [
    "## Model-Wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc431f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, graph):\n",
    "        self.LEARNING_RATE = 3e-4\n",
    "        self.MAX_EPOCHS = 40000\n",
    "\n",
    "        self.model = GraphNeuralNetwork(hidden_dim = 128, out_channels=1) \n",
    "        self.model = self.model.to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.LEARNING_RATE,betas=(0.9, 0.999), eps=1e-08)\n",
    "        self.graph = graph\n",
    "        \n",
    "        self.last_loss = 0\n",
    "        self.increased_loss = 0\n",
    "        self.BREAKING_THRESHOLD = 10    \n",
    "        self.val_loss = []\n",
    "        self.train_loss = []\n",
    "    \n",
    "    def validate(self):\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            out = self.model(self.graph)\n",
    "            loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[val_mask]), self.graph.y[val_mask].type(torch.float32),\n",
    "                                                      pos_weight=WEIGHT)\n",
    "            self.val_loss.append(loss.item())\n",
    "            if loss.item() > self.last_loss:\n",
    "                self.increased_loss += 1\n",
    "            else:\n",
    "                self.increased_loss = 0\n",
    "            self.last_loss = loss.item()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.MAX_EPOCHS):\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            out = self.model(self.graph)\n",
    "            loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[train_mask]), self.graph.y[train_mask].type(torch.float32),\n",
    "                                                      pos_weight=WEIGHT)\n",
    "            self.train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.validate() \n",
    "\n",
    "            if self.increased_loss >= self.BREAKING_THRESHOLD:\n",
    "#                 print(f\"Breaked at {str(epoch)}\")\n",
    "                break\n",
    "            \n",
    "    def get_model(self):\n",
    "        return self.model    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.epochs, self.train_loss, 'g', label='Training loss')\n",
    "        plt.plot(self.epochs, self.val_loss, 'y', label='Validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fad202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "model_wrapper = ModelWrapper(graph)\n",
    "start = time.time()\n",
    "model_wrapper.train()\n",
    "print(time.time()-start)\n",
    "model = model_wrapper.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665b464",
   "metadata": {},
   "source": [
    "## Shift data and model back to CPU for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae71419",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph.cpu()\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df674f0c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "evaluation = Evaluation(y_test.cpu(), y_gw_test.cpu(), X_test.cpu(), X_gw_test.cpu())\n",
    "evaluation.set_test_args([graph, test_l_mask])\n",
    "evaluation.set_gw_args([graph, test_gw_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9713c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_confusion_matrix(model)\n",
    "evaluation.get_df_metrics(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc5517",
   "metadata": {},
   "source": [
    "## Error evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5e8ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "number_of_iter = 100-13\n",
    "dataframes =[]\n",
    "gnn_models = []\n",
    "times = []\n",
    "for i in range(number_of_iter):\n",
    "#     print(i)\n",
    "    graph = graph.to(device)\n",
    "    start = time.time()\n",
    "    model_wrapper = ModelWrapper(graph)\n",
    "    model_wrapper.train()\n",
    "    times.append(time.time()-start)\n",
    "    print(time.time()- start)\n",
    "    model = model_wrapper.get_model()\n",
    "    model = model.cpu()\n",
    "    graph = graph.cpu()\n",
    "    df = evaluation.get_df_metrics(model)\n",
    "    print(df)\n",
    "    dataframes.append(df)\n",
    "    gnn_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a07f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in times:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaea966",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
