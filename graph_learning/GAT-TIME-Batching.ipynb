{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11a4ca8",
   "metadata": {},
   "source": [
    "## GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c344596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Assessable data are 528101 cases and 1015074 CBCs\n",
      "Control data are 527038 cases and 1013548 CBCs\n",
      "Sepsis data are 1488 cases and 1526 CBCs\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "Testing: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 365794, Sepsis: 490\n",
      "Assessable data are 180494 cases and 366284 CBCs\n",
      "Control data are 180157 cases and 365794 CBCs\n",
      "Sepsis data are 472 cases and 490 CBCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 437629, Sepsis: 448\n",
      "Assessable data are 157922 cases and 438077 CBCs\n",
      "Control data are 180157 cases and 437629 CBCs\n",
      "Sepsis data are 438 cases and 448 CBCs\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "import cudf\n",
    "\n",
    "data = pd.read_csv(r\"extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1591ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((data_analysis.get_training_data(), data_analysis.get_testing_data()))\n",
    "data = cudf.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fedac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac6d2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = data[\"Id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8d8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6556e31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           665587\n",
       "1           665588\n",
       "2           665589\n",
       "3           665590\n",
       "4           665591\n",
       "            ...   \n",
       "1381353    2709538\n",
       "1381354    2709541\n",
       "1381355    2709540\n",
       "1381356    2709539\n",
       "1381357    2709536\n",
       "Name: index, Length: 1381358, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pop(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50f24a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Center</th>\n",
       "      <th>Set</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Time</th>\n",
       "      <th>TargetIcu</th>\n",
       "      <th>SecToIcu</th>\n",
       "      <th>CRP</th>\n",
       "      <th>HGB</th>\n",
       "      <th>MCV</th>\n",
       "      <th>PCT</th>\n",
       "      <th>PLT</th>\n",
       "      <th>RBC</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>ED</td>\n",
       "      <td>1</td>\n",
       "      <td>420.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>167.0</td>\n",
       "      <td>4.36</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10.6</td>\n",
       "      <td>79.9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>199.0</td>\n",
       "      <td>6.02</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>AMB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.87</td>\n",
       "      <td>8.7</td>\n",
       "      <td>89.9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>298.0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>ED</td>\n",
       "      <td>1</td>\n",
       "      <td>780.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.9</td>\n",
       "      <td>96.2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>216.0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.3</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>W</td>\n",
       "      <td>Control</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Training</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>232.87</td>\n",
       "      <td>7.4</td>\n",
       "      <td>86.6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>189.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.9</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381353</th>\n",
       "      <td>778980</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>606720.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>296040.0</td>\n",
       "      <td>17.88</td>\n",
       "      <td>6.7</td>\n",
       "      <td>96.6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>121.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381354</th>\n",
       "      <td>778980</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>895680.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>7080.0</td>\n",
       "      <td>22.98</td>\n",
       "      <td>7.7</td>\n",
       "      <td>91.8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>155.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Sepsis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381355</th>\n",
       "      <td>778980</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>888540.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>14220.0</td>\n",
       "      <td>19.26</td>\n",
       "      <td>6.6</td>\n",
       "      <td>91.1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>149.0</td>\n",
       "      <td>3.14</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Sepsis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381356</th>\n",
       "      <td>778980</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>870420.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>32340.0</td>\n",
       "      <td>20.46</td>\n",
       "      <td>6.5</td>\n",
       "      <td>93.2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381357</th>\n",
       "      <td>778980</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Validation</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>267660.0</td>\n",
       "      <td>MICU</td>\n",
       "      <td>635100.0</td>\n",
       "      <td>19.55</td>\n",
       "      <td>6.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>129.0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1381358 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  Age Sex Diagnosis   Center         Set Sender  Episode  \\\n",
       "0             1   79   M   Control  Leipzig    Training     ED        1   \n",
       "1             2   35   M   Control  Leipzig    Training    GEN        1   \n",
       "2             3   47   W   Control  Leipzig    Training    AMB        1   \n",
       "3             4   28   M   Control  Leipzig    Training     ED        1   \n",
       "4             5   63   W   Control  Leipzig    Training    GEN        1   \n",
       "...         ...  ...  ..       ...      ...         ...    ...      ...   \n",
       "1381353  778980   56   M    Sepsis  Leipzig  Validation    GEN        1   \n",
       "1381354  778980   56   M    Sepsis  Leipzig  Validation    GEN        1   \n",
       "1381355  778980   56   M    Sepsis  Leipzig  Validation    GEN        1   \n",
       "1381356  778980   56   M    Sepsis  Leipzig  Validation    GEN        1   \n",
       "1381357  778980   56   M    Sepsis  Leipzig  Validation    GEN        1   \n",
       "\n",
       "             Time TargetIcu  SecToIcu     CRP   HGB    MCV   PCT    PLT   RBC  \\\n",
       "0           420.0      <NA>      <NA>    0.75   8.1   86.0  <NA>  167.0  4.36   \n",
       "1             0.0      <NA>      <NA>    <NA>  10.6   79.9  <NA>  199.0  6.02   \n",
       "2             0.0      <NA>      <NA>    3.87   8.7   89.9  <NA>  298.0  4.37   \n",
       "3           780.0      <NA>      <NA>    0.52   9.9   96.2  <NA>  216.0  4.79   \n",
       "4             0.0      <NA>      <NA>  232.87   7.4   86.6  <NA>  189.0  3.96   \n",
       "...           ...       ...       ...     ...   ...    ...   ...    ...   ...   \n",
       "1381353  606720.0      MICU  296040.0   17.88   6.7   96.6  <NA>  121.0  3.20   \n",
       "1381354  895680.0      MICU    7080.0   22.98   7.7   91.8  <NA>  155.0  3.67   \n",
       "1381355  888540.0      MICU   14220.0   19.26   6.6   91.1  <NA>  149.0  3.14   \n",
       "1381356  870420.0      MICU   32340.0   20.46   6.5   93.2  <NA>  114.0  3.07   \n",
       "1381357  267660.0      MICU  635100.0   19.55   6.7  100.0  <NA>  129.0  3.11   \n",
       "\n",
       "          WBC    Label  \n",
       "0         7.3  Control  \n",
       "1         4.7  Control  \n",
       "2         7.1  Control  \n",
       "3         5.3  Control  \n",
       "4        20.9  Control  \n",
       "...       ...      ...  \n",
       "1381353   7.2  Control  \n",
       "1381354   7.1   Sepsis  \n",
       "1381355   6.5   Sepsis  \n",
       "1381356   8.3  Control  \n",
       "1381357   6.0  Control  \n",
       "\n",
       "[1381358 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b446b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Constants import SEX_CATEGORY_COLUMN_NAME, SEX_COLUMN_NAME, FEATURES\n",
    "data[SEX_CATEGORY_COLUMN_NAME] = data.loc[:, SEX_COLUMN_NAME] ==\"W\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da53cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[SEX_CATEGORY_COLUMN_NAME] = data[SEX_CATEGORY_COLUMN_NAME].astype(\"int8\")\n",
    "data[\"Label\"] = data[\"Label\"] == \"Sepsis\"\n",
    "data[\"Label\"] = data[\"Label\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3aa4124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getPositionEncoding(seq_len, d = len(FEATURES), n=10000):\n",
    "    P = np.zeros((seq_len, d))\n",
    "    for k in range(seq_len):\n",
    "        for i in np.arange(int(d/2)):\n",
    "            denominator = np.power(n, 2*i/d)\n",
    "            P[k, 2*i] = np.sin(k/denominator)\n",
    "            P[k, 2*i+1] = np.cos(k/denominator)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2691663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Constants import FEATURES\n",
    "for feature in FEATURES:\n",
    "    data[feature] = (data[feature] - data[feature].mean()) / data[feature].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e65263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random = np.random.uniform(0, 1 ,data.shape[0])\n",
    "data[\"random\"] = random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "graph_list = []\n",
    "start = time.time()\n",
    "i = 0\n",
    "for Id, group in data.groupby(\"Id\"):\n",
    "    i+=1\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{str(i / unique_ids.shape[0] * 100)} %\")\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56522b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "class Fred(threading.Thread):\n",
    "    def __init__(self, Id, it):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.id = Id\n",
    "        self.it = it\n",
    "    \n",
    "    def run(self):\n",
    "        self.id\n",
    "        self.it = self.it+1\n",
    "        \n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "graph_list = []\n",
    "start = time.time()\n",
    "i = 0\n",
    "for Id, group in data.groupby(\"Id\"):\n",
    "    fred = Fred(Id, i)\n",
    "    fred.start()\n",
    "    i = fred.it\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{str(i / unique_ids.shape[0] * 100)} %\")\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cbb0678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1411243375976404 %\n",
      "0.2822486751952808 %\n",
      "0.4233730127929212 %\n",
      "0.5644973503905616 %\n",
      "0.705621687988202 %\n",
      "0.8467460255858424 %\n",
      "0.9878703631834829 %\n",
      "1.1289947007811232 %\n",
      "1.2701190383787637 %\n",
      "1.411243375976404 %\n",
      "1.5523677135740444 %\n",
      "1.6934920511716849 %\n",
      "1.8346163887693252 %\n",
      "1.9757407263669657 %\n",
      "2.116865063964606 %\n",
      "2.2579894015622464 %\n",
      "2.399113739159887 %\n",
      "2.5402380767575274 %\n",
      "2.6813624143551675 %\n",
      "2.822486751952808 %\n",
      "2.963611089550448 %\n",
      "3.1047354271480887 %\n",
      "3.2458597647457297 %\n",
      "3.3869841023433698 %\n",
      "3.52810843994101 %\n",
      "3.6692327775386504 %\n",
      "3.810357115136291 %\n",
      "3.9514814527339315 %\n",
      "4.092605790331572 %\n",
      "4.233730127929212 %\n",
      "4.374854465526853 %\n",
      "4.515978803124493 %\n",
      "4.657103140722133 %\n",
      "4.798227478319774 %\n",
      "4.939351815917414 %\n",
      "5.080476153515055 %\n",
      "5.221600491112695 %\n",
      "5.362724828710335 %\n",
      "5.503849166307976 %\n",
      "5.644973503905616 %\n",
      "5.786097841503256 %\n",
      "5.927222179100896 %\n",
      "6.068346516698537 %\n",
      "6.209470854296177 %\n",
      "6.350595191893818 %\n",
      "6.491719529491459 %\n",
      "6.632843867089099 %\n",
      "6.7739682046867395 %\n",
      "6.915092542284379 %\n",
      "7.05621687988202 %\n",
      "7.197341217479661 %\n",
      "7.338465555077301 %\n",
      "7.479589892674941 %\n",
      "7.620714230272582 %\n",
      "7.761838567870222 %\n",
      "7.902962905467863 %\n",
      "8.044087243065503 %\n",
      "8.185211580663143 %\n",
      "8.326335918260783 %\n",
      "8.467460255858423 %\n",
      "8.608584593456065 %\n",
      "8.749708931053705 %\n",
      "8.890833268651345 %\n",
      "9.031957606248985 %\n",
      "9.173081943846626 %\n",
      "9.314206281444266 %\n",
      "9.455330619041908 %\n",
      "9.596454956639548 %\n",
      "9.737579294237188 %\n",
      "9.878703631834828 %\n",
      "10.019827969432468 %\n",
      "10.16095230703011 %\n",
      "10.302076644627748 %\n",
      "10.44320098222539 %\n",
      "10.58432531982303 %\n",
      "10.72544965742067 %\n",
      "10.86657399501831 %\n",
      "11.007698332615952 %\n",
      "11.148822670213592 %\n",
      "11.289947007811232 %\n",
      "11.431071345408872 %\n",
      "11.572195683006512 %\n",
      "11.713320020604154 %\n",
      "11.854444358201793 %\n",
      "11.995568695799435 %\n",
      "12.136693033397075 %\n",
      "12.277817370994715 %\n",
      "12.418941708592355 %\n",
      "12.560066046189997 %\n",
      "12.701190383787637 %\n",
      "12.842314721385275 %\n",
      "12.983439058982919 %\n",
      "13.124563396580557 %\n",
      "13.265687734178197 %\n",
      "13.406812071775839 %\n",
      "13.547936409373479 %\n",
      "13.68906074697112 %\n",
      "13.830185084568758 %\n",
      "13.9713094221664 %\n",
      "14.11243375976404 %\n",
      "14.25355809736168 %\n",
      "14.394682434959321 %\n",
      "14.535806772556962 %\n",
      "14.676931110154602 %\n",
      "14.818055447752243 %\n",
      "14.959179785349882 %\n",
      "15.100304122947522 %\n",
      "15.241428460545164 %\n",
      "15.382552798142804 %\n",
      "15.523677135740444 %\n",
      "15.664801473338086 %\n",
      "15.805925810935726 %\n",
      "15.947050148533364 %\n",
      "16.088174486131006 %\n",
      "16.229298823728648 %\n",
      "16.370423161326286 %\n",
      "16.511547498923925 %\n",
      "16.652671836521566 %\n",
      "16.79379617411921 %\n",
      "16.934920511716847 %\n",
      "17.07604484931449 %\n",
      "17.21716918691213 %\n",
      "17.35829352450977 %\n",
      "17.49941786210741 %\n",
      "17.64054219970505 %\n",
      "17.78166653730269 %\n",
      "17.922790874900333 %\n",
      "18.06391521249797 %\n",
      "18.205039550095613 %\n",
      "18.34616388769325 %\n",
      "18.487288225290893 %\n",
      "18.62841256288853 %\n",
      "18.769536900486173 %\n",
      "18.910661238083815 %\n",
      "19.051785575681453 %\n",
      "19.192909913279095 %\n",
      "19.334034250876737 %\n",
      "19.475158588474375 %\n",
      "19.616282926072014 %\n",
      "19.757407263669656 %\n",
      "19.898531601267297 %\n",
      "20.039655938864936 %\n",
      "20.180780276462578 %\n",
      "20.32190461406022 %\n",
      "20.463028951657858 %\n",
      "20.604153289255496 %\n",
      "20.745277626853138 %\n",
      "20.88640196445078 %\n",
      "21.027526302048418 %\n",
      "21.16865063964606 %\n",
      "21.309774977243702 %\n",
      "21.45089931484134 %\n",
      "21.592023652438982 %\n",
      "21.73314799003662 %\n",
      "21.874272327634262 %\n",
      "22.015396665231904 %\n",
      "22.156521002829543 %\n",
      "22.297645340427184 %\n",
      "22.438769678024823 %\n",
      "22.579894015622465 %\n",
      "22.721018353220103 %\n",
      "22.862142690817745 %\n",
      "23.003267028415387 %\n",
      "23.144391366013025 %\n",
      "23.285515703610667 %\n",
      "23.42664004120831 %\n",
      "23.567764378805947 %\n",
      "23.708888716403585 %\n",
      "23.85001305400123 %\n",
      "23.99113739159887 %\n",
      "24.132261729196507 %\n",
      "24.27338606679415 %\n",
      "24.41451040439179 %\n",
      "24.55563474198943 %\n",
      "24.696759079587068 %\n",
      "24.83788341718471 %\n",
      "24.97900775478235 %\n",
      "25.120132092379993 %\n",
      "25.261256429977628 %\n",
      "25.402380767575274 %\n",
      "25.543505105172915 %\n",
      "25.68462944277055 %\n",
      "25.825753780368192 %\n",
      "25.966878117965837 %\n",
      "26.108002455563472 %\n",
      "26.249126793161114 %\n",
      "26.390251130758756 %\n",
      "26.531375468356394 %\n",
      "26.672499805954036 %\n",
      "26.813624143551678 %\n",
      "26.954748481149316 %\n",
      "27.095872818746958 %\n",
      "27.2369971563446 %\n",
      "27.37812149394224 %\n",
      "27.51924583153988 %\n",
      "27.660370169137515 %\n",
      "27.801494506735157 %\n",
      "27.9426188443328 %\n",
      "28.083743181930437 %\n",
      "28.22486751952808 %\n",
      "28.36599185712572 %\n",
      "28.50711619472336 %\n",
      "28.648240532321 %\n",
      "28.789364869918643 %\n",
      "28.93048920751628 %\n",
      "29.071613545113923 %\n",
      "29.212737882711565 %\n",
      "29.353862220309203 %\n",
      "29.494986557906845 %\n",
      "29.636110895504487 %\n",
      "29.77723523310212 %\n",
      "29.918359570699764 %\n",
      "30.05948390829741 %\n",
      "30.200608245895044 %\n",
      "30.341732583492686 %\n",
      "30.482856921090328 %\n",
      "30.623981258687966 %\n",
      "30.765105596285608 %\n",
      "30.90622993388325 %\n",
      "31.047354271480888 %\n",
      "31.18847860907853 %\n",
      "31.32960294667617 %\n",
      "31.47072728427381 %\n",
      "31.611851621871452 %\n",
      "31.752975959469094 %\n",
      "31.89410029706673 %\n",
      "32.035224634664374 %\n",
      "32.17634897226201 %\n",
      "32.31747330985965 %\n",
      "32.458597647457296 %\n",
      "32.59972198505493 %\n",
      "32.74084632265257 %\n",
      "32.88197066025022 %\n",
      "33.02309499784785 %\n",
      "33.164219335445495 %\n",
      "33.30534367304313 %\n",
      "33.44646801064077 %\n",
      "33.58759234823842 %\n",
      "33.728716685836055 %\n",
      "33.86984102343369 %\n",
      "34.01096536103134 %\n",
      "34.15208969862898 %\n",
      "34.293214036226615 %\n",
      "34.43433837382426 %\n",
      "34.5754627114219 %\n",
      "34.71658704901954 %\n",
      "34.85771138661718 %\n",
      "34.99883572421482 %\n",
      "35.13996006181246 %\n",
      "35.2810843994101 %\n",
      "35.42220873700774 %\n",
      "35.56333307460538 %\n",
      "35.70445741220302 %\n",
      "35.845581749800665 %\n",
      "35.986706087398304 %\n",
      "36.12783042499594 %\n",
      "36.26895476259358 %\n",
      "36.410079100191226 %\n",
      "36.551203437788864 %\n",
      "36.6923277753865 %\n",
      "36.83345211298415 %\n",
      "36.974576450581786 %\n",
      "37.115700788179424 %\n",
      "37.25682512577706 %\n",
      "37.39794946337471 %\n",
      "37.539073800972346 %\n",
      "37.680198138569985 %\n",
      "37.82132247616763 %\n",
      "37.96244681376527 %\n",
      "38.10357115136291 %\n",
      "38.24469548896055 %\n",
      "38.38581982655819 %\n",
      "38.52694416415583 %\n",
      "38.668068501753474 %\n",
      "38.809192839351105 %\n",
      "38.95031717694875 %\n",
      "39.091441514546396 %\n",
      "39.23256585214403 %\n",
      "39.37369018974167 %\n",
      "39.51481452733931 %\n",
      "39.65593886493695 %\n",
      "39.797063202534595 %\n",
      "39.93818754013223 %\n",
      "40.07931187772987 %\n",
      "40.22043621532752 %\n",
      "40.361560552925155 %\n",
      "40.502684890522794 %\n",
      "40.64380922812044 %\n",
      "40.78493356571807 %\n",
      "40.926057903315716 %\n",
      "41.06718224091336 %\n",
      "41.20830657851099 %\n",
      "41.34943091610864 %\n",
      "41.490555253706276 %\n",
      "41.631679591303914 %\n",
      "41.77280392890156 %\n",
      "41.9139282664992 %\n",
      "42.055052604096836 %\n",
      "42.19617694169448 %\n",
      "42.33730127929212 %\n",
      "42.47842561688976 %\n",
      "42.619549954487404 %\n",
      "42.76067429208504 %\n",
      "42.90179862968268 %\n",
      "43.042922967280326 %\n",
      "43.184047304877964 %\n",
      "43.3251716424756 %\n",
      "43.46629598007324 %\n",
      "43.607420317670886 %\n",
      "43.748544655268525 %\n",
      "43.88966899286616 %\n",
      "44.03079333046381 %\n",
      "44.17191766806145 %\n",
      "44.313042005659085 %\n",
      "44.45416634325673 %\n",
      "44.59529068085437 %\n",
      "44.73641501845201 %\n",
      "44.877539356049645 %\n",
      "45.018663693647284 %\n",
      "45.15978803124493 %\n",
      "45.30091236884257 %\n",
      "45.442036706440206 %\n",
      "45.58316104403785 %\n",
      "45.72428538163549 %\n",
      "45.86540971923313 %\n",
      "46.00653405683077 %\n",
      "46.14765839442841 %\n",
      "46.28878273202605 %\n",
      "46.429907069623695 %\n",
      "46.571031407221334 %\n",
      "46.71215574481897 %\n",
      "46.85328008241662 %\n",
      "46.99440442001425 %\n",
      "47.135528757611894 %\n",
      "47.27665309520954 %\n",
      "47.41777743280717 %\n",
      "47.558901770404816 %\n",
      "47.70002610800246 %\n",
      "47.84115044560009 %\n",
      "47.98227478319774 %\n",
      "48.123399120795376 %\n",
      "48.264523458393015 %\n",
      "48.40564779599066 %\n",
      "48.5467721335883 %\n",
      "48.68789647118594 %\n",
      "48.82902080878358 %\n",
      "48.97014514638121 %\n",
      "49.11126948397886 %\n",
      "49.252393821576504 %\n",
      "49.393518159174135 %\n",
      "49.53464249677178 %\n",
      "49.67576683436942 %\n",
      "49.81689117196706 %\n",
      "49.9580155095647 %\n",
      "50.09913984716234 %\n",
      "50.24026418475999 %\n",
      "50.381388522357625 %\n",
      "50.522512859955256 %\n",
      "50.6636371975529 %\n",
      "50.80476153515055 %\n",
      "50.945885872748185 %\n",
      "51.08701021034583 %\n",
      "51.22813454794346 %\n",
      "51.3692588855411 %\n",
      "51.510383223138746 %\n",
      "51.651507560736384 %\n",
      "51.79263189833403 %\n",
      "51.933756235931675 %\n",
      "52.074880573529306 %\n",
      "52.216004911126944 %\n",
      "52.35712924872459 %\n",
      "52.49825358632223 %\n",
      "52.639377923919874 %\n",
      "52.78050226151751 %\n",
      "52.92162659911514 %\n",
      "53.06275093671279 %\n",
      "53.203875274310434 %\n",
      "53.34499961190807 %\n",
      "53.48612394950572 %\n",
      "53.627248287103356 %\n",
      "53.76837262470099 %\n",
      "53.90949696229863 %\n",
      "54.05062129989627 %\n",
      "54.191745637493916 %\n",
      "54.332869975091555 %\n",
      "54.4739943126892 %\n",
      "54.61511865028683 %\n",
      "54.75624298788448 %\n",
      "54.897367325482115 %\n",
      "55.03849166307976 %\n",
      "55.1796160006774 %\n",
      "55.32074033827503 %\n",
      "55.461864675872675 %\n",
      "55.602989013470314 %\n",
      "55.74411335106796 %\n",
      "55.8852376886656 %\n",
      "56.02636202626324 %\n",
      "56.167486363860874 %\n",
      "56.30861070145852 %\n",
      "56.44973503905616 %\n",
      "56.5908593766538 %\n",
      "56.73198371425144 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.87310805184909 %\n",
      "57.01423238944672 %\n",
      "57.15535672704436 %\n",
      "57.296481064642 %\n",
      "57.43760540223965 %\n",
      "57.578729739837286 %\n",
      "57.71985407743493 %\n",
      "57.86097841503256 %\n",
      "58.0021027526302 %\n",
      "58.143227090227846 %\n",
      "58.284351427825484 %\n",
      "58.42547576542313 %\n",
      "58.566600103020775 %\n",
      "58.70772444061841 %\n",
      "58.848848778216045 %\n",
      "58.98997311581369 %\n",
      "59.13109745341133 %\n",
      "59.272221791008974 %\n",
      "59.413346128606605 %\n",
      "59.55447046620424 %\n",
      "59.69559480380189 %\n",
      "59.83671914139953 %\n",
      "59.97784347899717 %\n",
      "60.11896781659482 %\n",
      "60.26009215419245 %\n",
      "60.40121649179009 %\n",
      "60.54234082938773 %\n",
      "60.68346516698537 %\n",
      "60.82458950458302 %\n",
      "60.965713842180655 %\n",
      "61.106838179778286 %\n",
      "61.24796251737593 %\n",
      "61.38908685497357 %\n",
      "61.530211192571215 %\n",
      "61.67133553016886 %\n",
      "61.8124598677665 %\n",
      "61.95358420536413 %\n",
      "62.094708542961776 %\n",
      "62.235832880559414 %\n",
      "62.37695721815706 %\n",
      "62.5180815557547 %\n",
      "62.65920589335234 %\n",
      "62.800330230949974 %\n",
      "62.94145456854762 %\n",
      "63.08257890614526 %\n",
      "63.223703243742904 %\n",
      "63.36482758134054 %\n",
      "63.50595191893819 %\n",
      "63.64707625653582 %\n",
      "63.78820059413346 %\n",
      "63.9293249317311 %\n",
      "64.07044926932875 %\n",
      "64.2115736069264 %\n",
      "64.35269794452402 %\n",
      "64.49382228212166 %\n",
      "64.6349466197193 %\n",
      "64.77607095731695 %\n",
      "64.91719529491459 %\n",
      "65.05831963251222 %\n",
      "65.19944397010985 %\n",
      "65.3405683077075 %\n",
      "65.48169264530515 %\n",
      "65.62281698290279 %\n",
      "65.76394132050044 %\n",
      "65.90506565809807 %\n",
      "66.0461899956957 %\n",
      "66.18731433329334 %\n",
      "66.32843867089099 %\n",
      "66.46956300848863 %\n",
      "66.61068734608627 %\n",
      "66.75181168368391 %\n",
      "66.89293602128154 %\n",
      "67.03406035887919 %\n",
      "67.17518469647683 %\n",
      "67.31630903407448 %\n",
      "67.45743337167211 %\n",
      "67.59855770926976 %\n",
      "67.73968204686739 %\n",
      "67.88080638446503 %\n",
      "68.02193072206268 %\n",
      "68.16305505966031 %\n",
      "68.30417939725795 %\n",
      "68.44530373485559 %\n",
      "68.58642807245323 %\n",
      "68.72755241005088 %\n",
      "68.86867674764852 %\n",
      "69.00980108524615 %\n",
      "69.1509254228438 %\n",
      "69.29204976044143 %\n",
      "69.43317409803907 %\n",
      "69.57429843563672 %\n",
      "69.71542277323437 %\n",
      "69.856547110832 %\n",
      "69.99767144842964 %\n",
      "70.13879578602727 %\n",
      "70.27992012362492 %\n",
      "70.42104446122256 %\n",
      "70.5621687988202 %\n",
      "70.70329313641784 %\n",
      "70.84441747401549 %\n",
      "70.98554181161312 %\n",
      "71.12666614921076 %\n",
      "71.26779048680841 %\n",
      "71.40891482440604 %\n",
      "71.55003916200369 %\n",
      "71.69116349960133 %\n",
      "71.83228783719896 %\n",
      "71.97341217479661 %\n",
      "72.11453651239424 %\n",
      "72.25566084999188 %\n",
      "72.39678518758953 %\n",
      "72.53790952518716 %\n",
      "72.6790338627848 %\n",
      "72.82015820038245 %\n",
      "72.96128253798008 %\n",
      "73.10240687557773 %\n",
      "73.24353121317537 %\n",
      "73.384655550773 %\n",
      "73.52577988837065 %\n",
      "73.6669042259683 %\n",
      "73.80802856356593 %\n",
      "73.94915290116357 %\n",
      "74.09027723876122 %\n",
      "74.23140157635885 %\n",
      "74.3725259139565 %\n",
      "74.51365025155413 %\n",
      "74.65477458915177 %\n",
      "74.79589892674942 %\n",
      "74.93702326434706 %\n",
      "75.07814760194469 %\n",
      "75.21927193954234 %\n",
      "75.36039627713997 %\n",
      "75.50152061473761 %\n",
      "75.64264495233526 %\n",
      "75.7837692899329 %\n",
      "75.92489362753054 %\n",
      "76.06601796512817 %\n",
      "76.20714230272581 %\n",
      "76.34826664032346 %\n",
      "76.4893909779211 %\n",
      "76.63051531551874 %\n",
      "76.77163965311638 %\n",
      "76.91276399071401 %\n",
      "77.05388832831166 %\n",
      "77.1950126659093 %\n",
      "77.33613700350695 %\n",
      "77.47726134110458 %\n",
      "77.61838567870221 %\n",
      "77.75951001629986 %\n",
      "77.9006343538975 %\n",
      "78.04175869149515 %\n",
      "78.18288302909279 %\n",
      "78.32400736669042 %\n",
      "78.46513170428805 %\n",
      "78.6062560418857 %\n",
      "78.74738037948335 %\n",
      "78.88850471708099 %\n",
      "79.02962905467862 %\n",
      "79.17075339227625 %\n",
      "79.3118777298739 %\n",
      "79.45300206747154 %\n",
      "79.59412640506919 %\n",
      "79.73525074266684 %\n",
      "79.87637508026447 %\n",
      "80.0174994178621 %\n",
      "80.15862375545974 %\n",
      "80.29974809305739 %\n",
      "80.44087243065503 %\n",
      "80.58199676825268 %\n",
      "80.72312110585031 %\n",
      "80.86424544344794 %\n",
      "81.00536978104559 %\n",
      "81.14649411864323 %\n",
      "81.28761845624088 %\n",
      "81.42874279383851 %\n",
      "81.56986713143614 %\n",
      "81.71099146903379 %\n",
      "81.85211580663143 %\n",
      "81.99324014422908 %\n",
      "82.13436448182672 %\n",
      "82.27548881942435 %\n",
      "82.41661315702198 %\n",
      "82.55773749461963 %\n",
      "82.69886183221728 %\n",
      "82.83998616981492 %\n",
      "82.98111050741255 %\n",
      "83.1222348450102 %\n",
      "83.26335918260783 %\n",
      "83.40448352020547 %\n",
      "83.54560785780312 %\n",
      "83.68673219540077 %\n",
      "83.8278565329984 %\n",
      "83.96898087059604 %\n",
      "84.11010520819367 %\n",
      "84.25122954579132 %\n",
      "84.39235388338896 %\n",
      "84.53347822098661 %\n",
      "84.67460255858424 %\n",
      "84.81572689618187 %\n",
      "84.95685123377952 %\n",
      "85.09797557137716 %\n",
      "85.23909990897481 %\n",
      "85.38022424657244 %\n",
      "85.52134858417008 %\n",
      "85.66247292176772 %\n",
      "85.80359725936536 %\n",
      "85.944721596963 %\n",
      "86.08584593456065 %\n",
      "86.22697027215828 %\n",
      "86.36809460975593 %\n",
      "86.50921894735356 %\n",
      "86.6503432849512 %\n",
      "86.79146762254885 %\n",
      "86.93259196014648 %\n",
      "87.07371629774413 %\n",
      "87.21484063534177 %\n",
      "87.3559649729394 %\n",
      "87.49708931053705 %\n",
      "87.6382136481347 %\n",
      "87.77933798573233 %\n",
      "87.92046232332997 %\n",
      "88.06158666092762 %\n",
      "88.20271099852525 %\n",
      "88.3438353361229 %\n",
      "88.48495967372052 %\n",
      "88.62608401131817 %\n",
      "88.76720834891582 %\n",
      "88.90833268651346 %\n",
      "89.04945702411109 %\n",
      "89.19058136170874 %\n",
      "89.33170569930637 %\n",
      "89.47283003690401 %\n",
      "89.61395437450166 %\n",
      "89.75507871209929 %\n",
      "89.89620304969694 %\n",
      "90.03732738729457 %\n",
      "90.17845172489221 %\n",
      "90.31957606248986 %\n",
      "90.4607004000875 %\n",
      "90.60182473768513 %\n",
      "90.74294907528278 %\n",
      "90.88407341288041 %\n",
      "91.02519775047806 %\n",
      "91.1663220880757 %\n",
      "91.30744642567335 %\n",
      "91.44857076327098 %\n",
      "91.58969510086862 %\n",
      "91.73081943846626 %\n",
      "91.8719437760639 %\n",
      "92.01306811366155 %\n",
      "92.15419245125919 %\n",
      "92.29531678885682 %\n",
      "92.43644112645445 %\n",
      "92.5775654640521 %\n",
      "92.71868980164975 %\n",
      "92.85981413924739 %\n",
      "93.00093847684504 %\n",
      "93.14206281444267 %\n",
      "93.2831871520403 %\n",
      "93.42431148963794 %\n",
      "93.56543582723559 %\n",
      "93.70656016483323 %\n",
      "93.84768450243087 %\n",
      "93.9888088400285 %\n",
      "94.12993317762614 %\n",
      "94.27105751522379 %\n",
      "94.41218185282143 %\n",
      "94.55330619041908 %\n",
      "94.69443052801671 %\n",
      "94.83555486561434 %\n",
      "94.97667920321199 %\n",
      "95.11780354080963 %\n",
      "95.25892787840728 %\n",
      "95.40005221600492 %\n",
      "95.54117655360255 %\n",
      "95.68230089120019 %\n",
      "95.82342522879783 %\n",
      "95.96454956639548 %\n",
      "96.10567390399312 %\n",
      "96.24679824159075 %\n",
      "96.38792257918838 %\n",
      "96.52904691678603 %\n",
      "96.67017125438367 %\n",
      "96.81129559198132 %\n",
      "96.95241992957897 %\n",
      "97.0935442671766 %\n",
      "97.23466860477423 %\n",
      "97.37579294237187 %\n",
      "97.51691727996952 %\n",
      "97.65804161756716 %\n",
      "97.7991659551648 %\n",
      "97.94029029276243 %\n",
      "98.08141463036007 %\n",
      "98.22253896795772 %\n",
      "98.36366330555536 %\n",
      "98.50478764315301 %\n",
      "98.64591198075064 %\n",
      "98.78703631834827 %\n",
      "98.92816065594592 %\n",
      "99.06928499354356 %\n",
      "99.21040933114121 %\n",
      "99.35153366873884 %\n",
      "99.49265800633648 %\n",
      "99.63378234393412 %\n",
      "99.77490668153176 %\n",
      "99.9160310191294 %\n",
      "6433.3832466602325\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import threading\n",
    "\n",
    "class Edgy_Fred(threading.Thread):\n",
    "    def __init__(self, indices):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.indices = indices\n",
    "        self.edge_index = None\n",
    "    \n",
    "    def run(self):\n",
    "        indices = cp.expand_dims(self.indices.values, axis = 1)\n",
    "        target = cp.repeat(indices, indices.shape[0], axis = 1)\n",
    "        source = target.transpose().flatten()\n",
    "        target = target.flatten()\n",
    "        self.edge_index = np.asarray([np.asarray(source.get()), np.asarray(target.get())])\n",
    "        \n",
    "        \n",
    "class Encoding_Fred(threading.Thread):\n",
    "    def __init__(self, group):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.group = group\n",
    "        self.encoding = None\n",
    "    \n",
    "    def run(self):\n",
    "        self.encoding = getPositionEncoding(self.group.shape[0])\n",
    "        \n",
    "class Masked_Fred(threading.Thread):\n",
    "    def __init__(self, group):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.group = group\n",
    "        self.train_mask = None\n",
    "        self.val_mask = None\n",
    "        self.test_mask = None\n",
    "    \n",
    "    def run(self):\n",
    "        train_mask_ser = (self.group[\"Set\"] != \"Validation\").to_arrow().to_pylist()\n",
    "        val_ratio_mask = (self.group[\"random\"] >= 0.8)\n",
    "        train_ratio_mask = (self.group[\"random\"] < 0.8)\n",
    "        self.val_mask = np.logical_and(train_mask_ser, val_ratio_mask.to_arrow().to_pylist())\n",
    "        self.train_mask = np.logical_and(train_mask_ser, train_ratio_mask.to_arrow().to_pylist())    \n",
    "        self.test_mask = (group[\"Set\"] == \"Validation\").values.get()\n",
    "        \n",
    "class MainFred(threading.Thread):\n",
    "    def __init__(self, group, graph_list):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.group = group\n",
    "        self.graph_list = graph_list\n",
    "    \n",
    "    def run(self):\n",
    "        group = self.group.reset_index().sort_values(\"Time\").reset_index()\n",
    "        indices = group.index\n",
    "\n",
    "        ## Edge construction\n",
    "        edgy_fred = Edgy_Fred(indices)\n",
    "        edgy_fred.start()\n",
    "\n",
    "        ## Features\n",
    "        X_features = torch.tensor(group[FEATURES].values.get()).type(torch.float32)\n",
    "\n",
    "\n",
    "        ## Positions\n",
    "        encoding_fred = Encoding_Fred(group)\n",
    "        encoding_fred.start()\n",
    "\n",
    "        ## Masks\n",
    "        masked_fred = Masked_Fred(group)\n",
    "        masked_fred.start()\n",
    "        \n",
    "        edgy_fred.join()\n",
    "        encoding_fred.join()\n",
    "        masked_fred.join()\n",
    "        ## Graph\n",
    "        graph = Data(x= X_features + encoding_fred.encoding,\n",
    "                     y= torch.tensor(group[\"Label\"].values.get()).type(torch.int8),\n",
    "                     edge_index= torch.tensor(edgy_fred.edge_index),\n",
    "                     train_mask=torch.from_numpy(masked_fred.train_mask).type(torch.bool),\n",
    "                     test_mask=torch.from_numpy(masked_fred.test_mask).type(torch.bool),\n",
    "                     val_mask=torch.from_numpy(masked_fred.val_mask).type(torch.bool))\n",
    "        self.graph_list.append(graph)\n",
    "\n",
    "graph_list = []\n",
    "start = time.time()\n",
    "i = 0\n",
    "for Id, group in data.groupby(\"Id\"):\n",
    "    group = group.reset_index().sort_values(\"Time\").reset_index()\n",
    "    indices = group.index\n",
    "\n",
    "    ## Edge construction\n",
    "    edgy_fred = Edgy_Fred(indices)\n",
    "    edgy_fred.start()\n",
    "\n",
    "    ## Features\n",
    "    X_features = torch.tensor(group[FEATURES].values.get()).type(torch.float32)\n",
    "\n",
    "\n",
    "    ## Positions\n",
    "    encoding_fred = Encoding_Fred(group)\n",
    "    encoding_fred.start()\n",
    "\n",
    "    ## Masks\n",
    "    masked_fred = Masked_Fred(group)\n",
    "    masked_fred.start()\n",
    "\n",
    "    edgy_fred.join()\n",
    "    encoding_fred.join()\n",
    "    masked_fred.join()\n",
    "    ## Graph\n",
    "    graph = Data(x= X_features + encoding_fred.encoding,\n",
    "                 y= torch.tensor(group[\"Label\"].values.get()).type(torch.int8),\n",
    "                 edge_index= torch.tensor(edgy_fred.edge_index),\n",
    "                 train_mask=torch.from_numpy(masked_fred.train_mask).type(torch.bool),\n",
    "                 test_mask=torch.from_numpy(masked_fred.test_mask).type(torch.bool),\n",
    "                 val_mask=torch.from_numpy(masked_fred.val_mask).type(torch.bool))\n",
    "    graph_list.append(graph)\n",
    "    i+=1\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{str(i / unique_ids.shape[0] * 100)} %\")\n",
    "\n",
    "print(time.time() - start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb2089f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shifted to the device cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "WEIGHT = torch.tensor([664])\n",
    "WEIGHT = WEIGHT.to(device)\n",
    "\n",
    "print(\"Data shifted to the device \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54eb5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, GCNConv,GATv2Conv, GINConv, global_add_pool\n",
    "from torch.nn import Linear\n",
    "import torch\n",
    "from dataAnalysis.Constants import FEATURES\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "from torch.nn import BatchNorm1d as BatchNorm\n",
    "\n",
    "class GraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim = 128, out_channels = 1):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        input_dim = len(FEATURES)      \n",
    "        \n",
    "        conv_1= GATConv(input_dim, hidden_dim,heads=1, add_self_loops = False)\n",
    "        conv_end = GATConv((-1,-1), out_channels,add_self_loops = False)\n",
    "        \n",
    "        self.conv_1 = conv_1\n",
    "        self.conv_end = conv_end\n",
    "        \n",
    "\n",
    "    def forward(self, graph):\n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = x.type(torch.float)\n",
    "        x = self.conv_1(x, edge_index)\n",
    "        x = F.normalize(x, p=2., dim=-1)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv_end(x, edge_index)\n",
    "        return x\n",
    "            \n",
    "    def predict_proba(self, graph, mask):\n",
    "        with torch.inference_mode():\n",
    "            self.eval()\n",
    "            logits = self.forward(graph)\n",
    "            scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "            scores = torch.unsqueeze(scores, 0)\n",
    "            proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "            return torch.transpose(proba_predict, 0, 1)\n",
    "            \n",
    "    def predict(self, graph, mask):\n",
    "        return torch.round(self.predict_proba(graph, mask)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abbf29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in graph_list:\n",
    "    graph.cpu()#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8286351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader(graph_list, batch_size=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e34b2cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[192030, 7], edge_index=[2, 1239426], y=[192030], train_mask=[192030], test_mask=[192030], val_mask=[192030], batch=[192030], ptr=[100001])\n",
      "DataBatch(x=[192705, 7], edge_index=[2, 1433261], y=[192705], train_mask=[192705], test_mask=[192705], val_mask=[192705], batch=[192705], ptr=[100001])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, graph \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(graph)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/dataloader.py:20\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     18\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/batch.py:76\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_list: List[BaseData],\n\u001b[1;32m     66\u001b[0m                    follow_batch: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m                    exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)\n\u001b[1;32m     86\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/collate.py:84\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m value, slices, incs \u001b[38;5;241m=\u001b[39m \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[1;32m     88\u001b[0m     device \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/collate.py:137\u001b[0m, in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    133\u001b[0m     incs \u001b[38;5;241m=\u001b[39m get_incs(key, values, data_list, stores)\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(incs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m         values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    136\u001b[0m             value \u001b[38;5;241m+\u001b[39m inc\u001b[38;5;241m.\u001b[39mto(value\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 137\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value, inc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m         ]\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     incs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:940\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[1;32m    932\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[0;32m--> 940\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch, graph in enumerate(data_loader):\n",
    "    print(graph)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "526044da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "# import wandb\n",
    "\n",
    "LEARNING_RATE = 3e-4\n",
    "MAX_EPOCHS = 100 #40000\n",
    "HIDDEN_DIM = 128 #128\n",
    "# wandb.init(\n",
    "#     project=\"gat-time-analysis\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": LEARNING_RATE,\n",
    "#     \"architecture\": \"2 GATConv,128 neurons,1 head,layer normalization,ReLU,early stopping (10)\",\n",
    "#     \"dataset\": \"SBC\",\n",
    "#     \"epochs\": MAX_EPOCHS,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, data_loader):\n",
    "        self.LEARNING_RATE = LEARNING_RATE\n",
    "        self.MAX_EPOCHS = MAX_EPOCHS\n",
    "\n",
    "        self.model = GraphNeuralNetwork(hidden_dim = 7, out_channels=1) \n",
    "        self.model = self.model.to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.LEARNING_RATE,betas=(0.9, 0.999), eps=1e-08)\n",
    "        self.data_loader = data_loader\n",
    "        \n",
    "        self.last_loss = 0\n",
    "        self.increased_loss = 0\n",
    "        self.BREAKING_THRESHOLD = 10    \n",
    "        self.val_loss = []\n",
    "        self.train_loss = []\n",
    "    \n",
    "    def validate(self):\n",
    "        with torch.inference_mode():\n",
    "            for data in self.data_loader:\n",
    "                data = data.to(device)\n",
    "                self.model.eval()\n",
    "                out = self.model(data)\n",
    "                loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[data.val_mask]), torch.squeeze(data.y[data.val_mask].type(torch.float32)),\n",
    "                                                      pos_weight=torch.squeeze(WEIGHT))\n",
    "                self.val_loss.append(loss.item())\n",
    "                if loss.item() > self.last_loss:\n",
    "                    self.increased_loss += 1\n",
    "                else:\n",
    "                    self.increased_loss = 0\n",
    "                self.last_loss = loss.item()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.MAX_EPOCHS):\n",
    "            for data in self.data_loader:\n",
    "                data = data.to(device)\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(data)\n",
    "                loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[data.train_mask]), torch.squeeze(data.y[data.train_mask].type(torch.float32)),\n",
    "                                                          pos_weight=torch.squeeze(WEIGHT))\n",
    "                self.train_loss.append(loss.item())\n",
    "#                 wandb.log({\"loss\": loss.item()})\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.validate() \n",
    "                if self.increased_loss >= self.BREAKING_THRESHOLD:\n",
    "    #                 print(f\"Breaked at {str(epoch)}\")\n",
    "                    break\n",
    "            \n",
    "    def get_model(self):\n",
    "        return self.model    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.epochs, self.train_loss, 'g', label='Training loss')\n",
    "        plt.plot(self.epochs, self.val_loss, 'y', label='Validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = ModelWrapper(data_loader)\n",
    "model_wrapper.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_wrapper.get_model()\n",
    "graph = graph.cpu()\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits = torch.tensor([])\n",
    "true_val = torch.tensor([])\n",
    "for data in data_loader:\n",
    "    if data.test_mask.sum() == 0:\n",
    "        continue\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        logits = model(data)\n",
    "        test_logits = torch.sigmoid(logits[data.test_mask])\n",
    "        y_true = data.y[data.test_mask]\n",
    "        true_val = torch.concat((true_val, y_true))\n",
    "        pred_logits = torch.concat((pred_logits, test_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits_sq = torch.squeeze(pred_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fdbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.unsqueeze(pred_logits_sq, 0)\n",
    "proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "y_proba = torch.transpose(proba_predict, 0, 1)\n",
    "y_pred = torch.round(y_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "y_dict = Evaluation.create_y_dict(y_pred, y_proba , true_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "Evaluation.plot_confusion_matrix_from_pred(y_pred,true_val)\n",
    "Evaluation.get_df_metrics_from_pred(y_dict, y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e35162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "sound_file = './finish_sound.mp3'\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d262420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n",
      "Sleeping\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSleeping\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(10000):\n",
    "    time.sleep(60)\n",
    "    print(\"Sleeping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3a608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
