{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18b73dd",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431abf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.insert(0, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c929aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataAnalysis.data.Filter import Filter\n",
    "import pandas as pd\n",
    "from dataAnalysis.Constants import *\n",
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "\n",
    "FEATURES.extend(['Noise0', 'Noise1', 'Noise2', 'Noise3', 'Noise4', 'Noise5', 'Noise6', 'Noise7', 'Noise8', 'Noise9', 'Noise10', 'Noise11', 'Noise12', 'Noise13', 'Noise14', 'Noise15', 'Noise16', 'Noise17', 'Noise18', 'Noise19', 'Noise20', 'Noise21', 'Noise22', 'Noise23', 'Noise24', 'Noise25', 'Noise26', 'Noise27', 'Noise28', 'Noise29', 'Noise30', 'Noise31', 'Noise32', 'Noise33', 'Noise34', 'Noise35', 'Noise36', 'Noise37', 'Noise38', 'Noise39', 'Noise40', 'Noise41', 'Noise42', 'Noise43', 'Noise44', 'Noise45', 'Noise46', 'Noise47', 'Noise48', 'Noise49', 'Noise50', 'Noise51', 'Noise52', 'Noise53', 'Noise54', 'Noise55', 'Noise56', 'Noise57', 'Noise58', 'Noise59', 'Noise60', 'Noise61', 'Noise62', 'Noise63', 'Noise64', 'Noise65', 'Noise66', 'Noise67', 'Noise68', 'Noise69', 'Noise70', 'Noise71', 'Noise72', 'Noise73', 'Noise74', 'Noise75', 'Noise76', 'Noise77', 'Noise78', 'Noise79', 'Noise80', 'Noise81', 'Noise82', 'Noise83', 'Noise84', 'Noise85', 'Noise86', 'Noise87', 'Noise88', 'Noise89', 'Noise90', 'Noise91', 'Noise92', 'Noise93', 'Noise94', 'Noise95', 'Noise96', 'Noise97', 'Noise98', 'Noise99'])\n",
    "data = pd.read_csv(r\"../../extdata/noisy_sbc_100.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94724e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "y_train = torch.tensor(data_analysis.get_y_train(), dtype=torch.long)\n",
    "X_train = torch.tensor(data_analysis.get_X_train(), dtype=torch.float)\n",
    "\n",
    "y_test = torch.tensor(data_analysis.get_y_test(), dtype=torch.long)\n",
    "X_test = torch.tensor(data_analysis.get_X_test(), dtype=torch.float)\n",
    "\n",
    "y_gw_test = torch.tensor(data_analysis.get_y_gw(), dtype=torch.long)\n",
    "X_gw_test = torch.tensor(data_analysis.get_X_gw(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = torch.concat((y_train, y_test, y_gw_test))\n",
    "X_all = torch.concat((X_train, X_test, X_gw_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f90b6",
   "metadata": {},
   "source": [
    "## Train/Validation/Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29cee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_indices_like(tensor):\n",
    "    return torch.ones((tensor.shape[0])).type(torch.bool)\n",
    "\n",
    "def false_indices_like(tensor):\n",
    "    return torch.zeros((tensor.shape[0])).type(torch.bool)\n",
    "\n",
    "def split(train_features):\n",
    "    tensor = true_indices_like(train_features)\n",
    "    max_index = round(tensor.shape[0] * 0.8)\n",
    "    train = torch.zeros(tensor.shape[0])\n",
    "    train[:max_index] = 1\n",
    "    \n",
    "    val = torch.zeros(tensor.shape[0])\n",
    "    val[max_index:] = 1\n",
    "    return{\n",
    "        \"train\": train.type(torch.bool),\n",
    "        \"val\":val.type(torch.bool)\n",
    "    }\n",
    "train_data = split(X_train)\n",
    "\n",
    "train_mask = torch.concat((train_data[\"train\"], false_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "val_mask = torch.concat((train_data[\"val\"], false_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "test_l_mask = torch.concat((false_indices_like(X_train), true_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "test_gw_mask = torch.concat((false_indices_like(X_train), false_indices_like(X_test), true_indices_like(X_gw_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360310be",
   "metadata": {},
   "source": [
    "## Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c59b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dataAnalysis.Constants import *\n",
    "\n",
    "def to_tensor(df):\n",
    "    return torch.Tensor(list(df.values))\n",
    "\n",
    "def get_quantil_tensor():\n",
    "    number_of_quantiles = 10\n",
    "    q = torch.arange(0, 1, 1/number_of_quantiles)\n",
    "    q = torch.Tensor([0.025,0.05, 0.1, 0.2, 0.35, 0.5, 0.65, 0.8, 0.9, 0.95, 0.975, 1])\n",
    "    return q\n",
    "\n",
    "def get_quantiles(tensor):\n",
    "    q = get_quantil_tensor() \n",
    "    return torch.quantile(tensor, q)\n",
    "\n",
    "def normalize(tensor):\n",
    "    mean = torch.mean(tensor, dim = 0)\n",
    "    std = torch.std(tensor, dim = 0)\n",
    "    mean_diff = tensor - mean\n",
    "    return mean_diff / std\n",
    "\n",
    "def get_quantile_indices(tensor, quantiles):\n",
    "    quantile_indices = []\n",
    "    all_indices = torch.Tensor([])\n",
    "    prev_quantile = -1e-4\n",
    "    indices_control = torch.arange(0, tensor.shape[0])\n",
    "    for i in range(quantiles.nelement()):\n",
    "        indices_u = (tensor > prev_quantile).nonzero(as_tuple=True)[0] # (tensor > prev_quantile and tensor <= quantiles[i]).nonzero(as_tuple=True)[0]\n",
    "        indices_o = (tensor <= quantiles[i]).nonzero(as_tuple=True)[0]\n",
    "        indices = torch.from_numpy(np.intersect1d(indices_u, indices_o))\n",
    "        quantile_indices.append(indices)\n",
    "        prev_quantile = quantiles[i]\n",
    "    return quantile_indices\n",
    "\n",
    "\n",
    "def create_node_features(node_type, quantiles):\n",
    "    nodes_features = []\n",
    "    prev_quantile = torch.Tensor([0])\n",
    "    for i in range(quantiles.nelement()):\n",
    "        node_features = [prev_quantile.item(), quantiles[i].item(), get_quantil_tensor()[i].item()]\n",
    "        prev_quantile = quantiles[i]\n",
    "        nodes_features.append(node_features)\n",
    "    return torch.tensor(nodes_features)\n",
    "\n",
    "def create_edge_features_to_patient(node_type, quantile_indices):\n",
    "    source_edge_list = None\n",
    "    target_edge_list = None\n",
    "    for i in range(len(quantile_indices)):\n",
    "        target_edges = torch.ones((quantile_indices[i].nelement())) * i\n",
    "        source_edges = quantile_indices[i]\n",
    "        source_edge_list = source_edges if source_edge_list is None else torch.concat((source_edge_list, source_edges))\n",
    "        target_edge_list = target_edges if target_edge_list is None else torch.concat((target_edge_list, target_edges))\n",
    "    return torch.stack([source_edge_list, target_edge_list]).type(torch.long)\n",
    "\n",
    "def add_features_and_edges(graph):\n",
    "    for i, feature_name in enumerate(FEATURES):\n",
    "        if feature_name not in [HGB_COLUMN_NAME, WBC_COLUMN_NAME, RBC_COLUMN_NAME, MCV_COLUMN_NAME, PLT_COLUMN_NAME]:\n",
    "            continue\n",
    "        feature_vector = graph[PATIENT_NAME].x[:, i]\n",
    "        node_quantiles = get_quantiles(feature_vector)\n",
    "        quantile_indices = get_quantile_indices(feature_vector, node_quantiles)\n",
    "        graph[feature_name].x = create_node_features(feature_name, node_quantiles)\n",
    "        graph[PATIENT_NAME, EDGE_TYPE, feature_name].edge_index = create_edge_features_to_patient(feature_name, quantile_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def normalize(tensor):\n",
    "    mean = torch.mean(tensor, dim = 0)\n",
    "    std = torch.std(tensor, dim = 0)\n",
    "    mean_diff = tensor - mean\n",
    "    return mean_diff / std\n",
    "\n",
    "graph = HeteroData()\n",
    "graph[PATIENT_NAME].x = X_all\n",
    "add_features_and_edges(graph)\n",
    "graph[PATIENT_NAME].y = y_all\n",
    "graph[PATIENT_NAME].train_mask = train_mask\n",
    "graph[PATIENT_NAME].val_mask = val_mask\n",
    "graph[PATIENT_NAME].test_l_mask = test_l_mask\n",
    "graph[PATIENT_NAME].test_gw_mask = test_gw_mask\n",
    "graph = T.ToUndirected()(graph)\n",
    "graph[PATIENT_NAME].x = normalize(graph[PATIENT_NAME].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e41cf",
   "metadata": {},
   "source": [
    "### Model defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e45295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, to_hetero,Linear, HeteroConv, SAGEConv\n",
    "from torch_geometric.nn.conv import HANConv\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import AUROC\n",
    "\n",
    "class GraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim = 128, out_channels = 1):\n",
    "        hidden_channels = 128\n",
    "        out_channels = 1\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "#         self.lin = Linear(-1, 16)\n",
    "        self.conv1 = SAGEConv((-1,-1), hidden_channels, normalize=True,aggr = \"mean\",root_weight = True)\n",
    "        self.conv_end = SAGEConv(hidden_channels, out_channels, aggr = \"mean\", root_weight = True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv_end(x, edge_index)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a3cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e56db",
   "metadata": {},
   "source": [
    "## Shift data to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "graph = graph.to(device)\n",
    "\n",
    "sepsis_cases = torch.count_nonzero(graph[PATIENT_NAME].y[train_mask])\n",
    "control_cases = graph[PATIENT_NAME].y[train_mask].size(dim=0) - sepsis_cases\n",
    "WEIGHT = (control_cases / (sepsis_cases + 1e-10))\n",
    "WEIGHT = WEIGHT.to(device)\n",
    "\n",
    "print(\"Data shifted to the device \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d27ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "kwargs = {\n",
    "    \"num_neighbors\":[5] * 2,\n",
    "    \"batch_size\":1_000_000\n",
    "}\n",
    "loader = NeighborLoader(\n",
    "    graph,\n",
    "    input_nodes=(PATIENT_NAME, graph[PATIENT_NAME].train_mask),\n",
    "    **kwargs\n",
    ")\n",
    "val_loader = NeighborLoader(\n",
    "    graph,\n",
    "    input_nodes=(PATIENT_NAME, graph[PATIENT_NAME].val_mask),\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, graph in enumerate(loader):\n",
    "    print(graph)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a6b14",
   "metadata": {},
   "source": [
    "## Model-Wrapper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96602f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.nn import to_hetero\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, graph):\n",
    "        self.LEARNING_RATE = 3e-4\n",
    "        self.MAX_EPOCHS = 10000\n",
    "        \n",
    "        self.graph = graph\n",
    "#         model = HetGraphNeuralNetwork(graph.metadata(),graph.node_types, hidden_dim = 128, out_channels=1) \n",
    "        model = GraphNeuralNetwork(hidden_dim = 128, out_channels=1)         \n",
    "        model = to_hetero(model, graph.metadata(), aggr='sum')\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.LEARNING_RATE,betas=(0.9, 0.999), eps=1e-08)\n",
    "        \n",
    "        self.last_loss = 0\n",
    "        self.increased_loss = 0\n",
    "        self.BREAKING_THRESHOLD = 10    \n",
    "        self.val_loss = []\n",
    "        self.train_loss = []\n",
    "    \n",
    "    def validate(self):\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            acc_loss = 0\n",
    "            batch_size = 0\n",
    "            for batch, graph in enumerate(val_loader):\n",
    "                out = self.model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "                loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[val_mask]), graph[PATIENT_NAME].y[val_mask].type(torch.float32),\n",
    "                                                          pos_weight=WEIGHT)\n",
    "                acc_loss += loss.item()\n",
    "                batch_size += 1\n",
    "            avg_loss = acc_loss / batch_size\n",
    "            self.val_loss.append(avg_loss)\n",
    "            if avg_loss > self.last_loss:\n",
    "                self.increased_loss += 1\n",
    "            else:\n",
    "                self.increased_loss = 0\n",
    "            self.last_loss = avg_loss\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in tqdm(range(self.MAX_EPOCHS)):\n",
    "            acc_loss = 0\n",
    "            batch_size = 0\n",
    "            for batch, graph in enumerate(loader):\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "                loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[train_mask]), graph[PATIENT_NAME].y[train_mask].type(torch.float32),\n",
    "                                                          pos_weight=WEIGHT)\n",
    "                acc_loss += loss.item()\n",
    "                batch_size += 1\n",
    "            avg_loss = acc_loss / batch_size\n",
    "            self.train_loss.append(avg_loss)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.validate() \n",
    "\n",
    "            if self.increased_loss >= self.BREAKING_THRESHOLD:\n",
    "                print(f\"Breaked at {str(epoch)}\")\n",
    "                break\n",
    "                \n",
    "            \n",
    "    def get_model(self):\n",
    "        return self.model    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.epochs, self.train_loss, 'g', label='Training loss')\n",
    "        plt.plot(self.epochs, self.val_loss, 'y', label='Validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = ModelWrapper(graph)\n",
    "import time \n",
    "print(\"GIN-HET\")\n",
    "start = time.time()\n",
    "model_wrapper.train()\n",
    "print(time.time() - start )\n",
    "model = model_wrapper.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47edb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce472c7",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edee9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(graph, mask):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        logits = model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "        scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "        scores = torch.unsqueeze(scores, 0)\n",
    "        proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "    return torch.transpose(proba_predict, 0, 1)\n",
    "\n",
    "def predict(graph, mask):\n",
    "    pred = torch.round(predict_proba(graph, mask)[:, 1])\n",
    "    return pred\n",
    "\n",
    "model.predict_proba = predict_proba\n",
    "model.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da76ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "graph = graph.cpu()\n",
    "model = model.cpu()\n",
    "evaluation = Evaluation(y_test, y_gw_test, X_test, X_gw_test)\n",
    "evaluation.set_test_args([graph, test_l_mask])\n",
    "evaluation.set_gw_args([graph, test_gw_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_confusion_matrix(model)\n",
    "evaluation.get_df_metrics(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab05a48",
   "metadata": {},
   "source": [
    "## Error evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76c44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "number_of_iterations = 100\n",
    "dataframes = []\n",
    "for i in range(number_of_iterations):\n",
    "    graph = graph.to(device)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    model_wrapper = ModelWrapper(graph)\n",
    "    model_wrapper.train()\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    def predict_proba(graph, mask):\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            logits = model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "            scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "            scores = torch.unsqueeze(scores, 0)\n",
    "            proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "        return torch.transpose(proba_predict, 0, 1)\n",
    "\n",
    "    def predict(graph, mask):\n",
    "        pred = torch.round(predict_proba(graph, mask)[:, 1])\n",
    "        return pred\n",
    "    model = model_wrapper.get_model()\n",
    "    model.predict_proba = predict_proba\n",
    "    model.predict = predict\n",
    "    \n",
    "    from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "    graph = graph.cpu()\n",
    "    model = model.cpu()\n",
    "    evaluation = Evaluation(y_test, y_gw_test, X_test, X_gw_test)\n",
    "    evaluation.set_test_args([graph, test_l_mask])\n",
    "    evaluation.set_gw_args([graph, test_gw_mask])\n",
    "    \n",
    "    df = evaluation.get_df_metrics(model)\n",
    "    dataframes.append(df)\n",
    "for df in dataframes:\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
