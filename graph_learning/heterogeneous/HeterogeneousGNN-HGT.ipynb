{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18b73dd",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431abf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.insert(0, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c929aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/graph_learning/heterogeneous/../../dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Assessable data are 528101 cases and 1015074 CBCs\n",
      "Control data are 527038 cases and 1013548 CBCs\n",
      "Sepsis data are 1488 cases and 1526 CBCs\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "Testing: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/graph_learning/heterogeneous/../../dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 365794, Sepsis: 490\n",
      "Assessable data are 180494 cases and 366284 CBCs\n",
      "Control data are 180157 cases and 365794 CBCs\n",
      "Sepsis data are 472 cases and 490 CBCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/graph_learning/heterogeneous/../../dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 437629, Sepsis: 448\n",
      "Assessable data are 157922 cases and 438077 CBCs\n",
      "Control data are 180157 cases and 437629 CBCs\n",
      "Sepsis data are 438 cases and 448 CBCs\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"../../extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94724e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "y_train = torch.tensor(data_analysis.get_y_train(), dtype=torch.long)\n",
    "X_train = torch.tensor(data_analysis.get_X_train(), dtype=torch.float)\n",
    "\n",
    "y_test = torch.tensor(data_analysis.get_y_test(), dtype=torch.long)\n",
    "X_test = torch.tensor(data_analysis.get_X_test(), dtype=torch.float)\n",
    "\n",
    "y_gw_test = torch.tensor(data_analysis.get_y_gw(), dtype=torch.long)\n",
    "X_gw_test = torch.tensor(data_analysis.get_X_gw(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e6eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = torch.concat((y_train, y_test, y_gw_test))\n",
    "X_all = torch.concat((X_train, X_test, X_gw_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f90b6",
   "metadata": {},
   "source": [
    "## Train/Validation/Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29cee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_indices_like(tensor):\n",
    "    return torch.ones((tensor.shape[0])).type(torch.bool)\n",
    "\n",
    "def false_indices_like(tensor):\n",
    "    return torch.zeros((tensor.shape[0])).type(torch.bool)\n",
    "\n",
    "def split(train_features):\n",
    "    tensor = true_indices_like(train_features)\n",
    "    max_index = round(tensor.shape[0] * 0.8)\n",
    "    train = torch.zeros(tensor.shape[0])\n",
    "    train[:max_index] = 1\n",
    "    \n",
    "    val = torch.zeros(tensor.shape[0])\n",
    "    val[max_index:] = 1\n",
    "    return{\n",
    "        \"train\": train.type(torch.bool),\n",
    "        \"val\":val.type(torch.bool)\n",
    "    }\n",
    "train_data = split(X_train)\n",
    "\n",
    "train_mask = torch.concat((train_data[\"train\"], false_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "val_mask = torch.concat((train_data[\"val\"], false_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "test_l_mask = torch.concat((false_indices_like(X_train), true_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "test_gw_mask = torch.concat((false_indices_like(X_train), false_indices_like(X_test), true_indices_like(X_gw_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360310be",
   "metadata": {},
   "source": [
    "## Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09c59b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dataAnalysis.Constants import *\n",
    "\n",
    "def to_tensor(df):\n",
    "    return torch.Tensor(list(df.values))\n",
    "\n",
    "def get_quantil_tensor():\n",
    "    number_of_quantiles = 10\n",
    "    q = torch.arange(0, 1, 1/number_of_quantiles)\n",
    "    q = torch.Tensor([0.025,0.05, 0.1, 0.2, 0.35, 0.5, 0.65, 0.8, 0.9, 0.95, 0.975, 1])\n",
    "    return q\n",
    "\n",
    "def get_quantiles(tensor):\n",
    "    q = get_quantil_tensor() \n",
    "    return torch.quantile(tensor, q)\n",
    "\n",
    "def normalize(tensor):\n",
    "    mean = torch.mean(tensor, dim = 0)\n",
    "    std = torch.std(tensor, dim = 0)\n",
    "    mean_diff = tensor - mean\n",
    "    return mean_diff / std\n",
    "\n",
    "def get_quantile_indices(tensor, quantiles):\n",
    "    quantile_indices = []\n",
    "    all_indices = torch.Tensor([])\n",
    "    prev_quantile = -1e-4\n",
    "    indices_control = torch.arange(0, tensor.shape[0])\n",
    "    for i in range(quantiles.nelement()):\n",
    "        indices_u = (tensor > prev_quantile).nonzero(as_tuple=True)[0] # (tensor > prev_quantile and tensor <= quantiles[i]).nonzero(as_tuple=True)[0]\n",
    "        indices_o = (tensor <= quantiles[i]).nonzero(as_tuple=True)[0]\n",
    "        indices = torch.from_numpy(np.intersect1d(indices_u, indices_o))\n",
    "        quantile_indices.append(indices)\n",
    "        prev_quantile = quantiles[i]\n",
    "    return quantile_indices\n",
    "\n",
    "\n",
    "def create_node_features(node_type, quantiles):\n",
    "    nodes_features = []\n",
    "    prev_quantile = torch.Tensor([0])\n",
    "    for i in range(quantiles.nelement()):\n",
    "        node_features = [prev_quantile.item(), quantiles[i].item(), get_quantil_tensor()[i].item()]\n",
    "        prev_quantile = quantiles[i]\n",
    "        nodes_features.append(node_features)\n",
    "    return torch.tensor(nodes_features)\n",
    "\n",
    "def create_edge_features_to_patient(node_type, quantile_indices):\n",
    "    source_edge_list = None\n",
    "    target_edge_list = None\n",
    "    for i in range(len(quantile_indices)):\n",
    "        target_edges = torch.ones((quantile_indices[i].nelement())) * i\n",
    "        source_edges = quantile_indices[i]\n",
    "        source_edge_list = source_edges if source_edge_list is None else torch.concat((source_edge_list, source_edges))\n",
    "        target_edge_list = target_edges if target_edge_list is None else torch.concat((target_edge_list, target_edges))\n",
    "    return torch.stack([source_edge_list, target_edge_list]).type(torch.long)\n",
    "\n",
    "def add_features_and_edges(graph):\n",
    "    for i, feature_name in enumerate(FEATURES):\n",
    "        if feature_name not in [HGB_COLUMN_NAME, WBC_COLUMN_NAME, RBC_COLUMN_NAME, MCV_COLUMN_NAME, PLT_COLUMN_NAME]:\n",
    "            continue\n",
    "        feature_vector = graph[PATIENT_NAME].x[:, i]\n",
    "        node_quantiles = get_quantiles(feature_vector)\n",
    "        quantile_indices = get_quantile_indices(feature_vector, node_quantiles)\n",
    "        graph[feature_name].x = create_node_features(feature_name, node_quantiles)\n",
    "        graph[PATIENT_NAME, EDGE_TYPE, feature_name].edge_index = create_edge_features_to_patient(feature_name, quantile_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b8b2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def normalize(tensor):\n",
    "    mean = torch.mean(tensor, dim = 0)\n",
    "    std = torch.std(tensor, dim = 0)\n",
    "    mean_diff = tensor - mean\n",
    "    return mean_diff / std\n",
    "\n",
    "graph = HeteroData()\n",
    "graph[PATIENT_NAME].x = X_all\n",
    "add_features_and_edges(graph)\n",
    "graph[PATIENT_NAME].y = y_all\n",
    "graph[PATIENT_NAME].train_mask = train_mask\n",
    "graph[PATIENT_NAME].val_mask = val_mask\n",
    "graph[PATIENT_NAME].test_l_mask = test_l_mask\n",
    "graph[PATIENT_NAME].test_gw_mask = test_gw_mask\n",
    "graph = T.ToUndirected()(graph)\n",
    "graph[PATIENT_NAME].x = normalize(graph[PATIENT_NAME].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e380f8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mPATIENT\u001b[0m={\n",
       "    x=[1819435, 7],\n",
       "    y=[1819435],\n",
       "    train_mask=[1819435],\n",
       "    val_mask=[1819435],\n",
       "    test_l_mask=[1819435],\n",
       "    test_gw_mask=[1819435]\n",
       "  },\n",
       "  \u001b[1mHGB\u001b[0m={ x=[12, 3] },\n",
       "  \u001b[1mWBC\u001b[0m={ x=[12, 3] },\n",
       "  \u001b[1mRBC\u001b[0m={ x=[12, 3] },\n",
       "  \u001b[1mMCV\u001b[0m={ x=[12, 3] },\n",
       "  \u001b[1mPLT\u001b[0m={ x=[12, 3] },\n",
       "  \u001b[1m(PATIENT, HAS, HGB)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(PATIENT, HAS, WBC)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(PATIENT, HAS, RBC)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(PATIENT, HAS, MCV)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(PATIENT, HAS, PLT)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(HGB, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(WBC, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(RBC, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(MCV, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(PLT, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 1819435] }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e41cf",
   "metadata": {},
   "source": [
    "### Model defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfcec79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HANConv, HGTConv, FiLMConv, Linear\n",
    "import torch\n",
    "from dataAnalysis.Constants import FEATURES\n",
    "\n",
    "\n",
    "class HetGraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, metadata,node_types, hidden_dim = 128, out_channels = 1):\n",
    "        super(HetGraphNeuralNetwork, self).__init__()\n",
    "                 \n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_dim)\n",
    "        self.lin_end = Linear(-1, out_channels)\n",
    "        self.conv1 = HGTConv(-1,hidden_dim, metadata)\n",
    "        self.conv_end = HGTConv(hidden_dim, hidden_dim, metadata)\n",
    "\n",
    "\n",
    "    def forward(self, x_dict, edge_index):\n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "        x_dict = self.conv1(x_dict, edge_index)\n",
    "        x_dict = self.conv_end(x_dict, edge_index)\n",
    "        x_dict[PATIENT_NAME] = self.lin_end(x_dict[PATIENT_NAME])\n",
    "        \n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e56db",
   "metadata": {},
   "source": [
    "## Shift data to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97de16f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shifted to the device cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "graph = graph.to(device)\n",
    "\n",
    "sepsis_cases = torch.count_nonzero(graph[PATIENT_NAME].y[train_mask])\n",
    "control_cases = graph[PATIENT_NAME].y[train_mask].size(dim=0) - sepsis_cases\n",
    "WEIGHT = (control_cases / (sepsis_cases + 1e-10))\n",
    "WEIGHT = WEIGHT.to(device)\n",
    "\n",
    "print(\"Data shifted to the device \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a6b14",
   "metadata": {},
   "source": [
    "## Model-Wrapper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96602f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.nn import to_hetero\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, graph):\n",
    "        self.LEARNING_RATE = 3e-4\n",
    "        self.MAX_EPOCHS = 10000\n",
    "        \n",
    "        self.graph = graph\n",
    "        model = HetGraphNeuralNetwork(graph.metadata(),graph.node_types, hidden_dim = 128, out_channels=1) \n",
    "#         model = GraphNeuralNetwork(hidden_dim = 32, out_channels=1)         \n",
    "#         model = to_hetero(model, graph.metadata(), aggr='sum')\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.LEARNING_RATE,betas=(0.9, 0.999), eps=1e-08)\n",
    "        \n",
    "        self.last_loss = 0\n",
    "        self.increased_loss = 0\n",
    "        self.BREAKING_THRESHOLD = 10    \n",
    "        self.val_loss = []\n",
    "        self.train_loss = []\n",
    "    \n",
    "    def validate(self):\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            out = self.model(self.graph.x_dict, self.graph.edge_index_dict)[PATIENT_NAME]\n",
    "            loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[val_mask]), self.graph[PATIENT_NAME].y[val_mask].type(torch.float32),\n",
    "                                                      pos_weight=WEIGHT)\n",
    "            self.val_loss.append(loss.item())\n",
    "            if loss.item() > self.last_loss:\n",
    "                self.increased_loss += 1\n",
    "            else:\n",
    "                self.increased_loss = 0\n",
    "            self.last_loss = loss.item()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in tqdm(range(self.MAX_EPOCHS)):\n",
    "#             print(epoch)\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            out = self.model(self.graph.x_dict, self.graph.edge_index_dict)[PATIENT_NAME]\n",
    "            loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[train_mask]), self.graph[PATIENT_NAME].y[train_mask].type(torch.float32),\n",
    "                                                      pos_weight=WEIGHT)\n",
    "            self.train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.validate() \n",
    "\n",
    "            if self.increased_loss >= self.BREAKING_THRESHOLD:\n",
    "                print(f\"Breaked at {str(epoch)}\")\n",
    "                break\n",
    "                \n",
    "            \n",
    "    def get_model(self):\n",
    "        return self.model    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.epochs, self.train_loss, 'g', label='Training loss')\n",
    "        plt.plot(self.epochs, self.val_loss, 'y', label='Validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5fc9815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGT-Conv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f755942affe44dbb6c51a8901aa42cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 890.00 MiB (GPU 1; 47.54 GiB total capacity; 45.83 GiB already allocated; 348.88 MiB free; 46.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHGT-Conv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start )\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m model_wrapper\u001b[38;5;241m.\u001b[39mget_model()\n",
      "Cell \u001b[0;32mIn[43], line 41\u001b[0m, in \u001b[0;36mModelWrapper.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 41\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m[PATIENT_NAME]\n\u001b[1;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(torch\u001b[38;5;241m.\u001b[39msqueeze(out[train_mask]), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph[PATIENT_NAME]\u001b[38;5;241m.\u001b[39my[train_mask]\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     43\u001b[0m                                           pos_weight\u001b[38;5;241m=\u001b[39mWEIGHT)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[30], line 23\u001b[0m, in \u001b[0;36mHetGraphNeuralNetwork.forward\u001b[0;34m(self, x_dict, edge_index)\u001b[0m\n\u001b[1;32m     21\u001b[0m     x_dict[node_type] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_dict[node_type](x)\u001b[38;5;241m.\u001b[39mrelu_()\n\u001b[1;32m     22\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x_dict, edge_index)\n\u001b[0;32m---> 23\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m x_dict[PATIENT_NAME] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_end(x_dict[PATIENT_NAME])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_dict\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch_geometric/nn/conv/hgt_conv.py:172\u001b[0m, in \u001b[0;36mHGTConv.forward\u001b[0;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[1;32m    169\u001b[0m     v \u001b[38;5;241m=\u001b[39m (v_dict[src_type]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m@\u001b[39m m_rel)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# propagate_type: (k: Tensor, q: Tensor, v: Tensor, rel: Tensor)\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdst_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mrel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_rel\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     out_dict[dst_type]\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Iterate over node-types:\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:459\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    457\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 459\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:336\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, dim, data)\n\u001b[0;32m--> 336\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m         out[arg] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:282\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered an index error. Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(got interval \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmin())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound negative indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:272\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     index \u001b[38;5;241m=\u001b[39m edge_index[dim]\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim):\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 890.00 MiB (GPU 1; 47.54 GiB total capacity; 45.83 GiB already allocated; 348.88 MiB free; 46.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model_wrapper = ModelWrapper(graph)\n",
    "import time \n",
    "print(\"HGT-Conv\")\n",
    "start = time.time()\n",
    "model_wrapper.train()\n",
    "print(time.time() - start )\n",
    "model = model_wrapper.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47edb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab05a48",
   "metadata": {},
   "source": [
    "## Error evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc76c44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9891d803d3491c9761289251a42d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4528789520263672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     evaluation\u001b[38;5;241m.\u001b[39mset_test_args([graph, test_l_mask])\n\u001b[1;32m     36\u001b[0m     evaluation\u001b[38;5;241m.\u001b[39mset_gw_args([graph, test_gw_mask])\n\u001b[0;32m---> 38\u001b[0m     df \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mget_df_metrics(model)\n\u001b[1;32m     39\u001b[0m     dataframes\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m dataframes:\n",
      "File \u001b[0;32m~/git/sbc/graph_learning/../dataAnalysis/Metrics.py:45\u001b[0m, in \u001b[0;36mEvaluation.get_df_metrics\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_df_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, model):\n\u001b[0;32m---> 45\u001b[0m     test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_args) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test)\n\u001b[1;32m     46\u001b[0m     test_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_args) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test)\n\u001b[1;32m     47\u001b[0m     gw_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgw_args) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgw_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_gw_test)\n",
      "Cell \u001b[0;32mIn[26], line 24\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(graph, mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(graph, mask):\n\u001b[0;32m---> 24\u001b[0m     pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mround(predict_proba(graph, mask)[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "Cell \u001b[0;32mIn[26], line 17\u001b[0m, in \u001b[0;36mpredict_proba\u001b[0;34m(graph, mask)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 17\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(graph\u001b[38;5;241m.\u001b[39mx_dict, graph\u001b[38;5;241m.\u001b[39medge_index_dict)[PATIENT_NAME]\n\u001b[1;32m     18\u001b[0m     scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(torch\u001b[38;5;241m.\u001b[39msqueeze(logits[mask]))\n\u001b[1;32m     19\u001b[0m     scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(scores, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch/fx/graph_module.py:662\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_call(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch/fx/graph_module.py:271\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_call(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls, obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.5:30\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     28\u001b[0m conv1__PATIENT1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mHGB__rev_HAS__PATIENT((x__HGB, x__PATIENT), edge_index__HGB__rev_HAS__PATIENT);  x__HGB \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     29\u001b[0m conv1__PATIENT2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mWBC__rev_HAS__PATIENT((x__WBC, x__PATIENT), edge_index__WBC__rev_HAS__PATIENT);  x__WBC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m conv1__PATIENT3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mRBC__rev_HAS__PATIENT((x__RBC, x__PATIENT), edge_index__RBC__rev_HAS__PATIENT);  x__RBC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     31\u001b[0m conv1__PATIENT4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mMCV__rev_HAS__PATIENT((x__MCV, x__PATIENT), edge_index__MCV__rev_HAS__PATIENT);  x__MCV \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     32\u001b[0m conv1__PATIENT5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mPLT__rev_HAS__PATIENT((x__PLT, x__PATIENT), edge_index__PLT__rev_HAS__PATIENT);  x__PLT \u001b[38;5;241m=\u001b[39m x__PATIENT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch_geometric/nn/conv/gatv2_conv.py:250\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    245\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe usage of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimultaneously is currently not yet supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseTensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m form\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39m(x_l, x_r), edge_attr\u001b[38;5;241m=\u001b[39medge_attr,\n\u001b[1;32m    251\u001b[0m                      size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    253\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:467\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 467\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmsg_kwargs)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    469\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "number_of_iterations = 100\n",
    "dataframes = []\n",
    "for i in range(number_of_iterations):\n",
    "    graph = graph.to(device)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    model_wrapper = ModelWrapper(graph)\n",
    "    model_wrapper.train()\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    def predict_proba(graph, mask):\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            logits = model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "            scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "            scores = torch.unsqueeze(scores, 0)\n",
    "            proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "        return torch.transpose(proba_predict, 0, 1)\n",
    "\n",
    "    def predict(graph, mask):\n",
    "        pred = torch.round(predict_proba(graph, mask)[:, 1])\n",
    "        return pred\n",
    "    model = model_wrapper.get_model()\n",
    "    model.predict_proba = predict_proba\n",
    "    model.predict = predict\n",
    "    \n",
    "    from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "    graph = graph.cpu()\n",
    "    model = model.cpu()\n",
    "    evaluation = Evaluation(y_test, y_gw_test, X_test, X_gw_test)\n",
    "    evaluation.set_test_args([graph, test_l_mask])\n",
    "    evaluation.set_gw_args([graph, test_gw_mask])\n",
    "    \n",
    "    df = evaluation.get_df_metrics(model)\n",
    "    dataframes.append(df)\n",
    "for df in dataframes:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce472c7",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0edee9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(graph, mask):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        logits = model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "        scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "        scores = torch.unsqueeze(scores, 0)\n",
    "        proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "    return torch.transpose(proba_predict, 0, 1)\n",
    "\n",
    "def predict(graph, mask):\n",
    "    pred = torch.round(predict_proba(graph, mask)[:, 1])\n",
    "    return pred\n",
    "\n",
    "model.predict_proba = predict_proba\n",
    "model.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5da76ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "graph = graph.cpu()\n",
    "model = model.cpu()\n",
    "evaluation = Evaluation(y_test, y_gw_test, X_test, X_gw_test)\n",
    "evaluation.set_test_args([graph, test_l_mask])\n",
    "evaluation.set_gw_args([graph, test_gw_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc4e1c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1-Micro</th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Binary</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leipzig</td>\n",
       "      <td>0.047937</td>\n",
       "      <td>0.805394</td>\n",
       "      <td>0.450910</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>0.831655</td>\n",
       "      <td>0.012241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greifswald</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.716178</td>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.777820</td>\n",
       "      <td>0.004568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name       MCC  F1-Micro  F1-Macro  F1-Binary     AUROC     AUPRC\n",
       "0     Leipzig  0.047937  0.805394  0.450910   0.009725  0.831655  0.012241\n",
       "1  Greifswald  0.028924  0.716178  0.419722   0.004962  0.777820  0.004568"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation.plot_confusion_matrix(model)\n",
    "evaluation.get_df_metrics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a3ad29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
