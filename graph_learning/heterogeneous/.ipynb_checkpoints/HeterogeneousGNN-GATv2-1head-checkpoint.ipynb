{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18b73dd",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431abf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.insert(0, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c929aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"../../extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94724e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "y_train = torch.tensor(data_analysis.get_y_train(), dtype=torch.long)\n",
    "X_train = torch.tensor(data_analysis.get_X_train(), dtype=torch.float)\n",
    "\n",
    "y_test = torch.tensor(data_analysis.get_y_test(), dtype=torch.long)\n",
    "X_test = torch.tensor(data_analysis.get_X_test(), dtype=torch.float)\n",
    "\n",
    "y_gw_test = torch.tensor(data_analysis.get_y_gw(), dtype=torch.long)\n",
    "X_gw_test = torch.tensor(data_analysis.get_X_gw(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = torch.concat((y_train, y_test, y_gw_test))\n",
    "X_all = torch.concat((X_train, X_test, X_gw_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f90b6",
   "metadata": {},
   "source": [
    "## Train/Validation/Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29cee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_indices_like(tensor):\n",
    "    return torch.ones((tensor.shape[0])).type(torch.bool)\n",
    "\n",
    "def false_indices_like(tensor):\n",
    "    return torch.zeros((tensor.shape[0])).type(torch.bool)\n",
    "\n",
    "def split(train_features):\n",
    "    tensor = true_indices_like(train_features)\n",
    "    max_index = round(tensor.shape[0] * 0.8)\n",
    "    train = torch.zeros(tensor.shape[0])\n",
    "    train[:max_index] = 1\n",
    "    \n",
    "    val = torch.zeros(tensor.shape[0])\n",
    "    val[max_index:] = 1\n",
    "    return{\n",
    "        \"train\": train.type(torch.bool),\n",
    "        \"val\":val.type(torch.bool)\n",
    "    }\n",
    "train_data = split(X_train)\n",
    "\n",
    "train_mask = torch.concat((train_data[\"train\"], false_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "val_mask = torch.concat((train_data[\"val\"], false_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "test_l_mask = torch.concat((false_indices_like(X_train), true_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "test_gw_mask = torch.concat((false_indices_like(X_train), false_indices_like(X_test), true_indices_like(X_gw_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360310be",
   "metadata": {},
   "source": [
    "## Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c59b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dataAnalysis.Constants import *\n",
    "\n",
    "def to_tensor(df):\n",
    "    return torch.Tensor(list(df.values))\n",
    "\n",
    "def get_quantil_tensor():\n",
    "    number_of_quantiles = 10\n",
    "    q = torch.arange(0, 1, 1/number_of_quantiles)\n",
    "    q = torch.Tensor([0.025,0.05, 0.1, 0.2, 0.35, 0.5, 0.65, 0.8, 0.9, 0.95, 0.975, 1])\n",
    "    return q\n",
    "\n",
    "def get_quantiles(tensor):\n",
    "    q = get_quantil_tensor() \n",
    "    return torch.quantile(tensor, q)\n",
    "\n",
    "def normalize(tensor):\n",
    "    mean = torch.mean(tensor, dim = 0)\n",
    "    std = torch.std(tensor, dim = 0)\n",
    "    mean_diff = tensor - mean\n",
    "    return mean_diff / std\n",
    "\n",
    "def get_quantile_indices(tensor, quantiles):\n",
    "    quantile_indices = []\n",
    "    all_indices = torch.Tensor([])\n",
    "    prev_quantile = -1e-4\n",
    "    indices_control = torch.arange(0, tensor.shape[0])\n",
    "    for i in range(quantiles.nelement()):\n",
    "        indices_u = (tensor > prev_quantile).nonzero(as_tuple=True)[0] # (tensor > prev_quantile and tensor <= quantiles[i]).nonzero(as_tuple=True)[0]\n",
    "        indices_o = (tensor <= quantiles[i]).nonzero(as_tuple=True)[0]\n",
    "        indices = torch.from_numpy(np.intersect1d(indices_u, indices_o))\n",
    "        quantile_indices.append(indices)\n",
    "        prev_quantile = quantiles[i]\n",
    "    return quantile_indices\n",
    "\n",
    "\n",
    "def create_node_features(node_type, quantiles):\n",
    "    nodes_features = []\n",
    "    prev_quantile = torch.Tensor([0])\n",
    "    for i in range(quantiles.nelement()):\n",
    "        node_features = [prev_quantile.item(), quantiles[i].item(), get_quantil_tensor()[i].item()]\n",
    "        prev_quantile = quantiles[i]\n",
    "        nodes_features.append(node_features)\n",
    "    return torch.tensor(nodes_features)\n",
    "\n",
    "def create_edge_features_to_patient(node_type, quantile_indices):\n",
    "    source_edge_list = None\n",
    "    target_edge_list = None\n",
    "    for i in range(len(quantile_indices)):\n",
    "        target_edges = torch.ones((quantile_indices[i].nelement())) * i\n",
    "        source_edges = quantile_indices[i]\n",
    "        source_edge_list = source_edges if source_edge_list is None else torch.concat((source_edge_list, source_edges))\n",
    "        target_edge_list = target_edges if target_edge_list is None else torch.concat((target_edge_list, target_edges))\n",
    "    return torch.stack([source_edge_list, target_edge_list]).type(torch.long)\n",
    "\n",
    "def add_features_and_edges(graph):\n",
    "    for i, feature_name in enumerate(FEATURES):\n",
    "        if feature_name not in [HGB_COLUMN_NAME, WBC_COLUMN_NAME, RBC_COLUMN_NAME, MCV_COLUMN_NAME, PLT_COLUMN_NAME]:\n",
    "            continue\n",
    "        feature_vector = graph[PATIENT_NAME].x[:, i]\n",
    "        node_quantiles = get_quantiles(feature_vector)\n",
    "        quantile_indices = get_quantile_indices(feature_vector, node_quantiles)\n",
    "        graph[feature_name].x = create_node_features(feature_name, node_quantiles)\n",
    "        graph[PATIENT_NAME, EDGE_TYPE, feature_name].edge_index = create_edge_features_to_patient(feature_name, quantile_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def normalize(tensor):\n",
    "    mean = torch.mean(tensor, dim = 0)\n",
    "    std = torch.std(tensor, dim = 0)\n",
    "    mean_diff = tensor - mean\n",
    "    return mean_diff / std\n",
    "\n",
    "graph = HeteroData()\n",
    "graph[PATIENT_NAME].x = X_all\n",
    "add_features_and_edges(graph)\n",
    "graph[PATIENT_NAME].y = y_all\n",
    "graph[PATIENT_NAME].train_mask = train_mask\n",
    "graph[PATIENT_NAME].val_mask = val_mask\n",
    "graph[PATIENT_NAME].test_l_mask = test_l_mask\n",
    "graph[PATIENT_NAME].test_gw_mask = test_gw_mask\n",
    "graph = T.ToUndirected()(graph)\n",
    "graph[PATIENT_NAME].x = normalize(graph[PATIENT_NAME].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e41cf",
   "metadata": {},
   "source": [
    "### Model defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcec79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GINConv, Linear, GATConv, GATv2Conv\n",
    "import torch\n",
    "from dataAnalysis.Constants import FEATURES\n",
    "from torch.nn import ReLU, Sequential\n",
    "from torch.nn import BatchNorm1d as BatchNorm\n",
    "\n",
    "class GraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim = 128, out_channels=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv((-1, -1), hidden_dim, add_self_loops=False, heads=1)\n",
    "        self.conv2 = GATv2Conv((-1, -1), out_channels, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e56db",
   "metadata": {},
   "source": [
    "## Shift data to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "graph = graph.to(device)\n",
    "\n",
    "sepsis_cases = torch.count_nonzero(graph[PATIENT_NAME].y[train_mask])\n",
    "control_cases = graph[PATIENT_NAME].y[train_mask].size(dim=0) - sepsis_cases\n",
    "WEIGHT = (control_cases / (sepsis_cases + 1e-10))\n",
    "WEIGHT = WEIGHT.to(device)\n",
    "\n",
    "print(\"Data shifted to the device \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a6b14",
   "metadata": {},
   "source": [
    "## Model-Wrapper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96602f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.nn import to_hetero\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, graph):\n",
    "        self.LEARNING_RATE = 3e-4\n",
    "        self.MAX_EPOCHS = 10000\n",
    "        \n",
    "        self.graph = graph\n",
    "#         model = HetGraphNeuralNetwork(graph.metadata(),graph.node_types, hidden_dim = 128, out_channels=1) \n",
    "        model = GraphNeuralNetwork(hidden_dim = 128, out_channels=1)         \n",
    "        model = to_hetero(model, graph.metadata(), aggr='sum')\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.LEARNING_RATE,betas=(0.9, 0.999), eps=1e-08)\n",
    "        \n",
    "        self.last_loss = 0\n",
    "        self.increased_loss = 0\n",
    "        self.BREAKING_THRESHOLD = 10    \n",
    "        self.val_loss = []\n",
    "        self.train_loss = []\n",
    "    \n",
    "    def validate(self):\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            out = self.model(self.graph.x_dict, self.graph.edge_index_dict)[PATIENT_NAME]\n",
    "            loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[val_mask]), self.graph[PATIENT_NAME].y[val_mask].type(torch.float32),\n",
    "                                                      pos_weight=WEIGHT)\n",
    "            self.val_loss.append(loss.item())\n",
    "            if loss.item() > self.last_loss:\n",
    "                self.increased_loss += 1\n",
    "            else:\n",
    "                self.increased_loss = 0\n",
    "            self.last_loss = loss.item()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in tqdm(range(self.MAX_EPOCHS)):\n",
    "#             print(epoch)\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            out = self.model(self.graph.x_dict, self.graph.edge_index_dict)[PATIENT_NAME]\n",
    "            loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[train_mask]), self.graph[PATIENT_NAME].y[train_mask].type(torch.float32),\n",
    "                                                      pos_weight=WEIGHT)\n",
    "            self.train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.validate() \n",
    "\n",
    "            if self.increased_loss >= self.BREAKING_THRESHOLD:\n",
    "                print(f\"Breaked at {str(epoch)}\")\n",
    "                break\n",
    "#             if epoch % 100 == 3:\n",
    "#                 def predict_proba(graph, mask):\n",
    "#                     with torch.inference_mode():\n",
    "#                         model.eval()\n",
    "#                         logits = model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "#                         scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "#                         scores = torch.unsqueeze(scores, 0)\n",
    "#                         proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "#                     return torch.transpose(proba_predict, 0, 1)\n",
    "\n",
    "#                 def predict(graph, mask):\n",
    "#                     pred = torch.round(predict_proba(graph, mask)[:, 1])\n",
    "#                     return pred\n",
    "#                 model = self.model\n",
    "#                 graph = self.graph\n",
    "#                 model.predict_proba = predict_proba\n",
    "#                 model.predict = predict\n",
    "#                 from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "#                 graph = graph.cpu()\n",
    "#                 model = model.cpu()\n",
    "#                 evaluation = Evaluation(y_test, y_gw_test, X_test, X_gw_test)\n",
    "#                 evaluation.set_test_args([graph, test_l_mask])\n",
    "#                 evaluation.set_gw_args([graph, test_gw_mask])\n",
    "#                 print(evaluation.get_df_metrics(model))\n",
    "#                 model = model.to(device)\n",
    "#                 graph = graph.to(device)\n",
    "                \n",
    "            \n",
    "    def get_model(self):\n",
    "        return self.model    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.epochs, self.train_loss, 'g', label='Training loss')\n",
    "        plt.plot(self.epochs, self.val_loss, 'y', label='Validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = ModelWrapper(graph)\n",
    "import time \n",
    "print(\"GIN-HET\")\n",
    "start = time.time()\n",
    "model_wrapper.train()\n",
    "print(time.time() - start )\n",
    "model = model_wrapper.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47edb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab05a48",
   "metadata": {},
   "source": [
    "## Error evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76c44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "number_of_iterations = 100\n",
    "dataframes = []\n",
    "for i in range(number_of_iterations):\n",
    "    graph = graph.to(device)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    model_wrapper = ModelWrapper(graph)\n",
    "    model_wrapper.train()\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    def predict_proba(graph, mask):\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            logits = model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "            scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "            scores = torch.unsqueeze(scores, 0)\n",
    "            proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "        return torch.transpose(proba_predict, 0, 1)\n",
    "\n",
    "    def predict(graph, mask):\n",
    "        pred = torch.round(predict_proba(graph, mask)[:, 1])\n",
    "        return pred\n",
    "    model = model_wrapper.get_model()\n",
    "    model.predict_proba = predict_proba\n",
    "    model.predict = predict\n",
    "    \n",
    "    from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "    graph = graph.cpu()\n",
    "    model = model.cpu()\n",
    "    evaluation = Evaluation(y_test, y_gw_test, X_test, X_gw_test)\n",
    "    evaluation.set_test_args([graph, test_l_mask])\n",
    "    evaluation.set_gw_args([graph, test_gw_mask])\n",
    "    \n",
    "    df = evaluation.get_df_metrics(model)\n",
    "    dataframes.append(df)\n",
    "for df in dataframes:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce472c7",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edee9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(graph, mask):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        logits = model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "        scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "        scores = torch.unsqueeze(scores, 0)\n",
    "        proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "    return torch.transpose(proba_predict, 0, 1)\n",
    "\n",
    "def predict(graph, mask):\n",
    "    pred = torch.round(predict_proba(graph, mask)[:, 1])\n",
    "    return pred\n",
    "\n",
    "model.predict_proba = predict_proba\n",
    "model.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da76ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "graph = graph.cpu()\n",
    "model = model.cpu()\n",
    "evaluation = Evaluation(y_test, y_gw_test, X_test, X_gw_test)\n",
    "evaluation.set_test_args([graph, test_l_mask])\n",
    "evaluation.set_gw_args([graph, test_gw_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_confusion_matrix(model)\n",
    "evaluation.get_df_metrics(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68c854",
   "metadata": {},
   "source": [
    "## Maintain connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6dea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def sleeper(minutes):\n",
    "    for i in range(minutes):\n",
    "        time.sleep(60)\n",
    "        print(\"Still sleeping and waiting for you so you dont have to reconnect everything\")\n",
    "sleeper(60*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5addcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
