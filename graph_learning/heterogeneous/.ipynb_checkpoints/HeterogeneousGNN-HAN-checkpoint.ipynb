{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18b73dd",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431abf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.insert(0, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c929aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/graph_learning/heterogeneous/../../dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Assessable data are 528101 cases and 1015074 CBCs\n",
      "Control data are 527038 cases and 1013548 CBCs\n",
      "Sepsis data are 1488 cases and 1526 CBCs\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "Testing: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/graph_learning/heterogeneous/../../dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 365794, Sepsis: 490\n",
      "Assessable data are 180494 cases and 366284 CBCs\n",
      "Control data are 180157 cases and 365794 CBCs\n",
      "Sepsis data are 472 cases and 490 CBCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/sbc/graph_learning/heterogeneous/../../dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 437629, Sepsis: 448\n",
      "Assessable data are 157922 cases and 438077 CBCs\n",
      "Control data are 180157 cases and 437629 CBCs\n",
      "Sepsis data are 438 cases and 448 CBCs\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"../../extdata/sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94724e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "y_train = torch.tensor(data_analysis.get_y_train(), dtype=torch.long)\n",
    "X_train = torch.tensor(data_analysis.get_X_train(), dtype=torch.float)\n",
    "\n",
    "y_test = torch.tensor(data_analysis.get_y_test(), dtype=torch.long)\n",
    "X_test = torch.tensor(data_analysis.get_X_test(), dtype=torch.float)\n",
    "\n",
    "y_gw_test = torch.tensor(data_analysis.get_y_gw(), dtype=torch.long)\n",
    "X_gw_test = torch.tensor(data_analysis.get_X_gw(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e6eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = torch.concat((y_train, y_test, y_gw_test))\n",
    "X_all = torch.concat((X_train, X_test, X_gw_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f90b6",
   "metadata": {},
   "source": [
    "## Train/Validation/Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29cee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_indices_like(tensor):\n",
    "    return torch.ones((tensor.shape[0])).type(torch.bool)\n",
    "\n",
    "def false_indices_like(tensor):\n",
    "    return torch.zeros((tensor.shape[0])).type(torch.bool)\n",
    "\n",
    "def split(train_features):\n",
    "    tensor = true_indices_like(train_features)\n",
    "    max_index = round(tensor.shape[0] * 0.8)\n",
    "    train = torch.zeros(tensor.shape[0])\n",
    "    train[:max_index] = 1\n",
    "    \n",
    "    val = torch.zeros(tensor.shape[0])\n",
    "    val[max_index:] = 1\n",
    "    return{\n",
    "        \"train\": train.type(torch.bool),\n",
    "        \"val\":val.type(torch.bool)\n",
    "    }\n",
    "train_data = split(X_train)\n",
    "\n",
    "train_mask = torch.concat((train_data[\"train\"], false_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "val_mask = torch.concat((train_data[\"val\"], false_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "test_l_mask = torch.concat((false_indices_like(X_train), true_indices_like(X_test), false_indices_like(X_gw_test)))\n",
    "test_gw_mask = torch.concat((false_indices_like(X_train), false_indices_like(X_test), true_indices_like(X_gw_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360310be",
   "metadata": {},
   "source": [
    "## Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c59b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dataAnalysis.Constants import *\n",
    "\n",
    "def to_tensor(df):\n",
    "    return torch.Tensor(list(df.values))\n",
    "\n",
    "def get_quantil_tensor():\n",
    "    number_of_quantiles = 10\n",
    "    q = torch.arange(0, 1, 1/number_of_quantiles)\n",
    "    q = torch.Tensor([0.025,0.05, 0.1, 0.2, 0.35, 0.5, 0.65, 0.8, 0.9, 0.95, 0.975, 1])\n",
    "    return q\n",
    "\n",
    "def get_quantiles(tensor):\n",
    "    q = get_quantil_tensor() \n",
    "    return torch.quantile(tensor, q)\n",
    "\n",
    "def normalize(tensor):\n",
    "    mean = torch.mean(tensor, dim = 0)\n",
    "    std = torch.std(tensor, dim = 0)\n",
    "    mean_diff = tensor - mean\n",
    "    return mean_diff / std\n",
    "\n",
    "def get_quantile_indices(tensor, quantiles):\n",
    "    quantile_indices = []\n",
    "    all_indices = torch.Tensor([])\n",
    "    prev_quantile = -1e-4\n",
    "    indices_control = torch.arange(0, tensor.shape[0])\n",
    "    for i in range(quantiles.nelement()):\n",
    "        indices_u = (tensor > prev_quantile).nonzero(as_tuple=True)[0] # (tensor > prev_quantile and tensor <= quantiles[i]).nonzero(as_tuple=True)[0]\n",
    "        indices_o = (tensor <= quantiles[i]).nonzero(as_tuple=True)[0]\n",
    "        indices = torch.from_numpy(np.intersect1d(indices_u, indices_o))\n",
    "        quantile_indices.append(indices)\n",
    "        prev_quantile = quantiles[i]\n",
    "    return quantile_indices\n",
    "\n",
    "\n",
    "def create_node_features(node_type, quantiles):\n",
    "    nodes_features = []\n",
    "    prev_quantile = torch.Tensor([0])\n",
    "    for i in range(quantiles.nelement()):\n",
    "        node_features = [prev_quantile.item(), quantiles[i].item(), get_quantil_tensor()[i].item()]\n",
    "        prev_quantile = quantiles[i]\n",
    "        nodes_features.append(node_features)\n",
    "    return torch.tensor(nodes_features)\n",
    "\n",
    "def create_edge_features_to_patient(node_type, quantile_indices):\n",
    "    source_edge_list = None\n",
    "    target_edge_list = None\n",
    "    for i in range(len(quantile_indices)):\n",
    "        target_edges = torch.ones((quantile_indices[i].nelement())) * i\n",
    "        source_edges = quantile_indices[i]\n",
    "        source_edge_list = source_edges if source_edge_list is None else torch.concat((source_edge_list, source_edges))\n",
    "        target_edge_list = target_edges if target_edge_list is None else torch.concat((target_edge_list, target_edges))\n",
    "    return torch.stack([source_edge_list, target_edge_list]).type(torch.long)\n",
    "\n",
    "def add_features_and_edges(graph):\n",
    "    for i, feature_name in enumerate(FEATURES):\n",
    "        if feature_name not in [HGB_COLUMN_NAME, WBC_COLUMN_NAME, RBC_COLUMN_NAME, MCV_COLUMN_NAME, PLT_COLUMN_NAME]:\n",
    "            continue\n",
    "        feature_vector = graph[PATIENT_NAME].x[:, i]\n",
    "        node_quantiles = get_quantiles(feature_vector)\n",
    "        quantile_indices = get_quantile_indices(feature_vector, node_quantiles)\n",
    "        graph[feature_name].x = create_node_features(feature_name, node_quantiles)\n",
    "        graph[PATIENT_NAME, EDGE_TYPE, feature_name].edge_index = create_edge_features_to_patient(feature_name, quantile_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b8b2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def normalize(tensor):\n",
    "    mean = torch.mean(tensor, dim = 0)\n",
    "    std = torch.std(tensor, dim = 0)\n",
    "    mean_diff = tensor - mean\n",
    "    return mean_diff / std\n",
    "\n",
    "graph = HeteroData()\n",
    "graph[PATIENT_NAME].x = X_all\n",
    "add_features_and_edges(graph)\n",
    "graph[PATIENT_NAME].y = y_all\n",
    "graph[PATIENT_NAME].train_mask = train_mask\n",
    "graph[PATIENT_NAME].val_mask = val_mask\n",
    "graph[PATIENT_NAME].test_l_mask = test_l_mask\n",
    "graph[PATIENT_NAME].test_gw_mask = test_gw_mask\n",
    "graph = T.ToUndirected()(graph)\n",
    "graph[PATIENT_NAME].x = normalize(graph[PATIENT_NAME].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e380f8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mPATIENT\u001b[0m={\n",
       "    x=[1819435, 7],\n",
       "    y=[1819435],\n",
       "    train_mask=[1819435],\n",
       "    val_mask=[1819435],\n",
       "    test_l_mask=[1819435],\n",
       "    test_gw_mask=[1819435]\n",
       "  },\n",
       "  \u001b[1mHGB\u001b[0m={ x=[12, 3] },\n",
       "  \u001b[1mWBC\u001b[0m={ x=[12, 3] },\n",
       "  \u001b[1mRBC\u001b[0m={ x=[12, 3] },\n",
       "  \u001b[1mMCV\u001b[0m={ x=[12, 3] },\n",
       "  \u001b[1mPLT\u001b[0m={ x=[12, 3] },\n",
       "  \u001b[1m(PATIENT, HAS, HGB)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(PATIENT, HAS, WBC)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(PATIENT, HAS, RBC)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(PATIENT, HAS, MCV)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(PATIENT, HAS, PLT)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(HGB, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(WBC, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(RBC, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(MCV, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 1819435] },\n",
       "  \u001b[1m(PLT, rev_HAS, PATIENT)\u001b[0m={ edge_index=[2, 1819435] }\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e41cf",
   "metadata": {},
   "source": [
    "### Model defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfcec79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HANConv, HGTConv, FiLMConv, Linear\n",
    "import torch\n",
    "from dataAnalysis.Constants import FEATURES\n",
    "\n",
    "\n",
    "class HetGraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, metadata,node_types, hidden_dim = 128, out_channels = 1):\n",
    "        super(HetGraphNeuralNetwork, self).__init__()\n",
    "                 \n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_dim)\n",
    "        self.lin_end = Linear(-1, out_channels)\n",
    "        self.conv1 = HANConv(-1,hidden_dim, metadata)\n",
    "        self.conv_end = HANConv(hidden_dim, hidden_dim, metadata)\n",
    "\n",
    "\n",
    "    def forward(self, x_dict, edge_index):\n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "        x_dict = self.conv1(x_dict, edge_index)\n",
    "        x_dict = self.conv_end(x_dict, edge_index)\n",
    "        x_dict[PATIENT_NAME] = self.lin_end(x_dict[PATIENT_NAME])\n",
    "        \n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e56db",
   "metadata": {},
   "source": [
    "## Shift data to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97de16f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/miniconda3/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shifted to the device cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "graph = graph.to(device)\n",
    "\n",
    "sepsis_cases = torch.count_nonzero(graph[PATIENT_NAME].y[train_mask])\n",
    "control_cases = graph[PATIENT_NAME].y[train_mask].size(dim=0) - sepsis_cases\n",
    "WEIGHT = (control_cases / (sepsis_cases + 1e-10))\n",
    "WEIGHT = WEIGHT.to(device)\n",
    "\n",
    "print(\"Data shifted to the device \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a6b14",
   "metadata": {},
   "source": [
    "## Model-Wrapper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96602f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.nn import to_hetero\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, graph):\n",
    "        self.LEARNING_RATE = 3e-4\n",
    "        self.MAX_EPOCHS = 10000\n",
    "        \n",
    "        self.graph = graph\n",
    "        model = HetGraphNeuralNetwork(graph.metadata(),graph.node_types, hidden_dim = 64, out_channels=1) \n",
    "#         model = GraphNeuralNetwork(hidden_dim = 32, out_channels=1)         \n",
    "#         model = to_hetero(model, graph.metadata(), aggr='sum')\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.LEARNING_RATE,betas=(0.9, 0.999), eps=1e-08)\n",
    "        \n",
    "        self.last_loss = 0\n",
    "        self.increased_loss = 0\n",
    "        self.BREAKING_THRESHOLD = 10    \n",
    "        self.val_loss = []\n",
    "        self.train_loss = []\n",
    "    \n",
    "    def validate(self):\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            out = self.model(self.graph.x_dict, self.graph.edge_index_dict)[PATIENT_NAME]\n",
    "            loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[val_mask]), self.graph[PATIENT_NAME].y[val_mask].type(torch.float32),\n",
    "                                                      pos_weight=WEIGHT)\n",
    "            self.val_loss.append(loss.item())\n",
    "            if loss.item() > self.last_loss:\n",
    "                self.increased_loss += 1\n",
    "            else:\n",
    "                self.increased_loss = 0\n",
    "            self.last_loss = loss.item()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in tqdm(range(self.MAX_EPOCHS)):\n",
    "#             print(epoch)\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            out = self.model(self.graph.x_dict, self.graph.edge_index_dict)[PATIENT_NAME]\n",
    "            loss = F.binary_cross_entropy_with_logits(torch.squeeze(out[train_mask]), self.graph[PATIENT_NAME].y[train_mask].type(torch.float32),\n",
    "                                                      pos_weight=WEIGHT)\n",
    "            self.train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.validate() \n",
    "\n",
    "            if self.increased_loss >= self.BREAKING_THRESHOLD:\n",
    "                print(f\"Breaked at {str(epoch)}\")\n",
    "                break\n",
    "                \n",
    "            \n",
    "    def get_model(self):\n",
    "        return self.model    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.epochs, self.train_loss, 'g', label='Training loss')\n",
    "        plt.plot(self.epochs, self.val_loss, 'y', label='Validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc9815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGT-Conv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd86d29de188436ba4d5b6e871eccdb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_wrapper = ModelWrapper(graph)\n",
    "import time \n",
    "print(\"HAN-Conv\")\n",
    "start = time.time()\n",
    "model_wrapper.train()\n",
    "print(time.time() - start )\n",
    "model = model_wrapper.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47edb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab05a48",
   "metadata": {},
   "source": [
    "## Error evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc76c44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9891d803d3491c9761289251a42d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4528789520263672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     evaluation\u001b[38;5;241m.\u001b[39mset_test_args([graph, test_l_mask])\n\u001b[1;32m     36\u001b[0m     evaluation\u001b[38;5;241m.\u001b[39mset_gw_args([graph, test_gw_mask])\n\u001b[0;32m---> 38\u001b[0m     df \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mget_df_metrics(model)\n\u001b[1;32m     39\u001b[0m     dataframes\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m dataframes:\n",
      "File \u001b[0;32m~/git/sbc/graph_learning/../dataAnalysis/Metrics.py:45\u001b[0m, in \u001b[0;36mEvaluation.get_df_metrics\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_df_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, model):\n\u001b[0;32m---> 45\u001b[0m     test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_args) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test)\n\u001b[1;32m     46\u001b[0m     test_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_args) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test)\n\u001b[1;32m     47\u001b[0m     gw_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgw_args) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgw_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_gw_test)\n",
      "Cell \u001b[0;32mIn[26], line 24\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(graph, mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(graph, mask):\n\u001b[0;32m---> 24\u001b[0m     pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mround(predict_proba(graph, mask)[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "Cell \u001b[0;32mIn[26], line 17\u001b[0m, in \u001b[0;36mpredict_proba\u001b[0;34m(graph, mask)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 17\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(graph\u001b[38;5;241m.\u001b[39mx_dict, graph\u001b[38;5;241m.\u001b[39medge_index_dict)[PATIENT_NAME]\n\u001b[1;32m     18\u001b[0m     scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(torch\u001b[38;5;241m.\u001b[39msqueeze(logits[mask]))\n\u001b[1;32m     19\u001b[0m     scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(scores, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch/fx/graph_module.py:662\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_call(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch/fx/graph_module.py:271\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_call(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls, obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.5:30\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     28\u001b[0m conv1__PATIENT1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mHGB__rev_HAS__PATIENT((x__HGB, x__PATIENT), edge_index__HGB__rev_HAS__PATIENT);  x__HGB \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     29\u001b[0m conv1__PATIENT2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mWBC__rev_HAS__PATIENT((x__WBC, x__PATIENT), edge_index__WBC__rev_HAS__PATIENT);  x__WBC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m conv1__PATIENT3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mRBC__rev_HAS__PATIENT((x__RBC, x__PATIENT), edge_index__RBC__rev_HAS__PATIENT);  x__RBC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     31\u001b[0m conv1__PATIENT4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mMCV__rev_HAS__PATIENT((x__MCV, x__PATIENT), edge_index__MCV__rev_HAS__PATIENT);  x__MCV \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     32\u001b[0m conv1__PATIENT5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mPLT__rev_HAS__PATIENT((x__PLT, x__PATIENT), edge_index__PLT__rev_HAS__PATIENT);  x__PLT \u001b[38;5;241m=\u001b[39m x__PATIENT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch_geometric/nn/conv/gatv2_conv.py:250\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    245\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe usage of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimultaneously is currently not yet supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseTensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m form\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39m(x_l, x_r), edge_attr\u001b[38;5;241m=\u001b[39medge_attr,\n\u001b[1;32m    251\u001b[0m                      size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    253\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:467\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 467\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmsg_kwargs)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    469\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "number_of_iterations = 100\n",
    "dataframes = []\n",
    "for i in range(number_of_iterations):\n",
    "    graph = graph.to(device)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    model_wrapper = ModelWrapper(graph)\n",
    "    model_wrapper.train()\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    def predict_proba(graph, mask):\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            logits = model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "            scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "            scores = torch.unsqueeze(scores, 0)\n",
    "            proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "        return torch.transpose(proba_predict, 0, 1)\n",
    "\n",
    "    def predict(graph, mask):\n",
    "        pred = torch.round(predict_proba(graph, mask)[:, 1])\n",
    "        return pred\n",
    "    model = model_wrapper.get_model()\n",
    "    model.predict_proba = predict_proba\n",
    "    model.predict = predict\n",
    "    \n",
    "    from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "    graph = graph.cpu()\n",
    "    model = model.cpu()\n",
    "    evaluation = Evaluation(y_test, y_gw_test, X_test, X_gw_test)\n",
    "    evaluation.set_test_args([graph, test_l_mask])\n",
    "    evaluation.set_gw_args([graph, test_gw_mask])\n",
    "    \n",
    "    df = evaluation.get_df_metrics(model)\n",
    "    dataframes.append(df)\n",
    "for df in dataframes:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce472c7",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edee9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(graph, mask):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        logits = model(graph.x_dict, graph.edge_index_dict)[PATIENT_NAME]\n",
    "        scores = torch.sigmoid(torch.squeeze(logits[mask]))\n",
    "        scores = torch.unsqueeze(scores, 0)\n",
    "        proba_predict = torch.concat((1- scores, scores), dim = 0)\n",
    "    return torch.transpose(proba_predict, 0, 1)\n",
    "\n",
    "def predict(graph, mask):\n",
    "    pred = torch.round(predict_proba(graph, mask)[:, 1])\n",
    "    return pred\n",
    "\n",
    "model.predict_proba = predict_proba\n",
    "model.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da76ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Metrics import Evaluation\n",
    "\n",
    "graph = graph.cpu()\n",
    "model = model.cpu()\n",
    "evaluation = Evaluation(y_test, y_gw_test, X_test, X_gw_test)\n",
    "evaluation.set_test_args([graph, test_l_mask])\n",
    "evaluation.set_gw_args([graph, test_gw_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_confusion_matrix(model)\n",
    "evaluation.get_df_metrics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a3ad29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
