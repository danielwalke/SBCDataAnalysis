{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "490236b4-5f2d-47a6-abfa-40f411863e71",
   "metadata": {},
   "source": [
    "#### We re-start our transformer analysis here\n",
    "#### First, some assumptions or goals for this script:\n",
    " - training usinng SGD -> later batching\n",
    " - pad time series to maximum length with value -1 - first backward padding -> NOTE: forward padding will most probably cancel out the feature-induces bias\n",
    " - mask values which are -1\n",
    " - custom transformer\n",
    " - first information exchange over all measurements in a sequence (easier and should give the best scores)\n",
    " - Set manual seed for reproducibility and improvements over diverse hyperparams\n",
    " - first only one block, one head, without dropout (check validation loss and training loss diff after pre-def. intervals), without layernorm without ffd?\n",
    " - Now 1 block with ffd, 2 heads, batching, layer norm and pos encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18229354-cd3e-43bd-a34c-8bdd0e220f75",
   "metadata": {},
   "source": [
    "## Dataset loader and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20ee0d6-e85e-4935-a58c-fbb3f76452f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "import torch\n",
    " \n",
    "data = pd.read_csv(r\"../sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8784566-1c9f-4f64-814a-6afaa149ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((data_analysis.get_training_data(), data_analysis.get_testing_data()))\n",
    "max_Id = data[\"Id\"].unique().max()\n",
    "gw_data = data_analysis.get_gw_testing_data().copy(deep=True)\n",
    "gw_data = gw_data.assign(Id=lambda x: x.Id + max_Id)\n",
    "data = pd.concat((data, gw_data))\n",
    "data = data.sort_values([\"Id\", \"Time\"])\n",
    "data = data.reset_index(drop=True)\n",
    "popped_index = data.pop(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517e270b-b2e4-4287-a297-37155c5cbd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Constants import SEX_CATEGORY_COLUMN_NAME, SEX_COLUMN_NAME, FEATURES, LABEL_COLUMN_NAME\n",
    "\n",
    "data[SEX_CATEGORY_COLUMN_NAME] = data.loc[:, SEX_COLUMN_NAME] ==\"W\"\n",
    "\n",
    "data[SEX_CATEGORY_COLUMN_NAME] = data[SEX_CATEGORY_COLUMN_NAME].astype(\"int8\")\n",
    "data[\"Label\"] = data[\"Label\"] == \"Sepsis\"\n",
    "data[\"Label\"] = data[\"Label\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d6c76-3460-47ff-bbe1-e6dcc876b3f6",
   "metadata": {},
   "source": [
    "## Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6921df7b-52bf-4fbf-b464-312158cff5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 79.  ,   0.  ,   8.1 , ...,   4.36,  86.  , 167.  ],\n",
       "       [ 35.  ,   0.  ,  10.6 , ...,   6.02,  79.9 , 199.  ],\n",
       "       [ 47.  ,   1.  ,   8.7 , ...,   4.37,  89.9 , 298.  ],\n",
       "       ...,\n",
       "       [ 32.  ,   1.  ,   7.2 , ...,   3.87,  87.9 , 221.  ],\n",
       "       [ 47.  ,   0.  ,   8.3 , ...,   4.08,  91.9 , 148.  ],\n",
       "       [ 47.  ,   0.  ,   8.9 , ...,   4.39,  92.3 , 150.  ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"Set\"] == \"Training\", FEATURES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed5cee5b-a4cd-422e-8eab-a54b1902535b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data.loc[data[\"Set\"] == \"Training\", FEATURES].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e996e288-96e8-44e0-8131-ae790eb0dace",
   "metadata": {},
   "source": [
    "## Padding to max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f06201-e1ca-43bf-8bbd-8f4c7535267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_grouped_data = data.groupby(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70a5569-3843-46ba-9beb-61b8f0207504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f26d604eae46238920deac0ae93517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/866517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "max_len = 0\n",
    "for id, data_group in tqdm(id_grouped_data):\n",
    "    max_len = max(max_len, data_group.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef818a9-caac-4f72-977f-677537e35674",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train_ids = data.loc[data[\"Set\"] == \"Training\", \"Id\"].unique()\n",
    "max_train_idx = int(len(unique_train_ids)*.8)\n",
    "val_ids = unique_train_ids[max_train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f491cf-ef73-4245-9159-37953f0ae1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a490625dde4bf28de385dfb84fb996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/866517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pad_value = -10.0\n",
    "TRAIN = \"train\"\n",
    "GW = \"gw_test\"\n",
    "TEST = \"test\"\n",
    "VAL = \"val\"\n",
    "\n",
    "features = dict({})\n",
    "features[TRAIN] = []\n",
    "features[VAL] = []\n",
    "features[TEST] = []\n",
    "features[GW] = []\n",
    "\n",
    "labels = dict({})\n",
    "labels[TRAIN] = []\n",
    "labels[VAL] = []\n",
    "labels[TEST] = []\n",
    "labels[GW] = []\n",
    "\n",
    "for id, data_group in tqdm(id_grouped_data):\n",
    "    assert data_group[\"Set\"].unique().shape[0] == 1\n",
    "    assert data_group[\"Center\"].unique().shape[0] == 1\n",
    "\n",
    "    features_scaled = scaler.transform(data_group[FEATURES].values)\n",
    "\n",
    "    padded_features = np.pad(features_scaled, ((0, max_len - data_group.shape[0]), (0,0)), mode='constant', constant_values=pad_value)\n",
    "    padded_labels = np.pad(data_group[LABEL_COLUMN_NAME].values, ((0, max_len - data_group.shape[0])), mode='constant', constant_values=pad_value)\n",
    "    \n",
    "    first_el = data_group.iloc[0, :]\n",
    "    if first_el[\"Set\"] == \"Training\":\n",
    "        if first_el[\"Id\"] in val_ids:\n",
    "            features[VAL].append(padded_features)\n",
    "            labels[VAL].append(padded_labels)\n",
    "            continue\n",
    "        if first_el[\"Id\"] not in val_ids:\n",
    "            features[TRAIN].append(padded_features)\n",
    "            labels[TRAIN].append(padded_labels)\n",
    "            continue\n",
    "    if first_el[\"Set\"] == \"Validation\":\n",
    "        if first_el[\"Center\"] == \"Greifswald\":\n",
    "            features[GW].append(padded_features)\n",
    "            labels[GW].append(padded_labels)\n",
    "            continue\n",
    "        if first_el[\"Center\"] == \"Leipzig\":\n",
    "            features[TEST].append(padded_features)\n",
    "            labels[TEST].append(padded_labels)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bdac22-9b02-4077-a7f4-4db4a0ab5050",
   "metadata": {},
   "source": [
    "## Seed and hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c08009fa-f788-40d9-9a15-6ad7c5bb44c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "n_embd = len(FEATURES)\n",
    "head_size = 16\n",
    "dropout = 0\n",
    "out_dim = 1 #binary \n",
    "device = torch.device(\"cuda:0\") #torch.device(\"cuda:2\") #torch.device(\"cuda:2\")\n",
    "WEIGHT = 664\n",
    "lr = 1e-2\n",
    "wd = 0\n",
    "n_blocks = 2\n",
    "n_heads = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92127f1f-f8bf-41b7-be8f-aa85d0e3eba3",
   "metadata": {},
   "source": [
    "## Batching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "270f681d-a1aa-4c29-99aa-b31cd962b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Data(Dataset):\n",
    "    # Constructor\n",
    "    def __init__(self,X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.len = self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "455e9028-81aa-4f8f-9e1d-3c8493b21e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loader = dict({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a9c611-0cae-4f7d-983c-6bccab281d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_loader(set_name):\n",
    "    global bitch_loader, sets, labels\n",
    "    dataset = Data(torch.from_numpy(np.array(features[set_name])).type(torch.float).to(device), torch.from_numpy(np.array(labels[set_name])).type(torch.float).to(device))\n",
    "    loader = DataLoader(dataset=dataset, batch_size=500) #max is 100_000\n",
    "    batch_loader[set_name] = loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d221dbe-a7c3-414f-a23e-f390f551e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_loader(TRAIN)\n",
    "add_loader(VAL)\n",
    "add_loader(GW)\n",
    "add_loader(TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c638073-48af-4513-81f7-87f8729c4e14",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c1e7ff0-892d-462b-8096-d78f851db971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "torch.manual_seed(42)\n",
    "class Head(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, head_size, dropout):\n",
    "        super(Head, self).__init__()\n",
    "\n",
    "        self.query = torch.nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.key = torch.nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.value = torch.nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, ignore_mask):\n",
    "        B,T,C = x.shape\n",
    "        \n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        w = q@k.transpose(-2,-1)\n",
    "        w = w* C**-.5\n",
    "        w[ignore_mask] = float(\"-inf\")\n",
    "        w = torch.nan_to_num(torch.softmax(w, dim = -1))\n",
    "        \n",
    "        w = self.dropout(w)    \n",
    "        out = w@v\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d97973e4-40a2-4485-bb90-f570737023f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, num_heads, head_size, dropout):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        head_size = n_embd // n_heads\n",
    "        self.heads = torch.nn.ModuleList([Head(n_embd, head_size, dropout) for _ in range(num_heads)])\n",
    "        self.proj = torch.nn.Linear(head_size*num_heads, n_embd)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, ignore_mask):\n",
    "        out = torch.cat([h(x, ignore_mask) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80bcfd44-adf4-49a3-8961-19de38b23af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, dropout):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.lin = torch.nn.Linear(n_embd, 4*n_embd)\n",
    "        self.proj = torch.nn.Linear(4*n_embd, n_embd)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e49b754-6ee2-4fac-a1a8-6a17a0a3b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(torch.nn.Module):\n",
    "    def __init__(self, n_embd, n_heads, dropout):\n",
    "        super(Block, self).__init__()\n",
    "        head_size = n_embd // n_heads\n",
    "\n",
    "        self.sa_heads = MultiHeadAttention(n_embd, n_heads, head_size, dropout)\n",
    "        self.ffwd = FeedForward(n_embd, dropout)\n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(n_embd)\n",
    "        self.layer_norm_2 = torch.nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x, ignore_mask):\n",
    "        x = x + self.sa_heads(self.layer_norm_1(x), ignore_mask)\n",
    "        x = x + self.ffwd(self.layer_norm_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21724db2-ec23-4f55-8416-315cded98d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, n_embd, n_heads, dropout, n_blocks):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.lin_input = nn.Linear(input_dim, n_embd)\n",
    "        self.pos_embedding_table = nn.Embedding(max_len, n_embd)\n",
    "        \n",
    "        self.blocks = []\n",
    "        for _ in range(n_blocks):\n",
    "            self.blocks.append(Block(n_embd, n_heads, dropout).to(device)) #nn.Sequential(*[Block(n_embd, n_heads, dropout) for _ in range(n_blocks)], nn.LayerNorm(n_embd))\n",
    "        # self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        # self.sa = Head(head_size)\n",
    "        self.lin = nn.Linear(n_embd, out_dim)\n",
    "\n",
    "    def forward(self, x, targets = None):\n",
    "        B, T, C = x.shape\n",
    "        pad_mask = (x != pad_value).type(torch.float)\n",
    "        ignore_mask = torch.bmm(pad_mask, pad_mask.transpose(-2,-1))\n",
    "        ignore_mask = ignore_mask == 0\n",
    "        \n",
    "        x = self.lin_input(x)\n",
    "        pos_emb = self.pos_embedding_table(torch.arange(T, device = device))\n",
    "        x = x + pos_emb\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, ignore_mask)\n",
    "        logits = self.lin(x)\n",
    "        logits_mask = ignore_mask.sum(-1) != max_len\n",
    "        \n",
    "        return logits, logits_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c075cc-1333-4706-85ed-11b6ab0e3acc",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aad2bf23-22df-4204-ae11-8ff78ae5f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, set_name):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        acc_loss = 0\n",
    "        batch_size = 0\n",
    "\n",
    "        for i, (x,y) in enumerate(batch_loader[set_name]):\n",
    "            B,_,_ = x.shape\n",
    "            logits, logits_mask = model(x)\n",
    "        \n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(logits[logits_mask].squeeze(-1), y[logits_mask], pos_weight=torch.tensor(WEIGHT))\n",
    "            acc_loss += loss.item()\n",
    "            batch_size += B\n",
    "    return acc_loss / batch_size        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c607fedb-b8e6-4104-a818-778d1f00be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss_sets(model):\n",
    "    losses = dict({})\n",
    "    for set_name in features.keys():\n",
    "        if set_name != VAL:\n",
    "            continue\n",
    "        loss = evaluate_loss(model, set_name)\n",
    "        losses[set_name] = loss\n",
    "        print(f\"Loss of {set_name}: {loss:.5f}\") \n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bb27c79-5e05-4180-8181-b2be847ca22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "def evaluate_auroc(model, set_name):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        \n",
    "        logits_list = []\n",
    "        label_list = []\n",
    "\n",
    "        batch_size = 0\n",
    "        for i, (x,y) in enumerate(batch_loader[set_name]):\n",
    "            B,_,_ = x.shape\n",
    "            logits, logits_mask = model(x)\n",
    "\n",
    "            logits_list.extend(logits[logits_mask].squeeze(-1).tolist())\n",
    "            label_list.extend(y[logits_mask].squeeze(-1).tolist())\n",
    "            batch_size += B\n",
    "    auroc = roc_auc_score(np.array(label_list), torch.sigmoid(torch.tensor(logits_list)).numpy())\n",
    "    return auroc        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82d13cdd-c7c2-404b-80be-e31f4362e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_auroc_sets(model):\n",
    "    for set_name in features.keys():\n",
    "        if set_name == TRAIN:\n",
    "            continue\n",
    "        auroc = evaluate_auroc(model, set_name)\n",
    "        print(f\"AUROC of {set_name}: {auroc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ef05b-7e7a-4a86-8f8e-31b46d9207c2",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2e6f14e-bba3-4066-9aa8-5e8b36d55f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "input_dim, n_embd, n_heads, dropout, n_blocks = len(FEATURES), 8, 4, 0.0, 1\n",
    "model = TransformerModel(input_dim, n_embd, n_heads, dropout, n_blocks).to(device)\n",
    "optim= torch.optim.Adam(model.parameters(), lr = lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbfb5f8e-7250-4872-a7cc-fe0e6780d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# evaluate_auroc_sets(TransformerModel(input_dim, n_embd, n_heads, dropout, n_blocks).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "18781ac1-dfc7-4784-b8a6-e8159f74fe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of train: 0.00393\n",
      "Loss of val: 0.00416\n",
      "Loss of test: 0.00368\n",
      "Loss of gw_test: 0.00305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b95e8e22894acfa690c222bd851fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of train: 0.00204\n",
      "Loss of val: 0.00213\n",
      "Loss of test: 0.00201\n",
      "Loss of gw_test: 0.00209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae9b250c4104fdfa728ed1baeb11e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of train: 0.00191\n",
      "Loss of val: 0.00203\n",
      "Loss of test: 0.00189\n",
      "Loss of gw_test: 0.00198\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "evaluate_loss_sets(model)\n",
    "last_val_loss = None\n",
    "for epoch in range(5):#5\n",
    "    for i, (x,y) in tqdm(enumerate(batch_loader[TRAIN])):\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        logits, logits_mask = model(x)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(logits[logits_mask].squeeze(-1), y[logits_mask], pos_weight=torch.tensor(WEIGHT))\n",
    "            \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    losses = evaluate_loss_sets(model)\n",
    "    if last_val_loss and last_val_loss <= losses[VAL]:\n",
    "        print(epoch)\n",
    "        break\n",
    "    last_val_loss = losses[VAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "ee88475f-5a55-4ecf-b1aa-8a105a39e15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC of train: 0.86154\n",
      "AUROC of val: 0.85416\n",
      "AUROC of test: 0.84546\n",
      "AUROC of gw_test: 0.78312\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "evaluate_auroc_sets(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "79d22442-c0c9-48ef-b194-e8f55aa60295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0001 , 0.00505, 0.01   ])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.linspace(1e-4, 1e-2, 3, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f21d9-8153-441a-97de-b771f12914ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c1b08ab0704080be4fc5db1d7af35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8ce52e850744d89c5828b114aaac93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00201\n",
      "[0.002008010834815812]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9ed56dde2a4f38b2dfc5bc2b2f6f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00197\n",
      "[0.002008010834815812, 0.001970542478204296]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d2ecc67e1446818ef2f17e481c733c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00196\n",
      "[0.002008010834815812, 0.001970542478204296, 0.0019594985531473505]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef1215205ff4237a552c1a26c916222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00197\n",
      "[0.002008010834815812, 0.001970542478204296, 0.0019594985531473505, 0.0019670081706773955]\n",
      "Break at 3\n",
      "AUROC of val: 0.86929\n",
      "AUROC of test: 0.86974\n",
      "AUROC of gw_test: 0.83587\n",
      "Currently best params: \n",
      "{'block_size': 2, 'dropout': 0, 'lr': 0.01, 'n_embd': 16, 'num_heads': 2}\n",
      "260.8024691358024 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4871110ec5104dd791473722f3b197ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00192\n",
      "[0.0019234837257271016]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e6d95af37649f9a1cddf104df96540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00188\n",
      "[0.0019234837257271016, 0.0018762511772997068]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417529372ee94894beee35f7abbf0535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00193\n",
      "[0.0019234837257271016, 0.0018762511772997068, 0.0019346802461463444]\n",
      "Break at 2\n",
      "AUROC of val: 0.87549\n",
      "AUROC of test: 0.87140\n",
      "AUROC of gw_test: 0.83051\n",
      "Currently best params: \n",
      "{'block_size': 2, 'dropout': 0, 'lr': 0.01, 'n_embd': 16, 'num_heads': 4}\n",
      "260.8024691358024 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981437bdc9444501991655e581e1cdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00189\n",
      "[0.0018897349890694124]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3828fe7d9345d599c550bea57907b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00192\n",
      "[0.0018897349890694124, 0.0019172469936279148]\n",
      "Break at 1\n",
      "AUROC of val: 0.87371\n",
      "AUROC of test: 0.86989\n",
      "AUROC of gw_test: 0.80500\n",
      "Currently best params: \n",
      "{'block_size': 2, 'dropout': 0, 'lr': 0.01, 'n_embd': 16, 'num_heads': 8}\n",
      "260.8024691358024 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d094a6cd374a3c9bdc79605f3a368f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00189\n",
      "[0.0018881039238593672]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a5ba4b42904a29a8f174d2129176d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00195\n",
      "[0.0018881039238593672, 0.0019514727350485401]\n",
      "Break at 1\n",
      "AUROC of val: 0.87353\n",
      "AUROC of test: 0.86566\n",
      "AUROC of gw_test: 0.81821\n",
      "260.8024691358024 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250133edd77648e0af8399136f3e134e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00182\n",
      "[0.0018247517275474582]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598239dcdafd43dda49aa9a6580224b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00190\n",
      "[0.0018247517275474582, 0.0018990722938877855]\n",
      "Break at 1\n",
      "AUROC of val: 0.88264\n",
      "AUROC of test: 0.87080\n",
      "AUROC of gw_test: 0.82770\n",
      "Currently best params: \n",
      "{'block_size': 2, 'dropout': 0, 'lr': 0.01, 'n_embd': 32, 'num_heads': 4}\n",
      "260.8024691358024 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc3f933e45b4b4699ceeb61aee5af9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00179\n",
      "[0.0017926676808823318]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b857423c1e4647c98f732bff0685ee57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00190\n",
      "[0.0017926676808823318, 0.0018993113098056407]\n",
      "Break at 1\n",
      "AUROC of val: 0.88471\n",
      "AUROC of test: 0.86929\n",
      "AUROC of gw_test: 0.83221\n",
      "260.8024691358024 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e06e242a37244c382b0a6e1e6071408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00180\n",
      "[0.0018036911257131303]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2d86dd315349988af4c03e95842ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val: 0.00194\n",
      "[0.0018036911257131303, 0.001936771149331527]\n",
      "Break at 1\n",
      "AUROC of val: 0.88261\n",
      "AUROC of test: 0.86949\n",
      "AUROC of gw_test: 0.83583\n",
      "260.8024691358024 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97c8c9aaf08413593ec5719905bcfef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import copy\n",
    "\n",
    "torch.manual_seed(42)\n",
    "space = {\n",
    "    'lr': [1e-2], #np.linspace(1e-4, 1e-2, 4, endpoint=True),\n",
    "    'dropout':[0, 0.2,.4],\n",
    "    'block_size':[2, 4, 6],\n",
    "    'n_embd':[16, 32, 64],\n",
    "    'num_heads':[2, 4, 8],\n",
    "}\n",
    "param_grid = ParameterGrid(space)\n",
    "\n",
    "best_hyper_params = None\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 2\n",
    "i = 0\n",
    "for params in tqdm(param_grid.__iter__()):\n",
    "    lr = params[\"lr\"]\n",
    "    dropout = params[\"dropout\"]\n",
    "    block_size = params[\"block_size\"]\n",
    "    n_embd = params[\"n_embd\"]\n",
    "    num_heads = params[\"num_heads\"]\n",
    "    \n",
    "    model = TransformerModel(len(FEATURES), n_embd, num_heads, dropout, block_size).to(device)\n",
    "    models = []\n",
    "    optim= torch.optim.Adam(model.parameters(), lr = lr, weight_decay=wd)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    last_val_loss = None\n",
    "    val_losses = []\n",
    "    never_breaked = True\n",
    "    for epoch in range(100):#5\n",
    "        for i, (x,y) in tqdm(enumerate(batch_loader[TRAIN])):\n",
    "            model.train()\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            logits, logits_mask = model(x)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(logits[logits_mask].squeeze(-1), y[logits_mask], pos_weight=torch.tensor(WEIGHT))\n",
    "                \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        losses = evaluate_loss_sets(model)\n",
    "        val_losses.append(losses[VAL])\n",
    "        models.append(copy.deepcopy(model))\n",
    "        print(val_losses)\n",
    "        if len(val_losses) >= patience and all(list(map(lambda l: losses[VAL] >= l, val_losses[-patience:]))):\n",
    "            print(f\"Break at {epoch}\")\n",
    "            never_breaked = False\n",
    "            model = models[-2]\n",
    "            break\n",
    "    if never_breaked:\n",
    "        print(\"Never breaked with params\")\n",
    "        print(params)\n",
    "    evaluate_auroc_sets(model)\n",
    "    if val_losses[-1]<= best_val_loss:\n",
    "        best_val_loss = min(val_losses[-1], best_val_loss)\n",
    "        best_hyper_params = params\n",
    "        print(\"Currently best params: \")\n",
    "        print(best_hyper_params)\n",
    "    i+=1\n",
    "    print(f\"{i/324*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c35cc0b-d9db-4b0f-bafd-c002b0dd8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO add layer norm after Blocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
